[2024-10-14 14:41:45,837][root][INFO] - 

[2024-10-14 14:41:45,837][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:41:45,837][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs
[2024-10-14 14:41:45,837][root][INFO] - 

[2024-10-14 14:41:45,837][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:41:52,124][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,125][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,126][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,126][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,128][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,128][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,129][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,129][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,130][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,130][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,131][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,132][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,132][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,133][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,133][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,134][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,134][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,135][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,136][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,136][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,137][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,137][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,138][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,139][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,141][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:41:52,153][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:41:52,349][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:41:52,351][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:41:52,526][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:42:12,543][root][INFO] - 

[2024-10-14 14:42:12,544][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:42:12,544][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs
[2024-10-14 14:42:12,544][root][INFO] - 

[2024-10-14 14:42:12,544][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:42:17,212][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,213][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,213][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,213][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,214][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,214][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,215][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,215][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,216][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,216][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,216][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,217][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,217][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,218][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,218][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,218][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,219][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,219][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,220][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,220][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,221][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,221][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,221][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,222][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,223][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:42:17,230][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:42:17,430][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:42:17,432][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:42:17,610][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:42:21,919][root][INFO] - 

[2024-10-14 14:42:21,919][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 14:42:21,919][root][INFO] - Data Preprocessing
[2024-10-14 14:42:21,919][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 14:42:21,919][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 14:42:21,919][root][INFO] - ㄴ data_remove                False

[2024-10-14 14:42:21,920][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 14:42:21,929][root][INFO] - vocab size              : 51200
[2024-10-14 14:42:21,929][root][INFO] - device                  : gpu
[2024-10-14 14:42:21,929][root][INFO] - random seed             : 1
[2024-10-14 14:42:21,929][root][INFO] - train data size         : 5760
[2024-10-14 14:42:21,929][root][INFO] - max epochs              : 15
[2024-10-14 14:42:21,929][root][INFO] - total steps             : 1350
[2024-10-14 14:42:21,929][root][INFO] - warmup steps            : 135
[2024-10-14 14:42:21,929][root][INFO] - batch size              : 64
[2024-10-14 14:42:21,929][root][INFO] - accumulation steps      : 1
[2024-10-14 14:42:21,930][root][INFO] - optimizer               : adamwscale
[2024-10-14 14:42:21,930][root][INFO] - lr_scheduler            : cosine
[2024-10-14 14:42:21,930][root][INFO] - learning rate           : 0.01
[2024-10-14 14:42:21,930][root][INFO] - max length              : 256

[2024-10-14 14:42:21,930][root][INFO] - LoRA Configuration
[2024-10-14 14:42:21,930][root][INFO] - ㄴ r                    : 32
[2024-10-14 14:42:21,930][root][INFO] - ㄴ alpha                : 128
[2024-10-14 14:42:21,930][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 14:42:21,930][root][INFO] - KOMBO Configuration
[2024-10-14 14:42:21,930][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 14:42:21,930][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 14:42:21,931][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 14:42:21,931][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 14:42:21,931][root][INFO] - ㄴ do_combination       : True
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 14:42:21,931][root][INFO] - 

[2024-10-14 14:42:21,931][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs
[2024-10-14 14:42:21,931][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/ckpt
[2024-10-14 14:42:21,932][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/tb
[2024-10-14 14:42:21,932][root][INFO] - * tb interval   : 10000

[2024-10-14 14:42:21,932][root][INFO] - 

[2024-10-14 14:42:21,932][root][INFO] - Start the Training !
[2024-10-14 14:42:21,935][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 14:44:20,042][root][INFO] - 

[2024-10-14 14:44:20,042][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:44:20,042][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:44:20,042][root][INFO] - 

[2024-10-14 14:44:20,042][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:44:24,925][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,926][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,926][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,927][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,927][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,928][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,928][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,929][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,929][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,929][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,930][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,930][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,931][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,931][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,932][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,932][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,933][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,933][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,933][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,934][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,934][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,935][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,935][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,936][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,937][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:44:24,941][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:44:25,149][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:44:25,152][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:44:25,316][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:44:28,568][root][INFO] - 

[2024-10-14 14:44:28,569][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 14:44:28,569][root][INFO] - Data Preprocessing
[2024-10-14 14:44:28,569][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 14:44:28,569][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 14:44:28,569][root][INFO] - ㄴ data_remove                False

[2024-10-14 14:44:28,569][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 14:44:28,577][root][INFO] - vocab size              : 51200
[2024-10-14 14:44:28,578][root][INFO] - device                  : gpu
[2024-10-14 14:44:28,578][root][INFO] - random seed             : 1
[2024-10-14 14:44:28,578][root][INFO] - train data size         : 5760
[2024-10-14 14:44:28,578][root][INFO] - max epochs              : 15
[2024-10-14 14:44:28,578][root][INFO] - total steps             : 1350
[2024-10-14 14:44:28,578][root][INFO] - warmup steps            : 135
[2024-10-14 14:44:28,578][root][INFO] - batch size              : 64
[2024-10-14 14:44:28,578][root][INFO] - accumulation steps      : 1
[2024-10-14 14:44:28,578][root][INFO] - optimizer               : adamwscale
[2024-10-14 14:44:28,578][root][INFO] - lr_scheduler            : cosine
[2024-10-14 14:44:28,578][root][INFO] - learning rate           : 0.01
[2024-10-14 14:44:28,579][root][INFO] - max length              : 256

[2024-10-14 14:44:28,579][root][INFO] - LoRA Configuration
[2024-10-14 14:44:28,579][root][INFO] - ㄴ r                    : 32
[2024-10-14 14:44:28,579][root][INFO] - ㄴ alpha                : 128
[2024-10-14 14:44:28,579][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 14:44:28,579][root][INFO] - KOMBO Configuration
[2024-10-14 14:44:28,579][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 14:44:28,579][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 14:44:28,579][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 14:44:28,579][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 14:44:28,580][root][INFO] - ㄴ do_combination       : True
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 14:44:28,580][root][INFO] - 

[2024-10-14 14:44:28,580][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:44:28,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt
[2024-10-14 14:44:28,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/tb
[2024-10-14 14:44:28,580][root][INFO] - * tb interval   : 10000

[2024-10-14 14:44:28,580][root][INFO] - 

[2024-10-14 14:44:28,581][root][INFO] - Start the Training !
[2024-10-14 14:44:28,587][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 14:45:13,851][root][INFO] - 

[2024-10-14 14:45:13,851][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:45:13,851][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:45:13,851][root][INFO] - 

[2024-10-14 14:45:13,851][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:45:16,831][root][INFO] - Step: 90/1350  |  Loss: 2.5073  |  Score: 31.28 [%]  |  Seq Length: 256.0
[2024-10-14 14:45:23,037][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 14:45:23,038][root][INFO] - Score: 70.72 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 14:45:28,547][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 14:45:28,547][root][INFO] - Score: 62.83 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 14:45:28,549][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 14:45:28,550][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 14:45:36,423][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,424][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,424][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,425][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,425][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,425][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,426][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,426][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,427][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,427][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,428][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,428][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,429][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,429][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,429][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,430][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,430][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,431][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,431][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,432][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,432][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,432][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,433][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,433][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,435][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 14:45:36,439][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:45:36,641][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:45:36,643][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 14:45:36,827][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:45:44,626][root][INFO] - 

[2024-10-14 14:45:44,626][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:45:44,626][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 14:45:44,626][root][INFO] - 

[2024-10-14 14:45:44,627][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:46:02,717][root][INFO] - 

[2024-10-14 14:46:02,717][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:46:02,717][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:46:02,717][root][INFO] - 

[2024-10-14 14:46:02,718][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:46:09,303][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,304][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,305][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,305][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,306][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,306][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,307][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,307][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,308][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,308][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,309][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,309][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,310][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,310][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,311][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,311][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,312][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,312][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,313][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,313][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,314][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,315][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,315][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,316][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,318][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 14:46:09,324][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:46:09,555][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:46:09,558][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 14:46:09,744][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:46:16,986][root][INFO] - Step: 180/1350  |  Loss: 1.2407  |  Score: 64.58 [%]  |  Seq Length: 256.0
[2024-10-14 14:46:18,072][root][INFO] - 

[2024-10-14 14:46:18,072][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:46:18,072][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 14:46:18,072][root][INFO] - 

[2024-10-14 14:46:18,073][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:46:23,270][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 14:46:23,270][root][INFO] - Score: 76.63 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 14:46:28,990][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 14:46:28,991][root][INFO] - Score: 68.81 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 14:46:28,992][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 14:46:28,993][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 14:46:41,295][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,295][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,296][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,296][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,297][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,297][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,298][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,298][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,299][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,299][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,300][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,300][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,301][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,301][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,302][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,302][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,303][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,303][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,304][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,304][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,305][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,305][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,306][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,306][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,308][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 14:46:41,312][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:46:41,509][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:46:41,511][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 14:46:41,700][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:47:16,870][root][INFO] - Step: 270/1350  |  Loss: 1.0314  |  Score: 70.38 [%]  |  Seq Length: 256.0
[2024-10-14 14:47:23,051][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 14:47:23,051][root][INFO] - Score: 77.01 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 14:47:28,621][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 14:47:28,621][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 14:47:28,622][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 14:47:28,623][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 14:48:08,263][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,264][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,264][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,265][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,265][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,265][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,266][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,266][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,267][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,267][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,267][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,268][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,268][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,269][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,269][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,269][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,270][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,270][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,271][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,271][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,272][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,272][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,272][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,273][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,274][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 14:48:08,279][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:48:08,478][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:48:08,480][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 14:48:08,703][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:48:16,247][root][INFO] - Step: 360/1350  |  Loss: 0.8744  |  Score: 74.83 [%]  |  Seq Length: 256.0
[2024-10-14 14:48:16,773][root][INFO] - 

[2024-10-14 14:48:16,774][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:48:16,774][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 14:48:16,774][root][INFO] - 

[2024-10-14 14:48:16,774][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:48:22,335][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 14:48:22,336][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 14:48:27,902][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 14:48:27,902][root][INFO] - Score: 71.12 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 14:48:27,904][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 14:48:27,905][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 14:49:16,334][root][INFO] - Step: 450/1350  |  Loss: 0.7951  |  Score: 78.43 [%]  |  Seq Length: 256.0
[2024-10-14 14:49:22,501][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 14:49:22,501][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 14:49:28,021][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 14:49:28,021][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 14:49:28,022][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 14:49:28,023][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 14:50:15,967][root][INFO] - Step: 540/1350  |  Loss: 0.6585  |  Score: 81.06 [%]  |  Seq Length: 256.0
[2024-10-14 14:50:19,065][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,066][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,066][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,067][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,067][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,068][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,068][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,068][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,069][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,069][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,070][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,070][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,071][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,071][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,071][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,072][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,072][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,073][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,073][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,073][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,074][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,074][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,075][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,075][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,077][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 14:50:19,081][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:50:19,281][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:50:19,283][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 14:50:19,514][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:50:22,177][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 14:50:22,177][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 14:50:27,571][root][INFO] - 

[2024-10-14 14:50:27,571][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:50:27,571][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 14:50:27,571][root][INFO] - 

[2024-10-14 14:50:27,571][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:50:27,818][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 14:50:27,818][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 14:50:27,821][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 14:51:15,968][root][INFO] - Step: 630/1350  |  Loss: 0.5899  |  Score: 83.37 [%]  |  Seq Length: 256.0
[2024-10-14 14:51:22,170][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 14:51:22,170][root][INFO] - Score: 79.15 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 14:51:27,719][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 14:51:27,720][root][INFO] - Score: 71.80 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 14:51:27,721][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 14:51:27,722][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 14:52:16,116][root][INFO] - Step: 720/1350  |  Loss: 0.5440  |  Score: 85.10 [%]  |  Seq Length: 256.0
[2024-10-14 14:52:22,269][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 14:52:22,269][root][INFO] - Score: 78.00 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 14:52:27,806][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 14:52:27,806][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 14:52:27,808][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 14:52:31,741][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,742][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,743][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,743][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,744][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,744][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,745][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,745][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,746][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,746][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,747][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,747][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,748][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,748][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,749][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,749][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,750][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,750][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,751][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,751][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,752][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,752][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,753][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,753][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,755][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 14:52:31,760][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:52:31,962][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:52:31,964][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 14:52:32,207][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:53:15,596][root][INFO] - Step: 810/1350  |  Loss: 0.4735  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 14:53:21,739][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 14:53:21,739][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 14:53:27,210][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 14:53:27,210][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 5.47 [s]
[2024-10-14 14:53:27,213][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 14:54:14,877][root][INFO] - Step: 900/1350  |  Loss: 0.4182  |  Score: 87.59 [%]  |  Seq Length: 256.0
[2024-10-14 14:54:20,926][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 14:54:20,926][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 14:54:26,450][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 14:54:26,451][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 14:54:26,453][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 14:55:14,068][root][INFO] - Step: 990/1350  |  Loss: 0.3806  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-14 14:55:20,210][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 14:55:20,210][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 14:55:25,789][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 14:55:25,789][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 14:55:25,790][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-14 14:55:25,791][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 14:56:13,166][root][INFO] - Step: 1080/1350  |  Loss: 0.3530  |  Score: 89.42 [%]  |  Seq Length: 256.0
[2024-10-14 14:56:19,125][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 14:56:19,125][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 5.96 [s]
[2024-10-14 14:56:24,507][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 14:56:24,507][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 5.38 [s]
[2024-10-14 14:56:24,509][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 14:57:11,887][root][INFO] - Step: 1170/1350  |  Loss: 0.3506  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 14:57:17,814][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 14:57:17,815][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 5.92 [s]
[2024-10-14 14:57:23,242][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 14:57:23,242][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.43 [s]
[2024-10-14 14:57:23,244][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 14:58:10,900][root][INFO] - Step: 1260/1350  |  Loss: 0.3270  |  Score: 90.01 [%]  |  Seq Length: 256.0
[2024-10-14 14:58:16,990][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 14:58:16,991][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 14:58:22,518][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 14:58:22,518][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 14:58:22,521][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 14:59:10,306][root][INFO] - Step: 1350/1350  |  Loss: 0.3227  |  Score: 90.36 [%]  |  Seq Length: 256.0
[2024-10-14 14:59:16,428][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 14:59:16,428][root][INFO] - Score: 79.37 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 14:59:21,994][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 14:59:21,994][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 14:59:21,995][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 14:59:21,995][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 14:59:21,995][root][INFO] - - Epoch: 15
[2024-10-14 14:59:21,995][root][INFO] - - DEV score: 79.37 [%]
[2024-10-14 14:59:21,995][root][INFO] - - TEST score: 72.09 [%]
[2024-10-14 14:59:21,997][root][INFO] - Fine-tuning is done!
[2024-10-14 14:59:22,000][root][INFO] - 

[2024-10-14 14:59:22,000][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:59:22,000][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs
[2024-10-14 14:59:22,000][root][INFO] - 

[2024-10-14 14:59:22,000][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 14:59:25,260][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,260][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,261][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,262][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,262][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,263][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,263][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,264][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,265][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,265][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,265][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,266][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,266][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,267][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,267][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,268][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,268][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,269][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,269][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,270][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,270][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,271][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,271][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,272][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,273][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:59:25,473][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:59:25,476][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:59:25,477][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:59:25,654][root][INFO] - 

[2024-10-14 14:59:25,654][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 14:59:25,654][root][INFO] - Data Preprocessing
[2024-10-14 14:59:25,654][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 14:59:25,654][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 14:59:25,654][root][INFO] - ㄴ data_remove                False

[2024-10-14 14:59:25,654][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 14:59:25,662][root][INFO] - vocab size              : 51200
[2024-10-14 14:59:25,662][root][INFO] - device                  : gpu
[2024-10-14 14:59:25,662][root][INFO] - random seed             : 1
[2024-10-14 14:59:25,662][root][INFO] - train data size         : 5760
[2024-10-14 14:59:25,662][root][INFO] - max epochs              : 15
[2024-10-14 14:59:25,662][root][INFO] - total steps             : 1350
[2024-10-14 14:59:25,662][root][INFO] - warmup steps            : 135
[2024-10-14 14:59:25,663][root][INFO] - batch size              : 64
[2024-10-14 14:59:25,663][root][INFO] - accumulation steps      : 1
[2024-10-14 14:59:25,663][root][INFO] - optimizer               : adamwscale
[2024-10-14 14:59:25,663][root][INFO] - lr_scheduler            : cosine
[2024-10-14 14:59:25,663][root][INFO] - learning rate           : 0.02
[2024-10-14 14:59:25,663][root][INFO] - max length              : 256

[2024-10-14 14:59:25,663][root][INFO] - LoRA Configuration
[2024-10-14 14:59:25,663][root][INFO] - ㄴ r                    : 32
[2024-10-14 14:59:25,663][root][INFO] - ㄴ alpha                : 128
[2024-10-14 14:59:25,663][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 14:59:25,663][root][INFO] - KOMBO Configuration
[2024-10-14 14:59:25,664][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 14:59:25,664][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 14:59:25,664][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 14:59:25,664][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 14:59:25,664][root][INFO] - ㄴ do_combination       : True
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 14:59:25,665][root][INFO] - 

[2024-10-14 14:59:25,665][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs
[2024-10-14 14:59:25,665][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/ckpt
[2024-10-14 14:59:25,665][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/tb
[2024-10-14 14:59:25,665][root][INFO] - * tb interval   : 10000

[2024-10-14 14:59:25,665][root][INFO] - 

[2024-10-14 14:59:25,665][root][INFO] - Start the Training !
[2024-10-14 14:59:25,668][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:00:13,930][root][INFO] - Step: 90/1350  |  Loss: 2.0438  |  Score: 42.57 [%]  |  Seq Length: 256.0
[2024-10-14 15:00:20,126][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:00:20,126][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 15:00:25,680][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:00:25,680][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 15:00:25,682][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:00:25,683][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:01:13,654][root][INFO] - Step: 180/1350  |  Loss: 1.1176  |  Score: 68.59 [%]  |  Seq Length: 256.0
[2024-10-14 15:01:19,830][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:01:19,830][root][INFO] - Score: 76.90 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 15:01:25,406][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:01:25,406][root][INFO] - Score: 71.33 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 15:01:25,408][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:01:25,410][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:02:13,496][root][INFO] - Step: 270/1350  |  Loss: 0.9518  |  Score: 73.80 [%]  |  Seq Length: 256.0
[2024-10-14 15:02:19,664][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:02:19,664][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 15:02:25,204][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:02:25,205][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:02:25,206][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:02:25,207][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:03:13,222][root][INFO] - Step: 360/1350  |  Loss: 0.7880  |  Score: 78.92 [%]  |  Seq Length: 256.0
[2024-10-14 15:03:19,496][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:03:19,497][root][INFO] - Score: 78.09 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 15:03:25,158][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:03:25,159][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-14 15:03:25,163][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:04:13,299][root][INFO] - Step: 450/1350  |  Loss: 0.6588  |  Score: 81.87 [%]  |  Seq Length: 256.0
[2024-10-14 15:04:19,504][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:04:19,505][root][INFO] - Score: 78.11 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 15:04:25,116][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:04:25,116][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 15:04:25,119][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:05:13,102][root][INFO] - Step: 540/1350  |  Loss: 0.5402  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-14 15:05:19,357][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:05:19,358][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 15:05:25,011][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:05:25,011][root][INFO] - Score: 69.96 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 15:05:25,014][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:06:12,983][root][INFO] - Step: 630/1350  |  Loss: 0.4341  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-14 15:06:19,098][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:06:19,099][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:06:24,624][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:06:24,624][root][INFO] - Score: 70.39 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 15:06:24,627][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:07:12,222][root][INFO] - Step: 720/1350  |  Loss: 0.3781  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 15:07:18,370][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:07:18,370][root][INFO] - Score: 79.06 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:07:23,867][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:07:23,867][root][INFO] - Score: 70.59 [%]  |  Evaluation Time: 5.49 [s]
[2024-10-14 15:07:23,869][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:08:11,413][root][INFO] - Step: 810/1350  |  Loss: 0.3292  |  Score: 90.54 [%]  |  Seq Length: 256.0
[2024-10-14 15:08:17,445][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:08:17,445][root][INFO] - Score: 77.71 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-14 15:08:22,946][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:08:22,946][root][INFO] - Score: 70.83 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 15:08:22,950][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:09:10,553][root][INFO] - Step: 900/1350  |  Loss: 0.2628  |  Score: 92.09 [%]  |  Seq Length: 256.0
[2024-10-14 15:09:16,610][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:09:16,610][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 15:09:22,130][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:09:22,130][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 15:09:22,132][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:10:09,718][root][INFO] - Step: 990/1350  |  Loss: 0.2322  |  Score: 93.24 [%]  |  Seq Length: 256.0
[2024-10-14 15:10:15,782][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:10:15,782][root][INFO] - Score: 79.01 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:10:21,214][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:10:21,215][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 5.43 [s]
[2024-10-14 15:10:21,217][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:11:08,775][root][INFO] - Step: 1080/1350  |  Loss: 0.2070  |  Score: 93.90 [%]  |  Seq Length: 256.0
[2024-10-14 15:11:14,822][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:11:14,822][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.04 [s]
[2024-10-14 15:11:20,308][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:11:20,308][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 15:11:20,311][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:12:07,876][root][INFO] - Step: 1170/1350  |  Loss: 0.1930  |  Score: 94.23 [%]  |  Seq Length: 256.0
[2024-10-14 15:12:14,025][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:12:14,026][root][INFO] - Score: 78.67 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 15:12:19,608][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:12:19,608][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 15:12:19,611][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:13:07,435][root][INFO] - Step: 1260/1350  |  Loss: 0.1804  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-14 15:13:13,471][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:13:13,472][root][INFO] - Score: 78.84 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-14 15:13:18,914][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:13:18,914][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 5.44 [s]
[2024-10-14 15:13:18,915][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-14 15:13:18,916][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:14:06,315][root][INFO] - Step: 1350/1350  |  Loss: 0.1678  |  Score: 94.86 [%]  |  Seq Length: 256.0
[2024-10-14 15:14:12,434][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:14:12,435][root][INFO] - Score: 79.30 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 15:14:17,987][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:14:17,987][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 15:14:17,989][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 15:14:17,989][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:14:17,989][root][INFO] - - Epoch: 15
[2024-10-14 15:14:17,989][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 15:14:17,989][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 15:14:17,990][root][INFO] - Fine-tuning is done!
[2024-10-14 15:14:17,990][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 15:14:17,991][root][INFO] - - BEST LR: 0.02
[2024-10-14 15:14:17,991][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 15:14:17,991][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 15:14:24,493][root][INFO] - 

[2024-10-14 15:14:24,493][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:14:24,493][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 15:14:24,493][root][INFO] - 

[2024-10-14 15:14:24,493][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 15:14:28,834][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,835][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,835][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,835][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,836][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,836][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,837][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,837][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,838][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,838][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,838][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,839][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,839][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,840][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,840][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,840][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,841][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,841][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,842][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,842][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,843][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,843][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,844][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,844][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,845][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:14:28,849][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 15:14:29,045][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:14:29,047][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:14:29,238][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:14:32,150][root][INFO] - 

[2024-10-14 15:14:32,151][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:14:32,151][root][INFO] - Data Preprocessing
[2024-10-14 15:14:32,151][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:14:32,151][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:14:32,151][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:14:32,151][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:14:32,159][root][INFO] - vocab size              : 51200
[2024-10-14 15:14:32,159][root][INFO] - device                  : gpu
[2024-10-14 15:14:32,159][root][INFO] - random seed             : 2
[2024-10-14 15:14:32,159][root][INFO] - train data size         : 5760
[2024-10-14 15:14:32,159][root][INFO] - max epochs              : 15
[2024-10-14 15:14:32,159][root][INFO] - total steps             : 1350
[2024-10-14 15:14:32,159][root][INFO] - warmup steps            : 135
[2024-10-14 15:14:32,160][root][INFO] - batch size              : 64
[2024-10-14 15:14:32,160][root][INFO] - accumulation steps      : 1
[2024-10-14 15:14:32,160][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:14:32,160][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:14:32,160][root][INFO] - learning rate           : 0.01
[2024-10-14 15:14:32,160][root][INFO] - max length              : 256

[2024-10-14 15:14:32,160][root][INFO] - LoRA Configuration
[2024-10-14 15:14:32,160][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:14:32,160][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:14:32,160][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:14:32,160][root][INFO] - KOMBO Configuration
[2024-10-14 15:14:32,161][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:14:32,161][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:14:32,161][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:14:32,161][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:14:32,161][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:14:32,161][root][INFO] - 

[2024-10-14 15:14:32,162][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 15:14:32,162][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt
[2024-10-14 15:14:32,162][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/tb
[2024-10-14 15:14:32,162][root][INFO] - * tb interval   : 10000

[2024-10-14 15:14:32,162][root][INFO] - 

[2024-10-14 15:14:32,162][root][INFO] - Start the Training !
[2024-10-14 15:14:32,165][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:15:20,888][root][INFO] - Step: 90/1350  |  Loss: 2.0541  |  Score: 36.26 [%]  |  Seq Length: 256.0
[2024-10-14 15:15:27,098][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:15:27,099][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 15:15:32,995][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:15:32,995][root][INFO] - Score: 60.42 [%]  |  Evaluation Time: 5.89 [s]
[2024-10-14 15:15:32,997][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:15:32,998][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:16:21,089][root][INFO] - Step: 180/1350  |  Loss: 1.3146  |  Score: 64.93 [%]  |  Seq Length: 256.0
[2024-10-14 15:16:27,311][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:16:27,312][root][INFO] - Score: 75.98 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 15:16:32,955][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:16:32,955][root][INFO] - Score: 67.24 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 15:16:32,956][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:16:32,958][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:17:20,611][root][INFO] - Step: 270/1350  |  Loss: 1.0223  |  Score: 70.27 [%]  |  Seq Length: 256.0
[2024-10-14 15:17:26,755][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:17:26,756][root][INFO] - Score: 77.93 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:17:32,308][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:17:32,309][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 15:17:32,309][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:17:32,311][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:18:20,135][root][INFO] - Step: 360/1350  |  Loss: 0.8770  |  Score: 75.04 [%]  |  Seq Length: 256.0
[2024-10-14 15:18:26,280][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:18:26,280][root][INFO] - Score: 77.97 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:18:31,813][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:18:31,813][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:18:31,815][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:19:19,383][root][INFO] - Step: 450/1350  |  Loss: 0.7471  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-14 15:19:25,450][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:19:25,450][root][INFO] - Score: 79.34 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:19:30,924][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:19:30,924][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 5.47 [s]
[2024-10-14 15:19:30,925][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 15:19:30,926][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:20:18,902][root][INFO] - Step: 540/1350  |  Loss: 0.6158  |  Score: 82.27 [%]  |  Seq Length: 256.0
[2024-10-14 15:20:24,988][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:20:24,988][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-14 15:20:30,503][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:20:30,503][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:20:30,505][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:21:18,313][root][INFO] - Step: 630/1350  |  Loss: 0.5640  |  Score: 83.65 [%]  |  Seq Length: 256.0
[2024-10-14 15:21:24,401][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:21:24,401][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-14 15:21:29,898][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:21:29,898][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 15:21:29,900][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:22:17,681][root][INFO] - Step: 720/1350  |  Loss: 0.5180  |  Score: 85.66 [%]  |  Seq Length: 256.0
[2024-10-14 15:22:23,781][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:22:23,781][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:22:29,314][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:22:29,315][root][INFO] - Score: 71.89 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:22:29,317][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:23:17,125][root][INFO] - Step: 810/1350  |  Loss: 0.4363  |  Score: 87.48 [%]  |  Seq Length: 256.0
[2024-10-14 15:23:23,192][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:23:23,192][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:23:28,716][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:23:28,716][root][INFO] - Score: 71.63 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 15:23:28,718][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:24:16,527][root][INFO] - Step: 900/1350  |  Loss: 0.3983  |  Score: 88.50 [%]  |  Seq Length: 256.0
[2024-10-14 15:24:22,688][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:24:22,688][root][INFO] - Score: 78.40 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 15:24:28,252][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:24:28,252][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 15:24:28,254][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:25:16,103][root][INFO] - Step: 990/1350  |  Loss: 0.3682  |  Score: 89.09 [%]  |  Seq Length: 256.0
[2024-10-14 15:25:22,288][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:25:22,288][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 15:25:27,747][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:25:27,747][root][INFO] - Score: 70.98 [%]  |  Evaluation Time: 5.46 [s]
[2024-10-14 15:25:27,749][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:26:15,445][root][INFO] - Step: 1080/1350  |  Loss: 0.3299  |  Score: 90.28 [%]  |  Seq Length: 256.0
[2024-10-14 15:26:21,543][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:26:21,543][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:26:27,057][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:26:27,057][root][INFO] - Score: 71.50 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:26:27,059][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:27:14,572][root][INFO] - Step: 1170/1350  |  Loss: 0.3276  |  Score: 90.29 [%]  |  Seq Length: 256.0
[2024-10-14 15:27:20,707][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:27:20,707][root][INFO] - Score: 78.51 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 15:27:26,274][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:27:26,275][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 15:27:26,277][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:28:14,150][root][INFO] - Step: 1260/1350  |  Loss: 0.3079  |  Score: 90.56 [%]  |  Seq Length: 256.0
[2024-10-14 15:28:20,273][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:28:20,274][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 15:28:25,906][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:28:25,906][root][INFO] - Score: 71.46 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 15:28:25,908][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:29:13,568][root][INFO] - Step: 1350/1350  |  Loss: 0.3049  |  Score: 90.66 [%]  |  Seq Length: 256.0
[2024-10-14 15:29:19,710][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:29:19,710][root][INFO] - Score: 78.18 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:29:25,392][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:29:25,392][root][INFO] - Score: 71.20 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:29:25,393][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:29:25,393][root][INFO] - - Epoch: 5
[2024-10-14 15:29:25,393][root][INFO] - - DEV score: 79.34 [%]
[2024-10-14 15:29:25,393][root][INFO] - - TEST score: 71.45 [%]
[2024-10-14 15:29:25,394][root][INFO] - Fine-tuning is done!
[2024-10-14 15:29:25,398][root][INFO] - 

[2024-10-14 15:29:25,399][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:29:25,399][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs
[2024-10-14 15:29:25,399][root][INFO] - 

[2024-10-14 15:29:25,399][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 15:29:28,650][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,650][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,651][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,652][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,652][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,653][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,653][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,654][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,654][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,655][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,655][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,656][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,656][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,657][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,658][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,658][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,665][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,666][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,666][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,667][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,667][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,668][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,669][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,669][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,672][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:29:28,885][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:29:28,888][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:29:28,889][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:29:29,075][root][INFO] - 

[2024-10-14 15:29:29,075][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:29:29,075][root][INFO] - Data Preprocessing
[2024-10-14 15:29:29,075][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:29:29,076][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:29:29,076][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:29:29,076][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:29:29,083][root][INFO] - vocab size              : 51200
[2024-10-14 15:29:29,083][root][INFO] - device                  : gpu
[2024-10-14 15:29:29,084][root][INFO] - random seed             : 2
[2024-10-14 15:29:29,084][root][INFO] - train data size         : 5760
[2024-10-14 15:29:29,084][root][INFO] - max epochs              : 15
[2024-10-14 15:29:29,084][root][INFO] - total steps             : 1350
[2024-10-14 15:29:29,084][root][INFO] - warmup steps            : 135
[2024-10-14 15:29:29,084][root][INFO] - batch size              : 64
[2024-10-14 15:29:29,084][root][INFO] - accumulation steps      : 1
[2024-10-14 15:29:29,084][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:29:29,084][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:29:29,084][root][INFO] - learning rate           : 0.02
[2024-10-14 15:29:29,084][root][INFO] - max length              : 256

[2024-10-14 15:29:29,085][root][INFO] - LoRA Configuration
[2024-10-14 15:29:29,085][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:29:29,085][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:29:29,085][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:29:29,085][root][INFO] - KOMBO Configuration
[2024-10-14 15:29:29,085][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:29:29,085][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:29:29,085][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:29:29,085][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:29:29,085][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:29:29,086][root][INFO] - 

[2024-10-14 15:29:29,086][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs
[2024-10-14 15:29:29,086][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/ckpt
[2024-10-14 15:29:29,086][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/tb
[2024-10-14 15:29:29,086][root][INFO] - * tb interval   : 10000

[2024-10-14 15:29:29,086][root][INFO] - 

[2024-10-14 15:29:29,087][root][INFO] - Start the Training !
[2024-10-14 15:29:29,089][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:30:16,597][root][INFO] - Step: 90/1350  |  Loss: 1.8191  |  Score: 45.29 [%]  |  Seq Length: 256.0
[2024-10-14 15:30:22,666][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:30:22,666][root][INFO] - Score: 74.54 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 15:30:28,165][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:30:28,165][root][INFO] - Score: 64.35 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 15:30:28,166][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:30:28,167][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:31:15,657][root][INFO] - Step: 180/1350  |  Loss: 1.1164  |  Score: 67.84 [%]  |  Seq Length: 256.0
[2024-10-14 15:31:21,721][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:31:21,721][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:31:27,306][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:31:27,306][root][INFO] - Score: 67.89 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 15:31:27,307][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:31:27,308][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:32:14,894][root][INFO] - Step: 270/1350  |  Loss: 0.9153  |  Score: 74.49 [%]  |  Seq Length: 256.0
[2024-10-14 15:32:21,066][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:32:21,067][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 15:32:26,692][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:32:26,693][root][INFO] - Score: 70.82 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 15:32:26,694][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:32:26,695][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:33:14,479][root][INFO] - Step: 360/1350  |  Loss: 0.7498  |  Score: 79.16 [%]  |  Seq Length: 256.0
[2024-10-14 15:33:20,592][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:33:20,593][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:33:26,223][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:33:26,223][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 15:33:26,225][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:34:14,126][root][INFO] - Step: 450/1350  |  Loss: 0.6405  |  Score: 82.18 [%]  |  Seq Length: 256.0
[2024-10-14 15:34:20,354][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:34:20,355][root][INFO] - Score: 78.36 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 15:34:26,034][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:34:26,034][root][INFO] - Score: 69.69 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:34:26,036][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:35:13,661][root][INFO] - Step: 540/1350  |  Loss: 0.5123  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 15:35:19,778][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:35:19,778][root][INFO] - Score: 76.26 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:35:25,311][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:35:25,311][root][INFO] - Score: 69.61 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:35:25,313][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:36:13,087][root][INFO] - Step: 630/1350  |  Loss: 0.4074  |  Score: 88.00 [%]  |  Seq Length: 256.0
[2024-10-14 15:36:19,323][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:36:19,324][root][INFO] - Score: 77.46 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 15:36:25,009][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:36:25,009][root][INFO] - Score: 69.58 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:36:25,012][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:37:12,680][root][INFO] - Step: 720/1350  |  Loss: 0.3572  |  Score: 89.95 [%]  |  Seq Length: 256.0
[2024-10-14 15:37:18,838][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:37:18,838][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 15:37:24,352][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:37:24,352][root][INFO] - Score: 70.79 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:37:24,354][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:38:12,132][root][INFO] - Step: 810/1350  |  Loss: 0.2877  |  Score: 91.92 [%]  |  Seq Length: 256.0
[2024-10-14 15:38:18,334][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:38:18,335][root][INFO] - Score: 77.69 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 15:38:23,878][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:38:23,878][root][INFO] - Score: 70.37 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:38:23,880][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:39:11,502][root][INFO] - Step: 900/1350  |  Loss: 0.2515  |  Score: 92.90 [%]  |  Seq Length: 256.0
[2024-10-14 15:39:17,550][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:39:17,550][root][INFO] - Score: 77.30 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 15:39:23,028][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:39:23,028][root][INFO] - Score: 69.35 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 15:39:23,030][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:40:10,702][root][INFO] - Step: 990/1350  |  Loss: 0.2210  |  Score: 93.44 [%]  |  Seq Length: 256.0
[2024-10-14 15:40:16,921][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:40:16,921][root][INFO] - Score: 78.83 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 15:40:22,596][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:40:22,596][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 15:40:22,598][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:41:10,189][root][INFO] - Step: 1080/1350  |  Loss: 0.1857  |  Score: 94.43 [%]  |  Seq Length: 256.0
[2024-10-14 15:41:16,329][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:41:16,329][root][INFO] - Score: 78.58 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:41:21,897][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:41:21,898][root][INFO] - Score: 69.91 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 15:41:21,900][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:42:09,673][root][INFO] - Step: 1170/1350  |  Loss: 0.1870  |  Score: 94.50 [%]  |  Seq Length: 256.0
[2024-10-14 15:42:15,893][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:42:15,894][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 15:42:21,580][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:42:21,580][root][INFO] - Score: 69.71 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:42:21,582][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:43:09,330][root][INFO] - Step: 1260/1350  |  Loss: 0.1734  |  Score: 94.72 [%]  |  Seq Length: 256.0
[2024-10-14 15:43:15,400][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:43:15,400][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 15:43:20,933][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:43:20,934][root][INFO] - Score: 69.90 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:43:20,936][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:44:08,507][root][INFO] - Step: 1350/1350  |  Loss: 0.1596  |  Score: 95.08 [%]  |  Seq Length: 256.0
[2024-10-14 15:44:14,756][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:44:14,757][root][INFO] - Score: 78.07 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 15:44:20,358][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:44:20,358][root][INFO] - Score: 69.29 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 15:44:20,359][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:44:20,359][root][INFO] - - Epoch: 3
[2024-10-14 15:44:20,360][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 15:44:20,360][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 15:44:20,361][root][INFO] - Fine-tuning is done!
[2024-10-14 15:44:20,361][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 15:44:20,361][root][INFO] - - BEST LR: 0.02
[2024-10-14 15:44:20,361][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 15:44:20,361][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 15:44:26,910][root][INFO] - 

[2024-10-14 15:44:26,911][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:44:26,911][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 15:44:26,911][root][INFO] - 

[2024-10-14 15:44:26,911][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 15:44:31,424][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,424][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,425][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,425][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,425][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,426][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,426][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,427][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,427][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,428][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,428][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,429][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,429][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,430][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,430][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,430][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,431][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,431][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,432][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,432][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,433][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,433][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,434][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,434][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,436][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:44:31,439][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 15:44:31,634][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:44:31,636][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:44:31,820][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:44:34,930][root][INFO] - 

[2024-10-14 15:44:34,931][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:44:34,931][root][INFO] - Data Preprocessing
[2024-10-14 15:44:34,931][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:44:34,931][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:44:34,931][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:44:34,931][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:44:34,941][root][INFO] - vocab size              : 51200
[2024-10-14 15:44:34,941][root][INFO] - device                  : gpu
[2024-10-14 15:44:34,941][root][INFO] - random seed             : 3
[2024-10-14 15:44:34,941][root][INFO] - train data size         : 5760
[2024-10-14 15:44:34,941][root][INFO] - max epochs              : 15
[2024-10-14 15:44:34,941][root][INFO] - total steps             : 1350
[2024-10-14 15:44:34,942][root][INFO] - warmup steps            : 135
[2024-10-14 15:44:34,942][root][INFO] - batch size              : 64
[2024-10-14 15:44:34,942][root][INFO] - accumulation steps      : 1
[2024-10-14 15:44:34,942][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:44:34,942][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:44:34,942][root][INFO] - learning rate           : 0.01
[2024-10-14 15:44:34,942][root][INFO] - max length              : 256

[2024-10-14 15:44:34,942][root][INFO] - LoRA Configuration
[2024-10-14 15:44:34,942][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:44:34,942][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:44:34,942][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:44:34,942][root][INFO] - KOMBO Configuration
[2024-10-14 15:44:34,943][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:44:34,943][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:44:34,943][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:44:34,943][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:44:34,943][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:44:34,944][root][INFO] - 

[2024-10-14 15:44:34,944][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 15:44:34,944][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt
[2024-10-14 15:44:34,944][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/tb
[2024-10-14 15:44:34,944][root][INFO] - * tb interval   : 10000

[2024-10-14 15:44:34,944][root][INFO] - 

[2024-10-14 15:44:34,944][root][INFO] - Start the Training !
[2024-10-14 15:44:34,947][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:45:23,124][root][INFO] - Step: 90/1350  |  Loss: 2.2949  |  Score: 31.76 [%]  |  Seq Length: 256.0
[2024-10-14 15:45:29,388][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:45:29,388][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 15:45:34,999][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:45:34,999][root][INFO] - Score: 62.43 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 15:45:35,000][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:45:35,001][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:46:22,683][root][INFO] - Step: 180/1350  |  Loss: 1.1927  |  Score: 65.08 [%]  |  Seq Length: 256.0
[2024-10-14 15:46:28,882][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:46:28,882][root][INFO] - Score: 76.18 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 15:46:34,551][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:46:34,551][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 15:46:34,553][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:46:34,554][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:47:22,099][root][INFO] - Step: 270/1350  |  Loss: 1.0312  |  Score: 70.51 [%]  |  Seq Length: 256.0
[2024-10-14 15:47:28,206][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:47:28,206][root][INFO] - Score: 77.05 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:47:33,803][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:47:33,804][root][INFO] - Score: 68.79 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 15:47:33,804][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:47:33,806][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:48:21,550][root][INFO] - Step: 360/1350  |  Loss: 0.9194  |  Score: 74.60 [%]  |  Seq Length: 256.0
[2024-10-14 15:48:27,811][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:48:27,811][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 15:48:33,465][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:48:33,465][root][INFO] - Score: 71.35 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 15:48:33,467][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 15:48:33,468][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:49:21,489][root][INFO] - Step: 450/1350  |  Loss: 0.7997  |  Score: 77.85 [%]  |  Seq Length: 256.0
[2024-10-14 15:49:27,582][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:49:27,583][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 15:49:33,128][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:49:33,128][root][INFO] - Score: 71.53 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:49:33,130][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 15:49:33,131][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:50:20,308][root][INFO] - Step: 540/1350  |  Loss: 0.6629  |  Score: 80.50 [%]  |  Seq Length: 256.0
[2024-10-14 15:50:26,400][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:50:26,400][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 15:50:31,960][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:50:31,960][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 15:50:31,961][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 15:50:31,962][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:51:19,620][root][INFO] - Step: 630/1350  |  Loss: 0.6011  |  Score: 83.08 [%]  |  Seq Length: 256.0
[2024-10-14 15:51:25,803][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:51:25,804][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 15:51:31,297][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:51:31,297][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.49 [s]
[2024-10-14 15:51:31,298][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 15:51:31,299][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:52:18,834][root][INFO] - Step: 720/1350  |  Loss: 0.5142  |  Score: 84.76 [%]  |  Seq Length: 256.0
[2024-10-14 15:52:24,935][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:52:24,935][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:52:30,450][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:52:30,450][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:52:30,451][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-14 15:52:30,453][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:53:18,134][root][INFO] - Step: 810/1350  |  Loss: 0.4585  |  Score: 86.44 [%]  |  Seq Length: 256.0
[2024-10-14 15:53:24,329][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:53:24,329][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 15:53:29,875][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:53:29,875][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:53:29,878][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:54:17,424][root][INFO] - Step: 900/1350  |  Loss: 0.4325  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-14 15:54:23,460][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:54:23,460][root][INFO] - Score: 78.37 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-14 15:54:28,947][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:54:28,947][root][INFO] - Score: 71.26 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 15:54:28,949][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:55:16,679][root][INFO] - Step: 990/1350  |  Loss: 0.3816  |  Score: 88.82 [%]  |  Seq Length: 256.0
[2024-10-14 15:55:22,800][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:55:22,800][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 15:55:28,392][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:55:28,392][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-14 15:55:28,394][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:56:16,094][root][INFO] - Step: 1080/1350  |  Loss: 0.3515  |  Score: 89.60 [%]  |  Seq Length: 256.0
[2024-10-14 15:56:22,203][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:56:22,203][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:56:27,716][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:56:27,716][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:56:27,718][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:57:15,704][root][INFO] - Step: 1170/1350  |  Loss: 0.3390  |  Score: 89.75 [%]  |  Seq Length: 256.0
[2024-10-14 15:57:21,883][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:57:21,883][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 15:57:27,420][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:57:27,420][root][INFO] - Score: 71.90 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:57:27,422][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:58:15,168][root][INFO] - Step: 1260/1350  |  Loss: 0.3323  |  Score: 89.91 [%]  |  Seq Length: 256.0
[2024-10-14 15:58:21,485][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:58:21,486][root][INFO] - Score: 78.93 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 15:58:27,024][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:58:27,025][root][INFO] - Score: 70.96 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:58:27,027][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:59:14,330][root][INFO] - Step: 1350/1350  |  Loss: 0.3222  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-14 15:59:20,404][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:59:20,404][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 15:59:25,937][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:59:25,937][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:59:25,938][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:59:25,938][root][INFO] - - Epoch: 8
[2024-10-14 15:59:25,938][root][INFO] - - DEV score: 79.59 [%]
[2024-10-14 15:59:25,938][root][INFO] - - TEST score: 72.16 [%]
[2024-10-14 15:59:25,939][root][INFO] - Fine-tuning is done!
[2024-10-14 15:59:25,943][root][INFO] - 

[2024-10-14 15:59:25,943][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:59:25,943][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs
[2024-10-14 15:59:25,943][root][INFO] - 

[2024-10-14 15:59:25,944][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 15:59:29,371][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,371][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,372][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,372][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,373][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,374][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,375][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,375][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,376][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,376][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,377][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,377][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,378][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,378][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,379][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,379][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,380][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,380][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,381][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,381][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,382][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,383][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,383][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,384][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,386][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:59:29,593][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:59:29,595][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:59:29,597][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:59:29,707][root][INFO] - 

[2024-10-14 15:59:29,707][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:59:29,708][root][INFO] - Data Preprocessing
[2024-10-14 15:59:29,708][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:59:29,708][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:59:29,708][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:59:29,708][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:59:29,715][root][INFO] - vocab size              : 51200
[2024-10-14 15:59:29,715][root][INFO] - device                  : gpu
[2024-10-14 15:59:29,715][root][INFO] - random seed             : 3
[2024-10-14 15:59:29,715][root][INFO] - train data size         : 5760
[2024-10-14 15:59:29,716][root][INFO] - max epochs              : 15
[2024-10-14 15:59:29,716][root][INFO] - total steps             : 1350
[2024-10-14 15:59:29,716][root][INFO] - warmup steps            : 135
[2024-10-14 15:59:29,716][root][INFO] - batch size              : 64
[2024-10-14 15:59:29,716][root][INFO] - accumulation steps      : 1
[2024-10-14 15:59:29,716][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:59:29,716][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:59:29,716][root][INFO] - learning rate           : 0.02
[2024-10-14 15:59:29,716][root][INFO] - max length              : 256

[2024-10-14 15:59:29,716][root][INFO] - LoRA Configuration
[2024-10-14 15:59:29,716][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:59:29,716][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:59:29,717][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:59:29,717][root][INFO] - KOMBO Configuration
[2024-10-14 15:59:29,717][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:59:29,717][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:59:29,717][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:59:29,717][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:59:29,717][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:59:29,717][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:59:29,717][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:59:29,718][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:59:29,718][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:59:29,718][root][INFO] - 

[2024-10-14 15:59:29,718][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs
[2024-10-14 15:59:29,718][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/ckpt
[2024-10-14 15:59:29,718][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/tb
[2024-10-14 15:59:29,718][root][INFO] - * tb interval   : 10000

[2024-10-14 15:59:29,718][root][INFO] - 

[2024-10-14 15:59:29,718][root][INFO] - Start the Training !
[2024-10-14 15:59:29,720][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 16:00:17,492][root][INFO] - Step: 90/1350  |  Loss: 2.0019  |  Score: 41.72 [%]  |  Seq Length: 256.0
[2024-10-14 16:00:23,678][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 16:00:23,678][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 16:00:29,192][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 16:00:29,193][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 16:00:29,193][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 16:00:29,194][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 16:01:16,870][root][INFO] - Step: 180/1350  |  Loss: 1.1405  |  Score: 67.73 [%]  |  Seq Length: 256.0
[2024-10-14 16:01:22,975][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 16:01:22,976][root][INFO] - Score: 77.70 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 16:01:28,555][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 16:01:28,555][root][INFO] - Score: 69.25 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 16:01:28,556][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 16:01:28,557][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 16:02:16,249][root][INFO] - Step: 270/1350  |  Loss: 0.9414  |  Score: 73.77 [%]  |  Seq Length: 256.0
[2024-10-14 16:02:22,460][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 16:02:22,460][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 16:02:28,073][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 16:02:28,073][root][INFO] - Score: 70.45 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 16:02:28,074][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 16:02:28,076][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 16:03:15,605][root][INFO] - Step: 360/1350  |  Loss: 0.7943  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-14 16:03:21,702][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 16:03:21,702][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 16:03:27,229][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 16:03:27,229][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 16:03:27,231][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 16:04:14,604][root][INFO] - Step: 450/1350  |  Loss: 0.6279  |  Score: 82.66 [%]  |  Seq Length: 256.0
[2024-10-14 16:04:20,805][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 16:04:20,805][root][INFO] - Score: 76.10 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 16:04:26,389][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 16:04:26,389][root][INFO] - Score: 69.41 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 16:04:26,391][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 16:05:13,949][root][INFO] - Step: 540/1350  |  Loss: 0.5174  |  Score: 85.44 [%]  |  Seq Length: 256.0
[2024-10-14 16:05:20,115][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 16:05:20,115][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 16:05:25,684][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 16:05:25,684][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 16:05:25,686][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 16:06:13,102][root][INFO] - Step: 630/1350  |  Loss: 0.4309  |  Score: 87.86 [%]  |  Seq Length: 256.0
[2024-10-14 16:06:19,239][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 16:06:19,240][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 16:06:24,803][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 16:06:24,803][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 16:06:24,804][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 16:06:24,805][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 16:07:12,515][root][INFO] - Step: 720/1350  |  Loss: 0.3530  |  Score: 89.82 [%]  |  Seq Length: 256.0
[2024-10-14 16:07:18,703][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 16:07:18,703][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 16:07:24,313][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 16:07:24,313][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 16:07:24,315][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 16:08:11,779][root][INFO] - Step: 810/1350  |  Loss: 0.3051  |  Score: 91.04 [%]  |  Seq Length: 256.0
[2024-10-14 16:08:17,865][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 16:08:17,866][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-14 16:08:23,423][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 16:08:23,423][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 16:08:23,425][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 16:09:10,786][root][INFO] - Step: 900/1350  |  Loss: 0.2657  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 16:09:16,991][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 16:09:16,991][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 16:09:22,600][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 16:09:22,601][root][INFO] - Score: 70.10 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 16:09:22,603][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 16:10:10,337][root][INFO] - Step: 990/1350  |  Loss: 0.2278  |  Score: 93.40 [%]  |  Seq Length: 256.0
[2024-10-14 16:10:16,515][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 16:10:16,516][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 16:10:22,065][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 16:10:22,065][root][INFO] - Score: 70.20 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 16:10:22,067][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 16:11:09,797][root][INFO] - Step: 1080/1350  |  Loss: 0.1936  |  Score: 94.11 [%]  |  Seq Length: 256.0
[2024-10-14 16:11:15,945][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 16:11:15,945][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 16:11:21,540][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 16:11:21,540][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-14 16:11:21,542][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 16:12:09,267][root][INFO] - Step: 1170/1350  |  Loss: 0.1861  |  Score: 94.22 [%]  |  Seq Length: 256.0
[2024-10-14 16:12:15,412][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 16:12:15,412][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 16:12:20,929][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 16:12:20,929][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 16:12:20,931][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 16:13:08,587][root][INFO] - Step: 1260/1350  |  Loss: 0.1743  |  Score: 94.73 [%]  |  Seq Length: 256.0
[2024-10-14 16:13:14,871][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 16:13:14,872][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 16:13:20,525][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 16:13:20,525][root][INFO] - Score: 70.50 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 16:13:20,527][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 16:14:08,616][root][INFO] - Step: 1350/1350  |  Loss: 0.1664  |  Score: 95.00 [%]  |  Seq Length: 256.0
[2024-10-14 16:14:14,913][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 16:14:14,914][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 16:14:20,566][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 16:14:20,566][root][INFO] - Score: 70.95 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 16:14:20,567][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 16:14:20,568][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 16:14:20,568][root][INFO] - - Epoch: 15
[2024-10-14 16:14:20,568][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 16:14:20,568][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 16:14:20,569][root][INFO] - Fine-tuning is done!
[2024-10-14 16:14:20,569][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 16:14:20,569][root][INFO] - - BEST LR: 0.02
[2024-10-14 16:14:20,570][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 16:14:20,570][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 17:47:44,735][root][INFO] - 

[2024-10-14 17:47:44,735][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 17:47:44,735][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:47:44,735][root][INFO] - 

[2024-10-14 17:47:44,736][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 17:47:51,249][root][INFO] - 

[2024-10-14 17:47:51,249][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 17:47:51,249][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:47:51,249][root][INFO] - 

[2024-10-14 17:47:51,249][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 17:48:16,162][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,163][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,163][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,164][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,164][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,164][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,165][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,165][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,166][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,166][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,167][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,167][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,167][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,168][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,168][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,169][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,169][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,169][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,170][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,170][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,171][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,171][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,172][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,172][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,174][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 17:48:16,180][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 17:48:16,382][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 17:48:16,385][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 17:48:16,560][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 17:48:19,646][root][INFO] - 

[2024-10-14 17:48:19,646][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 17:48:19,646][root][INFO] - Data Preprocessing
[2024-10-14 17:48:19,646][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 17:48:19,647][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 17:48:19,647][root][INFO] - ㄴ data_remove                False

[2024-10-14 17:48:19,647][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 17:48:19,655][root][INFO] - vocab size              : 51200
[2024-10-14 17:48:19,655][root][INFO] - device                  : gpu
[2024-10-14 17:48:19,655][root][INFO] - random seed             : 1
[2024-10-14 17:48:19,655][root][INFO] - train data size         : 135040
[2024-10-14 17:48:19,655][root][INFO] - max epochs              : 5
[2024-10-14 17:48:19,655][root][INFO] - total steps             : 10550
[2024-10-14 17:48:19,655][root][INFO] - warmup steps            : 1055
[2024-10-14 17:48:19,655][root][INFO] - batch size              : 64
[2024-10-14 17:48:19,655][root][INFO] - accumulation steps      : 1
[2024-10-14 17:48:19,655][root][INFO] - optimizer               : adamwscale
[2024-10-14 17:48:19,656][root][INFO] - lr_scheduler            : cosine
[2024-10-14 17:48:19,656][root][INFO] - learning rate           : 0.01
[2024-10-14 17:48:19,656][root][INFO] - max length              : 256

[2024-10-14 17:48:19,656][root][INFO] - LoRA Configuration
[2024-10-14 17:48:19,656][root][INFO] - ㄴ r                    : 32
[2024-10-14 17:48:19,656][root][INFO] - ㄴ alpha                : 128
[2024-10-14 17:48:19,656][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 17:48:19,656][root][INFO] - KOMBO Configuration
[2024-10-14 17:48:19,656][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 17:48:19,656][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 17:48:19,656][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 17:48:19,657][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 17:48:19,657][root][INFO] - ㄴ do_combination       : True
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 17:48:19,657][root][INFO] - 

[2024-10-14 17:48:19,657][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:48:19,657][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 17:48:19,657][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 17:48:19,658][root][INFO] - * tb interval   : 10000

[2024-10-14 17:48:19,658][root][INFO] - 

[2024-10-14 17:48:19,658][root][INFO] - Start the Training !
[2024-10-14 17:48:19,661][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 17:49:49,077][root][INFO] - 

[2024-10-14 17:49:49,077][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 17:49:49,077][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:49:49,077][root][INFO] - 

[2024-10-14 17:49:49,077][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 17:49:53,899][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,900][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,900][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,901][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,901][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,902][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,902][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,902][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,903][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,903][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,904][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,904][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,905][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,905][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,906][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,906][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,907][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,907][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,908][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,908][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,909][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,909][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,910][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,910][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,912][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 17:49:53,916][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 17:49:54,121][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 17:49:54,123][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 17:49:54,294][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 17:49:56,038][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,039][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,039][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,040][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,040][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,041][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,041][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,042][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,042][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,043][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,044][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,044][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,045][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,045][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,046][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,046][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,047][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,047][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,048][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,048][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,049][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,049][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,050][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,050][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,052][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 17:49:56,057][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 17:49:56,263][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 17:49:56,265][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 17:49:56,480][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 17:49:57,553][root][INFO] - 

[2024-10-14 17:49:57,553][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 17:49:57,553][root][INFO] - Data Preprocessing
[2024-10-14 17:49:57,553][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 17:49:57,554][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 17:49:57,554][root][INFO] - ㄴ data_remove                False

[2024-10-14 17:49:57,554][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 17:49:57,563][root][INFO] - vocab size              : 51200
[2024-10-14 17:49:57,563][root][INFO] - device                  : gpu
[2024-10-14 17:49:57,563][root][INFO] - random seed             : 1
[2024-10-14 17:49:57,563][root][INFO] - train data size         : 5760
[2024-10-14 17:49:57,563][root][INFO] - max epochs              : 15
[2024-10-14 17:49:57,563][root][INFO] - total steps             : 1350
[2024-10-14 17:49:57,563][root][INFO] - warmup steps            : 135
[2024-10-14 17:49:57,564][root][INFO] - batch size              : 64
[2024-10-14 17:49:57,564][root][INFO] - accumulation steps      : 1
[2024-10-14 17:49:57,564][root][INFO] - optimizer               : adamwscale
[2024-10-14 17:49:57,564][root][INFO] - lr_scheduler            : cosine
[2024-10-14 17:49:57,564][root][INFO] - learning rate           : 0.01
[2024-10-14 17:49:57,564][root][INFO] - max length              : 256

[2024-10-14 17:49:57,564][root][INFO] - LoRA Configuration
[2024-10-14 17:49:57,564][root][INFO] - ㄴ r                    : 32
[2024-10-14 17:49:57,564][root][INFO] - ㄴ alpha                : 128
[2024-10-14 17:49:57,565][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 17:49:57,565][root][INFO] - KOMBO Configuration
[2024-10-14 17:49:57,565][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 17:49:57,565][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 17:49:57,565][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 17:49:57,565][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 17:49:57,565][root][INFO] - ㄴ do_combination       : True
[2024-10-14 17:49:57,565][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 17:49:57,566][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 17:49:57,566][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 17:49:57,566][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 17:49:57,566][root][INFO] - 

[2024-10-14 17:49:57,566][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:49:57,566][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 17:49:57,566][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 17:49:57,566][root][INFO] - * tb interval   : 10000

[2024-10-14 17:49:57,566][root][INFO] - 

[2024-10-14 17:49:57,566][root][INFO] - Start the Training !
[2024-10-14 17:49:57,570][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 17:49:59,687][root][INFO] - 

[2024-10-14 17:49:59,688][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-14 17:49:59,688][root][INFO] - Data Preprocessing
[2024-10-14 17:49:59,688][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 17:49:59,688][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 17:49:59,688][root][INFO] - ㄴ data_remove                False

[2024-10-14 17:49:59,688][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 17:49:59,696][root][INFO] - vocab size              : 51200
[2024-10-14 17:49:59,696][root][INFO] - device                  : gpu
[2024-10-14 17:49:59,696][root][INFO] - random seed             : 1
[2024-10-14 17:49:59,696][root][INFO] - train data size         : 942912
[2024-10-14 17:49:59,696][root][INFO] - max epochs              : 5
[2024-10-14 17:49:59,696][root][INFO] - total steps             : 73665
[2024-10-14 17:49:59,696][root][INFO] - warmup steps            : 7366
[2024-10-14 17:49:59,696][root][INFO] - batch size              : 64
[2024-10-14 17:49:59,696][root][INFO] - accumulation steps      : 1
[2024-10-14 17:49:59,696][root][INFO] - optimizer               : adamwscale
[2024-10-14 17:49:59,697][root][INFO] - lr_scheduler            : cosine
[2024-10-14 17:49:59,697][root][INFO] - learning rate           : 0.01
[2024-10-14 17:49:59,697][root][INFO] - max length              : 256

[2024-10-14 17:49:59,697][root][INFO] - LoRA Configuration
[2024-10-14 17:49:59,697][root][INFO] - ㄴ r                    : 32
[2024-10-14 17:49:59,697][root][INFO] - ㄴ alpha                : 128
[2024-10-14 17:49:59,697][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 17:49:59,697][root][INFO] - KOMBO Configuration
[2024-10-14 17:49:59,697][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 17:49:59,697][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 17:49:59,697][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 17:49:59,697][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 17:49:59,698][root][INFO] - ㄴ do_combination       : True
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 17:49:59,698][root][INFO] - 

[2024-10-14 17:49:59,698][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:49:59,698][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 17:49:59,698][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 17:49:59,698][root][INFO] - * tb interval   : 10000

[2024-10-14 17:49:59,699][root][INFO] - 

[2024-10-14 17:49:59,699][root][INFO] - Start the Training !
[2024-10-14 17:49:59,702][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 17:50:45,559][root][INFO] - Step: 90/1350  |  Loss: 2.5073  |  Score: 31.28 [%]  |  Seq Length: 256.0
[2024-10-14 17:50:51,671][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 17:50:51,671][root][INFO] - Score: 70.72 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 17:50:57,235][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 17:50:57,235][root][INFO] - Score: 62.83 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 17:50:57,237][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 17:50:57,238][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 17:51:45,042][root][INFO] - Step: 180/1350  |  Loss: 1.2407  |  Score: 64.58 [%]  |  Seq Length: 256.0
[2024-10-14 17:51:51,329][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 17:51:51,329][root][INFO] - Score: 76.63 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 17:51:56,953][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 17:51:56,953][root][INFO] - Score: 68.81 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 17:51:56,954][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 17:51:56,955][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 17:52:45,205][root][INFO] - Step: 270/1350  |  Loss: 1.0314  |  Score: 70.38 [%]  |  Seq Length: 256.0
[2024-10-14 17:52:51,428][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 17:52:51,428][root][INFO] - Score: 77.01 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 17:52:57,041][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 17:52:57,041][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 17:52:57,043][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 17:52:57,044][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 17:53:45,243][root][INFO] - Step: 360/1350  |  Loss: 0.8744  |  Score: 74.83 [%]  |  Seq Length: 256.0
[2024-10-14 17:53:51,371][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 17:53:51,371][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 17:53:57,004][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 17:53:57,004][root][INFO] - Score: 71.12 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 17:53:57,005][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 17:53:57,007][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 17:54:45,250][root][INFO] - Step: 450/1350  |  Loss: 0.7951  |  Score: 78.43 [%]  |  Seq Length: 256.0
[2024-10-14 17:54:51,435][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 17:54:51,436][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 17:54:57,064][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 17:54:57,064][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 17:54:57,065][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 17:54:57,066][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 17:55:45,162][root][INFO] - Step: 540/1350  |  Loss: 0.6585  |  Score: 81.06 [%]  |  Seq Length: 256.0
[2024-10-14 17:55:51,388][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 17:55:51,388][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 17:55:57,026][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 17:55:57,027][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 17:55:57,029][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 17:56:45,076][root][INFO] - Step: 630/1350  |  Loss: 0.5899  |  Score: 83.37 [%]  |  Seq Length: 256.0
[2024-10-14 17:56:51,284][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 17:56:51,285][root][INFO] - Score: 79.15 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 17:56:56,884][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 17:56:56,885][root][INFO] - Score: 71.80 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 17:56:56,886][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 17:56:56,887][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 17:57:44,549][root][INFO] - Step: 720/1350  |  Loss: 0.5440  |  Score: 85.10 [%]  |  Seq Length: 256.0
[2024-10-14 17:57:50,719][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 17:57:50,719][root][INFO] - Score: 78.00 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 17:57:56,289][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 17:57:56,289][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 17:57:56,292][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 17:58:44,611][root][INFO] - Step: 810/1350  |  Loss: 0.4735  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 17:58:50,687][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 17:58:50,688][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 17:58:56,206][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 17:58:56,206][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 17:58:56,208][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 17:59:44,186][root][INFO] - Step: 900/1350  |  Loss: 0.4182  |  Score: 87.59 [%]  |  Seq Length: 256.0
[2024-10-14 17:59:50,390][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 17:59:50,390][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 17:59:56,046][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 17:59:56,046][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 17:59:56,049][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:00:44,351][root][INFO] - Step: 990/1350  |  Loss: 0.3806  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-14 18:00:50,583][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:00:50,583][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 18:00:56,301][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:00:56,302][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 18:00:56,303][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-14 18:00:56,305][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:01:44,643][root][INFO] - Step: 1080/1350  |  Loss: 0.3530  |  Score: 89.42 [%]  |  Seq Length: 256.0
[2024-10-14 18:01:50,886][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:01:50,886][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-14 18:01:56,557][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:01:56,558][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 18:01:56,561][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:02:44,744][root][INFO] - Step: 1170/1350  |  Loss: 0.3506  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 18:02:50,890][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:02:50,890][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:02:56,527][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:02:56,527][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:02:56,530][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:03:44,680][root][INFO] - Step: 1260/1350  |  Loss: 0.3270  |  Score: 90.01 [%]  |  Seq Length: 256.0
[2024-10-14 18:03:50,799][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:03:50,799][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:03:56,401][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:03:56,401][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 18:03:56,403][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:04:44,737][root][INFO] - Step: 1350/1350  |  Loss: 0.3227  |  Score: 90.36 [%]  |  Seq Length: 256.0
[2024-10-14 18:04:50,891][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:04:50,891][root][INFO] - Score: 79.37 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:04:56,523][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:04:56,523][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:04:56,524][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 18:04:56,524][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:04:56,524][root][INFO] - - Epoch: 15
[2024-10-14 18:04:56,524][root][INFO] - - DEV score: 79.37 [%]
[2024-10-14 18:04:56,524][root][INFO] - - TEST score: 72.09 [%]
[2024-10-14 18:04:56,525][root][INFO] - Fine-tuning is done!
[2024-10-14 18:04:56,529][root][INFO] - 

[2024-10-14 18:04:56,529][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:04:56,529][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 18:04:56,529][root][INFO] - 

[2024-10-14 18:04:56,529][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 18:04:59,888][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,888][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,889][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,890][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,890][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,891][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,892][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,892][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,893][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,893][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,894][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,895][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,895][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,896][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,896][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,897][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,897][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,898][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,898][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,899][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,899][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,900][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,900][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,901][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,903][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:05:00,113][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:05:00,115][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:05:00,117][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:05:00,287][root][INFO] - 

[2024-10-14 18:05:00,287][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:05:00,287][root][INFO] - Data Preprocessing
[2024-10-14 18:05:00,287][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:05:00,287][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:05:00,287][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:05:00,287][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:05:00,295][root][INFO] - vocab size              : 51200
[2024-10-14 18:05:00,295][root][INFO] - device                  : gpu
[2024-10-14 18:05:00,295][root][INFO] - random seed             : 1
[2024-10-14 18:05:00,295][root][INFO] - train data size         : 5760
[2024-10-14 18:05:00,295][root][INFO] - max epochs              : 15
[2024-10-14 18:05:00,295][root][INFO] - total steps             : 1350
[2024-10-14 18:05:00,295][root][INFO] - warmup steps            : 135
[2024-10-14 18:05:00,295][root][INFO] - batch size              : 64
[2024-10-14 18:05:00,295][root][INFO] - accumulation steps      : 1
[2024-10-14 18:05:00,296][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:05:00,296][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:05:00,296][root][INFO] - learning rate           : 0.02
[2024-10-14 18:05:00,296][root][INFO] - max length              : 256

[2024-10-14 18:05:00,296][root][INFO] - LoRA Configuration
[2024-10-14 18:05:00,296][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:05:00,296][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:05:00,296][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:05:00,296][root][INFO] - KOMBO Configuration
[2024-10-14 18:05:00,296][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:05:00,297][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:05:00,297][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:05:00,297][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:05:00,297][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:05:00,297][root][INFO] - 

[2024-10-14 18:05:00,298][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 18:05:00,298][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 18:05:00,298][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 18:05:00,298][root][INFO] - * tb interval   : 10000

[2024-10-14 18:05:00,298][root][INFO] - 

[2024-10-14 18:05:00,298][root][INFO] - Start the Training !
[2024-10-14 18:05:00,300][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:05:48,365][root][INFO] - Step: 90/1350  |  Loss: 2.0438  |  Score: 42.57 [%]  |  Seq Length: 256.0
[2024-10-14 18:05:54,539][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:05:54,539][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:06:00,144][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:06:00,144][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 18:06:00,145][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:06:00,146][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:06:16,647][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-14 18:06:48,222][root][INFO] - Step: 180/1350  |  Loss: 1.1176  |  Score: 68.59 [%]  |  Seq Length: 256.0
[2024-10-14 18:06:54,437][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:06:54,438][root][INFO] - Score: 76.90 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 18:07:00,191][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:07:00,191][root][INFO] - Score: 71.33 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-14 18:07:00,193][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:07:00,194][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:07:10,372][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:07:10,373][root][INFO] - Score: 86.43 [%]  |  Evaluation Time: 53.72 [s]
[2024-10-14 18:07:48,448][root][INFO] - Step: 270/1350  |  Loss: 0.9518  |  Score: 73.80 [%]  |  Seq Length: 256.0
[2024-10-14 18:07:54,713][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:07:54,713][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 18:08:00,417][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:08:00,417][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:08:00,418][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:08:00,420][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:08:48,417][root][INFO] - Step: 360/1350  |  Loss: 0.7880  |  Score: 78.92 [%]  |  Seq Length: 256.0
[2024-10-14 18:08:54,714][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:08:54,715][root][INFO] - Score: 78.09 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:09:00,389][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:09:00,389][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 18:09:00,392][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:09:48,786][root][INFO] - Step: 450/1350  |  Loss: 0.6588  |  Score: 81.87 [%]  |  Seq Length: 256.0
[2024-10-14 18:09:55,091][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:09:55,092][root][INFO] - Score: 78.11 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 18:10:00,793][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:10:00,794][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:10:00,796][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:10:08,856][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:10:08,856][root][INFO] - Score: 86.52 [%]  |  Evaluation Time: 178.48 [s]
[2024-10-14 18:10:08,857][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:10:08,859][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 18:10:48,963][root][INFO] - Step: 540/1350  |  Loss: 0.5402  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-14 18:10:55,240][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:10:55,240][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 18:11:00,862][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:11:00,862][root][INFO] - Score: 69.96 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 18:11:00,865][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:11:48,819][root][INFO] - Step: 630/1350  |  Loss: 0.4341  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-14 18:11:54,987][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:11:54,987][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:12:00,652][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:12:00,652][root][INFO] - Score: 70.39 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-14 18:12:00,655][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:12:48,984][root][INFO] - Step: 720/1350  |  Loss: 0.3781  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 18:12:55,235][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:12:55,235][root][INFO] - Score: 79.06 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 18:13:00,868][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:13:00,868][root][INFO] - Score: 70.59 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:13:00,871][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:13:49,133][root][INFO] - Step: 810/1350  |  Loss: 0.3292  |  Score: 90.54 [%]  |  Seq Length: 256.0
[2024-10-14 18:13:55,375][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:13:55,375][root][INFO] - Score: 77.71 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-14 18:14:01,029][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:14:01,029][root][INFO] - Score: 70.83 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 18:14:01,032][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 18:14:49,482][root][INFO] - Step: 900/1350  |  Loss: 0.2628  |  Score: 92.09 [%]  |  Seq Length: 256.0
[2024-10-14 18:14:55,810][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 18:14:55,811][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-14 18:15:01,493][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 18:15:01,493][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 18:15:01,496][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:15:49,632][root][INFO] - Step: 990/1350  |  Loss: 0.2322  |  Score: 93.24 [%]  |  Seq Length: 256.0
[2024-10-14 18:15:56,034][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:15:56,035][root][INFO] - Score: 79.01 [%]  |  Evaluation Time: 6.40 [s]
[2024-10-14 18:16:01,735][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:16:01,735][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:16:01,738][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:16:50,011][root][INFO] - Step: 1080/1350  |  Loss: 0.2070  |  Score: 93.90 [%]  |  Seq Length: 256.0
[2024-10-14 18:16:56,342][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:16:56,343][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-14 18:17:02,026][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:17:02,027][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 18:17:02,030][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:17:50,263][root][INFO] - Step: 1170/1350  |  Loss: 0.1930  |  Score: 94.23 [%]  |  Seq Length: 256.0
[2024-10-14 18:17:56,542][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:17:56,542][root][INFO] - Score: 78.67 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 18:18:02,267][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:18:02,267][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 18:18:02,270][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:18:50,520][root][INFO] - Step: 1260/1350  |  Loss: 0.1804  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-14 18:18:56,697][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:18:56,698][root][INFO] - Score: 78.84 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:19:02,318][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:19:02,318][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 18:19:02,319][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-14 18:19:02,321][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:19:50,511][root][INFO] - Step: 1350/1350  |  Loss: 0.1678  |  Score: 94.86 [%]  |  Seq Length: 256.0
[2024-10-14 18:19:56,874][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:19:56,874][root][INFO] - Score: 79.30 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-14 18:20:02,541][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:20:02,542][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-14 18:20:02,543][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 18:20:02,543][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:20:02,543][root][INFO] - - Epoch: 15
[2024-10-14 18:20:02,543][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 18:20:02,543][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 18:20:02,545][root][INFO] - Fine-tuning is done!
[2024-10-14 18:20:02,545][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 18:20:02,545][root][INFO] - - BEST LR: 0.02
[2024-10-14 18:20:02,545][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 18:20:02,545][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 18:20:09,029][root][INFO] - 

[2024-10-14 18:20:09,029][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:20:09,029][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:20:09,029][root][INFO] - 

[2024-10-14 18:20:09,029][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 18:20:13,601][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,602][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,603][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,603][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,603][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,604][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,604][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,605][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,605][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,606][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,606][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,607][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,607][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,608][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,608][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,608][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,609][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,609][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,610][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,610][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,611][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,611][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,612][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,612][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,614][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:20:13,618][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 18:20:13,814][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:20:13,816][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:20:14,003][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:20:17,123][root][INFO] - 

[2024-10-14 18:20:17,123][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:20:17,123][root][INFO] - Data Preprocessing
[2024-10-14 18:20:17,123][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:20:17,123][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:20:17,124][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:20:17,124][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:20:17,132][root][INFO] - vocab size              : 51200
[2024-10-14 18:20:17,132][root][INFO] - device                  : gpu
[2024-10-14 18:20:17,132][root][INFO] - random seed             : 2
[2024-10-14 18:20:17,132][root][INFO] - train data size         : 5760
[2024-10-14 18:20:17,132][root][INFO] - max epochs              : 15
[2024-10-14 18:20:17,132][root][INFO] - total steps             : 1350
[2024-10-14 18:20:17,132][root][INFO] - warmup steps            : 135
[2024-10-14 18:20:17,132][root][INFO] - batch size              : 64
[2024-10-14 18:20:17,132][root][INFO] - accumulation steps      : 1
[2024-10-14 18:20:17,133][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:20:17,133][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:20:17,133][root][INFO] - learning rate           : 0.01
[2024-10-14 18:20:17,133][root][INFO] - max length              : 256

[2024-10-14 18:20:17,133][root][INFO] - LoRA Configuration
[2024-10-14 18:20:17,133][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:20:17,133][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:20:17,133][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:20:17,133][root][INFO] - KOMBO Configuration
[2024-10-14 18:20:17,133][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:20:17,133][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:20:17,134][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:20:17,134][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:20:17,134][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:20:17,134][root][INFO] - 

[2024-10-14 18:20:17,134][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:20:17,134][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-14 18:20:17,135][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb
[2024-10-14 18:20:17,135][root][INFO] - * tb interval   : 10000

[2024-10-14 18:20:17,135][root][INFO] - 

[2024-10-14 18:20:17,135][root][INFO] - Start the Training !
[2024-10-14 18:20:17,138][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:21:05,409][root][INFO] - Step: 90/1350  |  Loss: 2.0541  |  Score: 36.26 [%]  |  Seq Length: 256.0
[2024-10-14 18:21:11,542][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:21:11,542][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:21:17,063][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:21:17,063][root][INFO] - Score: 60.42 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:21:17,064][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:21:17,065][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:22:04,863][root][INFO] - Step: 180/1350  |  Loss: 1.3146  |  Score: 64.93 [%]  |  Seq Length: 256.0
[2024-10-14 18:22:10,971][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:22:10,971][root][INFO] - Score: 75.98 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 18:22:16,516][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:22:16,516][root][INFO] - Score: 67.24 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 18:22:16,518][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:22:16,519][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:23:04,491][root][INFO] - Step: 270/1350  |  Loss: 1.0223  |  Score: 70.27 [%]  |  Seq Length: 256.0
[2024-10-14 18:23:10,658][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:23:10,658][root][INFO] - Score: 77.93 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 18:23:16,464][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:23:16,465][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-14 18:23:16,466][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:23:16,467][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:24:04,396][root][INFO] - Step: 360/1350  |  Loss: 0.8770  |  Score: 75.04 [%]  |  Seq Length: 256.0
[2024-10-14 18:24:10,497][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:24:10,498][root][INFO] - Score: 77.97 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 18:24:16,024][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:24:16,025][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:24:16,027][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:25:03,941][root][INFO] - Step: 450/1350  |  Loss: 0.7471  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-14 18:25:10,070][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:25:10,071][root][INFO] - Score: 79.34 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:25:15,570][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:25:15,570][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 18:25:15,571][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 18:25:15,573][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:26:03,310][root][INFO] - Step: 540/1350  |  Loss: 0.6158  |  Score: 82.27 [%]  |  Seq Length: 256.0
[2024-10-14 18:26:09,369][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:26:09,369][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 18:26:14,886][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:26:14,886][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 18:26:14,889][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:27:02,890][root][INFO] - Step: 630/1350  |  Loss: 0.5640  |  Score: 83.65 [%]  |  Seq Length: 256.0
[2024-10-14 18:27:09,005][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:27:09,005][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 18:27:14,545][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:27:14,545][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 18:27:14,547][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:28:02,328][root][INFO] - Step: 4220/10550  |  Loss: 0.2897  |  Score: 87.70 [%]  |  Seq Length: 256.0
[2024-10-14 18:28:02,339][root][INFO] - Step: 720/1350  |  Loss: 0.5180  |  Score: 85.66 [%]  |  Seq Length: 256.0
[2024-10-14 18:28:08,521][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:28:08,522][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 18:28:14,077][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:28:14,077][root][INFO] - Score: 71.89 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:28:14,079][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:28:55,307][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:28:55,307][root][INFO] - Score: 88.08 [%]  |  Evaluation Time: 52.98 [s]
[2024-10-14 18:29:01,927][root][INFO] - Step: 810/1350  |  Loss: 0.4363  |  Score: 87.48 [%]  |  Seq Length: 256.0
[2024-10-14 18:29:07,996][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:29:07,996][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 18:29:13,461][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:29:13,462][root][INFO] - Score: 71.63 [%]  |  Evaluation Time: 5.46 [s]
[2024-10-14 18:29:13,464][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 18:30:01,258][root][INFO] - Step: 900/1350  |  Loss: 0.3983  |  Score: 88.50 [%]  |  Seq Length: 256.0
[2024-10-14 18:30:07,328][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 18:30:07,328][root][INFO] - Score: 78.40 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 18:30:12,807][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 18:30:12,807][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 18:30:12,809][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:31:00,498][root][INFO] - Step: 990/1350  |  Loss: 0.3682  |  Score: 89.09 [%]  |  Seq Length: 256.0
[2024-10-14 18:31:06,687][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:31:06,687][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 18:31:12,199][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:31:12,199][root][INFO] - Score: 70.98 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 18:31:12,204][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:31:51,229][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:31:51,229][root][INFO] - Score: 88.12 [%]  |  Evaluation Time: 175.92 [s]
[2024-10-14 18:31:51,230][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:31:51,232][root][INFO] - 
[3/ 5 Epoch]
[2024-10-14 18:32:00,230][root][INFO] - Step: 1080/1350  |  Loss: 0.3299  |  Score: 90.28 [%]  |  Seq Length: 256.0
[2024-10-14 18:32:06,281][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:32:06,281][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 18:32:11,806][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:32:11,806][root][INFO] - Score: 71.50 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:32:11,808][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:32:59,535][root][INFO] - Step: 1170/1350  |  Loss: 0.3276  |  Score: 90.29 [%]  |  Seq Length: 256.0
[2024-10-14 18:33:05,662][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:33:05,662][root][INFO] - Score: 78.51 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:33:11,170][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:33:11,170][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 18:33:11,173][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:33:58,980][root][INFO] - Step: 1260/1350  |  Loss: 0.3079  |  Score: 90.56 [%]  |  Seq Length: 256.0
[2024-10-14 18:34:05,041][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:34:05,041][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 18:34:10,520][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:34:10,520][root][INFO] - Score: 71.46 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 18:34:10,522][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:34:57,578][root][INFO] - Step: 1350/1350  |  Loss: 0.3049  |  Score: 90.66 [%]  |  Seq Length: 256.0
[2024-10-14 18:35:03,721][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:35:03,721][root][INFO] - Score: 78.18 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:35:09,255][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:35:09,255][root][INFO] - Score: 71.20 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 18:35:09,256][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:35:09,256][root][INFO] - - Epoch: 5
[2024-10-14 18:35:09,256][root][INFO] - - DEV score: 79.34 [%]
[2024-10-14 18:35:09,256][root][INFO] - - TEST score: 71.45 [%]
[2024-10-14 18:35:09,257][root][INFO] - Fine-tuning is done!
[2024-10-14 18:35:09,261][root][INFO] - 

[2024-10-14 18:35:09,261][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:35:09,261][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:35:09,261][root][INFO] - 

[2024-10-14 18:35:09,262][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 18:35:12,496][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,497][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,498][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,499][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,500][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,500][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,501][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,502][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,503][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,503][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,504][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,505][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,506][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,506][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,507][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,507][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,508][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,509][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,509][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,510][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,511][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,512][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,512][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,513][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,514][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:35:12,718][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:35:12,721][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:35:12,722][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:35:12,892][root][INFO] - 

[2024-10-14 18:35:12,892][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:35:12,892][root][INFO] - Data Preprocessing
[2024-10-14 18:35:12,892][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:35:12,892][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:35:12,893][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:35:12,893][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:35:12,900][root][INFO] - vocab size              : 51200
[2024-10-14 18:35:12,900][root][INFO] - device                  : gpu
[2024-10-14 18:35:12,900][root][INFO] - random seed             : 2
[2024-10-14 18:35:12,900][root][INFO] - train data size         : 5760
[2024-10-14 18:35:12,900][root][INFO] - max epochs              : 15
[2024-10-14 18:35:12,900][root][INFO] - total steps             : 1350
[2024-10-14 18:35:12,901][root][INFO] - warmup steps            : 135
[2024-10-14 18:35:12,901][root][INFO] - batch size              : 64
[2024-10-14 18:35:12,901][root][INFO] - accumulation steps      : 1
[2024-10-14 18:35:12,901][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:35:12,901][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:35:12,901][root][INFO] - learning rate           : 0.02
[2024-10-14 18:35:12,901][root][INFO] - max length              : 256

[2024-10-14 18:35:12,901][root][INFO] - LoRA Configuration
[2024-10-14 18:35:12,901][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:35:12,901][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:35:12,901][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:35:12,901][root][INFO] - KOMBO Configuration
[2024-10-14 18:35:12,902][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:35:12,902][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:35:12,902][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:35:12,902][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:35:12,902][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:35:12,903][root][INFO] - 

[2024-10-14 18:35:12,903][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:35:12,903][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-14 18:35:12,903][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb
[2024-10-14 18:35:12,903][root][INFO] - * tb interval   : 10000

[2024-10-14 18:35:12,903][root][INFO] - 

[2024-10-14 18:35:12,903][root][INFO] - Start the Training !
[2024-10-14 18:35:12,905][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:36:00,753][root][INFO] - Step: 90/1350  |  Loss: 1.8191  |  Score: 45.29 [%]  |  Seq Length: 256.0
[2024-10-14 18:36:06,927][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:36:06,927][root][INFO] - Score: 74.54 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:36:12,519][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:36:12,519][root][INFO] - Score: 64.35 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-14 18:36:12,521][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:36:12,522][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:37:00,441][root][INFO] - Step: 180/1350  |  Loss: 1.1164  |  Score: 67.84 [%]  |  Seq Length: 256.0
[2024-10-14 18:37:06,571][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:37:06,571][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:37:12,101][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:37:12,101][root][INFO] - Score: 67.89 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 18:37:12,102][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:37:12,103][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:37:59,863][root][INFO] - Step: 270/1350  |  Loss: 0.9153  |  Score: 74.49 [%]  |  Seq Length: 256.0
[2024-10-14 18:38:05,985][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:38:05,985][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:38:11,682][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:38:11,682][root][INFO] - Score: 70.82 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:38:11,684][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:38:11,685][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:38:59,837][root][INFO] - Step: 360/1350  |  Loss: 0.7498  |  Score: 79.16 [%]  |  Seq Length: 256.0
[2024-10-14 18:39:05,953][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:39:05,953][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 18:39:11,524][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:39:11,524][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:39:11,526][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:39:59,328][root][INFO] - Step: 450/1350  |  Loss: 0.6405  |  Score: 82.18 [%]  |  Seq Length: 256.0
[2024-10-14 18:40:05,477][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:40:05,477][root][INFO] - Score: 78.36 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:40:11,025][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:40:11,025][root][INFO] - Score: 69.69 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:40:11,027][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:40:58,876][root][INFO] - Step: 540/1350  |  Loss: 0.5123  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 18:41:04,995][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:41:04,995][root][INFO] - Score: 76.26 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:41:10,564][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:41:10,564][root][INFO] - Score: 69.61 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:41:10,566][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:41:58,455][root][INFO] - Step: 630/1350  |  Loss: 0.4074  |  Score: 88.00 [%]  |  Seq Length: 256.0
[2024-10-14 18:42:04,689][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:42:04,689][root][INFO] - Score: 77.46 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 18:42:10,236][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:42:10,236][root][INFO] - Score: 69.58 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:42:10,238][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:42:58,084][root][INFO] - Step: 720/1350  |  Loss: 0.3572  |  Score: 89.95 [%]  |  Seq Length: 256.0
[2024-10-14 18:43:04,238][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:43:04,239][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:43:09,813][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:43:09,813][root][INFO] - Score: 70.79 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:43:09,816][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:43:57,793][root][INFO] - Step: 810/1350  |  Loss: 0.2877  |  Score: 91.92 [%]  |  Seq Length: 256.0
[2024-10-14 18:44:03,932][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:44:03,932][root][INFO] - Score: 77.69 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:44:09,488][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:44:09,489][root][INFO] - Score: 70.37 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:44:09,493][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 18:44:57,771][root][INFO] - Step: 900/1350  |  Loss: 0.2515  |  Score: 92.90 [%]  |  Seq Length: 256.0
[2024-10-14 18:45:03,919][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 18:45:03,920][root][INFO] - Score: 77.30 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:45:09,506][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 18:45:09,506][root][INFO] - Score: 69.35 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 18:45:09,509][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:45:57,117][root][INFO] - Step: 990/1350  |  Loss: 0.2210  |  Score: 93.44 [%]  |  Seq Length: 256.0
[2024-10-14 18:46:03,263][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:46:03,263][root][INFO] - Score: 78.83 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:46:08,837][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:46:08,837][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:46:08,840][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:46:56,704][root][INFO] - Step: 1080/1350  |  Loss: 0.1857  |  Score: 94.43 [%]  |  Seq Length: 256.0
[2024-10-14 18:47:02,841][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:47:02,842][root][INFO] - Score: 78.58 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:47:08,397][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:47:08,397][root][INFO] - Score: 69.91 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:47:08,399][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:47:56,263][root][INFO] - Step: 1170/1350  |  Loss: 0.1870  |  Score: 94.50 [%]  |  Seq Length: 256.0
[2024-10-14 18:48:02,475][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:48:02,475][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 18:48:08,021][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:48:08,022][root][INFO] - Score: 69.71 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 18:48:08,024][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:48:56,062][root][INFO] - Step: 1260/1350  |  Loss: 0.1734  |  Score: 94.72 [%]  |  Seq Length: 256.0
[2024-10-14 18:49:02,201][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:49:02,201][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:49:07,733][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:49:07,733][root][INFO] - Score: 69.90 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 18:49:07,735][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:49:40,354][root][INFO] - Step: 6330/10550  |  Loss: 0.2514  |  Score: 89.56 [%]  |  Seq Length: 256.0
[2024-10-14 18:49:54,364][root][INFO] - Step: 1350/1350  |  Loss: 0.1596  |  Score: 95.08 [%]  |  Seq Length: 256.0
[2024-10-14 18:50:00,535][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:50:00,535][root][INFO] - Score: 78.07 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:50:06,057][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:50:06,057][root][INFO] - Score: 69.29 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:50:06,058][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:50:06,058][root][INFO] - - Epoch: 3
[2024-10-14 18:50:06,058][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 18:50:06,058][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 18:50:06,059][root][INFO] - Fine-tuning is done!
[2024-10-14 18:50:06,060][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 18:50:06,060][root][INFO] - - BEST LR: 0.02
[2024-10-14 18:50:06,060][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 18:50:06,060][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 18:50:12,409][root][INFO] - 

[2024-10-14 18:50:12,409][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:50:12,409][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 18:50:12,409][root][INFO] - 

[2024-10-14 18:50:12,409][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 18:50:17,129][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,129][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,130][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,130][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,131][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,131][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,131][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,132][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,132][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,133][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,133][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,133][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,134][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,134][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,135][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,135][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,136][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,136][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,136][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,137][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,137][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,138][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,138][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,139][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,140][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:50:17,144][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 18:50:17,346][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:50:17,349][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:50:17,532][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:50:20,676][root][INFO] - 

[2024-10-14 18:50:20,676][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:50:20,676][root][INFO] - Data Preprocessing
[2024-10-14 18:50:20,676][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:50:20,676][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:50:20,676][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:50:20,677][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:50:20,696][root][INFO] - vocab size              : 51200
[2024-10-14 18:50:20,697][root][INFO] - device                  : gpu
[2024-10-14 18:50:20,697][root][INFO] - random seed             : 3
[2024-10-14 18:50:20,697][root][INFO] - train data size         : 5760
[2024-10-14 18:50:20,697][root][INFO] - max epochs              : 15
[2024-10-14 18:50:20,698][root][INFO] - total steps             : 1350
[2024-10-14 18:50:20,698][root][INFO] - warmup steps            : 135
[2024-10-14 18:50:20,698][root][INFO] - batch size              : 64
[2024-10-14 18:50:20,698][root][INFO] - accumulation steps      : 1
[2024-10-14 18:50:20,698][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:50:20,698][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:50:20,698][root][INFO] - learning rate           : 0.01
[2024-10-14 18:50:20,698][root][INFO] - max length              : 256

[2024-10-14 18:50:20,699][root][INFO] - LoRA Configuration
[2024-10-14 18:50:20,699][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:50:20,699][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:50:20,699][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:50:20,699][root][INFO] - KOMBO Configuration
[2024-10-14 18:50:20,699][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:50:20,700][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:50:20,700][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:50:20,700][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:50:20,700][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:50:20,700][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:50:20,701][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:50:20,701][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:50:20,701][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:50:20,701][root][INFO] - 

[2024-10-14 18:50:20,701][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 18:50:20,701][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-14 18:50:20,702][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb
[2024-10-14 18:50:20,702][root][INFO] - * tb interval   : 10000

[2024-10-14 18:50:20,702][root][INFO] - 

[2024-10-14 18:50:20,702][root][INFO] - Start the Training !
[2024-10-14 18:50:20,707][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:50:33,803][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:50:33,803][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 53.45 [s]
[2024-10-14 18:51:09,354][root][INFO] - Step: 90/1350  |  Loss: 2.2949  |  Score: 31.76 [%]  |  Seq Length: 256.0
[2024-10-14 18:51:15,653][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:51:15,654][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:51:21,347][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:51:21,347][root][INFO] - Score: 62.43 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-14 18:51:21,349][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:51:21,351][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:52:09,654][root][INFO] - Step: 180/1350  |  Loss: 1.1927  |  Score: 65.08 [%]  |  Seq Length: 256.0
[2024-10-14 18:52:15,950][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:52:15,950][root][INFO] - Score: 76.18 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:52:21,594][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:52:21,594][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 18:52:21,595][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:52:21,596][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:53:09,895][root][INFO] - Step: 270/1350  |  Loss: 1.0312  |  Score: 70.51 [%]  |  Seq Length: 256.0
[2024-10-14 18:53:16,187][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:53:16,187][root][INFO] - Score: 77.05 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:53:21,920][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:53:21,920][root][INFO] - Score: 68.79 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-14 18:53:21,921][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:53:21,923][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:53:30,935][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:53:30,936][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 177.13 [s]
[2024-10-14 18:53:30,937][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:53:30,938][root][INFO] - 
[4/ 5 Epoch]
[2024-10-14 18:54:10,157][root][INFO] - Step: 360/1350  |  Loss: 0.9194  |  Score: 74.60 [%]  |  Seq Length: 256.0
[2024-10-14 18:54:16,377][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:54:16,378][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 18:54:22,012][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:54:22,012][root][INFO] - Score: 71.35 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:54:22,013][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 18:54:22,014][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:55:10,088][root][INFO] - Step: 450/1350  |  Loss: 0.7997  |  Score: 77.85 [%]  |  Seq Length: 256.0
[2024-10-14 18:55:16,378][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:55:16,378][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:55:22,144][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:55:22,145][root][INFO] - Score: 71.53 [%]  |  Evaluation Time: 5.76 [s]
[2024-10-14 18:55:22,146][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 18:55:22,148][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:56:10,271][root][INFO] - Step: 540/1350  |  Loss: 0.6629  |  Score: 80.50 [%]  |  Seq Length: 256.0
[2024-10-14 18:56:16,578][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:56:16,578][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 18:56:22,298][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:56:22,298][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 18:56:22,300][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 18:56:22,301][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:57:10,746][root][INFO] - Step: 630/1350  |  Loss: 0.6011  |  Score: 83.08 [%]  |  Seq Length: 256.0
[2024-10-14 18:57:17,032][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:57:17,032][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 18:57:22,738][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:57:22,738][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:57:22,739][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 18:57:22,741][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:58:10,996][root][INFO] - Step: 720/1350  |  Loss: 0.5142  |  Score: 84.76 [%]  |  Seq Length: 256.0
[2024-10-14 18:58:17,280][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:58:17,281][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 18:58:23,103][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:58:23,104][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.82 [s]
[2024-10-14 18:58:23,105][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-14 18:58:23,106][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:59:11,339][root][INFO] - Step: 810/1350  |  Loss: 0.4585  |  Score: 86.44 [%]  |  Seq Length: 256.0
[2024-10-14 18:59:17,691][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:59:17,691][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-14 18:59:23,446][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:59:23,447][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-14 18:59:23,449][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 19:00:11,614][root][INFO] - Step: 900/1350  |  Loss: 0.4325  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-14 19:00:17,878][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 19:00:17,878][root][INFO] - Score: 78.37 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 19:00:23,605][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 19:00:23,606][root][INFO] - Score: 71.26 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 19:00:23,608][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 19:01:11,876][root][INFO] - Step: 990/1350  |  Loss: 0.3816  |  Score: 88.82 [%]  |  Seq Length: 256.0
[2024-10-14 19:01:18,142][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 19:01:18,142][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 19:01:23,818][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 19:01:23,819][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 19:01:23,821][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 19:02:11,968][root][INFO] - Step: 1080/1350  |  Loss: 0.3515  |  Score: 89.60 [%]  |  Seq Length: 256.0
[2024-10-14 19:02:18,254][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 19:02:18,254][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 19:02:24,047][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 19:02:24,047][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-14 19:02:24,050][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 19:03:12,184][root][INFO] - Step: 1170/1350  |  Loss: 0.3390  |  Score: 89.75 [%]  |  Seq Length: 256.0
[2024-10-14 19:03:18,541][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 19:03:18,541][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-14 19:03:24,154][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 19:03:24,154][root][INFO] - Score: 71.90 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 19:03:24,157][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 19:04:12,536][root][INFO] - Step: 1260/1350  |  Loss: 0.3323  |  Score: 89.91 [%]  |  Seq Length: 256.0
[2024-10-14 19:04:18,808][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 19:04:18,808][root][INFO] - Score: 78.93 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 19:04:24,564][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 19:04:24,564][root][INFO] - Score: 70.96 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-14 19:04:24,567][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 19:05:13,021][root][INFO] - Step: 1350/1350  |  Loss: 0.3222  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-14 19:05:19,288][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 19:05:19,288][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 19:05:24,905][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 19:05:24,905][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 19:05:24,906][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 19:05:24,906][root][INFO] - - Epoch: 8
[2024-10-14 19:05:24,906][root][INFO] - - DEV score: 79.59 [%]
[2024-10-14 19:05:24,906][root][INFO] - - TEST score: 72.16 [%]
[2024-10-14 19:05:24,907][root][INFO] - Fine-tuning is done!
[2024-10-14 19:05:24,911][root][INFO] - 

[2024-10-14 19:05:24,911][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 19:05:24,911][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 19:05:24,911][root][INFO] - 

[2024-10-14 19:05:24,911][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 19:05:28,219][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,219][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,220][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,221][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,222][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,222][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,223][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,223][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,224][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,224][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,225][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,225][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,226][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,226][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,227][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,227][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,228][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,229][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,229][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,229][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,230][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,230][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,231][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,231][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,233][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 19:05:28,441][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 19:05:28,443][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 19:05:28,445][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 19:05:28,570][root][INFO] - 

[2024-10-14 19:05:28,570][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 19:05:28,570][root][INFO] - Data Preprocessing
[2024-10-14 19:05:28,570][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 19:05:28,570][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 19:05:28,570][root][INFO] - ㄴ data_remove                False

[2024-10-14 19:05:28,571][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 19:05:28,578][root][INFO] - vocab size              : 51200
[2024-10-14 19:05:28,578][root][INFO] - device                  : gpu
[2024-10-14 19:05:28,578][root][INFO] - random seed             : 3
[2024-10-14 19:05:28,578][root][INFO] - train data size         : 5760
[2024-10-14 19:05:28,579][root][INFO] - max epochs              : 15
[2024-10-14 19:05:28,579][root][INFO] - total steps             : 1350
[2024-10-14 19:05:28,579][root][INFO] - warmup steps            : 135
[2024-10-14 19:05:28,579][root][INFO] - batch size              : 64
[2024-10-14 19:05:28,579][root][INFO] - accumulation steps      : 1
[2024-10-14 19:05:28,579][root][INFO] - optimizer               : adamwscale
[2024-10-14 19:05:28,579][root][INFO] - lr_scheduler            : cosine
[2024-10-14 19:05:28,579][root][INFO] - learning rate           : 0.02
[2024-10-14 19:05:28,579][root][INFO] - max length              : 256

[2024-10-14 19:05:28,579][root][INFO] - LoRA Configuration
[2024-10-14 19:05:28,580][root][INFO] - ㄴ r                    : 32
[2024-10-14 19:05:28,580][root][INFO] - ㄴ alpha                : 128
[2024-10-14 19:05:28,580][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 19:05:28,580][root][INFO] - KOMBO Configuration
[2024-10-14 19:05:28,580][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 19:05:28,580][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 19:05:28,580][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 19:05:28,580][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 19:05:28,580][root][INFO] - ㄴ do_combination       : True
[2024-10-14 19:05:28,580][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 19:05:28,581][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 19:05:28,581][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 19:05:28,581][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 19:05:28,581][root][INFO] - 

[2024-10-14 19:05:28,581][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 19:05:28,581][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-14 19:05:28,581][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb
[2024-10-14 19:05:28,581][root][INFO] - * tb interval   : 10000

[2024-10-14 19:05:28,581][root][INFO] - 

[2024-10-14 19:05:28,581][root][INFO] - Start the Training !
[2024-10-14 19:05:28,584][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 19:06:17,097][root][INFO] - Step: 90/1350  |  Loss: 2.0019  |  Score: 41.72 [%]  |  Seq Length: 256.0
[2024-10-14 19:06:23,408][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 19:06:23,409][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 19:06:29,349][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 19:06:29,350][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 5.94 [s]
[2024-10-14 19:06:29,351][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 19:06:29,353][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 19:07:17,804][root][INFO] - Step: 180/1350  |  Loss: 1.1405  |  Score: 67.73 [%]  |  Seq Length: 256.0
[2024-10-14 19:07:24,147][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 19:07:24,147][root][INFO] - Score: 77.70 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-14 19:07:29,947][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 19:07:29,947][root][INFO] - Score: 69.25 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-14 19:07:29,949][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 19:07:29,950][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 19:08:18,419][root][INFO] - Step: 270/1350  |  Loss: 0.9414  |  Score: 73.77 [%]  |  Seq Length: 256.0
[2024-10-14 19:08:24,701][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 19:08:24,701][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 19:08:30,383][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 19:08:30,383][root][INFO] - Score: 70.45 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 19:08:30,384][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 19:08:30,386][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 19:09:18,693][root][INFO] - Step: 360/1350  |  Loss: 0.7943  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-14 19:09:25,087][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 19:09:25,088][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 6.39 [s]
[2024-10-14 19:09:30,896][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 19:09:30,896][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 5.81 [s]
[2024-10-14 19:09:30,899][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 19:10:19,236][root][INFO] - Step: 450/1350  |  Loss: 0.6279  |  Score: 82.66 [%]  |  Seq Length: 256.0
[2024-10-14 19:10:25,661][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 19:10:25,661][root][INFO] - Score: 76.10 [%]  |  Evaluation Time: 6.42 [s]
[2024-10-14 19:10:31,463][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 19:10:31,464][root][INFO] - Score: 69.41 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-14 19:10:31,466][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 19:11:19,802][root][INFO] - Step: 540/1350  |  Loss: 0.5174  |  Score: 85.44 [%]  |  Seq Length: 256.0
[2024-10-14 19:11:25,201][root][INFO] - Step: 8440/10550  |  Loss: 0.2147  |  Score: 91.18 [%]  |  Seq Length: 256.0
[2024-10-14 19:11:26,104][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 19:11:26,104][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 19:11:31,804][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 19:11:31,805][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:11:31,807][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 19:12:19,107][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 19:12:19,107][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 53.90 [s]
[2024-10-14 19:12:20,226][root][INFO] - Step: 630/1350  |  Loss: 0.4309  |  Score: 87.86 [%]  |  Seq Length: 256.0
[2024-10-14 19:12:26,674][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 19:12:26,674][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 6.44 [s]
[2024-10-14 19:12:32,510][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 19:12:32,511][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.83 [s]
[2024-10-14 19:12:32,512][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 19:12:32,514][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 19:13:20,923][root][INFO] - Step: 720/1350  |  Loss: 0.3530  |  Score: 89.82 [%]  |  Seq Length: 256.0
[2024-10-14 19:13:27,246][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 19:13:27,247][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-14 19:13:32,925][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 19:13:32,925][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 19:13:32,927][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 19:14:19,924][root][INFO] - Step: 810/1350  |  Loss: 0.3051  |  Score: 91.04 [%]  |  Seq Length: 256.0
[2024-10-14 19:14:26,232][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 19:14:26,233][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 19:14:31,918][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 19:14:31,918][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 19:14:31,920][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 19:15:14,438][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 19:15:14,438][root][INFO] - Score: 88.63 [%]  |  Evaluation Time: 175.33 [s]
[2024-10-14 19:15:14,440][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 19:15:14,441][root][INFO] - 
[5/ 5 Epoch]
[2024-10-14 19:15:18,759][root][INFO] - Step: 900/1350  |  Loss: 0.2657  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 19:15:25,070][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 19:15:25,070][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 19:15:30,768][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 19:15:30,768][root][INFO] - Score: 70.10 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:15:30,770][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 19:16:18,859][root][INFO] - Step: 990/1350  |  Loss: 0.2278  |  Score: 93.40 [%]  |  Seq Length: 256.0
[2024-10-14 19:16:25,193][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 19:16:25,194][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-14 19:16:30,887][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 19:16:30,887][root][INFO] - Score: 70.20 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-14 19:16:30,889][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 19:17:19,237][root][INFO] - Step: 1080/1350  |  Loss: 0.1936  |  Score: 94.11 [%]  |  Seq Length: 256.0
[2024-10-14 19:17:25,491][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 19:17:25,491][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 19:17:31,197][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 19:17:31,197][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:17:31,199][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 19:18:19,375][root][INFO] - Step: 1170/1350  |  Loss: 0.1861  |  Score: 94.22 [%]  |  Seq Length: 256.0
[2024-10-14 19:18:25,675][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 19:18:25,676][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 19:18:31,395][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 19:18:31,395][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 19:18:31,398][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 19:19:16,929][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.44 [%]  |  Seq Length: 256.0
[2024-10-14 19:19:19,545][root][INFO] - Step: 1260/1350  |  Loss: 0.1743  |  Score: 94.73 [%]  |  Seq Length: 256.0
[2024-10-14 19:19:25,875][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 19:19:25,876][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-14 19:19:31,574][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 19:19:31,574][root][INFO] - Score: 70.50 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:19:31,576][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 19:20:19,598][root][INFO] - Step: 1350/1350  |  Loss: 0.1664  |  Score: 95.00 [%]  |  Seq Length: 256.0
[2024-10-14 19:20:25,924][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 19:20:25,924][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-14 19:20:31,581][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 19:20:31,581][root][INFO] - Score: 70.95 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 19:20:31,582][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 19:20:31,582][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 19:20:31,582][root][INFO] - - Epoch: 15
[2024-10-14 19:20:31,582][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 19:20:31,582][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 19:20:31,583][root][INFO] - Fine-tuning is done!
[2024-10-14 19:20:31,584][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 19:20:31,584][root][INFO] - - BEST LR: 0.02
[2024-10-14 19:20:31,584][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 19:20:31,584][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 19:28:23,450][root][INFO] - Step: 10000/10550  |  Loss: 0.1926  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 19:33:00,042][root][INFO] - Step: 10550/10550  |  Loss: 0.1885  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-14 19:33:52,677][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 19:33:52,678][root][INFO] - Score: 88.75 [%]  |  Evaluation Time: 52.63 [s]
[2024-10-14 19:36:47,467][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 19:36:47,468][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 174.79 [s]
[2024-10-14 19:36:47,469][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 19:36:47,469][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 19:36:47,469][root][INFO] - - Epoch: 5
[2024-10-14 19:36:47,469][root][INFO] - - DEV score: 88.75 [%]
[2024-10-14 19:36:47,469][root][INFO] - - TEST score: 88.80 [%]
[2024-10-14 19:36:47,470][root][INFO] - Fine-tuning is done!
[2024-10-14 19:36:47,473][root][INFO] - 

[2024-10-14 19:36:47,474][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 19:36:47,474][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 19:36:47,474][root][INFO] - 

[2024-10-14 19:36:47,474][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 10550, 'epochs': 5, 'warmup_steps': 1055, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 19:37:08,122][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,122][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,123][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,123][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,124][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,124][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,125][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,125][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,126][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,126][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,127][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,127][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,127][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,128][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,128][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,129][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,129][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,130][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,130][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,131][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,132][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,132][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,133][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,133][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,135][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 19:37:08,337][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 19:37:08,339][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 19:37:08,340][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 19:37:08,481][root][INFO] - 

[2024-10-14 19:37:08,481][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 19:37:08,481][root][INFO] - Data Preprocessing
[2024-10-14 19:37:08,481][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 19:37:08,481][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 19:37:08,481][root][INFO] - ㄴ data_remove                False

[2024-10-14 19:37:08,481][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 19:37:08,490][root][INFO] - vocab size              : 51200
[2024-10-14 19:37:08,490][root][INFO] - device                  : gpu
[2024-10-14 19:37:08,490][root][INFO] - random seed             : 1
[2024-10-14 19:37:08,490][root][INFO] - train data size         : 135040
[2024-10-14 19:37:08,491][root][INFO] - max epochs              : 5
[2024-10-14 19:37:08,491][root][INFO] - total steps             : 10550
[2024-10-14 19:37:08,491][root][INFO] - warmup steps            : 1055
[2024-10-14 19:37:08,491][root][INFO] - batch size              : 64
[2024-10-14 19:37:08,491][root][INFO] - accumulation steps      : 1
[2024-10-14 19:37:08,491][root][INFO] - optimizer               : adamwscale
[2024-10-14 19:37:08,491][root][INFO] - lr_scheduler            : cosine
[2024-10-14 19:37:08,491][root][INFO] - learning rate           : 0.02
[2024-10-14 19:37:08,491][root][INFO] - max length              : 256

[2024-10-14 19:37:08,491][root][INFO] - LoRA Configuration
[2024-10-14 19:37:08,491][root][INFO] - ㄴ r                    : 32
[2024-10-14 19:37:08,492][root][INFO] - ㄴ alpha                : 128
[2024-10-14 19:37:08,492][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 19:37:08,492][root][INFO] - KOMBO Configuration
[2024-10-14 19:37:08,492][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 19:37:08,492][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 19:37:08,492][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 19:37:08,492][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 19:37:08,492][root][INFO] - ㄴ do_combination       : True
[2024-10-14 19:37:08,492][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 19:37:08,493][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 19:37:08,493][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 19:37:08,493][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 19:37:08,493][root][INFO] - 

[2024-10-14 19:37:08,493][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 19:37:08,493][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 19:37:08,493][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 19:37:08,493][root][INFO] - * tb interval   : 10000

[2024-10-14 19:37:08,493][root][INFO] - 

[2024-10-14 19:37:08,493][root][INFO] - Start the Training !
[2024-10-14 19:37:08,496][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 19:54:53,625][root][INFO] - Step: 2110/10550  |  Loss: 0.3659  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-14 19:55:46,385][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 19:55:46,385][root][INFO] - Score: 85.01 [%]  |  Evaluation Time: 52.76 [s]
[2024-10-14 19:58:41,601][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 19:58:41,601][root][INFO] - Score: 84.99 [%]  |  Evaluation Time: 175.21 [s]
[2024-10-14 19:58:41,603][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 19:58:41,604][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 20:01:08,029][root][INFO] - Step: 14733/73665  |  Loss: 0.6592  |  Score: 72.33 [%]  |  Seq Length: 256.0
[2024-10-14 20:01:17,985][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:01:17,986][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 9.95 [s]
[2024-10-14 20:01:37,625][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:01:37,625][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 19.64 [s]
[2024-10-14 20:01:37,627][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:01:37,628][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 20:08:26,366][root][INFO] - 

[2024-10-14 20:08:26,366][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:08:26,366][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:08:26,366][root][INFO] - 

[2024-10-14 20:08:26,366][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:08:39,286][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,286][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,287][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,287][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,288][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,288][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,288][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,289][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,289][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,290][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,290][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,291][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,291][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,291][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,292][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,292][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,293][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,293][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,294][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,294][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,294][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,295][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,295][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,296][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,297][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:08:39,301][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:08:39,501][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:08:39,504][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:08:39,686][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:08:42,738][root][INFO] - 

[2024-10-14 20:08:42,739][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 20:08:42,739][root][INFO] - Data Preprocessing
[2024-10-14 20:08:42,739][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:08:42,739][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:08:42,739][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:08:42,739][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:08:42,747][root][INFO] - vocab size              : 51200
[2024-10-14 20:08:42,747][root][INFO] - device                  : gpu
[2024-10-14 20:08:42,747][root][INFO] - random seed             : 1
[2024-10-14 20:08:42,747][root][INFO] - train data size         : 49152
[2024-10-14 20:08:42,747][root][INFO] - max epochs              : 10
[2024-10-14 20:08:42,747][root][INFO] - total steps             : 7680
[2024-10-14 20:08:42,747][root][INFO] - warmup steps            : 768
[2024-10-14 20:08:42,747][root][INFO] - batch size              : 64
[2024-10-14 20:08:42,747][root][INFO] - accumulation steps      : 1
[2024-10-14 20:08:42,747][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:08:42,748][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:08:42,748][root][INFO] - learning rate           : 0.01
[2024-10-14 20:08:42,748][root][INFO] - max length              : 256

[2024-10-14 20:08:42,748][root][INFO] - LoRA Configuration
[2024-10-14 20:08:42,748][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:08:42,748][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:08:42,748][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:08:42,748][root][INFO] - KOMBO Configuration
[2024-10-14 20:08:42,748][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:08:42,748][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:08:42,748][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:08:42,749][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:08:42,749][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:08:42,749][root][INFO] - 

[2024-10-14 20:08:42,749][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:08:42,749][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:08:42,749][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:08:42,750][root][INFO] - * tb interval   : 10000

[2024-10-14 20:08:42,750][root][INFO] - 

[2024-10-14 20:08:42,750][root][INFO] - Start the Training !
[2024-10-14 20:08:42,753][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 20:16:15,444][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-14 20:16:24,565][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:16:24,565][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-14 20:16:30,194][root][INFO] - Step: 4220/10550  |  Loss: 0.3136  |  Score: 86.57 [%]  |  Seq Length: 256.0
[2024-10-14 20:16:33,678][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:16:33,678][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-14 20:16:33,680][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:16:33,681][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 20:17:23,483][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 20:17:23,483][root][INFO] - Score: 87.31 [%]  |  Evaluation Time: 53.29 [s]
[2024-10-14 20:20:00,308][root][INFO] - 

[2024-10-14 20:20:00,309][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:20:00,309][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:00,309][root][INFO] - 

[2024-10-14 20:20:00,309][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:20:04,406][root][INFO] - 

[2024-10-14 20:20:04,407][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:20:04,407][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:04,407][root][INFO] - 

[2024-10-14 20:20:04,407][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:20:22,774][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,775][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,776][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,776][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,776][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,777][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,777][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,778][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,778][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,779][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,779][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,779][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,780][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,780][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,781][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,781][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,781][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,782][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,782][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,783][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,783][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,784][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,784][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,784][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,786][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:20:22,792][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:20:22,993][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:20:22,995][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:20:23,202][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:20:26,157][root][INFO] - 

[2024-10-14 20:20:26,157][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 20:20:26,157][root][INFO] - Data Preprocessing
[2024-10-14 20:20:26,157][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:20:26,157][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:20:26,157][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:20:26,157][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:20:26,165][root][INFO] - vocab size              : 51200
[2024-10-14 20:20:26,165][root][INFO] - device                  : gpu
[2024-10-14 20:20:26,165][root][INFO] - random seed             : 1
[2024-10-14 20:20:26,165][root][INFO] - train data size         : 135040
[2024-10-14 20:20:26,165][root][INFO] - max epochs              : 5
[2024-10-14 20:20:26,165][root][INFO] - total steps             : 10550
[2024-10-14 20:20:26,165][root][INFO] - warmup steps            : 1055
[2024-10-14 20:20:26,165][root][INFO] - batch size              : 64
[2024-10-14 20:20:26,165][root][INFO] - accumulation steps      : 1
[2024-10-14 20:20:26,166][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:20:26,166][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:20:26,166][root][INFO] - learning rate           : 0.01
[2024-10-14 20:20:26,166][root][INFO] - max length              : 256

[2024-10-14 20:20:26,166][root][INFO] - LoRA Configuration
[2024-10-14 20:20:26,166][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:20:26,166][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:20:26,166][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:20:26,166][root][INFO] - KOMBO Configuration
[2024-10-14 20:20:26,166][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:20:26,166][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:20:26,167][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:20:26,167][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:20:26,167][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:20:26,167][root][INFO] - 

[2024-10-14 20:20:26,168][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:26,168][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:20:26,168][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:20:26,168][root][INFO] - * tb interval   : 10000

[2024-10-14 20:20:26,168][root][INFO] - 

[2024-10-14 20:20:26,168][root][INFO] - Start the Training !
[2024-10-14 20:20:26,171][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:20:26,723][root][INFO] - 

[2024-10-14 20:20:26,723][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:20:26,723][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:26,723][root][INFO] - 

[2024-10-14 20:20:26,723][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:20:39,343][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,344][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,344][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,345][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,345][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,346][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,346][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,347][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,347][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,348][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,349][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,349][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,350][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,350][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,351][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,351][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,352][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,352][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,353][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,353][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,354][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,355][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,355][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,356][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,358][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:20:39,362][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:20:39,564][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:20:39,566][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:20:39,757][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:20:42,790][root][INFO] - 

[2024-10-14 20:20:42,790][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 20:20:42,790][root][INFO] - Data Preprocessing
[2024-10-14 20:20:42,790][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:20:42,790][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:20:42,790][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:20:42,790][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:20:42,798][root][INFO] - vocab size              : 51200
[2024-10-14 20:20:42,798][root][INFO] - device                  : gpu
[2024-10-14 20:20:42,798][root][INFO] - random seed             : 1
[2024-10-14 20:20:42,798][root][INFO] - train data size         : 49152
[2024-10-14 20:20:42,798][root][INFO] - max epochs              : 10
[2024-10-14 20:20:42,798][root][INFO] - total steps             : 7680
[2024-10-14 20:20:42,798][root][INFO] - warmup steps            : 768
[2024-10-14 20:20:42,798][root][INFO] - batch size              : 64
[2024-10-14 20:20:42,798][root][INFO] - accumulation steps      : 1
[2024-10-14 20:20:42,799][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:20:42,799][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:20:42,799][root][INFO] - learning rate           : 0.01
[2024-10-14 20:20:42,799][root][INFO] - max length              : 256

[2024-10-14 20:20:42,799][root][INFO] - LoRA Configuration
[2024-10-14 20:20:42,799][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:20:42,799][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:20:42,799][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:20:42,799][root][INFO] - KOMBO Configuration
[2024-10-14 20:20:42,799][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:20:42,799][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:20:42,800][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:20:42,800][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:20:42,800][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:20:42,800][root][INFO] - 

[2024-10-14 20:20:42,800][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:42,801][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:20:42,801][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:20:42,801][root][INFO] - * tb interval   : 10000

[2024-10-14 20:20:42,801][root][INFO] - 

[2024-10-14 20:20:42,801][root][INFO] - Start the Training !
[2024-10-14 20:20:42,804][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 20:22:06,723][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,723][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,724][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,724][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,725][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,725][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,725][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,726][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,726][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,727][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,727][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,727][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,728][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,728][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,729][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,729][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,730][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,730][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,730][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,731][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,731][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,732][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,732][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,732][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,734][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 20:22:06,738][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:22:06,933][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:22:06,935][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 20:22:07,159][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:22:10,237][root][INFO] - 

[2024-10-14 20:22:10,237][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-14 20:22:10,237][root][INFO] - Data Preprocessing
[2024-10-14 20:22:10,237][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:22:10,237][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:22:10,237][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:22:10,237][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:22:10,245][root][INFO] - vocab size              : 51200
[2024-10-14 20:22:10,245][root][INFO] - device                  : gpu
[2024-10-14 20:22:10,245][root][INFO] - random seed             : 1
[2024-10-14 20:22:10,246][root][INFO] - train data size         : 942912
[2024-10-14 20:22:10,246][root][INFO] - max epochs              : 5
[2024-10-14 20:22:10,246][root][INFO] - total steps             : 73665
[2024-10-14 20:22:10,246][root][INFO] - warmup steps            : 7366
[2024-10-14 20:22:10,246][root][INFO] - batch size              : 64
[2024-10-14 20:22:10,246][root][INFO] - accumulation steps      : 1
[2024-10-14 20:22:10,246][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:22:10,246][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:22:10,246][root][INFO] - learning rate           : 0.01
[2024-10-14 20:22:10,246][root][INFO] - max length              : 256

[2024-10-14 20:22:10,246][root][INFO] - LoRA Configuration
[2024-10-14 20:22:10,246][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:22:10,247][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:22:10,247][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:22:10,247][root][INFO] - KOMBO Configuration
[2024-10-14 20:22:10,247][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:22:10,247][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:22:10,247][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:22:10,247][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:22:10,247][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:22:10,247][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:22:10,247][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:22:10,248][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:22:10,248][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:22:10,248][root][INFO] - 

[2024-10-14 20:22:10,248][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:22:10,248][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:22:10,248][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:22:10,248][root][INFO] - * tb interval   : 10000

[2024-10-14 20:22:10,248][root][INFO] - 

[2024-10-14 20:22:10,248][root][INFO] - Start the Training !
[2024-10-14 20:22:10,251][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:23:17,359][root][INFO] - 

[2024-10-14 20:23:17,359][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:23:17,359][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:17,359][root][INFO] - 

[2024-10-14 20:23:17,359][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:23:19,587][root][INFO] - 

[2024-10-14 20:23:19,587][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:23:19,588][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:19,588][root][INFO] - 

[2024-10-14 20:23:19,588][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:23:21,279][root][INFO] - 

[2024-10-14 20:23:21,279][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:23:21,280][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:21,280][root][INFO] - 

[2024-10-14 20:23:21,280][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:23:34,554][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,554][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,555][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,555][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,556][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,556][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,557][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,557][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,558][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,558][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,559][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,559][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,559][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,560][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,560][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,561][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,561][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,562][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,562][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,563][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,563][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,564][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,564][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,565][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,566][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:23:34,571][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:23:34,770][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:23:34,772][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:23:34,963][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:23:38,039][root][INFO] - 

[2024-10-14 20:23:38,039][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 20:23:38,039][root][INFO] - Data Preprocessing
[2024-10-14 20:23:38,039][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:23:38,040][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:23:38,040][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:23:38,040][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:23:38,047][root][INFO] - vocab size              : 51200
[2024-10-14 20:23:38,048][root][INFO] - device                  : gpu
[2024-10-14 20:23:38,048][root][INFO] - random seed             : 1
[2024-10-14 20:23:38,048][root][INFO] - train data size         : 49152
[2024-10-14 20:23:38,048][root][INFO] - max epochs              : 10
[2024-10-14 20:23:38,048][root][INFO] - total steps             : 7680
[2024-10-14 20:23:38,048][root][INFO] - warmup steps            : 768
[2024-10-14 20:23:38,048][root][INFO] - batch size              : 64
[2024-10-14 20:23:38,048][root][INFO] - accumulation steps      : 1
[2024-10-14 20:23:38,049][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:23:38,049][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:23:38,049][root][INFO] - learning rate           : 0.01
[2024-10-14 20:23:38,049][root][INFO] - max length              : 256

[2024-10-14 20:23:38,049][root][INFO] - LoRA Configuration
[2024-10-14 20:23:38,049][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:23:38,049][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:23:38,049][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:23:38,049][root][INFO] - KOMBO Configuration
[2024-10-14 20:23:38,049][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:23:38,050][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:23:38,050][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:23:38,050][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:23:38,050][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:23:38,051][root][INFO] - 

[2024-10-14 20:23:38,051][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:38,051][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:23:38,051][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:23:38,051][root][INFO] - * tb interval   : 10000

[2024-10-14 20:23:38,051][root][INFO] - 

[2024-10-14 20:23:38,051][root][INFO] - Start the Training !
[2024-10-14 20:23:38,055][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 20:23:42,166][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,167][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,167][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,168][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,168][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,169][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,169][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,169][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,170][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,170][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,171][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,171][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,172][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,172][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,173][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,173][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,173][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,174][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,174][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,175][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,175][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,176][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,176][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,176][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,178][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:23:42,182][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:23:42,374][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:23:42,376][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:23:42,557][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:23:45,540][root][INFO] - 

[2024-10-14 20:23:45,540][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 20:23:45,541][root][INFO] - Data Preprocessing
[2024-10-14 20:23:45,541][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:23:45,541][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:23:45,541][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:23:45,541][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:23:45,548][root][INFO] - vocab size              : 51200
[2024-10-14 20:23:45,548][root][INFO] - device                  : gpu
[2024-10-14 20:23:45,548][root][INFO] - random seed             : 1
[2024-10-14 20:23:45,549][root][INFO] - train data size         : 135040
[2024-10-14 20:23:45,549][root][INFO] - max epochs              : 5
[2024-10-14 20:23:45,549][root][INFO] - total steps             : 10550
[2024-10-14 20:23:45,549][root][INFO] - warmup steps            : 1055
[2024-10-14 20:23:45,549][root][INFO] - batch size              : 64
[2024-10-14 20:23:45,549][root][INFO] - accumulation steps      : 1
[2024-10-14 20:23:45,549][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:23:45,549][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:23:45,549][root][INFO] - learning rate           : 0.01
[2024-10-14 20:23:45,549][root][INFO] - max length              : 256

[2024-10-14 20:23:45,549][root][INFO] - LoRA Configuration
[2024-10-14 20:23:45,550][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:23:45,550][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:23:45,550][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:23:45,550][root][INFO] - KOMBO Configuration
[2024-10-14 20:23:45,550][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:23:45,550][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:23:45,550][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:23:45,550][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:23:45,550][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:23:45,550][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:23:45,551][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:23:45,551][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:23:45,551][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:23:45,551][root][INFO] - 

[2024-10-14 20:23:45,551][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:45,551][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:23:45,551][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:23:45,551][root][INFO] - * tb interval   : 10000

[2024-10-14 20:23:45,551][root][INFO] - 

[2024-10-14 20:23:45,551][root][INFO] - Start the Training !
[2024-10-14 20:23:45,554][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:25:18,621][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,622][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,623][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,623][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,624][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,625][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,626][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,626][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,627][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,628][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,629][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,629][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,630][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,631][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,632][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,632][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,633][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,634][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,635][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,635][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,636][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,637][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,638][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,638][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,641][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 20:25:18,649][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:25:18,887][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:25:18,890][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 20:25:19,107][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:25:22,163][root][INFO] - 

[2024-10-14 20:25:22,163][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-14 20:25:22,163][root][INFO] - Data Preprocessing
[2024-10-14 20:25:22,163][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:25:22,163][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:25:22,163][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:25:22,163][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:25:22,171][root][INFO] - vocab size              : 51200
[2024-10-14 20:25:22,171][root][INFO] - device                  : gpu
[2024-10-14 20:25:22,171][root][INFO] - random seed             : 1
[2024-10-14 20:25:22,171][root][INFO] - train data size         : 942912
[2024-10-14 20:25:22,171][root][INFO] - max epochs              : 5
[2024-10-14 20:25:22,171][root][INFO] - total steps             : 73665
[2024-10-14 20:25:22,172][root][INFO] - warmup steps            : 7366
[2024-10-14 20:25:22,172][root][INFO] - batch size              : 64
[2024-10-14 20:25:22,172][root][INFO] - accumulation steps      : 1
[2024-10-14 20:25:22,172][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:25:22,172][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:25:22,172][root][INFO] - learning rate           : 0.01
[2024-10-14 20:25:22,172][root][INFO] - max length              : 256

[2024-10-14 20:25:22,172][root][INFO] - LoRA Configuration
[2024-10-14 20:25:22,172][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:25:22,172][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:25:22,172][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:25:22,172][root][INFO] - KOMBO Configuration
[2024-10-14 20:25:22,173][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:25:22,173][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:25:22,173][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:25:22,173][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:25:22,173][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:25:22,174][root][INFO] - 

[2024-10-14 20:25:22,174][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:25:22,174][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:25:22,174][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:25:22,174][root][INFO] - * tb interval   : 10000

[2024-10-14 20:25:22,174][root][INFO] - 

[2024-10-14 20:25:22,174][root][INFO] - Start the Training !
[2024-10-14 20:25:22,177][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:31:10,974][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-14 20:31:20,083][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:31:20,084][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-14 20:31:29,137][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:31:29,137][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-14 20:31:29,138][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:31:29,139][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 20:39:01,832][root][INFO] - Step: 1536/7680  |  Loss: 0.5295  |  Score: 73.27 [%]  |  Seq Length: 256.0
[2024-10-14 20:39:11,168][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 20:39:11,168][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 9.33 [s]
[2024-10-14 20:39:20,446][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 20:39:20,446][root][INFO] - Score: 69.51 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-14 20:39:20,447][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 20:39:20,449][root][INFO] - 
[3/ 10 Epoch]
[2024-10-14 20:41:30,485][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-14 20:42:24,568][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:42:24,568][root][INFO] - Score: 86.43 [%]  |  Evaluation Time: 54.08 [s]
[2024-10-14 20:45:19,547][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:45:19,547][root][INFO] - Score: 86.52 [%]  |  Evaluation Time: 174.98 [s]
[2024-10-14 20:45:19,548][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:45:19,549][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 20:46:52,440][root][INFO] - Step: 2304/7680  |  Loss: 0.4638  |  Score: 77.33 [%]  |  Seq Length: 256.0
[2024-10-14 20:47:01,808][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 20:47:01,808][root][INFO] - Score: 72.97 [%]  |  Evaluation Time: 9.36 [s]
[2024-10-14 20:47:10,841][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 20:47:10,841][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-14 20:47:10,842][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 20:47:10,844][root][INFO] - 
[4/ 10 Epoch]
[2024-10-14 20:54:43,174][root][INFO] - Step: 3072/7680  |  Loss: 0.4107  |  Score: 80.68 [%]  |  Seq Length: 256.0
[2024-10-14 20:54:52,414][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 20:54:52,414][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-14 20:55:01,549][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 20:55:01,550][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 20:55:01,551][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 20:55:01,552][root][INFO] - 
[5/ 10 Epoch]
[2024-10-14 21:02:35,819][root][INFO] - Step: 3840/7680  |  Loss: 0.3698  |  Score: 82.74 [%]  |  Seq Length: 256.0
[2024-10-14 21:02:45,164][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 21:02:45,164][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 9.34 [s]
[2024-10-14 21:02:54,424][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 21:02:54,424][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-14 21:02:54,427][root][INFO] - 
[6/ 10 Epoch]
[2024-10-14 21:03:07,999][root][INFO] - Step: 4220/10550  |  Loss: 0.2897  |  Score: 87.70 [%]  |  Seq Length: 256.0
[2024-10-14 21:04:01,821][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 21:04:01,821][root][INFO] - Score: 88.08 [%]  |  Evaluation Time: 53.82 [s]
[2024-10-14 21:07:00,558][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 21:07:00,558][root][INFO] - Score: 88.12 [%]  |  Evaluation Time: 178.73 [s]
[2024-10-14 21:07:00,559][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 21:07:00,560][root][INFO] - 
[3/ 5 Epoch]
[2024-10-14 21:10:29,432][root][INFO] - Step: 4608/7680  |  Loss: 0.3322  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-14 21:10:38,562][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 21:10:38,562][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-14 21:10:47,857][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 21:10:47,858][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.29 [s]
[2024-10-14 21:10:47,859][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 21:10:47,860][root][INFO] - 
[7/ 10 Epoch]
[2024-10-14 21:18:22,718][root][INFO] - Step: 5376/7680  |  Loss: 0.2993  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-14 21:18:31,920][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 21:18:31,920][root][INFO] - Score: 75.63 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-14 21:18:41,080][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 21:18:41,081][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-14 21:18:41,082][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 21:18:41,083][root][INFO] - 
[8/ 10 Epoch]
[2024-10-14 21:24:56,190][root][INFO] - Step: 6330/10550  |  Loss: 0.2514  |  Score: 89.56 [%]  |  Seq Length: 256.0
[2024-10-14 21:25:49,763][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 21:25:49,763][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 53.57 [s]
[2024-10-14 21:26:16,429][root][INFO] - Step: 6144/7680  |  Loss: 0.2694  |  Score: 88.03 [%]  |  Seq Length: 256.0
[2024-10-14 21:26:25,649][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 21:26:25,649][root][INFO] - Score: 76.32 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-14 21:26:34,884][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 21:26:34,885][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 21:26:34,886][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-14 21:26:34,888][root][INFO] - 
[9/ 10 Epoch]
[2024-10-14 21:28:48,070][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 21:28:48,070][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 178.31 [s]
[2024-10-14 21:28:48,071][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 21:28:48,073][root][INFO] - 
[4/ 5 Epoch]
[2024-10-14 21:34:10,407][root][INFO] - Step: 6912/7680  |  Loss: 0.2510  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-14 21:34:19,536][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 21:34:19,536][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 21:34:28,660][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 21:34:28,661][root][INFO] - Score: 72.82 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-14 21:34:28,661][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-14 21:34:28,663][root][INFO] - 
[10/ 10 Epoch]
[2024-10-14 21:42:03,822][root][INFO] - Step: 7680/7680  |  Loss: 0.2422  |  Score: 89.34 [%]  |  Seq Length: 256.0
[2024-10-14 21:42:13,049][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 21:42:13,049][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-14 21:42:22,280][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 21:42:22,281][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 21:42:22,282][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 21:42:22,282][root][INFO] - - Epoch: 9
[2024-10-14 21:42:22,282][root][INFO] - - DEV score: 76.67 [%]
[2024-10-14 21:42:22,282][root][INFO] - - TEST score: 72.82 [%]
[2024-10-14 21:42:22,283][root][INFO] - Fine-tuning is done!
[2024-10-14 21:42:34,069][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,070][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,071][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,072][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,072][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,073][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,074][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,075][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,076][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,076][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,077][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,078][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,079][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,080][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,080][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,081][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,082][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,082][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,083][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,083][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,084][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,084][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,084][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,085][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,087][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 21:42:34,320][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 21:42:34,322][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 21:42:34,324][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 21:42:34,497][root][INFO] - 

[2024-10-14 21:42:34,497][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 21:42:34,497][root][INFO] - Data Preprocessing
[2024-10-14 21:42:34,498][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 21:42:34,498][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 21:42:34,498][root][INFO] - ㄴ data_remove                False

[2024-10-14 21:42:34,498][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 21:42:34,507][root][INFO] - vocab size              : 51200
[2024-10-14 21:42:34,507][root][INFO] - device                  : gpu
[2024-10-14 21:42:34,507][root][INFO] - random seed             : 1
[2024-10-14 21:42:34,507][root][INFO] - train data size         : 49152
[2024-10-14 21:42:34,507][root][INFO] - max epochs              : 10
[2024-10-14 21:42:34,507][root][INFO] - total steps             : 7680
[2024-10-14 21:42:34,507][root][INFO] - warmup steps            : 768
[2024-10-14 21:42:34,507][root][INFO] - batch size              : 64
[2024-10-14 21:42:34,508][root][INFO] - accumulation steps      : 1
[2024-10-14 21:42:34,508][root][INFO] - optimizer               : adamwscale
[2024-10-14 21:42:34,508][root][INFO] - lr_scheduler            : cosine
[2024-10-14 21:42:34,508][root][INFO] - learning rate           : 0.02
[2024-10-14 21:42:34,508][root][INFO] - max length              : 256

[2024-10-14 21:42:34,508][root][INFO] - LoRA Configuration
[2024-10-14 21:42:34,508][root][INFO] - ㄴ r                    : 32
[2024-10-14 21:42:34,508][root][INFO] - ㄴ alpha                : 128
[2024-10-14 21:42:34,508][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 21:42:34,508][root][INFO] - KOMBO Configuration
[2024-10-14 21:42:34,508][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 21:42:34,509][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 21:42:34,509][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 21:42:34,509][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 21:42:34,509][root][INFO] - ㄴ do_combination       : True
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 21:42:34,509][root][INFO] - 

[2024-10-14 21:42:34,510][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 21:42:34,510][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 21:42:34,510][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 21:42:34,510][root][INFO] - * tb interval   : 10000

[2024-10-14 21:42:34,510][root][INFO] - 

[2024-10-14 21:42:34,510][root][INFO] - Start the Training !
[2024-10-14 21:42:34,512][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 21:46:40,376][root][INFO] - Step: 8440/10550  |  Loss: 0.2147  |  Score: 91.18 [%]  |  Seq Length: 256.0
[2024-10-14 21:47:33,637][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 21:47:33,637][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 53.26 [s]
[2024-10-14 21:50:11,756][root][INFO] - Step: 768/7680  |  Loss: 0.6396  |  Score: 61.85 [%]  |  Seq Length: 256.0
[2024-10-14 21:50:20,970][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 21:50:20,971][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-14 21:50:30,260][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 21:50:30,260][root][INFO] - Score: 66.86 [%]  |  Evaluation Time: 9.29 [s]
[2024-10-14 21:50:30,262][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 21:50:30,264][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 21:50:30,395][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 21:50:30,395][root][INFO] - Score: 88.63 [%]  |  Evaluation Time: 176.76 [s]
[2024-10-14 21:50:30,396][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 21:50:30,398][root][INFO] - 
[5/ 5 Epoch]
[2024-10-14 21:54:14,521][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.44 [%]  |  Seq Length: 256.0
[2024-10-14 21:58:08,018][root][INFO] - Step: 1536/7680  |  Loss: 0.5290  |  Score: 73.49 [%]  |  Seq Length: 256.0
[2024-10-14 21:58:17,325][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 21:58:17,325][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 9.30 [s]
[2024-10-14 21:58:26,788][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 21:58:26,789][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 9.46 [s]
[2024-10-14 21:58:26,790][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 21:58:26,792][root][INFO] - 
[3/ 10 Epoch]
[2024-10-14 22:03:45,734][root][INFO] - Step: 10000/10550  |  Loss: 0.1926  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 22:06:05,777][root][INFO] - Step: 2304/7680  |  Loss: 0.4797  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-14 22:06:15,256][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 22:06:15,257][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.47 [s]
[2024-10-14 22:06:24,730][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 22:06:24,731][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 9.47 [s]
[2024-10-14 22:06:24,732][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 22:06:24,733][root][INFO] - 
[4/ 10 Epoch]
[2024-10-14 22:08:26,067][root][INFO] - Step: 10550/10550  |  Loss: 0.1885  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-14 22:09:19,872][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 22:09:19,873][root][INFO] - Score: 88.75 [%]  |  Evaluation Time: 53.80 [s]
[2024-10-14 22:12:17,049][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 22:12:17,049][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 177.17 [s]
[2024-10-14 22:12:17,051][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 22:12:17,051][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 22:12:17,051][root][INFO] - - Epoch: 5
[2024-10-14 22:12:17,051][root][INFO] - - DEV score: 88.75 [%]
[2024-10-14 22:12:17,051][root][INFO] - - TEST score: 88.80 [%]
[2024-10-14 22:12:17,052][root][INFO] - Fine-tuning is done!
[2024-10-14 22:12:38,767][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,768][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,769][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,770][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,770][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,771][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,772][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,773][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,774][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,774][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,775][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,776][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,777][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,778][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,778][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,779][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,780][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,780][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,781][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,781][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,782][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,782][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,783][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,783][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,785][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 22:12:39,004][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 22:12:39,007][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 22:12:39,008][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 22:12:39,230][root][INFO] - 

[2024-10-14 22:12:39,230][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 22:12:39,230][root][INFO] - Data Preprocessing
[2024-10-14 22:12:39,230][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 22:12:39,230][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 22:12:39,230][root][INFO] - ㄴ data_remove                False

[2024-10-14 22:12:39,231][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 22:12:39,240][root][INFO] - vocab size              : 51200
[2024-10-14 22:12:39,241][root][INFO] - device                  : gpu
[2024-10-14 22:12:39,241][root][INFO] - random seed             : 1
[2024-10-14 22:12:39,241][root][INFO] - train data size         : 135040
[2024-10-14 22:12:39,241][root][INFO] - max epochs              : 5
[2024-10-14 22:12:39,241][root][INFO] - total steps             : 10550
[2024-10-14 22:12:39,241][root][INFO] - warmup steps            : 1055
[2024-10-14 22:12:39,241][root][INFO] - batch size              : 64
[2024-10-14 22:12:39,241][root][INFO] - accumulation steps      : 1
[2024-10-14 22:12:39,241][root][INFO] - optimizer               : adamwscale
[2024-10-14 22:12:39,241][root][INFO] - lr_scheduler            : cosine
[2024-10-14 22:12:39,241][root][INFO] - learning rate           : 0.02
[2024-10-14 22:12:39,242][root][INFO] - max length              : 256

[2024-10-14 22:12:39,242][root][INFO] - LoRA Configuration
[2024-10-14 22:12:39,242][root][INFO] - ㄴ r                    : 32
[2024-10-14 22:12:39,242][root][INFO] - ㄴ alpha                : 128
[2024-10-14 22:12:39,242][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 22:12:39,242][root][INFO] - KOMBO Configuration
[2024-10-14 22:12:39,242][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 22:12:39,242][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 22:12:39,242][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 22:12:39,242][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 22:12:39,242][root][INFO] - ㄴ do_combination       : True
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 22:12:39,243][root][INFO] - 

[2024-10-14 22:12:39,243][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 22:12:39,243][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 22:12:39,243][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 22:12:39,243][root][INFO] - * tb interval   : 10000

[2024-10-14 22:12:39,243][root][INFO] - 

[2024-10-14 22:12:39,243][root][INFO] - Start the Training !
[2024-10-14 22:12:39,246][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 22:14:03,277][root][INFO] - Step: 3072/7680  |  Loss: 0.4315  |  Score: 79.38 [%]  |  Seq Length: 256.0
[2024-10-14 22:14:12,684][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 22:14:12,684][root][INFO] - Score: 72.79 [%]  |  Evaluation Time: 9.40 [s]
[2024-10-14 22:14:22,055][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 22:14:22,055][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 9.37 [s]
[2024-10-14 22:14:22,057][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 22:14:22,058][root][INFO] - 
[5/ 10 Epoch]
[2024-10-14 22:21:59,172][root][INFO] - Step: 3840/7680  |  Loss: 0.3944  |  Score: 81.60 [%]  |  Seq Length: 256.0
[2024-10-14 22:22:08,512][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 22:22:08,513][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 9.34 [s]
[2024-10-14 22:22:17,743][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 22:22:17,744][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 22:22:17,745][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 22:22:17,746][root][INFO] - 
[6/ 10 Epoch]
[2024-10-14 22:29:54,506][root][INFO] - Step: 4608/7680  |  Loss: 0.3457  |  Score: 84.04 [%]  |  Seq Length: 256.0
[2024-10-14 22:30:03,709][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 22:30:03,709][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-14 22:30:12,924][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 22:30:12,924][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-14 22:30:12,925][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 22:30:12,926][root][INFO] - 
[7/ 10 Epoch]
[2024-10-14 22:30:29,752][root][INFO] - Step: 2110/10550  |  Loss: 0.3659  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-14 22:31:23,772][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 22:31:23,773][root][INFO] - Score: 85.01 [%]  |  Evaluation Time: 54.02 [s]
[2024-10-14 22:34:22,146][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 22:34:22,146][root][INFO] - Score: 84.99 [%]  |  Evaluation Time: 178.37 [s]
[2024-10-14 22:34:22,147][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 22:34:22,149][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 22:36:21,608][root][INFO] - Step: 14733/73665  |  Loss: 0.6592  |  Score: 72.33 [%]  |  Seq Length: 256.0
[2024-10-14 22:36:31,835][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 22:36:31,835][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 10.22 [s]
[2024-10-14 22:36:51,911][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 22:36:51,911][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 20.07 [s]
[2024-10-14 22:36:51,912][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 22:36:51,913][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 22:37:50,227][root][INFO] - Step: 5376/7680  |  Loss: 0.2974  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-14 22:37:59,536][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 22:37:59,536][root][INFO] - Score: 75.11 [%]  |  Evaluation Time: 9.31 [s]
[2024-10-14 22:38:08,805][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 22:38:08,805][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 9.27 [s]
[2024-10-14 22:38:08,808][root][INFO] - 
[8/ 10 Epoch]
[2024-10-14 22:45:44,502][root][INFO] - Step: 6144/7680  |  Loss: 0.2532  |  Score: 88.87 [%]  |  Seq Length: 256.0
[2024-10-14 22:45:53,651][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 22:45:53,651][root][INFO] - Score: 75.03 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-14 22:46:02,880][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 22:46:02,880][root][INFO] - Score: 72.98 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 22:46:02,882][root][INFO] - 
[9/ 10 Epoch]
[2024-10-14 22:52:12,466][root][INFO] - Step: 4220/10550  |  Loss: 0.3136  |  Score: 86.57 [%]  |  Seq Length: 256.0
[2024-10-14 22:53:07,273][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 22:53:07,273][root][INFO] - Score: 87.31 [%]  |  Evaluation Time: 54.80 [s]
[2024-10-14 22:53:35,074][root][INFO] - Step: 6912/7680  |  Loss: 0.2230  |  Score: 90.33 [%]  |  Seq Length: 256.0
[2024-10-14 22:53:44,226][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 22:53:44,226][root][INFO] - Score: 75.21 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-14 22:53:53,368][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 22:53:53,369][root][INFO] - Score: 72.91 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-14 22:53:53,371][root][INFO] - 
[10/ 10 Epoch]
[2024-10-14 22:56:03,326][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 22:56:03,326][root][INFO] - Score: 87.45 [%]  |  Evaluation Time: 176.05 [s]
[2024-10-14 22:56:03,328][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 22:56:03,330][root][INFO] - 
[3/ 5 Epoch]
[2024-10-14 23:01:25,438][root][INFO] - Step: 7680/7680  |  Loss: 0.2027  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-14 23:01:34,569][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 23:01:34,569][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 23:01:43,709][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 23:01:43,709][root][INFO] - Score: 73.03 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-14 23:01:43,710][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 23:01:43,710][root][INFO] - - Epoch: 6
[2024-10-14 23:01:43,710][root][INFO] - - DEV score: 74.90 [%]
[2024-10-14 23:01:43,710][root][INFO] - - TEST score: 73.44 [%]
[2024-10-14 23:01:43,711][root][INFO] - Fine-tuning is done!
[2024-10-14 23:01:43,712][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 23:01:43,712][root][INFO] - - BEST LR: 0.01
[2024-10-14 23:01:43,712][root][INFO] - - DEV score: 76.67 [%]
[2024-10-14 23:01:43,712][root][INFO] - - TEST score: 72.82 [%]
[2024-10-14 23:01:50,119][root][INFO] - 

[2024-10-14 23:01:50,119][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 23:01:50,119][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-14 23:01:50,119][root][INFO] - 

[2024-10-14 23:01:50,119][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 23:02:02,942][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,942][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,943][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,943][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,944][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,944][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,945][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,946][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,946][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,947][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,947][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,948][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,948][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,949][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,949][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,950][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,950][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,951][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,952][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,952][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,953][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,953][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,954][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,954][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,956][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 23:02:02,961][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 23:02:03,191][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 23:02:03,193][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 23:02:03,385][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 23:02:06,542][root][INFO] - 

[2024-10-14 23:02:06,543][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 23:02:06,543][root][INFO] - Data Preprocessing
[2024-10-14 23:02:06,543][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 23:02:06,543][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 23:02:06,543][root][INFO] - ㄴ data_remove                False

[2024-10-14 23:02:06,543][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 23:02:06,551][root][INFO] - vocab size              : 51200
[2024-10-14 23:02:06,551][root][INFO] - device                  : gpu
[2024-10-14 23:02:06,551][root][INFO] - random seed             : 2
[2024-10-14 23:02:06,551][root][INFO] - train data size         : 49152
[2024-10-14 23:02:06,551][root][INFO] - max epochs              : 10
[2024-10-14 23:02:06,551][root][INFO] - total steps             : 7680
[2024-10-14 23:02:06,551][root][INFO] - warmup steps            : 768
[2024-10-14 23:02:06,552][root][INFO] - batch size              : 64
[2024-10-14 23:02:06,552][root][INFO] - accumulation steps      : 1
[2024-10-14 23:02:06,552][root][INFO] - optimizer               : adamwscale
[2024-10-14 23:02:06,552][root][INFO] - lr_scheduler            : cosine
[2024-10-14 23:02:06,552][root][INFO] - learning rate           : 0.01
[2024-10-14 23:02:06,552][root][INFO] - max length              : 256

[2024-10-14 23:02:06,552][root][INFO] - LoRA Configuration
[2024-10-14 23:02:06,552][root][INFO] - ㄴ r                    : 32
[2024-10-14 23:02:06,552][root][INFO] - ㄴ alpha                : 128
[2024-10-14 23:02:06,552][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 23:02:06,552][root][INFO] - KOMBO Configuration
[2024-10-14 23:02:06,552][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 23:02:06,553][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 23:02:06,553][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 23:02:06,553][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 23:02:06,553][root][INFO] - ㄴ do_combination       : True
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 23:02:06,553][root][INFO] - 

[2024-10-14 23:02:06,553][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-14 23:02:06,554][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-14 23:02:06,554][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb
[2024-10-14 23:02:06,554][root][INFO] - * tb interval   : 10000

[2024-10-14 23:02:06,554][root][INFO] - 

[2024-10-14 23:02:06,554][root][INFO] - Start the Training !
[2024-10-14 23:02:06,557][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 23:09:40,209][root][INFO] - Step: 768/7680  |  Loss: 0.6386  |  Score: 62.54 [%]  |  Seq Length: 256.0
[2024-10-14 23:09:49,345][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 23:09:49,345][root][INFO] - Score: 68.40 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 23:09:58,526][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 23:09:58,527][root][INFO] - Score: 66.23 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-14 23:09:58,528][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 23:09:58,529][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 23:13:57,589][root][INFO] - Step: 6330/10550  |  Loss: 0.2831  |  Score: 88.06 [%]  |  Seq Length: 256.0
[2024-10-14 23:14:51,750][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 23:14:51,750][root][INFO] - Score: 88.06 [%]  |  Evaluation Time: 54.16 [s]
[2024-10-14 23:17:33,453][root][INFO] - Step: 1536/7680  |  Loss: 0.5177  |  Score: 74.29 [%]  |  Seq Length: 256.0
[2024-10-14 23:17:42,471][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 23:17:42,471][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-14 23:17:48,268][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 23:17:48,268][root][INFO] - Score: 88.11 [%]  |  Evaluation Time: 176.51 [s]
[2024-10-14 23:17:48,270][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 23:17:48,272][root][INFO] - 
[4/ 5 Epoch]
[2024-10-14 23:17:51,529][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 23:17:51,530][root][INFO] - Score: 67.61 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-14 23:17:51,530][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 23:17:51,532][root][INFO] - 
[3/ 10 Epoch]
[2024-10-14 23:23:41,344][root][INFO] - Step: 20000/73665  |  Loss: 0.6348  |  Score: 73.69 [%]  |  Seq Length: 256.0
[2024-10-14 23:25:25,090][root][INFO] - Step: 2304/7680  |  Loss: 0.4565  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-14 23:25:34,104][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 23:25:34,105][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-14 23:25:43,234][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 23:25:43,234][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 23:25:43,235][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 23:25:43,236][root][INFO] - 
[4/ 10 Epoch]
[2024-10-14 23:33:14,205][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-14 23:33:23,255][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 23:33:23,255][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-14 23:33:32,294][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 23:33:32,294][root][INFO] - Score: 72.89 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-14 23:33:32,295][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 23:33:32,297][root][INFO] - 
[5/ 10 Epoch]
[2024-10-14 23:35:39,647][root][INFO] - Step: 8440/10550  |  Loss: 0.2366  |  Score: 90.27 [%]  |  Seq Length: 256.0
[2024-10-14 23:36:33,164][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 23:36:33,164][root][INFO] - Score: 88.76 [%]  |  Evaluation Time: 53.51 [s]
[2024-10-14 23:39:29,554][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 23:39:29,554][root][INFO] - Score: 88.64 [%]  |  Evaluation Time: 176.39 [s]
[2024-10-14 23:39:29,555][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 23:39:29,557][root][INFO] - 
[5/ 5 Epoch]
[2024-10-14 23:41:06,269][root][INFO] - Step: 3840/7680  |  Loss: 0.3670  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-14 23:41:15,350][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 23:41:15,351][root][INFO] - Score: 76.05 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-14 23:41:24,351][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 23:41:24,351][root][INFO] - Score: 73.63 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-14 23:41:24,352][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 23:41:24,353][root][INFO] - 
[6/ 10 Epoch]
[2024-10-14 23:48:57,595][root][INFO] - Step: 4608/7680  |  Loss: 0.3297  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-14 23:49:06,736][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 23:49:06,736][root][INFO] - Score: 75.79 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-14 23:49:15,802][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 23:49:15,802][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-14 23:49:15,803][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 23:49:15,804][root][INFO] - 
[7/ 10 Epoch]
[2024-10-14 23:52:38,683][root][INFO] - Step: 10000/10550  |  Loss: 0.1977  |  Score: 92.02 [%]  |  Seq Length: 256.0
[2024-10-14 23:56:49,879][root][INFO] - Step: 5376/7680  |  Loss: 0.2950  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-14 23:56:58,926][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 23:56:58,926][root][INFO] - Score: 75.40 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-14 23:57:08,006][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 23:57:08,007][root][INFO] - Score: 72.84 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-14 23:57:08,009][root][INFO] - 
[8/ 10 Epoch]
[2024-10-14 23:57:17,536][root][INFO] - Step: 10550/10550  |  Loss: 0.1920  |  Score: 92.38 [%]  |  Seq Length: 256.0
[2024-10-14 23:58:10,799][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 23:58:10,799][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 53.26 [s]
[2024-10-15 00:01:07,136][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 00:01:07,136][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 176.33 [s]
[2024-10-15 00:01:07,137][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 00:01:07,137][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 00:01:07,137][root][INFO] - - Epoch: 5
[2024-10-15 00:01:07,137][root][INFO] - - DEV score: 88.84 [%]
[2024-10-15 00:01:07,137][root][INFO] - - TEST score: 88.88 [%]
[2024-10-15 00:01:07,139][root][INFO] - Fine-tuning is done!
[2024-10-15 00:01:07,139][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 00:01:07,139][root][INFO] - - BEST LR: 0.02
[2024-10-15 00:01:07,139][root][INFO] - - DEV score: 88.84 [%]
[2024-10-15 00:01:07,139][root][INFO] - - TEST score: 88.88 [%]
[2024-10-15 00:01:13,486][root][INFO] - 

[2024-10-15 00:01:13,487][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 00:01:13,487][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 00:01:13,487][root][INFO] - 

[2024-10-15 00:01:13,487][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 00:01:36,953][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,954][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,954][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,955][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,955][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,956][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,956][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,957][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,957][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,958][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,958][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,959][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,959][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,960][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,960][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,961][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,961][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,962][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,962][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,963][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,963][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,964][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,964][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,965][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,967][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 00:01:36,972][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 00:01:37,175][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 00:01:37,177][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 00:01:37,384][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 00:01:40,452][root][INFO] - 

[2024-10-15 00:01:40,452][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 00:01:40,453][root][INFO] - Data Preprocessing
[2024-10-15 00:01:40,453][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 00:01:40,453][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 00:01:40,453][root][INFO] - ㄴ data_remove                False

[2024-10-15 00:01:40,453][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 00:01:40,461][root][INFO] - vocab size              : 51200
[2024-10-15 00:01:40,461][root][INFO] - device                  : gpu
[2024-10-15 00:01:40,461][root][INFO] - random seed             : 2
[2024-10-15 00:01:40,462][root][INFO] - train data size         : 135040
[2024-10-15 00:01:40,462][root][INFO] - max epochs              : 5
[2024-10-15 00:01:40,462][root][INFO] - total steps             : 10550
[2024-10-15 00:01:40,462][root][INFO] - warmup steps            : 1055
[2024-10-15 00:01:40,462][root][INFO] - batch size              : 64
[2024-10-15 00:01:40,462][root][INFO] - accumulation steps      : 1
[2024-10-15 00:01:40,462][root][INFO] - optimizer               : adamwscale
[2024-10-15 00:01:40,462][root][INFO] - lr_scheduler            : cosine
[2024-10-15 00:01:40,462][root][INFO] - learning rate           : 0.01
[2024-10-15 00:01:40,462][root][INFO] - max length              : 256

[2024-10-15 00:01:40,462][root][INFO] - LoRA Configuration
[2024-10-15 00:01:40,462][root][INFO] - ㄴ r                    : 32
[2024-10-15 00:01:40,463][root][INFO] - ㄴ alpha                : 128
[2024-10-15 00:01:40,463][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 00:01:40,463][root][INFO] - KOMBO Configuration
[2024-10-15 00:01:40,463][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 00:01:40,463][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 00:01:40,463][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 00:01:40,463][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 00:01:40,463][root][INFO] - ㄴ do_combination       : True
[2024-10-15 00:01:40,463][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 00:01:40,463][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 00:01:40,464][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 00:01:40,464][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 00:01:40,464][root][INFO] - 

[2024-10-15 00:01:40,464][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 00:01:40,464][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 00:01:40,464][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 00:01:40,464][root][INFO] - * tb interval   : 10000

[2024-10-15 00:01:40,464][root][INFO] - 

[2024-10-15 00:01:40,464][root][INFO] - Start the Training !
[2024-10-15 00:01:40,467][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 00:04:40,778][root][INFO] - Step: 6144/7680  |  Loss: 0.2654  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-15 00:04:49,864][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 00:04:49,864][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:04:58,919][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 00:04:58,919][root][INFO] - Score: 73.65 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-15 00:04:58,921][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 00:12:32,592][root][INFO] - Step: 6912/7680  |  Loss: 0.2486  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-15 00:12:41,620][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 00:12:41,620][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-15 00:12:50,658][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 00:12:50,658][root][INFO] - Score: 73.59 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-15 00:12:50,660][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 00:19:35,044][root][INFO] - Step: 2110/10550  |  Loss: 0.3658  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-15 00:20:22,509][root][INFO] - Step: 7680/7680  |  Loss: 0.2369  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-15 00:20:28,978][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 00:20:28,978][root][INFO] - Score: 87.16 [%]  |  Evaluation Time: 53.93 [s]
[2024-10-15 00:20:31,520][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 00:20:31,520][root][INFO] - Score: 76.51 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-15 00:20:40,560][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 00:20:40,560][root][INFO] - Score: 73.88 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-15 00:20:40,561][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 00:20:40,561][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 00:20:40,561][root][INFO] - - Epoch: 10
[2024-10-15 00:20:40,561][root][INFO] - - DEV score: 76.51 [%]
[2024-10-15 00:20:40,561][root][INFO] - - TEST score: 73.88 [%]
[2024-10-15 00:20:40,562][root][INFO] - Fine-tuning is done!
[2024-10-15 00:20:52,277][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,277][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,278][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,279][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,279][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,280][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,280][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,281][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,282][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,282][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,283][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,283][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,284][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,284][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,285][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,285][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,286][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,286][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,287][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,287][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,288][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,288][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,289][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,289][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,291][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 00:20:52,499][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 00:20:52,501][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 00:20:52,502][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 00:20:52,668][root][INFO] - 

[2024-10-15 00:20:52,668][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 00:20:52,668][root][INFO] - Data Preprocessing
[2024-10-15 00:20:52,668][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 00:20:52,669][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 00:20:52,669][root][INFO] - ㄴ data_remove                False

[2024-10-15 00:20:52,669][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 00:20:52,676][root][INFO] - vocab size              : 51200
[2024-10-15 00:20:52,677][root][INFO] - device                  : gpu
[2024-10-15 00:20:52,677][root][INFO] - random seed             : 2
[2024-10-15 00:20:52,677][root][INFO] - train data size         : 49152
[2024-10-15 00:20:52,677][root][INFO] - max epochs              : 10
[2024-10-15 00:20:52,677][root][INFO] - total steps             : 7680
[2024-10-15 00:20:52,677][root][INFO] - warmup steps            : 768
[2024-10-15 00:20:52,677][root][INFO] - batch size              : 64
[2024-10-15 00:20:52,677][root][INFO] - accumulation steps      : 1
[2024-10-15 00:20:52,677][root][INFO] - optimizer               : adamwscale
[2024-10-15 00:20:52,677][root][INFO] - lr_scheduler            : cosine
[2024-10-15 00:20:52,678][root][INFO] - learning rate           : 0.02
[2024-10-15 00:20:52,678][root][INFO] - max length              : 256

[2024-10-15 00:20:52,678][root][INFO] - LoRA Configuration
[2024-10-15 00:20:52,678][root][INFO] - ㄴ r                    : 32
[2024-10-15 00:20:52,678][root][INFO] - ㄴ alpha                : 128
[2024-10-15 00:20:52,678][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 00:20:52,678][root][INFO] - KOMBO Configuration
[2024-10-15 00:20:52,678][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 00:20:52,678][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 00:20:52,678][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 00:20:52,678][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 00:20:52,679][root][INFO] - ㄴ do_combination       : True
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 00:20:52,679][root][INFO] - 

[2024-10-15 00:20:52,679][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-15 00:20:52,679][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 00:20:52,679][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 00:20:52,679][root][INFO] - * tb interval   : 10000

[2024-10-15 00:20:52,679][root][INFO] - 

[2024-10-15 00:20:52,680][root][INFO] - Start the Training !
[2024-10-15 00:20:52,682][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 00:23:24,933][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 00:23:24,933][root][INFO] - Score: 87.02 [%]  |  Evaluation Time: 175.95 [s]
[2024-10-15 00:23:24,934][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 00:23:24,936][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 00:28:23,200][root][INFO] - Step: 768/7680  |  Loss: 0.6222  |  Score: 64.46 [%]  |  Seq Length: 256.0
[2024-10-15 00:28:32,240][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 00:28:32,240][root][INFO] - Score: 67.73 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-15 00:28:41,361][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 00:28:41,362][root][INFO] - Score: 66.79 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 00:28:41,363][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 00:28:41,364][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 00:36:14,746][root][INFO] - Step: 1536/7680  |  Loss: 0.5210  |  Score: 74.06 [%]  |  Seq Length: 256.0
[2024-10-15 00:36:23,854][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 00:36:23,854][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 00:36:32,936][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 00:36:32,936][root][INFO] - Score: 67.05 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:36:32,937][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 00:36:32,939][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 00:41:16,102][root][INFO] - Step: 4220/10550  |  Loss: 0.2907  |  Score: 87.67 [%]  |  Seq Length: 256.0
[2024-10-15 00:42:09,340][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 00:42:09,340][root][INFO] - Score: 88.16 [%]  |  Evaluation Time: 53.24 [s]
[2024-10-15 00:44:08,451][root][INFO] - Step: 2304/7680  |  Loss: 0.4707  |  Score: 77.22 [%]  |  Seq Length: 256.0
[2024-10-15 00:44:17,555][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 00:44:17,556][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 00:44:26,656][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 00:44:26,656][root][INFO] - Score: 70.17 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 00:44:26,657][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 00:44:26,659][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 00:45:05,372][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 00:45:05,372][root][INFO] - Score: 88.11 [%]  |  Evaluation Time: 176.03 [s]
[2024-10-15 00:45:05,374][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 00:45:05,375][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 00:47:55,985][root][INFO] - Step: 29466/73665  |  Loss: 0.6277  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-15 00:48:06,161][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 00:48:06,161][root][INFO] - Score: 73.23 [%]  |  Evaluation Time: 10.17 [s]
[2024-10-15 00:48:26,276][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 00:48:26,276][root][INFO] - Score: 73.97 [%]  |  Evaluation Time: 20.11 [s]
[2024-10-15 00:48:26,277][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 00:48:26,278][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 00:52:01,350][root][INFO] - Step: 3072/7680  |  Loss: 0.4338  |  Score: 79.22 [%]  |  Seq Length: 256.0
[2024-10-15 00:52:10,436][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 00:52:10,436][root][INFO] - Score: 74.96 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:52:19,516][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 00:52:19,516][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:52:19,517][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 00:52:19,519][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 00:53:13,737][root][INFO] - Step: 30000/73665  |  Loss: 0.5975  |  Score: 75.59 [%]  |  Seq Length: 256.0
[2024-10-15 00:59:54,995][root][INFO] - Step: 3840/7680  |  Loss: 0.3913  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-15 01:00:04,109][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 01:00:04,109][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-15 01:00:13,253][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 01:00:13,253][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 01:00:13,254][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 01:00:13,255][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 01:02:53,712][root][INFO] - Step: 6330/10550  |  Loss: 0.2512  |  Score: 89.50 [%]  |  Seq Length: 256.0
[2024-10-15 01:03:47,090][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 01:03:47,091][root][INFO] - Score: 88.58 [%]  |  Evaluation Time: 53.37 [s]
[2024-10-15 01:06:43,340][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 01:06:43,341][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 176.25 [s]
[2024-10-15 01:06:43,342][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 01:06:43,344][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 01:07:45,407][root][INFO] - Step: 4608/7680  |  Loss: 0.3479  |  Score: 84.10 [%]  |  Seq Length: 256.0
[2024-10-15 01:07:54,505][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 01:07:54,505][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-15 01:08:03,616][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 01:08:03,616][root][INFO] - Score: 72.64 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-15 01:08:03,617][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 01:08:03,619][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 01:15:38,401][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.63 [%]  |  Seq Length: 256.0
[2024-10-15 01:15:47,484][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 01:15:47,484][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 01:15:56,576][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 01:15:56,576][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-15 01:15:56,578][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 01:23:30,646][root][INFO] - Step: 6144/7680  |  Loss: 0.2514  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-15 01:23:39,683][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 01:23:39,683][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-15 01:23:48,770][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 01:23:48,770][root][INFO] - Score: 74.42 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 01:23:48,771][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 01:23:48,772][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 01:24:31,356][root][INFO] - Step: 8440/10550  |  Loss: 0.2171  |  Score: 91.10 [%]  |  Seq Length: 256.0
[2024-10-15 01:25:24,552][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 01:25:24,553][root][INFO] - Score: 89.05 [%]  |  Evaluation Time: 53.19 [s]
[2024-10-15 01:28:21,617][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 01:28:21,617][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 177.06 [s]
[2024-10-15 01:28:21,618][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 01:28:21,619][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 01:31:20,104][root][INFO] - Step: 6912/7680  |  Loss: 0.2204  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-15 01:31:29,200][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 01:31:29,200][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-15 01:31:38,327][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 01:31:38,327][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 01:31:38,330][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 01:39:11,109][root][INFO] - Step: 7680/7680  |  Loss: 0.1994  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-15 01:39:20,295][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 01:39:20,296][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-15 01:39:29,453][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 01:39:29,453][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 01:39:29,454][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 01:39:29,454][root][INFO] - - Epoch: 8
[2024-10-15 01:39:29,454][root][INFO] - - DEV score: 77.23 [%]
[2024-10-15 01:39:29,454][root][INFO] - - TEST score: 74.42 [%]
[2024-10-15 01:39:29,455][root][INFO] - Fine-tuning is done!
[2024-10-15 01:39:29,456][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 01:39:29,456][root][INFO] - - BEST LR: 0.02
[2024-10-15 01:39:29,456][root][INFO] - - DEV score: 77.23 [%]
[2024-10-15 01:39:29,456][root][INFO] - - TEST score: 74.42 [%]
[2024-10-15 01:39:35,559][root][INFO] - 

[2024-10-15 01:39:35,559][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 01:39:35,560][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 01:39:35,560][root][INFO] - 

[2024-10-15 01:39:35,560][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 01:41:29,422][root][INFO] - Step: 10000/10550  |  Loss: 0.1917  |  Score: 92.31 [%]  |  Seq Length: 256.0
[2024-10-15 01:46:07,685][root][INFO] - Step: 10550/10550  |  Loss: 0.1923  |  Score: 92.27 [%]  |  Seq Length: 256.0
[2024-10-15 01:47:00,134][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 01:47:00,134][root][INFO] - Score: 88.99 [%]  |  Evaluation Time: 52.45 [s]
[2024-10-15 01:49:55,204][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 01:49:55,204][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 175.07 [s]
[2024-10-15 01:49:55,205][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 01:49:55,206][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 01:49:55,206][root][INFO] - - Epoch: 5
[2024-10-15 01:49:55,206][root][INFO] - - DEV score: 88.99 [%]
[2024-10-15 01:49:55,206][root][INFO] - - TEST score: 88.84 [%]
[2024-10-15 01:49:55,206][root][INFO] - Fine-tuning is done!
[2024-10-15 01:51:38,320][root][INFO] - 

[2024-10-15 01:51:38,320][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 01:51:38,320][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 01:51:38,320][root][INFO] - 

[2024-10-15 01:51:38,320][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 02:22:13,398][root][INFO] - Step: 40000/73665  |  Loss: 0.5971  |  Score: 75.45 [%]  |  Seq Length: 256.0
[2024-10-15 02:59:42,781][root][INFO] - Step: 44199/73665  |  Loss: 0.5820  |  Score: 76.20 [%]  |  Seq Length: 256.0
[2024-10-15 02:59:53,124][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 02:59:53,124][root][INFO] - Score: 74.93 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-15 03:00:13,363][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 03:00:13,363][root][INFO] - Score: 75.74 [%]  |  Evaluation Time: 20.24 [s]
[2024-10-15 03:00:13,364][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 03:00:13,366][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 03:51:55,843][root][INFO] - Step: 50000/73665  |  Loss: 0.5498  |  Score: 77.61 [%]  |  Seq Length: 256.0
[2024-10-15 05:11:36,531][root][INFO] - Step: 58932/73665  |  Loss: 0.5401  |  Score: 78.25 [%]  |  Seq Length: 256.0
[2024-10-15 05:11:46,745][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 05:11:46,745][root][INFO] - Score: 74.43 [%]  |  Evaluation Time: 10.21 [s]
[2024-10-15 05:12:06,856][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 05:12:06,856][root][INFO] - Score: 76.33 [%]  |  Evaluation Time: 20.11 [s]
[2024-10-15 05:12:06,857][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 05:12:06,858][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 05:21:39,145][root][INFO] - Step: 60000/73665  |  Loss: 0.5116  |  Score: 79.42 [%]  |  Seq Length: 256.0
[2024-10-15 06:50:52,439][root][INFO] - Step: 70000/73665  |  Loss: 0.5054  |  Score: 79.74 [%]  |  Seq Length: 256.0
[2024-10-15 07:23:29,393][root][INFO] - Step: 73665/73665  |  Loss: 0.5026  |  Score: 79.99 [%]  |  Seq Length: 256.0
[2024-10-15 07:23:39,408][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 07:23:39,408][root][INFO] - Score: 74.99 [%]  |  Evaluation Time: 10.01 [s]
[2024-10-15 07:23:59,218][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 07:23:59,218][root][INFO] - Score: 76.27 [%]  |  Evaluation Time: 19.81 [s]
[2024-10-15 07:23:59,219][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 07:23:59,219][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 07:23:59,219][root][INFO] - - Epoch: 5
[2024-10-15 07:23:59,219][root][INFO] - - DEV score: 74.99 [%]
[2024-10-15 07:23:59,219][root][INFO] - - TEST score: 76.27 [%]
[2024-10-15 07:23:59,220][root][INFO] - Fine-tuning is done!
[2024-10-15 07:25:57,223][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,224][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,225][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,225][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,226][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,226][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,227][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,228][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,228][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,229][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,229][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,230][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,230][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,231][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,231][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,232][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,232][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,233][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,233][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,234][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,235][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,235][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,236][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,236][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,238][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-15 07:25:57,439][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 07:25:57,441][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-15 07:25:57,442][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 07:25:57,625][root][INFO] - 

[2024-10-15 07:25:57,626][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-15 07:25:57,626][root][INFO] - Data Preprocessing
[2024-10-15 07:25:57,626][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 07:25:57,626][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 07:25:57,626][root][INFO] - ㄴ data_remove                False

[2024-10-15 07:25:57,626][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 07:25:57,639][root][INFO] - vocab size              : 51200
[2024-10-15 07:25:57,640][root][INFO] - device                  : gpu
[2024-10-15 07:25:57,640][root][INFO] - random seed             : 1
[2024-10-15 07:25:57,640][root][INFO] - train data size         : 942912
[2024-10-15 07:25:57,640][root][INFO] - max epochs              : 5
[2024-10-15 07:25:57,640][root][INFO] - total steps             : 73665
[2024-10-15 07:25:57,640][root][INFO] - warmup steps            : 7366
[2024-10-15 07:25:57,640][root][INFO] - batch size              : 64
[2024-10-15 07:25:57,640][root][INFO] - accumulation steps      : 1
[2024-10-15 07:25:57,640][root][INFO] - optimizer               : adamwscale
[2024-10-15 07:25:57,640][root][INFO] - lr_scheduler            : cosine
[2024-10-15 07:25:57,641][root][INFO] - learning rate           : 0.02
[2024-10-15 07:25:57,641][root][INFO] - max length              : 256

[2024-10-15 07:25:57,641][root][INFO] - LoRA Configuration
[2024-10-15 07:25:57,641][root][INFO] - ㄴ r                    : 32
[2024-10-15 07:25:57,641][root][INFO] - ㄴ alpha                : 128
[2024-10-15 07:25:57,641][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 07:25:57,641][root][INFO] - KOMBO Configuration
[2024-10-15 07:25:57,641][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 07:25:57,641][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 07:25:57,641][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 07:25:57,641][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 07:25:57,642][root][INFO] - ㄴ do_combination       : True
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 07:25:57,642][root][INFO] - 

[2024-10-15 07:25:57,642][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-15 07:25:57,642][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 07:25:57,642][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-15 07:25:57,642][root][INFO] - * tb interval   : 10000

[2024-10-15 07:25:57,642][root][INFO] - 

[2024-10-15 07:25:57,642][root][INFO] - Start the Training !
[2024-10-15 07:25:57,645][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 08:54:07,115][root][INFO] - Step: 10000/73665  |  Loss: 0.7559  |  Score: 67.09 [%]  |  Seq Length: 256.0
[2024-10-15 09:35:56,960][root][INFO] - Step: 14733/73665  |  Loss: 0.8257  |  Score: 62.91 [%]  |  Seq Length: 256.0
[2024-10-15 09:36:07,328][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 09:36:07,329][root][INFO] - Score: 56.10 [%]  |  Evaluation Time: 10.37 [s]
[2024-10-15 09:36:27,604][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 09:36:27,604][root][INFO] - Score: 56.93 [%]  |  Evaluation Time: 20.27 [s]
[2024-10-15 09:36:27,605][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 09:36:27,607][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 09:51:12,328][root][INFO] - 

[2024-10-15 09:51:12,328][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 09:51:12,328][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 09:51:12,328][root][INFO] - 

[2024-10-15 09:51:12,328][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 09:51:24,863][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,864][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,865][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,865][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,866][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,866][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,867][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,867][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,868][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,868][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,869][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,869][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,870][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,870][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,871][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,871][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,872][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,872][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,873][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,873][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,874][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,874][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,875][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,875][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,877][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 09:51:24,881][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 09:51:25,083][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 09:51:25,086][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 09:51:25,277][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 09:51:27,374][root][INFO] - 

[2024-10-15 09:51:27,374][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 09:51:27,374][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 09:51:27,374][root][INFO] - 

[2024-10-15 09:51:27,375][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 09:51:28,541][root][INFO] - 

[2024-10-15 09:51:28,541][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 09:51:28,542][root][INFO] - Data Preprocessing
[2024-10-15 09:51:28,542][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 09:51:28,542][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 09:51:28,542][root][INFO] - ㄴ data_remove                False

[2024-10-15 09:51:28,542][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 09:51:28,550][root][INFO] - vocab size              : 51200
[2024-10-15 09:51:28,550][root][INFO] - device                  : gpu
[2024-10-15 09:51:28,550][root][INFO] - random seed             : 3
[2024-10-15 09:51:28,550][root][INFO] - train data size         : 49152
[2024-10-15 09:51:28,550][root][INFO] - max epochs              : 10
[2024-10-15 09:51:28,550][root][INFO] - total steps             : 7680
[2024-10-15 09:51:28,550][root][INFO] - warmup steps            : 768
[2024-10-15 09:51:28,550][root][INFO] - batch size              : 64
[2024-10-15 09:51:28,550][root][INFO] - accumulation steps      : 1
[2024-10-15 09:51:28,550][root][INFO] - optimizer               : adamwscale
[2024-10-15 09:51:28,550][root][INFO] - lr_scheduler            : cosine
[2024-10-15 09:51:28,551][root][INFO] - learning rate           : 0.01
[2024-10-15 09:51:28,551][root][INFO] - max length              : 256

[2024-10-15 09:51:28,551][root][INFO] - LoRA Configuration
[2024-10-15 09:51:28,551][root][INFO] - ㄴ r                    : 32
[2024-10-15 09:51:28,551][root][INFO] - ㄴ alpha                : 128
[2024-10-15 09:51:28,551][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 09:51:28,551][root][INFO] - KOMBO Configuration
[2024-10-15 09:51:28,551][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 09:51:28,551][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 09:51:28,551][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 09:51:28,551][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 09:51:28,552][root][INFO] - ㄴ do_combination       : True
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 09:51:28,552][root][INFO] - 

[2024-10-15 09:51:28,552][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 09:51:28,552][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 09:51:28,552][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 09:51:28,552][root][INFO] - * tb interval   : 10000

[2024-10-15 09:51:28,553][root][INFO] - 

[2024-10-15 09:51:28,553][root][INFO] - Start the Training !
[2024-10-15 09:51:28,555][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 09:51:49,586][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,587][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,588][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,588][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,589][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,589][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,590][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,590][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,591][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,591][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,592][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,592][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,592][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,593][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,593][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,594][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,594][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,595][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,595][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,596][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,596][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,597][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,597][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,598][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,599][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 09:51:49,603][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 09:51:49,804][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 09:51:49,807][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 09:51:49,976][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 09:51:53,230][root][INFO] - 

[2024-10-15 09:51:53,231][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 09:51:53,231][root][INFO] - Data Preprocessing
[2024-10-15 09:51:53,231][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 09:51:53,231][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 09:51:53,231][root][INFO] - ㄴ data_remove                False

[2024-10-15 09:51:53,231][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 09:51:53,239][root][INFO] - vocab size              : 51200
[2024-10-15 09:51:53,239][root][INFO] - device                  : gpu
[2024-10-15 09:51:53,239][root][INFO] - random seed             : 2
[2024-10-15 09:51:53,239][root][INFO] - train data size         : 135040
[2024-10-15 09:51:53,239][root][INFO] - max epochs              : 5
[2024-10-15 09:51:53,239][root][INFO] - total steps             : 10550
[2024-10-15 09:51:53,239][root][INFO] - warmup steps            : 1055
[2024-10-15 09:51:53,239][root][INFO] - batch size              : 64
[2024-10-15 09:51:53,239][root][INFO] - accumulation steps      : 1
[2024-10-15 09:51:53,240][root][INFO] - optimizer               : adamwscale
[2024-10-15 09:51:53,240][root][INFO] - lr_scheduler            : cosine
[2024-10-15 09:51:53,240][root][INFO] - learning rate           : 0.01
[2024-10-15 09:51:53,240][root][INFO] - max length              : 256

[2024-10-15 09:51:53,240][root][INFO] - LoRA Configuration
[2024-10-15 09:51:53,240][root][INFO] - ㄴ r                    : 32
[2024-10-15 09:51:53,240][root][INFO] - ㄴ alpha                : 128
[2024-10-15 09:51:53,240][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 09:51:53,240][root][INFO] - KOMBO Configuration
[2024-10-15 09:51:53,240][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 09:51:53,240][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 09:51:53,240][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 09:51:53,241][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 09:51:53,241][root][INFO] - ㄴ do_combination       : True
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 09:51:53,241][root][INFO] - 

[2024-10-15 09:51:53,241][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 09:51:53,241][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 09:51:53,242][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 09:51:53,242][root][INFO] - * tb interval   : 10000

[2024-10-15 09:51:53,242][root][INFO] - 

[2024-10-15 09:51:53,242][root][INFO] - Start the Training !
[2024-10-15 09:51:53,245][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 09:59:00,664][root][INFO] - Step: 768/7680  |  Loss: 0.6403  |  Score: 62.30 [%]  |  Seq Length: 256.0
[2024-10-15 09:59:09,745][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 09:59:09,746][root][INFO] - Score: 65.99 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 09:59:18,885][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 09:59:18,885][root][INFO] - Score: 65.19 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 09:59:18,886][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 09:59:18,888][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 10:06:53,200][root][INFO] - Step: 1536/7680  |  Loss: 0.5201  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-15 10:07:02,474][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 10:07:02,474][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 9.27 [s]
[2024-10-15 10:07:11,668][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 10:07:11,668][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-15 10:07:11,669][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 10:07:11,671][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 10:09:48,175][root][INFO] - Step: 2110/10550  |  Loss: 0.3658  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-15 10:10:42,149][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 10:10:42,150][root][INFO] - Score: 87.16 [%]  |  Evaluation Time: 53.97 [s]
[2024-10-15 10:13:38,575][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 10:13:38,575][root][INFO] - Score: 87.02 [%]  |  Evaluation Time: 176.42 [s]
[2024-10-15 10:13:38,577][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 10:13:38,578][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 10:14:46,644][root][INFO] - Step: 2304/7680  |  Loss: 0.4547  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-15 10:14:55,731][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 10:14:55,731][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 10:15:04,867][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 10:15:04,867][root][INFO] - Score: 70.54 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-15 10:15:04,868][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 10:15:04,870][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 10:22:37,012][root][INFO] - Step: 3072/7680  |  Loss: 0.4076  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-15 10:22:46,181][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 10:22:46,181][root][INFO] - Score: 73.46 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-15 10:22:55,320][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 10:22:55,321][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 10:22:55,322][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 10:22:55,323][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 10:23:23,648][root][INFO] - Step: 20000/73665  |  Loss: 1.0698  |  Score: 41.69 [%]  |  Seq Length: 256.0
[2024-10-15 10:30:24,839][root][INFO] - Step: 3840/7680  |  Loss: 0.3683  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-15 10:30:34,016][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 10:30:34,017][root][INFO] - Score: 75.77 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-15 10:30:42,933][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 10:30:42,933][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-15 10:30:42,935][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 10:30:42,936][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 10:31:24,004][root][INFO] - Step: 4220/10550  |  Loss: 0.2907  |  Score: 87.67 [%]  |  Seq Length: 256.0
[2024-10-15 10:32:17,338][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 10:32:17,338][root][INFO] - Score: 88.16 [%]  |  Evaluation Time: 53.33 [s]
[2024-10-15 10:35:15,488][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 10:35:15,488][root][INFO] - Score: 88.11 [%]  |  Evaluation Time: 178.15 [s]
[2024-10-15 10:35:15,490][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 10:35:15,491][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 10:38:17,501][root][INFO] - Step: 4608/7680  |  Loss: 0.3315  |  Score: 84.98 [%]  |  Seq Length: 256.0
[2024-10-15 10:38:26,620][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 10:38:26,620][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 10:38:35,726][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 10:38:35,726][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 10:38:35,727][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 10:38:35,728][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 10:46:08,205][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-15 10:46:17,328][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 10:46:17,328][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 10:46:26,460][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 10:46:26,460][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-15 10:46:26,461][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-15 10:46:26,463][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 10:53:03,252][root][INFO] - Step: 6330/10550  |  Loss: 0.2512  |  Score: 89.50 [%]  |  Seq Length: 256.0
[2024-10-15 10:53:56,571][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 10:53:56,571][root][INFO] - Score: 88.58 [%]  |  Evaluation Time: 53.31 [s]
[2024-10-15 10:54:00,282][root][INFO] - Step: 6144/7680  |  Loss: 0.2681  |  Score: 87.98 [%]  |  Seq Length: 256.0
[2024-10-15 10:54:09,440][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 10:54:09,441][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 10:54:18,566][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 10:54:18,566][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 10:54:18,567][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 10:54:18,568][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 10:56:52,848][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 10:56:52,848][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 176.27 [s]
[2024-10-15 10:56:52,850][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 10:56:52,851][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 11:01:53,992][root][INFO] - Step: 6912/7680  |  Loss: 0.2485  |  Score: 89.16 [%]  |  Seq Length: 256.0
[2024-10-15 11:02:03,147][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 11:02:03,147][root][INFO] - Score: 76.72 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 11:02:12,267][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 11:02:12,267][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 11:02:12,268][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-15 11:02:12,269][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 11:09:47,825][root][INFO] - Step: 7680/7680  |  Loss: 0.2410  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-15 11:09:56,937][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 11:09:56,938][root][INFO] - Score: 76.46 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-15 11:10:06,079][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 11:10:06,080][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 11:10:06,081][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 11:10:06,081][root][INFO] - - Epoch: 9
[2024-10-15 11:10:06,081][root][INFO] - - DEV score: 76.72 [%]
[2024-10-15 11:10:06,081][root][INFO] - - TEST score: 72.05 [%]
[2024-10-15 11:10:06,082][root][INFO] - Fine-tuning is done!
[2024-10-15 11:10:18,103][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,103][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,104][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,104][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,105][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,105][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,106][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,106][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,107][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,107][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,108][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,109][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,109][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,110][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,110][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,111][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,111][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,112][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,112][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,113][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,114][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,114][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,115][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,115][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,117][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 11:10:18,326][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 11:10:18,329][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 11:10:18,330][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 11:10:18,502][root][INFO] - 

[2024-10-15 11:10:18,502][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 11:10:18,502][root][INFO] - Data Preprocessing
[2024-10-15 11:10:18,502][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 11:10:18,502][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 11:10:18,502][root][INFO] - ㄴ data_remove                False

[2024-10-15 11:10:18,502][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 11:10:18,510][root][INFO] - vocab size              : 51200
[2024-10-15 11:10:18,511][root][INFO] - device                  : gpu
[2024-10-15 11:10:18,511][root][INFO] - random seed             : 3
[2024-10-15 11:10:18,511][root][INFO] - train data size         : 49152
[2024-10-15 11:10:18,511][root][INFO] - max epochs              : 10
[2024-10-15 11:10:18,511][root][INFO] - total steps             : 7680
[2024-10-15 11:10:18,511][root][INFO] - warmup steps            : 768
[2024-10-15 11:10:18,511][root][INFO] - batch size              : 64
[2024-10-15 11:10:18,511][root][INFO] - accumulation steps      : 1
[2024-10-15 11:10:18,511][root][INFO] - optimizer               : adamwscale
[2024-10-15 11:10:18,511][root][INFO] - lr_scheduler            : cosine
[2024-10-15 11:10:18,511][root][INFO] - learning rate           : 0.02
[2024-10-15 11:10:18,512][root][INFO] - max length              : 256

[2024-10-15 11:10:18,512][root][INFO] - LoRA Configuration
[2024-10-15 11:10:18,512][root][INFO] - ㄴ r                    : 32
[2024-10-15 11:10:18,512][root][INFO] - ㄴ alpha                : 128
[2024-10-15 11:10:18,512][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 11:10:18,512][root][INFO] - KOMBO Configuration
[2024-10-15 11:10:18,512][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 11:10:18,512][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 11:10:18,512][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 11:10:18,512][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 11:10:18,513][root][INFO] - ㄴ do_combination       : True
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 11:10:18,513][root][INFO] - 

[2024-10-15 11:10:18,513][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 11:10:18,513][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 11:10:18,513][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 11:10:18,514][root][INFO] - * tb interval   : 10000

[2024-10-15 11:10:18,514][root][INFO] - 

[2024-10-15 11:10:18,514][root][INFO] - Start the Training !
[2024-10-15 11:10:18,516][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 11:14:36,583][root][INFO] - Step: 8440/10550  |  Loss: 0.2171  |  Score: 91.10 [%]  |  Seq Length: 256.0
[2024-10-15 11:15:29,869][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 11:15:29,869][root][INFO] - Score: 89.05 [%]  |  Evaluation Time: 53.28 [s]
[2024-10-15 11:17:50,043][root][INFO] - Step: 768/7680  |  Loss: 0.6252  |  Score: 64.13 [%]  |  Seq Length: 256.0
[2024-10-15 11:17:59,397][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 11:17:59,397][root][INFO] - Score: 68.57 [%]  |  Evaluation Time: 9.35 [s]
[2024-10-15 11:18:08,654][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 11:18:08,655][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-15 11:18:08,655][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 11:18:08,657][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 11:18:26,817][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 11:18:26,817][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 176.94 [s]
[2024-10-15 11:18:26,818][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 11:18:26,820][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 11:25:43,789][root][INFO] - Step: 1536/7680  |  Loss: 0.5207  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-15 11:25:53,007][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 11:25:53,007][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-15 11:26:02,337][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 11:26:02,337][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 9.33 [s]
[2024-10-15 11:26:02,338][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 11:26:02,340][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 11:31:38,625][root][INFO] - Step: 10000/10550  |  Loss: 0.1917  |  Score: 92.31 [%]  |  Seq Length: 256.0
[2024-10-15 11:33:37,203][root][INFO] - Step: 2304/7680  |  Loss: 0.4711  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-15 11:33:46,355][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 11:33:46,355][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 11:33:55,511][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 11:33:55,511][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 11:33:55,512][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 11:33:55,513][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 11:36:16,917][root][INFO] - Step: 10550/10550  |  Loss: 0.1923  |  Score: 92.27 [%]  |  Seq Length: 256.0
[2024-10-15 11:37:10,067][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 11:37:10,067][root][INFO] - Score: 88.99 [%]  |  Evaluation Time: 53.15 [s]
[2024-10-15 11:40:06,147][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 11:40:06,147][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 176.08 [s]
[2024-10-15 11:40:06,148][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 11:40:06,148][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 11:40:06,149][root][INFO] - - Epoch: 5
[2024-10-15 11:40:06,149][root][INFO] - - DEV score: 88.99 [%]
[2024-10-15 11:40:06,149][root][INFO] - - TEST score: 88.84 [%]
[2024-10-15 11:40:06,149][root][INFO] - Fine-tuning is done!
[2024-10-15 11:40:27,563][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,564][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,565][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,566][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,567][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,567][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,568][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,568][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,569][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,570][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,571][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,571][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,573][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,573][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,574][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,574][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,575][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,575][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,576][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,576][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,578][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,578][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,579][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,579][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,581][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 11:40:27,791][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 11:40:27,793][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 11:40:27,795][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 11:40:27,953][root][INFO] - 

[2024-10-15 11:40:27,953][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 11:40:27,953][root][INFO] - Data Preprocessing
[2024-10-15 11:40:27,953][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 11:40:27,953][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 11:40:27,953][root][INFO] - ㄴ data_remove                False

[2024-10-15 11:40:27,953][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 11:40:27,962][root][INFO] - vocab size              : 51200
[2024-10-15 11:40:27,963][root][INFO] - device                  : gpu
[2024-10-15 11:40:27,963][root][INFO] - random seed             : 2
[2024-10-15 11:40:27,963][root][INFO] - train data size         : 135040
[2024-10-15 11:40:27,963][root][INFO] - max epochs              : 5
[2024-10-15 11:40:27,963][root][INFO] - total steps             : 10550
[2024-10-15 11:40:27,963][root][INFO] - warmup steps            : 1055
[2024-10-15 11:40:27,963][root][INFO] - batch size              : 64
[2024-10-15 11:40:27,963][root][INFO] - accumulation steps      : 1
[2024-10-15 11:40:27,963][root][INFO] - optimizer               : adamwscale
[2024-10-15 11:40:27,963][root][INFO] - lr_scheduler            : cosine
[2024-10-15 11:40:27,964][root][INFO] - learning rate           : 0.02
[2024-10-15 11:40:27,964][root][INFO] - max length              : 256

[2024-10-15 11:40:27,964][root][INFO] - LoRA Configuration
[2024-10-15 11:40:27,964][root][INFO] - ㄴ r                    : 32
[2024-10-15 11:40:27,964][root][INFO] - ㄴ alpha                : 128
[2024-10-15 11:40:27,964][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 11:40:27,964][root][INFO] - KOMBO Configuration
[2024-10-15 11:40:27,964][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 11:40:27,964][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 11:40:27,964][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 11:40:27,964][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 11:40:27,965][root][INFO] - ㄴ do_combination       : True
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 11:40:27,965][root][INFO] - 

[2024-10-15 11:40:27,965][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 11:40:27,965][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 11:40:27,965][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 11:40:27,965][root][INFO] - * tb interval   : 10000

[2024-10-15 11:40:27,965][root][INFO] - 

[2024-10-15 11:40:27,966][root][INFO] - Start the Training !
[2024-10-15 11:40:27,968][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 11:41:30,461][root][INFO] - Step: 3072/7680  |  Loss: 0.4328  |  Score: 79.44 [%]  |  Seq Length: 256.0
[2024-10-15 11:41:39,716][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 11:41:39,716][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.25 [s]
[2024-10-15 11:41:48,899][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 11:41:48,900][root][INFO] - Score: 71.79 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-15 11:41:48,901][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 11:41:48,902][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 11:47:01,502][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-15 11:47:11,848][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 11:47:11,848][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-15 11:47:32,074][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 11:47:32,074][root][INFO] - Score: 33.59 [%]  |  Evaluation Time: 20.22 [s]
[2024-10-15 11:47:32,076][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 11:49:23,166][root][INFO] - Step: 3840/7680  |  Loss: 0.3889  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-15 11:49:32,311][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 11:49:32,311][root][INFO] - Score: 74.17 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 11:49:41,537][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 11:49:41,537][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-15 11:49:41,539][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 11:52:16,948][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-15 11:57:15,453][root][INFO] - Step: 4608/7680  |  Loss: 0.3400  |  Score: 84.52 [%]  |  Seq Length: 256.0
[2024-10-15 11:57:24,663][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 11:57:24,663][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-15 11:57:33,892][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 11:57:33,892][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-15 11:57:33,893][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 11:57:33,894][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 11:58:19,057][root][INFO] - Step: 2110/10550  |  Loss: 0.3668  |  Score: 83.72 [%]  |  Seq Length: 256.0
[2024-10-15 11:59:12,379][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 11:59:12,380][root][INFO] - Score: 86.08 [%]  |  Evaluation Time: 53.32 [s]
[2024-10-15 12:02:10,473][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 12:02:10,473][root][INFO] - Score: 86.34 [%]  |  Evaluation Time: 178.09 [s]
[2024-10-15 12:02:10,474][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 12:02:10,476][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 12:05:09,228][root][INFO] - Step: 5376/7680  |  Loss: 0.2948  |  Score: 86.84 [%]  |  Seq Length: 256.0
[2024-10-15 12:05:18,544][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 12:05:18,544][root][INFO] - Score: 75.16 [%]  |  Evaluation Time: 9.31 [s]
[2024-10-15 12:05:27,721][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 12:05:27,722][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-15 12:05:27,724][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 12:13:03,804][root][INFO] - Step: 6144/7680  |  Loss: 0.2517  |  Score: 88.88 [%]  |  Seq Length: 256.0
[2024-10-15 12:13:13,021][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 12:13:13,022][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-15 12:13:22,376][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 12:13:22,377][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 9.35 [s]
[2024-10-15 12:13:22,378][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 12:13:22,379][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 12:20:00,312][root][INFO] - Step: 4220/10550  |  Loss: 0.3154  |  Score: 86.38 [%]  |  Seq Length: 256.0
[2024-10-15 12:20:53,785][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 12:20:53,785][root][INFO] - Score: 86.89 [%]  |  Evaluation Time: 53.47 [s]
[2024-10-15 12:20:58,416][root][INFO] - Step: 6912/7680  |  Loss: 0.2166  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-15 12:21:07,623][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 12:21:07,623][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-15 12:21:16,822][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 12:21:16,822][root][INFO] - Score: 73.41 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-15 12:21:16,823][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-15 12:21:16,824][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 12:23:50,560][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 12:23:50,560][root][INFO] - Score: 87.14 [%]  |  Evaluation Time: 176.77 [s]
[2024-10-15 12:23:50,561][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 12:23:50,563][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 12:28:50,894][root][INFO] - Step: 7680/7680  |  Loss: 0.1979  |  Score: 91.43 [%]  |  Seq Length: 256.0
[2024-10-15 12:29:00,039][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 12:29:00,039][root][INFO] - Score: 76.60 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 12:29:09,459][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 12:29:09,460][root][INFO] - Score: 73.52 [%]  |  Evaluation Time: 9.42 [s]
[2024-10-15 12:29:09,461][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 12:29:09,461][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 12:29:09,461][root][INFO] - - Epoch: 10
[2024-10-15 12:29:09,461][root][INFO] - - DEV score: 76.60 [%]
[2024-10-15 12:29:09,461][root][INFO] - - TEST score: 73.52 [%]
[2024-10-15 12:29:09,462][root][INFO] - Fine-tuning is done!
[2024-10-15 12:29:09,463][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 12:29:09,463][root][INFO] - - BEST LR: 0.01
[2024-10-15 12:29:09,463][root][INFO] - - DEV score: 76.72 [%]
[2024-10-15 12:29:09,463][root][INFO] - - TEST score: 72.05 [%]
[2024-10-15 12:41:42,815][root][INFO] - Step: 6330/10550  |  Loss: 0.2803  |  Score: 88.04 [%]  |  Seq Length: 256.0
[2024-10-15 12:42:36,497][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 12:42:36,497][root][INFO] - Score: 87.95 [%]  |  Evaluation Time: 53.68 [s]
[2024-10-15 12:45:32,791][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 12:45:32,791][root][INFO] - Score: 87.96 [%]  |  Evaluation Time: 176.29 [s]
[2024-10-15 12:45:32,792][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 12:45:32,794][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 13:03:23,510][root][INFO] - Step: 8440/10550  |  Loss: 0.2375  |  Score: 90.17 [%]  |  Seq Length: 256.0
[2024-10-15 13:04:17,097][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 13:04:17,097][root][INFO] - Score: 88.71 [%]  |  Evaluation Time: 53.58 [s]
[2024-10-15 13:07:13,744][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 13:07:13,744][root][INFO] - Score: 88.59 [%]  |  Evaluation Time: 176.64 [s]
[2024-10-15 13:07:13,745][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 13:07:13,747][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 13:20:26,192][root][INFO] - Step: 10000/10550  |  Loss: 0.1955  |  Score: 92.11 [%]  |  Seq Length: 256.0
[2024-10-15 13:20:40,589][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-15 13:25:05,086][root][INFO] - Step: 10550/10550  |  Loss: 0.1946  |  Score: 92.04 [%]  |  Seq Length: 256.0
[2024-10-15 13:25:58,572][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 13:25:58,572][root][INFO] - Score: 88.89 [%]  |  Evaluation Time: 53.48 [s]
[2024-10-15 13:28:55,154][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 13:28:55,155][root][INFO] - Score: 88.68 [%]  |  Evaluation Time: 176.58 [s]
[2024-10-15 13:28:55,156][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 13:28:55,156][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 13:28:55,156][root][INFO] - - Epoch: 5
[2024-10-15 13:28:55,157][root][INFO] - - DEV score: 88.89 [%]
[2024-10-15 13:28:55,157][root][INFO] - - TEST score: 88.68 [%]
[2024-10-15 13:28:55,158][root][INFO] - Fine-tuning is done!
[2024-10-15 13:28:55,159][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 13:28:55,159][root][INFO] - - BEST LR: 0.01
[2024-10-15 13:28:55,159][root][INFO] - - DEV score: 88.99 [%]
[2024-10-15 13:28:55,159][root][INFO] - - TEST score: 88.84 [%]
[2024-10-15 13:29:01,931][root][INFO] - 

[2024-10-15 13:29:01,931][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 13:29:01,931][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 13:29:01,931][root][INFO] - 

[2024-10-15 13:29:01,932][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 13:29:25,307][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,308][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,308][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,309][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,309][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,310][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,310][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,310][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,311][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,311][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,312][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,312][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,313][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,313][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,313][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,314][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,314][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,314][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,315][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,315][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,316][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,316][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,317][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,317][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,319][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 13:29:25,323][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 13:29:25,526][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 13:29:25,528][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 13:29:25,705][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 13:29:28,811][root][INFO] - 

[2024-10-15 13:29:28,812][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 13:29:28,812][root][INFO] - Data Preprocessing
[2024-10-15 13:29:28,812][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 13:29:28,812][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 13:29:28,812][root][INFO] - ㄴ data_remove                False

[2024-10-15 13:29:28,812][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 13:29:28,820][root][INFO] - vocab size              : 51200
[2024-10-15 13:29:28,820][root][INFO] - device                  : gpu
[2024-10-15 13:29:28,820][root][INFO] - random seed             : 3
[2024-10-15 13:29:28,820][root][INFO] - train data size         : 135040
[2024-10-15 13:29:28,820][root][INFO] - max epochs              : 5
[2024-10-15 13:29:28,820][root][INFO] - total steps             : 10550
[2024-10-15 13:29:28,820][root][INFO] - warmup steps            : 1055
[2024-10-15 13:29:28,820][root][INFO] - batch size              : 64
[2024-10-15 13:29:28,820][root][INFO] - accumulation steps      : 1
[2024-10-15 13:29:28,820][root][INFO] - optimizer               : adamwscale
[2024-10-15 13:29:28,821][root][INFO] - lr_scheduler            : cosine
[2024-10-15 13:29:28,821][root][INFO] - learning rate           : 0.01
[2024-10-15 13:29:28,821][root][INFO] - max length              : 256

[2024-10-15 13:29:28,821][root][INFO] - LoRA Configuration
[2024-10-15 13:29:28,821][root][INFO] - ㄴ r                    : 32
[2024-10-15 13:29:28,821][root][INFO] - ㄴ alpha                : 128
[2024-10-15 13:29:28,821][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 13:29:28,821][root][INFO] - KOMBO Configuration
[2024-10-15 13:29:28,821][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 13:29:28,821][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 13:29:28,821][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 13:29:28,821][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 13:29:28,822][root][INFO] - ㄴ do_combination       : True
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 13:29:28,822][root][INFO] - 

[2024-10-15 13:29:28,822][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 13:29:28,822][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 13:29:28,822][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 13:29:28,822][root][INFO] - * tb interval   : 10000

[2024-10-15 13:29:28,823][root][INFO] - 

[2024-10-15 13:29:28,823][root][INFO] - Start the Training !
[2024-10-15 13:29:28,826][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 13:47:18,708][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-15 13:48:11,907][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 13:48:11,908][root][INFO] - Score: 86.73 [%]  |  Evaluation Time: 53.19 [s]
[2024-10-15 13:51:08,454][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 13:51:08,454][root][INFO] - Score: 87.03 [%]  |  Evaluation Time: 176.54 [s]
[2024-10-15 13:51:08,455][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 13:51:08,457][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 13:57:37,192][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-15 13:57:47,723][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 13:57:47,724][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.53 [s]
[2024-10-15 13:58:07,970][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 13:58:07,970][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.24 [s]
[2024-10-15 13:58:07,972][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 13:58:12,590][root][INFO] - 

[2024-10-15 13:58:12,590][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 13:58:12,591][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 13:58:12,591][root][INFO] - 

[2024-10-15 13:58:12,591][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 13:58:20,869][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,870][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,871][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,872][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,872][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,873][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,873][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,874][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,874][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,875][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,875][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,876][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,876][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,877][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,877][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,878][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,878][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,879][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,879][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,880][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,882][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,882][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,883][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,883][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,885][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 13:58:20,890][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 13:58:21,095][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 13:58:21,097][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 13:58:21,289][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 13:58:24,568][root][INFO] - 

[2024-10-15 13:58:24,568][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 13:58:24,568][root][INFO] - Data Preprocessing
[2024-10-15 13:58:24,568][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 13:58:24,568][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 13:58:24,568][root][INFO] - ㄴ data_remove                True

[2024-10-15 13:58:24,568][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 13:58:24,576][root][INFO] - vocab size              : 51200
[2024-10-15 13:58:24,576][root][INFO] - device                  : gpu
[2024-10-15 13:58:24,577][root][INFO] - random seed             : 1
[2024-10-15 13:58:24,577][root][INFO] - train data size         : 24256
[2024-10-15 13:58:24,577][root][INFO] - max epochs              : 10
[2024-10-15 13:58:24,577][root][INFO] - total steps             : 3790
[2024-10-15 13:58:24,577][root][INFO] - warmup steps            : 379
[2024-10-15 13:58:24,577][root][INFO] - batch size              : 64
[2024-10-15 13:58:24,577][root][INFO] - accumulation steps      : 1
[2024-10-15 13:58:24,577][root][INFO] - optimizer               : adamwscale
[2024-10-15 13:58:24,577][root][INFO] - lr_scheduler            : cosine
[2024-10-15 13:58:24,578][root][INFO] - learning rate           : 0.01
[2024-10-15 13:58:24,578][root][INFO] - max length              : 256

[2024-10-15 13:58:24,578][root][INFO] - LoRA Configuration
[2024-10-15 13:58:24,578][root][INFO] - ㄴ r                    : 32
[2024-10-15 13:58:24,578][root][INFO] - ㄴ alpha                : 128
[2024-10-15 13:58:24,578][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 13:58:24,578][root][INFO] - KOMBO Configuration
[2024-10-15 13:58:24,578][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 13:58:24,578][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 13:58:24,579][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 13:58:24,579][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 13:58:24,579][root][INFO] - ㄴ do_combination       : True
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 13:58:24,579][root][INFO] - 

[2024-10-15 13:58:24,580][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 13:58:24,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 13:58:24,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 13:58:24,580][root][INFO] - * tb interval   : 10000

[2024-10-15 13:58:24,580][root][INFO] - 

[2024-10-15 13:58:24,580][root][INFO] - Start the Training !
[2024-10-15 13:58:24,583][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 14:02:03,140][root][INFO] - Step: 379/3790  |  Loss: 0.6989  |  Score: 54.10 [%]  |  Seq Length: 256.0
[2024-10-15 14:02:07,770][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 14:02:07,771][root][INFO] - Score: 58.98 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:02:12,347][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 14:02:12,347][root][INFO] - Score: 56.52 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 14:02:12,348][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 14:02:12,349][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 14:05:54,132][root][INFO] - Step: 758/3790  |  Loss: 0.5957  |  Score: 68.22 [%]  |  Seq Length: 256.0
[2024-10-15 14:05:58,782][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 14:05:58,782][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 14:06:03,405][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 14:06:03,405][root][INFO] - Score: 60.83 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 14:06:03,406][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 14:06:03,408][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 14:09:00,063][root][INFO] - Step: 4220/10550  |  Loss: 0.2911  |  Score: 87.62 [%]  |  Seq Length: 256.0
[2024-10-15 14:09:46,537][root][INFO] - Step: 1137/3790  |  Loss: 0.5221  |  Score: 73.95 [%]  |  Seq Length: 256.0
[2024-10-15 14:09:51,218][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 14:09:51,219][root][INFO] - Score: 65.33 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 14:09:53,385][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 14:09:53,385][root][INFO] - Score: 87.75 [%]  |  Evaluation Time: 53.32 [s]
[2024-10-15 14:09:55,842][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 14:09:55,843][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 14:09:55,844][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 14:09:55,845][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 14:12:50,262][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 14:12:50,263][root][INFO] - Score: 87.94 [%]  |  Evaluation Time: 176.88 [s]
[2024-10-15 14:12:50,264][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 14:12:50,265][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 14:13:39,469][root][INFO] - Step: 1516/3790  |  Loss: 0.4657  |  Score: 77.93 [%]  |  Seq Length: 256.0
[2024-10-15 14:13:44,142][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 14:13:44,143][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 14:13:48,842][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 14:13:48,842][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:13:48,843][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 14:13:48,845][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 14:17:32,263][root][INFO] - Step: 1895/3790  |  Loss: 0.4148  |  Score: 80.71 [%]  |  Seq Length: 256.0
[2024-10-15 14:17:37,022][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 14:17:37,023][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-15 14:17:41,723][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 14:17:41,724][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:17:41,725][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 14:17:41,726][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 14:21:26,145][root][INFO] - Step: 2274/3790  |  Loss: 0.3753  |  Score: 82.87 [%]  |  Seq Length: 256.0
[2024-10-15 14:21:30,797][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 14:21:30,797][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 14:21:35,398][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 14:21:35,398][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 14:21:35,399][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 14:21:35,400][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 14:25:16,186][root][INFO] - Step: 2653/3790  |  Loss: 0.3384  |  Score: 84.64 [%]  |  Seq Length: 256.0
[2024-10-15 14:25:20,875][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 14:25:20,875][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 14:25:25,460][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 14:25:25,460][root][INFO] - Score: 66.65 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 14:25:25,463][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 14:29:08,024][root][INFO] - Step: 3032/3790  |  Loss: 0.3095  |  Score: 86.36 [%]  |  Seq Length: 256.0
[2024-10-15 14:29:12,694][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 14:29:12,694][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 14:29:17,280][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 14:29:17,280][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 14:29:17,282][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 14:30:37,468][root][INFO] - Step: 6330/10550  |  Loss: 0.2529  |  Score: 89.52 [%]  |  Seq Length: 256.0
[2024-10-15 14:31:31,302][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 14:31:31,302][root][INFO] - Score: 88.52 [%]  |  Evaluation Time: 53.83 [s]
[2024-10-15 14:33:00,351][root][INFO] - Step: 3411/3790  |  Loss: 0.2896  |  Score: 87.03 [%]  |  Seq Length: 256.0
[2024-10-15 14:33:05,090][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 14:33:05,090][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 14:33:09,712][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 14:33:09,712][root][INFO] - Score: 66.61 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 14:33:09,715][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 14:34:28,067][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 14:34:28,067][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 176.76 [s]
[2024-10-15 14:34:28,068][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 14:34:28,070][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 14:36:51,898][root][INFO] - Step: 3790/3790  |  Loss: 0.2791  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-15 14:36:56,553][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 14:36:56,554][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 14:37:01,109][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 14:37:01,109][root][INFO] - Score: 67.19 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 14:37:01,110][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 14:37:01,110][root][INFO] - - Epoch: 6
[2024-10-15 14:37:01,110][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 14:37:01,111][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 14:37:01,111][root][INFO] - Fine-tuning is done!
[2024-10-15 14:37:07,953][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,954][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,955][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,955][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,956][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,956][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,957][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,958][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,958][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,959][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,959][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,960][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,961][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,961][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,962][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,962][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,963][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,963][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,964][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,964][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,965][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,965][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,966][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,966][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,968][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 14:37:08,177][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 14:37:08,179][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 14:37:08,180][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 14:37:08,354][root][INFO] - 

[2024-10-15 14:37:08,355][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 14:37:08,355][root][INFO] - Data Preprocessing
[2024-10-15 14:37:08,355][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 14:37:08,355][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 14:37:08,355][root][INFO] - ㄴ data_remove                True

[2024-10-15 14:37:08,355][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 14:37:08,363][root][INFO] - vocab size              : 51200
[2024-10-15 14:37:08,363][root][INFO] - device                  : gpu
[2024-10-15 14:37:08,363][root][INFO] - random seed             : 1
[2024-10-15 14:37:08,363][root][INFO] - train data size         : 24256
[2024-10-15 14:37:08,363][root][INFO] - max epochs              : 10
[2024-10-15 14:37:08,363][root][INFO] - total steps             : 3790
[2024-10-15 14:37:08,364][root][INFO] - warmup steps            : 379
[2024-10-15 14:37:08,364][root][INFO] - batch size              : 64
[2024-10-15 14:37:08,364][root][INFO] - accumulation steps      : 1
[2024-10-15 14:37:08,364][root][INFO] - optimizer               : adamwscale
[2024-10-15 14:37:08,364][root][INFO] - lr_scheduler            : cosine
[2024-10-15 14:37:08,364][root][INFO] - learning rate           : 0.02
[2024-10-15 14:37:08,364][root][INFO] - max length              : 256

[2024-10-15 14:37:08,364][root][INFO] - LoRA Configuration
[2024-10-15 14:37:08,364][root][INFO] - ㄴ r                    : 32
[2024-10-15 14:37:08,364][root][INFO] - ㄴ alpha                : 128
[2024-10-15 14:37:08,364][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 14:37:08,364][root][INFO] - KOMBO Configuration
[2024-10-15 14:37:08,365][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 14:37:08,365][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 14:37:08,365][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 14:37:08,365][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 14:37:08,365][root][INFO] - ㄴ do_combination       : True
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 14:37:08,366][root][INFO] - 

[2024-10-15 14:37:08,366][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 14:37:08,366][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 14:37:08,366][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 14:37:08,366][root][INFO] - * tb interval   : 10000

[2024-10-15 14:37:08,366][root][INFO] - 

[2024-10-15 14:37:08,366][root][INFO] - Start the Training !
[2024-10-15 14:37:08,368][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 14:40:46,776][root][INFO] - Step: 379/3790  |  Loss: 0.6780  |  Score: 57.60 [%]  |  Seq Length: 256.0
[2024-10-15 14:40:51,460][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 14:40:51,460][root][INFO] - Score: 64.06 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 14:40:56,046][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 14:40:56,046][root][INFO] - Score: 59.82 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 14:40:56,047][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 14:40:56,048][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 14:44:38,353][root][INFO] - Step: 758/3790  |  Loss: 0.5684  |  Score: 70.11 [%]  |  Seq Length: 256.0
[2024-10-15 14:44:43,061][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 14:44:43,062][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:44:47,811][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 14:44:47,811][root][INFO] - Score: 64.67 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 14:44:47,813][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 14:44:47,814][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 14:48:31,535][root][INFO] - Step: 1137/3790  |  Loss: 0.5130  |  Score: 74.31 [%]  |  Seq Length: 256.0
[2024-10-15 14:48:36,200][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 14:48:36,200][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 14:48:40,833][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 14:48:40,834][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:48:40,835][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 14:48:40,836][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 14:49:24,500][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-15 14:52:17,965][root][INFO] - Step: 8440/10550  |  Loss: 0.2170  |  Score: 91.11 [%]  |  Seq Length: 256.0
[2024-10-15 14:52:23,640][root][INFO] - Step: 1516/3790  |  Loss: 0.4611  |  Score: 77.89 [%]  |  Seq Length: 256.0
[2024-10-15 14:52:28,269][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 14:52:28,270][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:52:32,870][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 14:52:32,870][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 14:52:32,871][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 14:52:32,872][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 14:53:11,355][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 14:53:11,355][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 53.39 [s]
[2024-10-15 14:56:08,996][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 14:56:08,996][root][INFO] - Score: 88.79 [%]  |  Evaluation Time: 177.64 [s]
[2024-10-15 14:56:08,997][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 14:56:08,998][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 14:56:15,418][root][INFO] - Step: 1895/3790  |  Loss: 0.4025  |  Score: 81.25 [%]  |  Seq Length: 256.0
[2024-10-15 14:56:20,122][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 14:56:20,122][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:56:24,751][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 14:56:24,751][root][INFO] - Score: 65.55 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:56:24,754][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 15:00:07,436][root][INFO] - Step: 2274/3790  |  Loss: 0.3566  |  Score: 83.93 [%]  |  Seq Length: 256.0
[2024-10-15 15:00:12,211][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 15:00:12,211][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-15 15:00:16,832][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 15:00:16,832][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:00:16,835][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 15:04:00,200][root][INFO] - Step: 2653/3790  |  Loss: 0.3011  |  Score: 86.48 [%]  |  Seq Length: 256.0
[2024-10-15 15:04:04,938][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 15:04:04,938][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-15 15:04:09,558][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 15:04:09,558][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:04:09,560][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 15:07:52,105][root][INFO] - Step: 3032/3790  |  Loss: 0.2530  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-15 15:07:56,796][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 15:07:56,797][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 15:08:01,427][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 15:08:01,427][root][INFO] - Score: 67.99 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:08:01,429][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 15:09:17,191][root][INFO] - Step: 10000/10550  |  Loss: 0.1949  |  Score: 92.12 [%]  |  Seq Length: 256.0
[2024-10-15 15:11:44,185][root][INFO] - Step: 3411/3790  |  Loss: 0.2240  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-15 15:11:48,875][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 15:11:48,875][root][INFO] - Score: 68.85 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 15:11:53,494][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 15:11:53,494][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:11:53,497][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 15:13:56,354][root][INFO] - Step: 10550/10550  |  Loss: 0.1925  |  Score: 92.37 [%]  |  Seq Length: 256.0
[2024-10-15 15:14:49,739][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 15:14:49,739][root][INFO] - Score: 88.95 [%]  |  Evaluation Time: 53.38 [s]
[2024-10-15 15:15:36,277][root][INFO] - Step: 3790/3790  |  Loss: 0.2060  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-15 15:15:40,907][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 15:15:40,907][root][INFO] - Score: 70.21 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:15:45,484][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 15:15:45,484][root][INFO] - Score: 67.39 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 15:15:45,485][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 15:15:45,485][root][INFO] - - Epoch: 4
[2024-10-15 15:15:45,485][root][INFO] - - DEV score: 70.02 [%]
[2024-10-15 15:15:45,485][root][INFO] - - TEST score: 67.80 [%]
[2024-10-15 15:15:45,487][root][INFO] - Fine-tuning is done!
[2024-10-15 15:15:45,487][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 15:15:45,487][root][INFO] - - BEST LR: 0.01
[2024-10-15 15:15:45,488][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 15:15:45,488][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 15:15:51,682][root][INFO] - 

[2024-10-15 15:15:51,682][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 15:15:51,682][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 15:15:51,682][root][INFO] - 

[2024-10-15 15:15:51,683][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 15:15:59,889][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,890][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,891][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,891][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,892][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,892][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,893][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,893][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,894][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,895][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,895][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,896][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,896][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,897][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,897][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,898][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,898][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,899][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,899][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,900][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,903][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,904][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,904][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,905][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,907][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 15:15:59,912][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 15:16:00,117][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 15:16:00,119][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 15:16:00,306][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 15:16:03,599][root][INFO] - 

[2024-10-15 15:16:03,599][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 15:16:03,599][root][INFO] - Data Preprocessing
[2024-10-15 15:16:03,599][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 15:16:03,599][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 15:16:03,599][root][INFO] - ㄴ data_remove                True

[2024-10-15 15:16:03,599][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 15:16:03,607][root][INFO] - vocab size              : 51200
[2024-10-15 15:16:03,607][root][INFO] - device                  : gpu
[2024-10-15 15:16:03,608][root][INFO] - random seed             : 2
[2024-10-15 15:16:03,608][root][INFO] - train data size         : 24256
[2024-10-15 15:16:03,608][root][INFO] - max epochs              : 10
[2024-10-15 15:16:03,608][root][INFO] - total steps             : 3790
[2024-10-15 15:16:03,608][root][INFO] - warmup steps            : 379
[2024-10-15 15:16:03,608][root][INFO] - batch size              : 64
[2024-10-15 15:16:03,608][root][INFO] - accumulation steps      : 1
[2024-10-15 15:16:03,608][root][INFO] - optimizer               : adamwscale
[2024-10-15 15:16:03,608][root][INFO] - lr_scheduler            : cosine
[2024-10-15 15:16:03,608][root][INFO] - learning rate           : 0.01
[2024-10-15 15:16:03,609][root][INFO] - max length              : 256

[2024-10-15 15:16:03,609][root][INFO] - LoRA Configuration
[2024-10-15 15:16:03,609][root][INFO] - ㄴ r                    : 32
[2024-10-15 15:16:03,609][root][INFO] - ㄴ alpha                : 128
[2024-10-15 15:16:03,609][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 15:16:03,609][root][INFO] - KOMBO Configuration
[2024-10-15 15:16:03,609][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 15:16:03,609][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 15:16:03,609][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 15:16:03,609][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 15:16:03,609][root][INFO] - ㄴ do_combination       : True
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 15:16:03,610][root][INFO] - 

[2024-10-15 15:16:03,610][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 15:16:03,610][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 15:16:03,610][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 15:16:03,610][root][INFO] - * tb interval   : 10000

[2024-10-15 15:16:03,610][root][INFO] - 

[2024-10-15 15:16:03,610][root][INFO] - Start the Training !
[2024-10-15 15:16:03,614][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 15:17:47,343][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 15:17:47,344][root][INFO] - Score: 88.85 [%]  |  Evaluation Time: 177.60 [s]
[2024-10-15 15:17:47,345][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 15:17:47,345][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 15:17:47,345][root][INFO] - - Epoch: 5
[2024-10-15 15:17:47,345][root][INFO] - - DEV score: 88.95 [%]
[2024-10-15 15:17:47,345][root][INFO] - - TEST score: 88.85 [%]
[2024-10-15 15:17:47,346][root][INFO] - Fine-tuning is done!
[2024-10-15 15:18:09,775][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,776][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,776][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,777][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,778][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,779][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,779][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,780][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,781][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,781][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,782][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,783][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,784][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,784][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,785][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,786][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,786][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,787][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,787][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,788][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,789][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,789][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,790][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,790][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,792][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 15:18:10,072][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 15:18:10,075][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 15:18:10,076][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 15:18:10,295][root][INFO] - 

[2024-10-15 15:18:10,295][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 15:18:10,295][root][INFO] - Data Preprocessing
[2024-10-15 15:18:10,295][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 15:18:10,295][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 15:18:10,295][root][INFO] - ㄴ data_remove                False

[2024-10-15 15:18:10,295][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 15:18:10,304][root][INFO] - vocab size              : 51200
[2024-10-15 15:18:10,305][root][INFO] - device                  : gpu
[2024-10-15 15:18:10,305][root][INFO] - random seed             : 3
[2024-10-15 15:18:10,305][root][INFO] - train data size         : 135040
[2024-10-15 15:18:10,305][root][INFO] - max epochs              : 5
[2024-10-15 15:18:10,305][root][INFO] - total steps             : 10550
[2024-10-15 15:18:10,305][root][INFO] - warmup steps            : 1055
[2024-10-15 15:18:10,305][root][INFO] - batch size              : 64
[2024-10-15 15:18:10,305][root][INFO] - accumulation steps      : 1
[2024-10-15 15:18:10,305][root][INFO] - optimizer               : adamwscale
[2024-10-15 15:18:10,306][root][INFO] - lr_scheduler            : cosine
[2024-10-15 15:18:10,306][root][INFO] - learning rate           : 0.02
[2024-10-15 15:18:10,306][root][INFO] - max length              : 256

[2024-10-15 15:18:10,306][root][INFO] - LoRA Configuration
[2024-10-15 15:18:10,306][root][INFO] - ㄴ r                    : 32
[2024-10-15 15:18:10,306][root][INFO] - ㄴ alpha                : 128
[2024-10-15 15:18:10,306][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 15:18:10,306][root][INFO] - KOMBO Configuration
[2024-10-15 15:18:10,306][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 15:18:10,306][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 15:18:10,306][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 15:18:10,307][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 15:18:10,307][root][INFO] - ㄴ do_combination       : True
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 15:18:10,307][root][INFO] - 

[2024-10-15 15:18:10,307][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 15:18:10,307][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 15:18:10,307][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 15:18:10,307][root][INFO] - * tb interval   : 10000

[2024-10-15 15:18:10,308][root][INFO] - 

[2024-10-15 15:18:10,308][root][INFO] - Start the Training !
[2024-10-15 15:18:10,310][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 15:19:45,939][root][INFO] - Step: 379/3790  |  Loss: 0.6820  |  Score: 57.01 [%]  |  Seq Length: 256.0
[2024-10-15 15:19:50,723][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 15:19:50,723][root][INFO] - Score: 62.79 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 15:19:55,319][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 15:19:55,320][root][INFO] - Score: 59.45 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 15:19:55,321][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 15:19:55,323][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 15:23:37,251][root][INFO] - Step: 758/3790  |  Loss: 0.5809  |  Score: 69.35 [%]  |  Seq Length: 256.0
[2024-10-15 15:23:41,938][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 15:23:41,938][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 15:23:46,555][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 15:23:46,555][root][INFO] - Score: 62.75 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 15:23:46,556][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 15:23:46,558][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 15:27:27,272][root][INFO] - Step: 1137/3790  |  Loss: 0.5210  |  Score: 74.19 [%]  |  Seq Length: 256.0
[2024-10-15 15:27:31,904][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 15:27:31,904][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:27:36,469][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 15:27:36,469][root][INFO] - Score: 64.53 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 15:27:36,470][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 15:27:36,471][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 15:31:18,136][root][INFO] - Step: 1516/3790  |  Loss: 0.4662  |  Score: 77.42 [%]  |  Seq Length: 256.0
[2024-10-15 15:31:22,811][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 15:31:22,811][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 15:31:27,409][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 15:31:27,410][root][INFO] - Score: 65.94 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 15:31:27,412][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 15:35:09,188][root][INFO] - Step: 1895/3790  |  Loss: 0.4199  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-15 15:35:13,855][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 15:35:13,855][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 15:35:18,422][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 15:35:18,423][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 15:35:18,424][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 15:35:18,425][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 15:36:03,811][root][INFO] - Step: 2110/10550  |  Loss: 0.3661  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-15 15:36:57,123][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 15:36:57,123][root][INFO] - Score: 86.43 [%]  |  Evaluation Time: 53.31 [s]
[2024-10-15 15:39:00,427][root][INFO] - Step: 2274/3790  |  Loss: 0.3750  |  Score: 82.67 [%]  |  Seq Length: 256.0
[2024-10-15 15:39:05,227][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 15:39:05,228][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 15:39:09,905][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 15:39:09,905][root][INFO] - Score: 66.42 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 15:39:09,908][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 15:39:54,748][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 15:39:54,748][root][INFO] - Score: 86.50 [%]  |  Evaluation Time: 177.62 [s]
[2024-10-15 15:39:54,750][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 15:39:54,751][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 15:42:51,759][root][INFO] - Step: 2653/3790  |  Loss: 0.3405  |  Score: 84.53 [%]  |  Seq Length: 256.0
[2024-10-15 15:42:56,422][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 15:42:56,423][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 15:43:00,981][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 15:43:00,981][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 15:43:00,983][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 15:46:40,218][root][INFO] - Step: 3032/3790  |  Loss: 0.3098  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-15 15:46:44,808][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 15:46:44,808][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 15:46:49,314][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 15:46:49,314][root][INFO] - Score: 68.67 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-15 15:46:49,315][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 15:46:49,316][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 15:50:33,653][root][INFO] - Step: 3411/3790  |  Loss: 0.2952  |  Score: 86.68 [%]  |  Seq Length: 256.0
[2024-10-15 15:50:38,278][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 15:50:38,278][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:50:42,803][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 15:50:42,803][root][INFO] - Score: 67.27 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 15:50:42,805][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 15:54:25,191][root][INFO] - Step: 3790/3790  |  Loss: 0.2806  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-15 15:54:29,828][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 15:54:29,828][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:54:34,398][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 15:54:34,398][root][INFO] - Score: 68.42 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 15:54:34,399][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 15:54:34,400][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 15:54:34,400][root][INFO] - - Epoch: 10
[2024-10-15 15:54:34,400][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 15:54:34,400][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 15:54:34,400][root][INFO] - Fine-tuning is done!
[2024-10-15 15:54:41,173][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,174][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,175][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,175][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,176][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,177][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,177][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,178][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,178][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,179][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,179][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,180][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,181][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,181][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,182][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,182][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,183][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,183][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,184][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,184][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,185][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,185][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,186][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,186][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,188][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 15:54:41,395][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 15:54:41,397][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 15:54:41,398][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 15:54:41,568][root][INFO] - 

[2024-10-15 15:54:41,568][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 15:54:41,568][root][INFO] - Data Preprocessing
[2024-10-15 15:54:41,569][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 15:54:41,569][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 15:54:41,569][root][INFO] - ㄴ data_remove                True

[2024-10-15 15:54:41,569][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 15:54:41,577][root][INFO] - vocab size              : 51200
[2024-10-15 15:54:41,577][root][INFO] - device                  : gpu
[2024-10-15 15:54:41,577][root][INFO] - random seed             : 2
[2024-10-15 15:54:41,577][root][INFO] - train data size         : 24256
[2024-10-15 15:54:41,577][root][INFO] - max epochs              : 10
[2024-10-15 15:54:41,577][root][INFO] - total steps             : 3790
[2024-10-15 15:54:41,577][root][INFO] - warmup steps            : 379
[2024-10-15 15:54:41,577][root][INFO] - batch size              : 64
[2024-10-15 15:54:41,578][root][INFO] - accumulation steps      : 1
[2024-10-15 15:54:41,578][root][INFO] - optimizer               : adamwscale
[2024-10-15 15:54:41,578][root][INFO] - lr_scheduler            : cosine
[2024-10-15 15:54:41,578][root][INFO] - learning rate           : 0.02
[2024-10-15 15:54:41,578][root][INFO] - max length              : 256

[2024-10-15 15:54:41,578][root][INFO] - LoRA Configuration
[2024-10-15 15:54:41,578][root][INFO] - ㄴ r                    : 32
[2024-10-15 15:54:41,578][root][INFO] - ㄴ alpha                : 128
[2024-10-15 15:54:41,578][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 15:54:41,578][root][INFO] - KOMBO Configuration
[2024-10-15 15:54:41,578][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 15:54:41,579][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 15:54:41,579][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 15:54:41,579][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 15:54:41,579][root][INFO] - ㄴ do_combination       : True
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 15:54:41,579][root][INFO] - 

[2024-10-15 15:54:41,579][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 15:54:41,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 15:54:41,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 15:54:41,580][root][INFO] - * tb interval   : 10000

[2024-10-15 15:54:41,580][root][INFO] - 

[2024-10-15 15:54:41,580][root][INFO] - Start the Training !
[2024-10-15 15:54:41,582][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 15:57:44,068][root][INFO] - Step: 4220/10550  |  Loss: 0.3149  |  Score: 86.50 [%]  |  Seq Length: 256.0
[2024-10-15 15:58:24,547][root][INFO] - Step: 379/3790  |  Loss: 0.6703  |  Score: 59.12 [%]  |  Seq Length: 256.0
[2024-10-15 15:58:29,297][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 15:58:29,297][root][INFO] - Score: 66.41 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 15:58:33,928][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 15:58:33,928][root][INFO] - Score: 59.91 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:58:33,930][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 15:58:33,931][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 15:58:37,184][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 15:58:37,184][root][INFO] - Score: 87.29 [%]  |  Evaluation Time: 53.11 [s]
[2024-10-15 16:01:33,146][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 16:01:33,147][root][INFO] - Score: 87.03 [%]  |  Evaluation Time: 175.96 [s]
[2024-10-15 16:01:33,148][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 16:01:33,149][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 16:02:16,818][root][INFO] - Step: 758/3790  |  Loss: 0.5669  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-15 16:02:21,611][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 16:02:21,611][root][INFO] - Score: 67.58 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 16:02:26,248][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 16:02:26,248][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 16:02:26,249][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 16:02:26,250][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 16:06:09,275][root][INFO] - Step: 1137/3790  |  Loss: 0.5082  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-15 16:06:14,015][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 16:06:14,015][root][INFO] - Score: 65.53 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-15 16:06:18,737][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 16:06:18,737][root][INFO] - Score: 67.04 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 16:06:18,739][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 16:08:25,851][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-15 16:08:36,173][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:08:36,173][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.32 [s]
[2024-10-15 16:08:56,360][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:08:56,360][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.18 [s]
[2024-10-15 16:08:56,363][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 16:10:01,824][root][INFO] - Step: 1516/3790  |  Loss: 0.4569  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-15 16:10:06,671][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:10:06,672][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-15 16:10:11,348][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:10:11,348][root][INFO] - Score: 66.84 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 16:10:11,349][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 16:10:11,350][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 16:13:54,775][root][INFO] - Step: 1895/3790  |  Loss: 0.4079  |  Score: 81.11 [%]  |  Seq Length: 256.0
[2024-10-15 16:13:59,495][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 16:13:59,495][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 16:14:04,231][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 16:14:04,232][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 16:14:04,233][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 16:14:04,234][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 16:17:47,048][root][INFO] - Step: 2274/3790  |  Loss: 0.3487  |  Score: 84.15 [%]  |  Seq Length: 256.0
[2024-10-15 16:17:51,877][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 16:17:51,878][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-15 16:17:56,589][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 16:17:56,589][root][INFO] - Score: 68.03 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 16:17:56,591][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 16:17:56,592][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 16:18:22,910][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-15 16:19:25,244][root][INFO] - Step: 6330/10550  |  Loss: 0.2820  |  Score: 88.07 [%]  |  Seq Length: 256.0
[2024-10-15 16:20:18,572][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 16:20:18,572][root][INFO] - Score: 88.03 [%]  |  Evaluation Time: 53.33 [s]
[2024-10-15 16:21:40,276][root][INFO] - Step: 2653/3790  |  Loss: 0.2954  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-15 16:21:45,055][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 16:21:45,055][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 16:21:49,743][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 16:21:49,743][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 16:21:49,745][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-15 16:21:49,746][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 16:23:15,825][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 16:23:15,825][root][INFO] - Score: 87.82 [%]  |  Evaluation Time: 177.25 [s]
[2024-10-15 16:23:15,826][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 16:23:15,827][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 16:25:34,098][root][INFO] - Step: 3032/3790  |  Loss: 0.2463  |  Score: 89.20 [%]  |  Seq Length: 256.0
[2024-10-15 16:25:38,921][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 16:25:38,922][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-15 16:25:43,707][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 16:25:43,708][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 16:25:43,712][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 16:29:26,372][root][INFO] - Step: 3411/3790  |  Loss: 0.2186  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-15 16:29:31,074][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 16:29:31,074][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 16:29:35,713][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 16:29:35,713][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 16:29:35,715][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 16:33:18,260][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-15 16:33:22,960][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 16:33:22,960][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 16:33:27,712][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 16:33:27,713][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 16:33:27,714][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 16:33:27,714][root][INFO] - - Epoch: 7
[2024-10-15 16:33:27,714][root][INFO] - - DEV score: 71.29 [%]
[2024-10-15 16:33:27,715][root][INFO] - - TEST score: 69.32 [%]
[2024-10-15 16:33:27,716][root][INFO] - Fine-tuning is done!
[2024-10-15 16:33:27,716][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 16:33:27,716][root][INFO] - - BEST LR: 0.01
[2024-10-15 16:33:27,716][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 16:33:27,716][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 16:33:34,156][root][INFO] - 

[2024-10-15 16:33:34,156][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 16:33:34,156][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 16:33:34,156][root][INFO] - 

[2024-10-15 16:33:34,157][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 16:33:42,711][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,712][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,712][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,713][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,713][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,714][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,714][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,715][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,716][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,716][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,717][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,717][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,718][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,718][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,719][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,720][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,720][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,721][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,721][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,722][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,724][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,724][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,725][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,726][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,728][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 16:33:42,733][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 16:33:42,941][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 16:33:42,944][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 16:33:43,130][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 16:33:46,095][root][INFO] - 

[2024-10-15 16:33:46,095][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 16:33:46,095][root][INFO] - Data Preprocessing
[2024-10-15 16:33:46,095][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 16:33:46,095][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 16:33:46,095][root][INFO] - ㄴ data_remove                True

[2024-10-15 16:33:46,095][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 16:33:46,103][root][INFO] - vocab size              : 51200
[2024-10-15 16:33:46,103][root][INFO] - device                  : gpu
[2024-10-15 16:33:46,103][root][INFO] - random seed             : 3
[2024-10-15 16:33:46,103][root][INFO] - train data size         : 24256
[2024-10-15 16:33:46,104][root][INFO] - max epochs              : 10
[2024-10-15 16:33:46,104][root][INFO] - total steps             : 3790
[2024-10-15 16:33:46,104][root][INFO] - warmup steps            : 379
[2024-10-15 16:33:46,104][root][INFO] - batch size              : 64
[2024-10-15 16:33:46,104][root][INFO] - accumulation steps      : 1
[2024-10-15 16:33:46,104][root][INFO] - optimizer               : adamwscale
[2024-10-15 16:33:46,104][root][INFO] - lr_scheduler            : cosine
[2024-10-15 16:33:46,104][root][INFO] - learning rate           : 0.01
[2024-10-15 16:33:46,104][root][INFO] - max length              : 256

[2024-10-15 16:33:46,104][root][INFO] - LoRA Configuration
[2024-10-15 16:33:46,104][root][INFO] - ㄴ r                    : 32
[2024-10-15 16:33:46,104][root][INFO] - ㄴ alpha                : 128
[2024-10-15 16:33:46,105][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 16:33:46,105][root][INFO] - KOMBO Configuration
[2024-10-15 16:33:46,105][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 16:33:46,105][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 16:33:46,105][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 16:33:46,105][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 16:33:46,105][root][INFO] - ㄴ do_combination       : True
[2024-10-15 16:33:46,105][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 16:33:46,105][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 16:33:46,105][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 16:33:46,106][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 16:33:46,106][root][INFO] - 

[2024-10-15 16:33:46,106][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 16:33:46,106][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 16:33:46,106][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 16:33:46,106][root][INFO] - * tb interval   : 10000

[2024-10-15 16:33:46,106][root][INFO] - 

[2024-10-15 16:33:46,106][root][INFO] - Start the Training !
[2024-10-15 16:33:46,109][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 16:37:29,820][root][INFO] - Step: 379/3790  |  Loss: 0.6791  |  Score: 57.91 [%]  |  Seq Length: 256.0
[2024-10-15 16:37:34,480][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 16:37:34,480][root][INFO] - Score: 61.13 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 16:37:39,051][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 16:37:39,051][root][INFO] - Score: 60.72 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 16:37:39,052][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 16:37:39,053][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 16:41:10,836][root][INFO] - Step: 8440/10550  |  Loss: 0.2389  |  Score: 90.16 [%]  |  Seq Length: 256.0
[2024-10-15 16:41:22,603][root][INFO] - Step: 758/3790  |  Loss: 0.5750  |  Score: 69.89 [%]  |  Seq Length: 256.0
[2024-10-15 16:41:27,302][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 16:41:27,302][root][INFO] - Score: 66.02 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 16:41:32,037][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 16:41:32,037][root][INFO] - Score: 64.05 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 16:41:32,039][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 16:41:32,040][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 16:42:05,028][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:42:05,029][root][INFO] - Score: 88.90 [%]  |  Evaluation Time: 54.19 [s]
[2024-10-15 16:45:02,446][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:45:02,447][root][INFO] - Score: 88.55 [%]  |  Evaluation Time: 177.42 [s]
[2024-10-15 16:45:02,448][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 16:45:02,449][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 16:45:15,031][root][INFO] - Step: 1137/3790  |  Loss: 0.5122  |  Score: 74.67 [%]  |  Seq Length: 256.0
[2024-10-15 16:45:19,677][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 16:45:19,678][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 16:45:24,426][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 16:45:24,426][root][INFO] - Score: 64.39 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 16:45:24,427][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 16:45:24,429][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 16:49:06,695][root][INFO] - Step: 1516/3790  |  Loss: 0.4581  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-15 16:49:11,391][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:49:11,391][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 16:49:16,026][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:49:16,026][root][INFO] - Score: 63.62 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 16:49:16,029][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 16:52:59,474][root][INFO] - Step: 1895/3790  |  Loss: 0.4133  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-15 16:53:04,192][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 16:53:04,192][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 16:53:08,791][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 16:53:08,791][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 16:53:08,792][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 16:53:08,794][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 16:56:51,971][root][INFO] - Step: 2274/3790  |  Loss: 0.3714  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-15 16:56:56,666][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 16:56:56,667][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 16:57:01,303][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 16:57:01,303][root][INFO] - Score: 65.54 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 16:57:01,305][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 16:58:11,437][root][INFO] - Step: 10000/10550  |  Loss: 0.1991  |  Score: 91.97 [%]  |  Seq Length: 256.0
[2024-10-15 17:00:47,463][root][INFO] - Step: 2653/3790  |  Loss: 0.3333  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-15 17:00:52,179][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 17:00:52,179][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 17:00:56,783][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 17:00:56,783][root][INFO] - Score: 65.60 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 17:00:56,785][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 17:02:51,862][root][INFO] - Step: 10550/10550  |  Loss: 0.1941  |  Score: 92.22 [%]  |  Seq Length: 256.0
[2024-10-15 17:03:45,782][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 17:03:45,782][root][INFO] - Score: 88.90 [%]  |  Evaluation Time: 53.92 [s]
[2024-10-15 17:04:40,659][root][INFO] - Step: 3032/3790  |  Loss: 0.3040  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-15 17:04:45,360][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 17:04:45,360][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 17:04:49,997][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 17:04:49,997][root][INFO] - Score: 66.08 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 17:04:49,998][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 17:04:50,000][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 17:06:43,942][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 17:06:43,942][root][INFO] - Score: 88.72 [%]  |  Evaluation Time: 178.16 [s]
[2024-10-15 17:06:43,944][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 17:06:43,944][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 17:06:43,944][root][INFO] - - Epoch: 5
[2024-10-15 17:06:43,944][root][INFO] - - DEV score: 88.90 [%]
[2024-10-15 17:06:43,944][root][INFO] - - TEST score: 88.72 [%]
[2024-10-15 17:06:43,945][root][INFO] - Fine-tuning is done!
[2024-10-15 17:06:43,945][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 17:06:43,946][root][INFO] - - BEST LR: 0.01
[2024-10-15 17:06:43,946][root][INFO] - - DEV score: 88.95 [%]
[2024-10-15 17:06:43,946][root][INFO] - - TEST score: 88.85 [%]
[2024-10-15 17:08:33,131][root][INFO] - Step: 3411/3790  |  Loss: 0.2838  |  Score: 87.23 [%]  |  Seq Length: 256.0
[2024-10-15 17:08:37,821][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 17:08:37,822][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 17:08:42,402][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 17:08:42,402][root][INFO] - Score: 65.73 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 17:08:42,404][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 17:12:25,809][root][INFO] - Step: 3790/3790  |  Loss: 0.2712  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-15 17:12:30,572][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 17:12:30,572][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-15 17:12:35,152][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 17:12:35,152][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 17:12:35,153][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 17:12:35,153][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 17:12:35,153][root][INFO] - - Epoch: 10
[2024-10-15 17:12:35,154][root][INFO] - - DEV score: 72.85 [%]
[2024-10-15 17:12:35,154][root][INFO] - - TEST score: 65.70 [%]
[2024-10-15 17:12:35,154][root][INFO] - Fine-tuning is done!
[2024-10-15 17:12:42,164][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,164][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,165][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,166][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,167][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,168][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,169][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,170][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,170][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,171][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,172][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,173][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,175][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,176][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,177][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,178][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,179][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,180][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,181][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,183][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,184][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,186][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,187][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,188][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,191][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 17:12:42,420][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 17:12:42,423][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 17:12:42,424][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 17:12:42,540][root][INFO] - 

[2024-10-15 17:12:42,540][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 17:12:42,540][root][INFO] - Data Preprocessing
[2024-10-15 17:12:42,540][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 17:12:42,541][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 17:12:42,541][root][INFO] - ㄴ data_remove                True

[2024-10-15 17:12:42,541][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 17:12:42,549][root][INFO] - vocab size              : 51200
[2024-10-15 17:12:42,550][root][INFO] - device                  : gpu
[2024-10-15 17:12:42,550][root][INFO] - random seed             : 3
[2024-10-15 17:12:42,550][root][INFO] - train data size         : 24256
[2024-10-15 17:12:42,550][root][INFO] - max epochs              : 10
[2024-10-15 17:12:42,550][root][INFO] - total steps             : 3790
[2024-10-15 17:12:42,550][root][INFO] - warmup steps            : 379
[2024-10-15 17:12:42,550][root][INFO] - batch size              : 64
[2024-10-15 17:12:42,550][root][INFO] - accumulation steps      : 1
[2024-10-15 17:12:42,550][root][INFO] - optimizer               : adamwscale
[2024-10-15 17:12:42,550][root][INFO] - lr_scheduler            : cosine
[2024-10-15 17:12:42,551][root][INFO] - learning rate           : 0.02
[2024-10-15 17:12:42,551][root][INFO] - max length              : 256

[2024-10-15 17:12:42,551][root][INFO] - LoRA Configuration
[2024-10-15 17:12:42,551][root][INFO] - ㄴ r                    : 32
[2024-10-15 17:12:42,551][root][INFO] - ㄴ alpha                : 128
[2024-10-15 17:12:42,551][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 17:12:42,551][root][INFO] - KOMBO Configuration
[2024-10-15 17:12:42,551][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 17:12:42,551][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 17:12:42,551][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 17:12:42,551][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 17:12:42,552][root][INFO] - ㄴ do_combination       : True
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 17:12:42,552][root][INFO] - 

[2024-10-15 17:12:42,552][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 17:12:42,552][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 17:12:42,552][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 17:12:42,552][root][INFO] - * tb interval   : 10000

[2024-10-15 17:12:42,553][root][INFO] - 

[2024-10-15 17:12:42,553][root][INFO] - Start the Training !
[2024-10-15 17:12:42,555][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 17:16:26,251][root][INFO] - Step: 379/3790  |  Loss: 0.6607  |  Score: 60.10 [%]  |  Seq Length: 256.0
[2024-10-15 17:16:31,025][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 17:16:31,025][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-15 17:16:35,704][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 17:16:35,704][root][INFO] - Score: 60.64 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 17:16:35,706][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 17:16:35,707][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 17:20:19,572][root][INFO] - Step: 758/3790  |  Loss: 0.5616  |  Score: 71.12 [%]  |  Seq Length: 256.0
[2024-10-15 17:20:24,455][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 17:20:24,455][root][INFO] - Score: 65.04 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-15 17:20:29,239][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 17:20:29,239][root][INFO] - Score: 62.68 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 17:20:29,242][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 17:24:12,865][root][INFO] - Step: 1137/3790  |  Loss: 0.4997  |  Score: 75.63 [%]  |  Seq Length: 256.0
[2024-10-15 17:24:17,671][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 17:24:17,671][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 17:24:22,362][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 17:24:22,362][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 17:24:22,363][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 17:24:22,365][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 17:28:04,185][root][INFO] - Step: 1516/3790  |  Loss: 0.4472  |  Score: 78.90 [%]  |  Seq Length: 256.0
[2024-10-15 17:28:08,985][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 17:28:08,985][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 17:28:13,721][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 17:28:13,721][root][INFO] - Score: 66.80 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 17:28:13,722][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 17:28:13,723][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 17:31:55,978][root][INFO] - Step: 1895/3790  |  Loss: 0.3977  |  Score: 81.23 [%]  |  Seq Length: 256.0
[2024-10-15 17:32:00,786][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 17:32:00,786][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 17:32:05,496][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 17:32:05,496][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 17:32:05,497][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 17:32:05,498][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 17:35:48,362][root][INFO] - Step: 2274/3790  |  Loss: 0.3445  |  Score: 84.26 [%]  |  Seq Length: 256.0
[2024-10-15 17:35:53,171][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 17:35:53,171][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-15 17:35:57,843][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 17:35:57,843][root][INFO] - Score: 66.36 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 17:35:57,845][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 17:39:40,291][root][INFO] - Step: 2653/3790  |  Loss: 0.2995  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-15 17:39:45,075][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 17:39:45,075][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 17:39:49,796][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 17:39:49,796][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 17:39:49,798][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 17:43:33,180][root][INFO] - Step: 3032/3790  |  Loss: 0.2495  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-15 17:43:37,947][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 17:43:37,947][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-15 17:43:42,676][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 17:43:42,676][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 17:43:42,677][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 17:43:42,679][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 17:46:47,228][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.26 [%]  |  Seq Length: 256.0
[2024-10-15 17:47:25,057][root][INFO] - Step: 3411/3790  |  Loss: 0.2111  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-15 17:47:29,786][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 17:47:29,787][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 17:47:34,536][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 17:47:34,536][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 17:47:34,538][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 17:51:16,233][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.52 [%]  |  Seq Length: 256.0
[2024-10-15 17:51:21,023][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 17:51:21,023][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 17:51:25,715][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 17:51:25,715][root][INFO] - Score: 68.36 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 17:51:25,716][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 17:51:25,716][root][INFO] - - Epoch: 8
[2024-10-15 17:51:25,716][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 17:51:25,716][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 17:51:25,717][root][INFO] - Fine-tuning is done!
[2024-10-15 17:51:25,718][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 17:51:25,718][root][INFO] - - BEST LR: 0.02
[2024-10-15 17:51:25,718][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 17:51:25,718][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 18:19:01,863][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.45 [%]  |  Seq Length: 256.0
[2024-10-15 18:19:12,079][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 18:19:12,080][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.21 [s]
[2024-10-15 18:19:32,065][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 18:19:32,065][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 19.98 [s]
[2024-10-15 18:19:32,066][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 18:19:32,066][root][INFO] - - Epoch: 1
[2024-10-15 18:19:32,066][root][INFO] - - DEV score: 56.10 [%]
[2024-10-15 18:19:32,066][root][INFO] - - TEST score: 56.93 [%]
[2024-10-15 18:19:32,067][root][INFO] - Fine-tuning is done!
[2024-10-15 18:19:32,068][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 18:19:32,068][root][INFO] - - BEST LR: 0.01
[2024-10-15 18:19:32,068][root][INFO] - - DEV score: 74.99 [%]
[2024-10-15 18:19:32,068][root][INFO] - - TEST score: 76.27 [%]
[2024-10-15 18:19:38,593][root][INFO] - 

[2024-10-15 18:19:38,594][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 18:19:38,594][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-15 18:19:38,594][root][INFO] - 

[2024-10-15 18:19:38,594][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 18:21:41,254][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,255][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,255][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,256][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,256][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,257][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,257][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,258][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,258][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,259][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,259][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,260][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,260][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,261][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,261][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,262][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,262][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,263][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,263][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,264][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,264][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,265][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,265][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,266][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,268][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-15 18:21:41,272][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 18:21:41,471][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 18:21:41,473][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-15 18:21:41,746][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 18:21:44,907][root][INFO] - 

[2024-10-15 18:21:44,907][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-15 18:21:44,907][root][INFO] - Data Preprocessing
[2024-10-15 18:21:44,907][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 18:21:44,908][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 18:21:44,908][root][INFO] - ㄴ data_remove                False

[2024-10-15 18:21:44,908][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 18:21:44,915][root][INFO] - vocab size              : 51200
[2024-10-15 18:21:44,915][root][INFO] - device                  : gpu
[2024-10-15 18:21:44,916][root][INFO] - random seed             : 2
[2024-10-15 18:21:44,916][root][INFO] - train data size         : 942912
[2024-10-15 18:21:44,916][root][INFO] - max epochs              : 5
[2024-10-15 18:21:44,916][root][INFO] - total steps             : 73665
[2024-10-15 18:21:44,916][root][INFO] - warmup steps            : 7366
[2024-10-15 18:21:44,916][root][INFO] - batch size              : 64
[2024-10-15 18:21:44,916][root][INFO] - accumulation steps      : 1
[2024-10-15 18:21:44,916][root][INFO] - optimizer               : adamwscale
[2024-10-15 18:21:44,916][root][INFO] - lr_scheduler            : cosine
[2024-10-15 18:21:44,916][root][INFO] - learning rate           : 0.01
[2024-10-15 18:21:44,916][root][INFO] - max length              : 256

[2024-10-15 18:21:44,916][root][INFO] - LoRA Configuration
[2024-10-15 18:21:44,917][root][INFO] - ㄴ r                    : 32
[2024-10-15 18:21:44,917][root][INFO] - ㄴ alpha                : 128
[2024-10-15 18:21:44,917][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 18:21:44,917][root][INFO] - KOMBO Configuration
[2024-10-15 18:21:44,917][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 18:21:44,917][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 18:21:44,917][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 18:21:44,917][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 18:21:44,917][root][INFO] - ㄴ do_combination       : True
[2024-10-15 18:21:44,917][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 18:21:44,918][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 18:21:44,918][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 18:21:44,918][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 18:21:44,918][root][INFO] - 

[2024-10-15 18:21:44,918][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-15 18:21:44,918][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 18:21:44,918][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 18:21:44,918][root][INFO] - * tb interval   : 10000

[2024-10-15 18:21:44,918][root][INFO] - 

[2024-10-15 18:21:44,918][root][INFO] - Start the Training !
[2024-10-15 18:21:44,921][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 19:46:05,733][root][INFO] - 

[2024-10-15 19:46:05,733][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 19:46:05,733][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 19:46:05,733][root][INFO] - 

[2024-10-15 19:46:05,733][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 19:46:13,476][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,477][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,477][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,478][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,479][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,479][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,479][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,480][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,480][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,481][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,481][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,482][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,482][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,483][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,483][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,484][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,484][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,485][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,485][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,485][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,487][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,487][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,488][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,488][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,490][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 19:46:13,494][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 19:46:13,732][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 19:46:13,734][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 19:46:13,912][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 19:46:16,998][root][INFO] - 

[2024-10-15 19:46:16,999][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 19:46:16,999][root][INFO] - Data Preprocessing
[2024-10-15 19:46:16,999][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 19:46:16,999][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 19:46:16,999][root][INFO] - ㄴ data_remove                True

[2024-10-15 19:46:16,999][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 19:46:17,007][root][INFO] - vocab size              : 51200
[2024-10-15 19:46:17,008][root][INFO] - device                  : gpu
[2024-10-15 19:46:17,008][root][INFO] - random seed             : 1
[2024-10-15 19:46:17,008][root][INFO] - train data size         : 24256
[2024-10-15 19:46:17,008][root][INFO] - max epochs              : 10
[2024-10-15 19:46:17,008][root][INFO] - total steps             : 3790
[2024-10-15 19:46:17,008][root][INFO] - warmup steps            : 379
[2024-10-15 19:46:17,008][root][INFO] - batch size              : 64
[2024-10-15 19:46:17,008][root][INFO] - accumulation steps      : 1
[2024-10-15 19:46:17,008][root][INFO] - optimizer               : adamwscale
[2024-10-15 19:46:17,009][root][INFO] - lr_scheduler            : cosine
[2024-10-15 19:46:17,009][root][INFO] - learning rate           : 0.01
[2024-10-15 19:46:17,009][root][INFO] - max length              : 256

[2024-10-15 19:46:17,009][root][INFO] - LoRA Configuration
[2024-10-15 19:46:17,009][root][INFO] - ㄴ r                    : 32
[2024-10-15 19:46:17,009][root][INFO] - ㄴ alpha                : 128
[2024-10-15 19:46:17,009][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 19:46:17,009][root][INFO] - KOMBO Configuration
[2024-10-15 19:46:17,009][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 19:46:17,009][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 19:46:17,009][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 19:46:17,010][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 19:46:17,010][root][INFO] - ㄴ do_combination       : True
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 19:46:17,010][root][INFO] - 

[2024-10-15 19:46:17,010][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 19:46:17,010][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 19:46:17,011][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 19:46:17,011][root][INFO] - * tb interval   : 10000

[2024-10-15 19:46:17,011][root][INFO] - 

[2024-10-15 19:46:17,011][root][INFO] - Start the Training !
[2024-10-15 19:46:17,014][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 19:49:57,912][root][INFO] - Step: 379/3790  |  Loss: 0.6989  |  Score: 54.10 [%]  |  Seq Length: 256.0
[2024-10-15 19:50:02,526][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 19:50:02,526][root][INFO] - Score: 58.98 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 19:50:07,049][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 19:50:07,049][root][INFO] - Score: 56.52 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 19:50:07,050][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 19:50:07,051][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 19:50:12,524][root][INFO] - Step: 10000/73665  |  Loss: 0.7335  |  Score: 68.28 [%]  |  Seq Length: 256.0
[2024-10-15 19:53:48,351][root][INFO] - Step: 758/3790  |  Loss: 0.5957  |  Score: 68.22 [%]  |  Seq Length: 256.0
[2024-10-15 19:53:52,961][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 19:53:52,961][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 19:53:57,481][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 19:53:57,482][root][INFO] - Score: 60.83 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 19:53:57,483][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 19:53:57,485][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 19:57:38,783][root][INFO] - Step: 1137/3790  |  Loss: 0.5221  |  Score: 73.95 [%]  |  Seq Length: 256.0
[2024-10-15 19:57:43,466][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 19:57:43,466][root][INFO] - Score: 65.33 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 19:57:48,016][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 19:57:48,016][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 19:57:48,017][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 19:57:48,019][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 20:01:29,338][root][INFO] - Step: 1516/3790  |  Loss: 0.4657  |  Score: 77.93 [%]  |  Seq Length: 256.0
[2024-10-15 20:01:34,118][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 20:01:34,118][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 20:01:38,691][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 20:01:38,691][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 20:01:38,692][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 20:01:38,694][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 20:05:20,689][root][INFO] - Step: 1895/3790  |  Loss: 0.4148  |  Score: 80.71 [%]  |  Seq Length: 256.0
[2024-10-15 20:05:25,337][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 20:05:25,337][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 20:05:29,889][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 20:05:29,890][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 20:05:29,891][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 20:05:29,892][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 20:09:11,853][root][INFO] - Step: 2274/3790  |  Loss: 0.3753  |  Score: 82.87 [%]  |  Seq Length: 256.0
[2024-10-15 20:09:16,492][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 20:09:16,492][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 20:09:21,058][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 20:09:21,058][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 20:09:21,059][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 20:09:21,061][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 20:13:02,907][root][INFO] - Step: 2653/3790  |  Loss: 0.3384  |  Score: 84.64 [%]  |  Seq Length: 256.0
[2024-10-15 20:13:07,531][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 20:13:07,532][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 20:13:12,081][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 20:13:12,081][root][INFO] - Score: 66.65 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 20:13:12,083][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 20:16:53,765][root][INFO] - Step: 3032/3790  |  Loss: 0.3095  |  Score: 86.36 [%]  |  Seq Length: 256.0
[2024-10-15 20:16:58,433][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 20:16:58,433][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:17:02,987][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 20:17:02,987][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 20:17:02,990][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 20:20:46,227][root][INFO] - Step: 3411/3790  |  Loss: 0.2896  |  Score: 87.03 [%]  |  Seq Length: 256.0
[2024-10-15 20:20:50,859][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 20:20:50,859][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 20:20:55,394][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 20:20:55,394][root][INFO] - Score: 66.61 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-15 20:20:55,397][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 20:24:37,315][root][INFO] - Step: 3790/3790  |  Loss: 0.2791  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-15 20:24:41,930][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 20:24:41,930][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 20:24:46,490][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 20:24:46,490][root][INFO] - Score: 67.19 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 20:24:46,491][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 20:24:46,491][root][INFO] - - Epoch: 6
[2024-10-15 20:24:46,491][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 20:24:46,491][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 20:24:46,492][root][INFO] - Fine-tuning is done!
[2024-10-15 20:24:53,270][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,271][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,271][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,272][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,272][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,273][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,274][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,274][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,275][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,275][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,276][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,277][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,277][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,278][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,279][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,279][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,279][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,280][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,280][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,281][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,281][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,281][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,282][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,282][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,284][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 20:24:53,509][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 20:24:53,511][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 20:24:53,513][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 20:24:53,682][root][INFO] - 

[2024-10-15 20:24:53,683][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 20:24:53,683][root][INFO] - Data Preprocessing
[2024-10-15 20:24:53,683][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 20:24:53,683][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 20:24:53,683][root][INFO] - ㄴ data_remove                True

[2024-10-15 20:24:53,683][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 20:24:53,692][root][INFO] - vocab size              : 51200
[2024-10-15 20:24:53,692][root][INFO] - device                  : gpu
[2024-10-15 20:24:53,693][root][INFO] - random seed             : 1
[2024-10-15 20:24:53,693][root][INFO] - train data size         : 24256
[2024-10-15 20:24:53,693][root][INFO] - max epochs              : 10
[2024-10-15 20:24:53,693][root][INFO] - total steps             : 3790
[2024-10-15 20:24:53,693][root][INFO] - warmup steps            : 379
[2024-10-15 20:24:53,693][root][INFO] - batch size              : 64
[2024-10-15 20:24:53,693][root][INFO] - accumulation steps      : 1
[2024-10-15 20:24:53,693][root][INFO] - optimizer               : adamwscale
[2024-10-15 20:24:53,693][root][INFO] - lr_scheduler            : cosine
[2024-10-15 20:24:53,693][root][INFO] - learning rate           : 0.02
[2024-10-15 20:24:53,693][root][INFO] - max length              : 256

[2024-10-15 20:24:53,693][root][INFO] - LoRA Configuration
[2024-10-15 20:24:53,694][root][INFO] - ㄴ r                    : 32
[2024-10-15 20:24:53,694][root][INFO] - ㄴ alpha                : 128
[2024-10-15 20:24:53,694][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 20:24:53,694][root][INFO] - KOMBO Configuration
[2024-10-15 20:24:53,694][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 20:24:53,694][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 20:24:53,694][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 20:24:53,694][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 20:24:53,694][root][INFO] - ㄴ do_combination       : True
[2024-10-15 20:24:53,694][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 20:24:53,695][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 20:24:53,695][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 20:24:53,695][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 20:24:53,695][root][INFO] - 

[2024-10-15 20:24:53,695][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 20:24:53,695][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 20:24:53,695][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 20:24:53,695][root][INFO] - * tb interval   : 10000

[2024-10-15 20:24:53,695][root][INFO] - 

[2024-10-15 20:24:53,695][root][INFO] - Start the Training !
[2024-10-15 20:24:53,698][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 20:28:36,469][root][INFO] - Step: 379/3790  |  Loss: 0.6780  |  Score: 57.60 [%]  |  Seq Length: 256.0
[2024-10-15 20:28:41,141][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 20:28:41,142][root][INFO] - Score: 64.06 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 20:28:45,811][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 20:28:45,811][root][INFO] - Score: 59.82 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 20:28:45,812][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 20:28:45,814][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 20:32:20,676][root][INFO] - Step: 14733/73665  |  Loss: 0.6624  |  Score: 72.24 [%]  |  Seq Length: 256.0
[2024-10-15 20:32:28,796][root][INFO] - Step: 758/3790  |  Loss: 0.5684  |  Score: 70.11 [%]  |  Seq Length: 256.0
[2024-10-15 20:32:30,982][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 20:32:30,982][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-15 20:32:33,469][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 20:32:33,469][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 20:32:38,134][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 20:32:38,134][root][INFO] - Score: 64.67 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:32:38,136][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 20:32:38,137][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 20:32:51,038][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 20:32:51,038][root][INFO] - Score: 70.95 [%]  |  Evaluation Time: 20.05 [s]
[2024-10-15 20:32:51,039][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 20:32:51,041][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 20:36:20,754][root][INFO] - Step: 1137/3790  |  Loss: 0.5130  |  Score: 74.31 [%]  |  Seq Length: 256.0
[2024-10-15 20:36:25,407][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 20:36:25,408][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 20:36:30,044][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 20:36:30,044][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 20:36:30,046][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 20:36:30,047][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 20:40:12,071][root][INFO] - Step: 1516/3790  |  Loss: 0.4611  |  Score: 77.89 [%]  |  Seq Length: 256.0
[2024-10-15 20:40:16,784][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 20:40:16,784][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 20:40:21,398][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 20:40:21,398][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 20:40:21,399][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 20:40:21,401][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 20:44:03,125][root][INFO] - Step: 1895/3790  |  Loss: 0.4025  |  Score: 81.25 [%]  |  Seq Length: 256.0
[2024-10-15 20:44:07,785][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 20:44:07,785][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:44:12,361][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 20:44:12,361][root][INFO] - Score: 65.55 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 20:44:12,363][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 20:47:54,308][root][INFO] - Step: 2274/3790  |  Loss: 0.3566  |  Score: 83.93 [%]  |  Seq Length: 256.0
[2024-10-15 20:47:59,112][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 20:47:59,112][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 20:48:03,732][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 20:48:03,732][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 20:48:03,734][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 20:51:46,419][root][INFO] - Step: 2653/3790  |  Loss: 0.3011  |  Score: 86.48 [%]  |  Seq Length: 256.0
[2024-10-15 20:51:51,118][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 20:51:51,118][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 20:51:55,727][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 20:51:55,727][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 20:51:55,729][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 20:55:38,104][root][INFO] - Step: 3032/3790  |  Loss: 0.2530  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-15 20:55:42,926][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 20:55:42,926][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-15 20:55:47,619][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 20:55:47,620][root][INFO] - Score: 67.99 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 20:55:47,622][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 20:59:29,705][root][INFO] - Step: 3411/3790  |  Loss: 0.2240  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-15 20:59:34,364][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 20:59:34,364][root][INFO] - Score: 68.85 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:59:38,995][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 20:59:38,996][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 20:59:38,998][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 21:03:21,286][root][INFO] - Step: 3790/3790  |  Loss: 0.2060  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-15 21:03:26,036][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 21:03:26,036][root][INFO] - Score: 70.21 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 21:03:30,654][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 21:03:30,654][root][INFO] - Score: 67.39 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:03:30,656][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 21:03:30,656][root][INFO] - - Epoch: 4
[2024-10-15 21:03:30,656][root][INFO] - - DEV score: 70.02 [%]
[2024-10-15 21:03:30,656][root][INFO] - - TEST score: 67.80 [%]
[2024-10-15 21:03:30,657][root][INFO] - Fine-tuning is done!
[2024-10-15 21:03:30,657][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 21:03:30,657][root][INFO] - - BEST LR: 0.01
[2024-10-15 21:03:30,657][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 21:03:30,658][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 21:03:36,857][root][INFO] - 

[2024-10-15 21:03:36,857][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 21:03:36,857][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 21:03:36,857][root][INFO] - 

[2024-10-15 21:03:36,858][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 21:03:44,959][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,960][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,961][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,961][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,962][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,962][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,963][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,963][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,963][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,964][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,964][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,965][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,965][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,966][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,966][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,966][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,967][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,967][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,968][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,968][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,972][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,972][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,973][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,973][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,975][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 21:03:44,980][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 21:03:45,181][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 21:03:45,183][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 21:03:45,365][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 21:03:48,595][root][INFO] - 

[2024-10-15 21:03:48,595][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 21:03:48,595][root][INFO] - Data Preprocessing
[2024-10-15 21:03:48,595][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 21:03:48,595][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 21:03:48,595][root][INFO] - ㄴ data_remove                True

[2024-10-15 21:03:48,595][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 21:03:48,603][root][INFO] - vocab size              : 51200
[2024-10-15 21:03:48,603][root][INFO] - device                  : gpu
[2024-10-15 21:03:48,603][root][INFO] - random seed             : 2
[2024-10-15 21:03:48,604][root][INFO] - train data size         : 24256
[2024-10-15 21:03:48,604][root][INFO] - max epochs              : 10
[2024-10-15 21:03:48,604][root][INFO] - total steps             : 3790
[2024-10-15 21:03:48,604][root][INFO] - warmup steps            : 379
[2024-10-15 21:03:48,604][root][INFO] - batch size              : 64
[2024-10-15 21:03:48,604][root][INFO] - accumulation steps      : 1
[2024-10-15 21:03:48,604][root][INFO] - optimizer               : adamwscale
[2024-10-15 21:03:48,604][root][INFO] - lr_scheduler            : cosine
[2024-10-15 21:03:48,604][root][INFO] - learning rate           : 0.01
[2024-10-15 21:03:48,604][root][INFO] - max length              : 256

[2024-10-15 21:03:48,604][root][INFO] - LoRA Configuration
[2024-10-15 21:03:48,605][root][INFO] - ㄴ r                    : 32
[2024-10-15 21:03:48,605][root][INFO] - ㄴ alpha                : 128
[2024-10-15 21:03:48,605][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 21:03:48,605][root][INFO] - KOMBO Configuration
[2024-10-15 21:03:48,605][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 21:03:48,605][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 21:03:48,605][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 21:03:48,605][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 21:03:48,605][root][INFO] - ㄴ do_combination       : True
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 21:03:48,606][root][INFO] - 

[2024-10-15 21:03:48,606][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 21:03:48,606][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 21:03:48,606][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 21:03:48,606][root][INFO] - * tb interval   : 10000

[2024-10-15 21:03:48,606][root][INFO] - 

[2024-10-15 21:03:48,606][root][INFO] - Start the Training !
[2024-10-15 21:03:48,610][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 21:07:29,087][root][INFO] - Step: 379/3790  |  Loss: 0.6820  |  Score: 57.01 [%]  |  Seq Length: 256.0
[2024-10-15 21:07:33,746][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 21:07:33,746][root][INFO] - Score: 62.79 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 21:07:38,353][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 21:07:38,353][root][INFO] - Score: 59.45 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 21:07:38,355][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 21:07:38,356][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 21:11:19,012][root][INFO] - Step: 758/3790  |  Loss: 0.5809  |  Score: 69.35 [%]  |  Seq Length: 256.0
[2024-10-15 21:11:23,645][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 21:11:23,646][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:11:28,205][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 21:11:28,205][root][INFO] - Score: 62.75 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:11:28,206][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 21:11:28,208][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 21:15:08,824][root][INFO] - Step: 1137/3790  |  Loss: 0.5210  |  Score: 74.19 [%]  |  Seq Length: 256.0
[2024-10-15 21:15:13,452][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 21:15:13,452][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:15:18,044][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 21:15:18,045][root][INFO] - Score: 64.53 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 21:15:18,046][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 21:15:18,047][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 21:18:59,006][root][INFO] - Step: 1516/3790  |  Loss: 0.4662  |  Score: 77.42 [%]  |  Seq Length: 256.0
[2024-10-15 21:19:03,641][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 21:19:03,641][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:19:08,223][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 21:19:08,223][root][INFO] - Score: 65.94 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 21:19:08,225][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 21:19:45,805][root][INFO] - Step: 20000/73665  |  Loss: 0.6373  |  Score: 73.48 [%]  |  Seq Length: 256.0
[2024-10-15 21:22:49,212][root][INFO] - Step: 1895/3790  |  Loss: 0.4199  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-15 21:22:53,872][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 21:22:53,873][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 21:22:58,434][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 21:22:58,434][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:22:58,435][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 21:22:58,436][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 21:26:39,700][root][INFO] - Step: 2274/3790  |  Loss: 0.3750  |  Score: 82.67 [%]  |  Seq Length: 256.0
[2024-10-15 21:26:44,352][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 21:26:44,352][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 21:26:48,989][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 21:26:48,989][root][INFO] - Score: 66.42 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:26:48,992][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 21:30:31,365][root][INFO] - Step: 2653/3790  |  Loss: 0.3405  |  Score: 84.53 [%]  |  Seq Length: 256.0
[2024-10-15 21:30:35,988][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 21:30:35,989][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:30:40,617][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 21:30:40,617][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:30:40,620][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 21:34:21,375][root][INFO] - Step: 3032/3790  |  Loss: 0.3098  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-15 21:34:26,108][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 21:34:26,109][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 21:34:30,674][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 21:34:30,675][root][INFO] - Score: 68.67 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:34:30,676][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 21:34:30,677][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 21:38:11,286][root][INFO] - Step: 3411/3790  |  Loss: 0.2952  |  Score: 86.68 [%]  |  Seq Length: 256.0
[2024-10-15 21:38:15,910][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 21:38:15,910][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:38:20,473][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 21:38:20,473][root][INFO] - Score: 67.27 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:38:20,475][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 21:42:00,688][root][INFO] - Step: 3790/3790  |  Loss: 0.2806  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-15 21:42:05,281][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 21:42:05,282][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 21:42:09,882][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 21:42:09,882][root][INFO] - Score: 68.42 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 21:42:09,883][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 21:42:09,883][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 21:42:09,883][root][INFO] - - Epoch: 10
[2024-10-15 21:42:09,883][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 21:42:09,883][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 21:42:09,884][root][INFO] - Fine-tuning is done!
[2024-10-15 21:42:16,872][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,872][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,873][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,873][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,874][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,874][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,875][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,875][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,876][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,876][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,877][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,877][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,877][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,878][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,878][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,879][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,879][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,880][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,880][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,880][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,881][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,881][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,882][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,882][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,884][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 21:42:17,086][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 21:42:17,088][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 21:42:17,089][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 21:42:17,256][root][INFO] - 

[2024-10-15 21:42:17,256][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 21:42:17,256][root][INFO] - Data Preprocessing
[2024-10-15 21:42:17,256][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 21:42:17,256][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 21:42:17,256][root][INFO] - ㄴ data_remove                True

[2024-10-15 21:42:17,256][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 21:42:17,264][root][INFO] - vocab size              : 51200
[2024-10-15 21:42:17,264][root][INFO] - device                  : gpu
[2024-10-15 21:42:17,264][root][INFO] - random seed             : 2
[2024-10-15 21:42:17,265][root][INFO] - train data size         : 24256
[2024-10-15 21:42:17,265][root][INFO] - max epochs              : 10
[2024-10-15 21:42:17,265][root][INFO] - total steps             : 3790
[2024-10-15 21:42:17,265][root][INFO] - warmup steps            : 379
[2024-10-15 21:42:17,265][root][INFO] - batch size              : 64
[2024-10-15 21:42:17,265][root][INFO] - accumulation steps      : 1
[2024-10-15 21:42:17,265][root][INFO] - optimizer               : adamwscale
[2024-10-15 21:42:17,265][root][INFO] - lr_scheduler            : cosine
[2024-10-15 21:42:17,265][root][INFO] - learning rate           : 0.02
[2024-10-15 21:42:17,265][root][INFO] - max length              : 256

[2024-10-15 21:42:17,265][root][INFO] - LoRA Configuration
[2024-10-15 21:42:17,265][root][INFO] - ㄴ r                    : 32
[2024-10-15 21:42:17,266][root][INFO] - ㄴ alpha                : 128
[2024-10-15 21:42:17,266][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 21:42:17,266][root][INFO] - KOMBO Configuration
[2024-10-15 21:42:17,266][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 21:42:17,266][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 21:42:17,266][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 21:42:17,266][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 21:42:17,266][root][INFO] - ㄴ do_combination       : True
[2024-10-15 21:42:17,266][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 21:42:17,266][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 21:42:17,267][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 21:42:17,267][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 21:42:17,267][root][INFO] - 

[2024-10-15 21:42:17,267][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 21:42:17,267][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 21:42:17,267][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 21:42:17,267][root][INFO] - * tb interval   : 10000

[2024-10-15 21:42:17,267][root][INFO] - 

[2024-10-15 21:42:17,267][root][INFO] - Start the Training !
[2024-10-15 21:42:17,269][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 21:45:58,069][root][INFO] - Step: 379/3790  |  Loss: 0.6703  |  Score: 59.12 [%]  |  Seq Length: 256.0
[2024-10-15 21:46:02,776][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 21:46:02,776][root][INFO] - Score: 66.41 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 21:46:07,473][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 21:46:07,473][root][INFO] - Score: 59.91 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 21:46:07,474][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 21:46:07,476][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 21:49:49,207][root][INFO] - Step: 758/3790  |  Loss: 0.5669  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-15 21:49:53,994][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 21:49:53,994][root][INFO] - Score: 67.58 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 21:49:58,606][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 21:49:58,607][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 21:49:58,608][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 21:49:58,609][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 21:53:39,844][root][INFO] - Step: 1137/3790  |  Loss: 0.5082  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-15 21:53:44,527][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 21:53:44,528][root][INFO] - Score: 65.53 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 21:53:49,116][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 21:53:49,116][root][INFO] - Score: 67.04 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 21:53:49,119][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 21:57:30,489][root][INFO] - Step: 1516/3790  |  Loss: 0.4569  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-15 21:57:35,106][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 21:57:35,106][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 21:57:39,752][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 21:57:39,752][root][INFO] - Score: 66.84 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 21:57:39,753][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 21:57:39,755][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 22:01:21,068][root][INFO] - Step: 1895/3790  |  Loss: 0.4079  |  Score: 81.11 [%]  |  Seq Length: 256.0
[2024-10-15 22:01:25,767][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 22:01:25,767][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 22:01:30,362][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 22:01:30,362][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 22:01:30,363][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 22:01:30,364][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 22:05:11,591][root][INFO] - Step: 2274/3790  |  Loss: 0.3487  |  Score: 84.15 [%]  |  Seq Length: 256.0
[2024-10-15 22:05:16,239][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 22:05:16,239][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 22:05:20,785][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 22:05:20,785][root][INFO] - Score: 68.03 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-15 22:05:20,786][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 22:05:20,787][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 22:09:02,302][root][INFO] - Step: 2653/3790  |  Loss: 0.2954  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-15 22:09:06,940][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 22:09:06,940][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 22:09:11,513][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 22:09:11,513][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 22:09:11,514][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-15 22:09:11,515][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 22:12:53,185][root][INFO] - Step: 3032/3790  |  Loss: 0.2463  |  Score: 89.20 [%]  |  Seq Length: 256.0
[2024-10-15 22:12:57,785][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 22:12:57,785][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 22:13:02,342][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 22:13:02,342][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 22:13:02,344][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 22:16:43,650][root][INFO] - Step: 3411/3790  |  Loss: 0.2186  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-15 22:16:48,282][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 22:16:48,282][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 22:16:52,938][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 22:16:52,939][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 22:16:52,941][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 22:20:34,237][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-15 22:20:38,880][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 22:20:38,880][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 22:20:43,382][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 22:20:43,382][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-15 22:20:43,383][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 22:20:43,383][root][INFO] - - Epoch: 7
[2024-10-15 22:20:43,383][root][INFO] - - DEV score: 71.29 [%]
[2024-10-15 22:20:43,383][root][INFO] - - TEST score: 69.32 [%]
[2024-10-15 22:20:43,384][root][INFO] - Fine-tuning is done!
[2024-10-15 22:20:43,384][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 22:20:43,385][root][INFO] - - BEST LR: 0.01
[2024-10-15 22:20:43,385][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 22:20:43,385][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 22:20:49,545][root][INFO] - 

[2024-10-15 22:20:49,546][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 22:20:49,546][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 22:20:49,546][root][INFO] - 

[2024-10-15 22:20:49,546][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 22:20:57,844][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,845][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,845][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,846][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,847][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,848][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,848][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,849][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,849][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,850][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,850][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,851][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,852][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,852][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,853][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,853][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,854][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,854][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,855][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,855][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,857][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,857][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,858][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,858][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,860][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 22:20:57,863][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 22:20:58,063][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 22:20:58,065][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 22:20:58,256][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 22:21:01,279][root][INFO] - 

[2024-10-15 22:21:01,279][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 22:21:01,279][root][INFO] - Data Preprocessing
[2024-10-15 22:21:01,279][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 22:21:01,279][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 22:21:01,279][root][INFO] - ㄴ data_remove                True

[2024-10-15 22:21:01,279][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 22:21:01,287][root][INFO] - vocab size              : 51200
[2024-10-15 22:21:01,287][root][INFO] - device                  : gpu
[2024-10-15 22:21:01,287][root][INFO] - random seed             : 3
[2024-10-15 22:21:01,287][root][INFO] - train data size         : 24256
[2024-10-15 22:21:01,287][root][INFO] - max epochs              : 10
[2024-10-15 22:21:01,287][root][INFO] - total steps             : 3790
[2024-10-15 22:21:01,287][root][INFO] - warmup steps            : 379
[2024-10-15 22:21:01,288][root][INFO] - batch size              : 64
[2024-10-15 22:21:01,288][root][INFO] - accumulation steps      : 1
[2024-10-15 22:21:01,288][root][INFO] - optimizer               : adamwscale
[2024-10-15 22:21:01,288][root][INFO] - lr_scheduler            : cosine
[2024-10-15 22:21:01,288][root][INFO] - learning rate           : 0.01
[2024-10-15 22:21:01,288][root][INFO] - max length              : 256

[2024-10-15 22:21:01,288][root][INFO] - LoRA Configuration
[2024-10-15 22:21:01,288][root][INFO] - ㄴ r                    : 32
[2024-10-15 22:21:01,288][root][INFO] - ㄴ alpha                : 128
[2024-10-15 22:21:01,288][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 22:21:01,288][root][INFO] - KOMBO Configuration
[2024-10-15 22:21:01,288][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 22:21:01,289][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 22:21:01,289][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 22:21:01,289][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 22:21:01,289][root][INFO] - ㄴ do_combination       : True
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 22:21:01,289][root][INFO] - 

[2024-10-15 22:21:01,289][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 22:21:01,290][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 22:21:01,290][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 22:21:01,290][root][INFO] - * tb interval   : 10000

[2024-10-15 22:21:01,290][root][INFO] - 

[2024-10-15 22:21:01,290][root][INFO] - Start the Training !
[2024-10-15 22:21:01,293][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 22:24:42,586][root][INFO] - Step: 379/3790  |  Loss: 0.6791  |  Score: 57.91 [%]  |  Seq Length: 256.0
[2024-10-15 22:24:47,161][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 22:24:47,161][root][INFO] - Score: 61.13 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 22:24:51,640][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 22:24:51,640][root][INFO] - Score: 60.72 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-15 22:24:51,641][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 22:24:51,642][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 22:28:30,992][root][INFO] - Step: 758/3790  |  Loss: 0.5750  |  Score: 69.89 [%]  |  Seq Length: 256.0
[2024-10-15 22:28:35,565][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 22:28:35,566][root][INFO] - Score: 66.02 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 22:28:40,062][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 22:28:40,062][root][INFO] - Score: 64.05 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-15 22:28:40,063][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 22:28:40,065][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 22:32:20,227][root][INFO] - Step: 1137/3790  |  Loss: 0.5122  |  Score: 74.67 [%]  |  Seq Length: 256.0
[2024-10-15 22:32:24,809][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 22:32:24,809][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 22:32:29,351][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 22:32:29,351][root][INFO] - Score: 64.39 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-15 22:32:29,352][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 22:32:29,353][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 22:36:11,443][root][INFO] - Step: 1516/3790  |  Loss: 0.4581  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-15 22:36:16,217][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 22:36:16,217][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-15 22:36:20,908][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 22:36:20,908][root][INFO] - Score: 63.62 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:36:20,911][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 22:40:03,361][root][INFO] - Step: 1895/3790  |  Loss: 0.4133  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-15 22:40:08,058][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 22:40:08,059][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:40:12,666][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 22:40:12,666][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 22:40:12,667][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 22:40:12,669][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 22:43:53,283][root][INFO] - Step: 2274/3790  |  Loss: 0.3714  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-15 22:43:57,944][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 22:43:57,944][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 22:44:02,575][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 22:44:02,575][root][INFO] - Score: 65.54 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 22:44:02,578][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 22:44:06,162][root][INFO] - Step: 29466/73665  |  Loss: 0.6288  |  Score: 73.89 [%]  |  Seq Length: 256.0
[2024-10-15 22:44:16,365][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 22:44:16,366][root][INFO] - Score: 71.38 [%]  |  Evaluation Time: 10.20 [s]
[2024-10-15 22:44:36,433][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 22:44:36,433][root][INFO] - Score: 73.48 [%]  |  Evaluation Time: 20.07 [s]
[2024-10-15 22:44:36,434][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 22:44:36,435][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 22:47:43,593][root][INFO] - Step: 2653/3790  |  Loss: 0.3333  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-15 22:47:48,283][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 22:47:48,284][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:47:52,957][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 22:47:52,957][root][INFO] - Score: 65.60 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 22:47:52,960][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 22:49:21,331][root][INFO] - Step: 30000/73665  |  Loss: 0.6015  |  Score: 75.37 [%]  |  Seq Length: 256.0
[2024-10-15 22:51:34,082][root][INFO] - Step: 3032/3790  |  Loss: 0.3040  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-15 22:51:38,773][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 22:51:38,773][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:51:43,391][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 22:51:43,392][root][INFO] - Score: 66.08 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 22:51:43,393][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 22:51:43,394][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 22:55:24,569][root][INFO] - Step: 3411/3790  |  Loss: 0.2838  |  Score: 87.23 [%]  |  Seq Length: 256.0
[2024-10-15 22:55:29,364][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 22:55:29,365][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 22:55:33,885][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 22:55:33,886][root][INFO] - Score: 65.73 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 22:55:33,888][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 22:59:14,900][root][INFO] - Step: 3790/3790  |  Loss: 0.2712  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-15 22:59:19,574][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 22:59:19,575][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 22:59:24,222][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 22:59:24,222][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 22:59:24,223][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 22:59:24,223][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 22:59:24,223][root][INFO] - - Epoch: 10
[2024-10-15 22:59:24,223][root][INFO] - - DEV score: 72.85 [%]
[2024-10-15 22:59:24,223][root][INFO] - - TEST score: 65.70 [%]
[2024-10-15 22:59:24,224][root][INFO] - Fine-tuning is done!
[2024-10-15 22:59:30,813][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,814][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,815][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,816][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,817][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,818][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,819][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,820][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,821][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,822][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,823][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,824][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,825][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,826][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,827][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,827][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,828][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,829][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,829][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,830][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,831][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,831][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,832][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,833][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,835][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 22:59:31,084][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 22:59:31,087][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 22:59:31,088][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 22:59:31,254][root][INFO] - 

[2024-10-15 22:59:31,254][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 22:59:31,255][root][INFO] - Data Preprocessing
[2024-10-15 22:59:31,255][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 22:59:31,255][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 22:59:31,255][root][INFO] - ㄴ data_remove                True

[2024-10-15 22:59:31,255][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 22:59:31,263][root][INFO] - vocab size              : 51200
[2024-10-15 22:59:31,263][root][INFO] - device                  : gpu
[2024-10-15 22:59:31,264][root][INFO] - random seed             : 3
[2024-10-15 22:59:31,264][root][INFO] - train data size         : 24256
[2024-10-15 22:59:31,264][root][INFO] - max epochs              : 10
[2024-10-15 22:59:31,264][root][INFO] - total steps             : 3790
[2024-10-15 22:59:31,264][root][INFO] - warmup steps            : 379
[2024-10-15 22:59:31,264][root][INFO] - batch size              : 64
[2024-10-15 22:59:31,264][root][INFO] - accumulation steps      : 1
[2024-10-15 22:59:31,264][root][INFO] - optimizer               : adamwscale
[2024-10-15 22:59:31,264][root][INFO] - lr_scheduler            : cosine
[2024-10-15 22:59:31,264][root][INFO] - learning rate           : 0.02
[2024-10-15 22:59:31,264][root][INFO] - max length              : 256

[2024-10-15 22:59:31,264][root][INFO] - LoRA Configuration
[2024-10-15 22:59:31,265][root][INFO] - ㄴ r                    : 32
[2024-10-15 22:59:31,265][root][INFO] - ㄴ alpha                : 128
[2024-10-15 22:59:31,265][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 22:59:31,265][root][INFO] - KOMBO Configuration
[2024-10-15 22:59:31,265][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 22:59:31,265][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 22:59:31,265][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 22:59:31,265][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 22:59:31,265][root][INFO] - ㄴ do_combination       : True
[2024-10-15 22:59:31,265][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 22:59:31,266][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 22:59:31,266][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 22:59:31,266][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 22:59:31,266][root][INFO] - 

[2024-10-15 22:59:31,266][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 22:59:31,266][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 22:59:31,266][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 22:59:31,266][root][INFO] - * tb interval   : 10000

[2024-10-15 22:59:31,266][root][INFO] - 

[2024-10-15 22:59:31,266][root][INFO] - Start the Training !
[2024-10-15 22:59:31,268][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 23:03:12,843][root][INFO] - Step: 379/3790  |  Loss: 0.6607  |  Score: 60.10 [%]  |  Seq Length: 256.0
[2024-10-15 23:03:17,721][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 23:03:17,721][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 4.87 [s]
[2024-10-15 23:03:22,391][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 23:03:22,391][root][INFO] - Score: 60.64 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 23:03:22,392][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 23:03:22,394][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 23:07:03,645][root][INFO] - Step: 758/3790  |  Loss: 0.5616  |  Score: 71.12 [%]  |  Seq Length: 256.0
[2024-10-15 23:07:08,434][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 23:07:08,434][root][INFO] - Score: 65.04 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 23:07:13,085][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 23:07:13,085][root][INFO] - Score: 62.68 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 23:07:13,087][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 23:10:54,621][root][INFO] - Step: 1137/3790  |  Loss: 0.4997  |  Score: 75.63 [%]  |  Seq Length: 256.0
[2024-10-15 23:10:59,325][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 23:10:59,325][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 23:11:04,103][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 23:11:04,103][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 23:11:04,104][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 23:11:04,106][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 23:14:46,034][root][INFO] - Step: 1516/3790  |  Loss: 0.4472  |  Score: 78.90 [%]  |  Seq Length: 256.0
[2024-10-15 23:14:50,757][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 23:14:50,757][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 23:14:55,350][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 23:14:55,350][root][INFO] - Score: 66.80 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 23:14:55,351][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 23:14:55,353][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 23:18:36,565][root][INFO] - Step: 1895/3790  |  Loss: 0.3977  |  Score: 81.23 [%]  |  Seq Length: 256.0
[2024-10-15 23:18:41,264][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 23:18:41,265][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 23:18:45,924][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 23:18:45,925][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 23:18:45,926][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 23:18:45,927][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 23:22:25,909][root][INFO] - Step: 2274/3790  |  Loss: 0.3445  |  Score: 84.26 [%]  |  Seq Length: 256.0
[2024-10-15 23:22:30,707][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 23:22:30,707][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 23:22:35,294][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 23:22:35,294][root][INFO] - Score: 66.36 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 23:22:35,297][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 23:26:16,686][root][INFO] - Step: 2653/3790  |  Loss: 0.2995  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-15 23:26:21,437][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 23:26:21,438][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 23:26:26,227][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 23:26:26,227][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 23:26:26,229][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 23:30:07,120][root][INFO] - Step: 3032/3790  |  Loss: 0.2495  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-15 23:30:11,804][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 23:30:11,804][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 23:30:16,369][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 23:30:16,369][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 23:30:16,370][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 23:30:16,372][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 23:33:54,801][root][INFO] - Step: 3411/3790  |  Loss: 0.2111  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-15 23:33:59,424][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 23:33:59,424][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 23:34:04,070][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 23:34:04,070][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 23:34:04,073][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 23:37:45,760][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.52 [%]  |  Seq Length: 256.0
[2024-10-15 23:37:50,335][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 23:37:50,335][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 23:37:54,867][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 23:37:54,867][root][INFO] - Score: 68.36 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-15 23:37:54,868][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 23:37:54,868][root][INFO] - - Epoch: 8
[2024-10-15 23:37:54,868][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 23:37:54,868][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 23:37:54,869][root][INFO] - Fine-tuning is done!
[2024-10-15 23:37:54,869][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 23:37:54,869][root][INFO] - - BEST LR: 0.02
[2024-10-15 23:37:54,870][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 23:37:54,870][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 23:38:00,580][root][INFO] - 

[2024-10-15 23:38:00,580][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 23:38:00,580][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 23:38:00,580][root][INFO] - 

[2024-10-15 23:38:00,580][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 23:38:13,953][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,954][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,954][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,955][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,955][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,956][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,956][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,957][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,957][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,958][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,958][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,959][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,959][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,960][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,960][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,961][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,961][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,962][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,962][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,963][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,963][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,964][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,964][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,965][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,967][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 23:38:13,972][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 23:38:14,168][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 23:38:14,170][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 23:38:14,353][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 23:38:17,297][root][INFO] - 

[2024-10-15 23:38:17,298][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 23:38:17,298][root][INFO] - Data Preprocessing
[2024-10-15 23:38:17,298][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 23:38:17,298][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 23:38:17,298][root][INFO] - ㄴ data_remove                False

[2024-10-15 23:38:17,298][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 23:38:17,305][root][INFO] - vocab size              : 51200
[2024-10-15 23:38:17,306][root][INFO] - device                  : gpu
[2024-10-15 23:38:17,306][root][INFO] - random seed             : 1
[2024-10-15 23:38:17,306][root][INFO] - train data size         : 49152
[2024-10-15 23:38:17,306][root][INFO] - max epochs              : 10
[2024-10-15 23:38:17,306][root][INFO] - total steps             : 7680
[2024-10-15 23:38:17,306][root][INFO] - warmup steps            : 768
[2024-10-15 23:38:17,306][root][INFO] - batch size              : 64
[2024-10-15 23:38:17,306][root][INFO] - accumulation steps      : 1
[2024-10-15 23:38:17,306][root][INFO] - optimizer               : adamwscale
[2024-10-15 23:38:17,306][root][INFO] - lr_scheduler            : cosine
[2024-10-15 23:38:17,306][root][INFO] - learning rate           : 0.01
[2024-10-15 23:38:17,307][root][INFO] - max length              : 256

[2024-10-15 23:38:17,307][root][INFO] - LoRA Configuration
[2024-10-15 23:38:17,307][root][INFO] - ㄴ r                    : 32
[2024-10-15 23:38:17,307][root][INFO] - ㄴ alpha                : 128
[2024-10-15 23:38:17,307][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 23:38:17,307][root][INFO] - KOMBO Configuration
[2024-10-15 23:38:17,307][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 23:38:17,307][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 23:38:17,307][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 23:38:17,307][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 23:38:17,307][root][INFO] - ㄴ do_combination       : True
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 23:38:17,308][root][INFO] - 

[2024-10-15 23:38:17,308][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 23:38:17,308][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 23:38:17,308][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 23:38:17,308][root][INFO] - * tb interval   : 10000

[2024-10-15 23:38:17,308][root][INFO] - 

[2024-10-15 23:38:17,308][root][INFO] - Start the Training !
[2024-10-15 23:38:17,311][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 23:45:47,747][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-15 23:45:56,652][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 23:45:56,652][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-15 23:46:05,578][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 23:46:05,578][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-15 23:46:05,579][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 23:46:05,580][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 23:53:33,246][root][INFO] - Step: 1536/7680  |  Loss: 0.5295  |  Score: 73.27 [%]  |  Seq Length: 256.0
[2024-10-15 23:53:42,150][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 23:53:42,150][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-15 23:53:51,200][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 23:53:51,200][root][INFO] - Score: 69.51 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-15 23:53:51,201][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 23:53:51,203][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 00:01:20,605][root][INFO] - Step: 2304/7680  |  Loss: 0.4638  |  Score: 77.33 [%]  |  Seq Length: 256.0
[2024-10-16 00:01:29,679][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 00:01:29,679][root][INFO] - Score: 72.97 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 00:01:38,639][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 00:01:38,640][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 00:01:38,640][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 00:01:38,642][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 00:09:07,017][root][INFO] - Step: 3072/7680  |  Loss: 0.4107  |  Score: 80.68 [%]  |  Seq Length: 256.0
[2024-10-16 00:09:15,938][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 00:09:15,938][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 00:09:24,861][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 00:09:24,861][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 00:09:24,862][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 00:09:24,864][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 00:16:51,683][root][INFO] - Step: 3840/7680  |  Loss: 0.3698  |  Score: 82.74 [%]  |  Seq Length: 256.0
[2024-10-16 00:17:00,601][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 00:17:00,601][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 00:17:09,516][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 00:17:09,516][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 00:17:09,518][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 00:18:00,301][root][INFO] - Step: 40000/73665  |  Loss: 0.5978  |  Score: 75.45 [%]  |  Seq Length: 256.0
[2024-10-16 00:24:36,672][root][INFO] - Step: 4608/7680  |  Loss: 0.3322  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-16 00:24:45,618][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 00:24:45,618][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:24:54,568][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 00:24:54,569][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 00:24:54,570][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 00:24:54,574][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 00:32:21,458][root][INFO] - Step: 5376/7680  |  Loss: 0.2993  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-16 00:32:30,364][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 00:32:30,365][root][INFO] - Score: 75.63 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 00:32:39,308][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 00:32:39,308][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:32:39,309][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 00:32:39,311][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 00:40:07,713][root][INFO] - Step: 6144/7680  |  Loss: 0.2694  |  Score: 88.03 [%]  |  Seq Length: 256.0
[2024-10-16 00:40:16,791][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 00:40:16,791][root][INFO] - Score: 76.32 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 00:40:25,798][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 00:40:25,798][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 00:40:25,799][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 00:40:25,801][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 00:47:54,006][root][INFO] - Step: 6912/7680  |  Loss: 0.2510  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-16 00:48:03,110][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 00:48:03,110][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-16 00:48:12,069][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 00:48:12,069][root][INFO] - Score: 72.82 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 00:48:12,070][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 00:48:12,071][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 00:55:12,684][root][INFO] - Step: 44199/73665  |  Loss: 0.5851  |  Score: 76.10 [%]  |  Seq Length: 256.0
[2024-10-16 00:55:22,868][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 00:55:22,868][root][INFO] - Score: 74.12 [%]  |  Evaluation Time: 10.18 [s]
[2024-10-16 00:55:42,054][root][INFO] - Step: 7680/7680  |  Loss: 0.2422  |  Score: 89.34 [%]  |  Seq Length: 256.0
[2024-10-16 00:55:42,790][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 00:55:42,790][root][INFO] - Score: 74.55 [%]  |  Evaluation Time: 19.92 [s]
[2024-10-16 00:55:42,791][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 00:55:42,793][root][INFO] - 
[4/ 5 Epoch]
[2024-10-16 00:55:51,001][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 00:55:51,001][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:55:59,947][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 00:55:59,947][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:55:59,948][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 00:55:59,948][root][INFO] - - Epoch: 9
[2024-10-16 00:55:59,949][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 00:55:59,949][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 00:55:59,949][root][INFO] - Fine-tuning is done!
[2024-10-16 00:56:11,061][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,062][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,063][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,063][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,064][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,064][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,065][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,065][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,066][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,066][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,067][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,067][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,068][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,068][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,069][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,069][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,070][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,070][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,071][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,071][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,072][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,072][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,073][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,073][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,075][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 00:56:11,283][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 00:56:11,285][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 00:56:11,286][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 00:56:11,449][root][INFO] - 

[2024-10-16 00:56:11,449][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 00:56:11,450][root][INFO] - Data Preprocessing
[2024-10-16 00:56:11,450][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 00:56:11,450][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 00:56:11,450][root][INFO] - ㄴ data_remove                False

[2024-10-16 00:56:11,450][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 00:56:11,457][root][INFO] - vocab size              : 51200
[2024-10-16 00:56:11,458][root][INFO] - device                  : gpu
[2024-10-16 00:56:11,458][root][INFO] - random seed             : 1
[2024-10-16 00:56:11,458][root][INFO] - train data size         : 49152
[2024-10-16 00:56:11,458][root][INFO] - max epochs              : 10
[2024-10-16 00:56:11,458][root][INFO] - total steps             : 7680
[2024-10-16 00:56:11,458][root][INFO] - warmup steps            : 768
[2024-10-16 00:56:11,458][root][INFO] - batch size              : 64
[2024-10-16 00:56:11,458][root][INFO] - accumulation steps      : 1
[2024-10-16 00:56:11,458][root][INFO] - optimizer               : adamwscale
[2024-10-16 00:56:11,458][root][INFO] - lr_scheduler            : cosine
[2024-10-16 00:56:11,459][root][INFO] - learning rate           : 0.02
[2024-10-16 00:56:11,459][root][INFO] - max length              : 256

[2024-10-16 00:56:11,459][root][INFO] - LoRA Configuration
[2024-10-16 00:56:11,459][root][INFO] - ㄴ r                    : 32
[2024-10-16 00:56:11,459][root][INFO] - ㄴ alpha                : 128
[2024-10-16 00:56:11,459][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 00:56:11,460][root][INFO] - KOMBO Configuration
[2024-10-16 00:56:11,460][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 00:56:11,460][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 00:56:11,460][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 00:56:11,460][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 00:56:11,460][root][INFO] - ㄴ do_combination       : True
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 00:56:11,461][root][INFO] - 

[2024-10-16 00:56:11,461][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 00:56:11,461][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 00:56:11,461][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 00:56:11,461][root][INFO] - * tb interval   : 10000

[2024-10-16 00:56:11,461][root][INFO] - 

[2024-10-16 00:56:11,461][root][INFO] - Start the Training !
[2024-10-16 00:56:11,463][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 01:03:43,744][root][INFO] - Step: 768/7680  |  Loss: 0.6396  |  Score: 61.85 [%]  |  Seq Length: 256.0
[2024-10-16 01:03:52,713][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 01:03:52,713][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 01:04:01,784][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 01:04:01,785][root][INFO] - Score: 66.86 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 01:04:01,786][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 01:04:01,787][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 01:11:30,341][root][INFO] - Step: 1536/7680  |  Loss: 0.5290  |  Score: 73.49 [%]  |  Seq Length: 256.0
[2024-10-16 01:11:39,323][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 01:11:39,323][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 01:11:48,418][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 01:11:48,418][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 01:11:48,420][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 01:11:48,421][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 01:19:17,791][root][INFO] - Step: 2304/7680  |  Loss: 0.4797  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-16 01:19:26,831][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 01:19:26,831][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 01:19:35,826][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 01:19:35,826][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 01:19:35,827][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 01:19:35,828][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 01:27:04,949][root][INFO] - Step: 3072/7680  |  Loss: 0.4315  |  Score: 79.38 [%]  |  Seq Length: 256.0
[2024-10-16 01:27:13,938][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 01:27:13,938][root][INFO] - Score: 72.79 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 01:27:22,911][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 01:27:22,911][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 01:27:22,912][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 01:27:22,913][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 01:34:51,132][root][INFO] - Step: 3840/7680  |  Loss: 0.3944  |  Score: 81.60 [%]  |  Seq Length: 256.0
[2024-10-16 01:35:00,078][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 01:35:00,079][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 01:35:09,117][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 01:35:09,117][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 01:35:09,118][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 01:35:09,120][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 01:42:37,772][root][INFO] - Step: 4608/7680  |  Loss: 0.3457  |  Score: 84.04 [%]  |  Seq Length: 256.0
[2024-10-16 01:42:46,832][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 01:42:46,832][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 01:42:55,880][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 01:42:55,880][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-16 01:42:55,881][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 01:42:55,882][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 01:47:07,301][root][INFO] - Step: 50000/73665  |  Loss: 0.5508  |  Score: 77.68 [%]  |  Seq Length: 256.0
[2024-10-16 01:50:22,470][root][INFO] - Step: 5376/7680  |  Loss: 0.2974  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-16 01:50:31,441][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 01:50:31,441][root][INFO] - Score: 75.11 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 01:50:40,393][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 01:50:40,393][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 01:50:40,395][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 01:58:10,956][root][INFO] - Step: 6144/7680  |  Loss: 0.2532  |  Score: 88.87 [%]  |  Seq Length: 256.0
[2024-10-16 01:58:20,129][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 01:58:20,129][root][INFO] - Score: 75.03 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-16 01:58:29,317][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 01:58:29,318][root][INFO] - Score: 72.98 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-16 01:58:29,320][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 02:06:04,779][root][INFO] - Step: 6912/7680  |  Loss: 0.2230  |  Score: 90.33 [%]  |  Seq Length: 256.0
[2024-10-16 02:06:13,740][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 02:06:13,740][root][INFO] - Score: 75.21 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 02:06:22,759][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 02:06:22,760][root][INFO] - Score: 72.91 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 02:06:22,762][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 02:13:50,732][root][INFO] - Step: 7680/7680  |  Loss: 0.2027  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-16 02:13:59,725][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 02:13:59,725][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 02:14:08,720][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 02:14:08,720][root][INFO] - Score: 73.03 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 02:14:08,721][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 02:14:08,721][root][INFO] - - Epoch: 6
[2024-10-16 02:14:08,721][root][INFO] - - DEV score: 74.90 [%]
[2024-10-16 02:14:08,721][root][INFO] - - TEST score: 73.44 [%]
[2024-10-16 02:14:08,722][root][INFO] - Fine-tuning is done!
[2024-10-16 02:14:08,723][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 02:14:08,723][root][INFO] - - BEST LR: 0.01
[2024-10-16 02:14:08,723][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 02:14:08,723][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 02:14:14,564][root][INFO] - 

[2024-10-16 02:14:14,564][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 02:14:14,565][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 02:14:14,565][root][INFO] - 

[2024-10-16 02:14:14,565][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 02:14:27,248][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,248][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,249][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,249][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,250][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,250][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,250][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,251][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,251][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,252][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,252][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,253][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,253][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,254][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,254][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,255][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,255][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,256][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,256][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,257][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,257][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,258][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,258][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,259][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,260][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 02:14:27,265][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 02:14:27,461][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 02:14:27,464][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 02:14:27,650][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 02:14:30,663][root][INFO] - 

[2024-10-16 02:14:30,663][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 02:14:30,663][root][INFO] - Data Preprocessing
[2024-10-16 02:14:30,664][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 02:14:30,664][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 02:14:30,664][root][INFO] - ㄴ data_remove                False

[2024-10-16 02:14:30,664][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 02:14:30,671][root][INFO] - vocab size              : 51200
[2024-10-16 02:14:30,672][root][INFO] - device                  : gpu
[2024-10-16 02:14:30,672][root][INFO] - random seed             : 2
[2024-10-16 02:14:30,672][root][INFO] - train data size         : 49152
[2024-10-16 02:14:30,672][root][INFO] - max epochs              : 10
[2024-10-16 02:14:30,672][root][INFO] - total steps             : 7680
[2024-10-16 02:14:30,672][root][INFO] - warmup steps            : 768
[2024-10-16 02:14:30,672][root][INFO] - batch size              : 64
[2024-10-16 02:14:30,672][root][INFO] - accumulation steps      : 1
[2024-10-16 02:14:30,672][root][INFO] - optimizer               : adamwscale
[2024-10-16 02:14:30,672][root][INFO] - lr_scheduler            : cosine
[2024-10-16 02:14:30,672][root][INFO] - learning rate           : 0.01
[2024-10-16 02:14:30,673][root][INFO] - max length              : 256

[2024-10-16 02:14:30,673][root][INFO] - LoRA Configuration
[2024-10-16 02:14:30,673][root][INFO] - ㄴ r                    : 32
[2024-10-16 02:14:30,673][root][INFO] - ㄴ alpha                : 128
[2024-10-16 02:14:30,673][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 02:14:30,673][root][INFO] - KOMBO Configuration
[2024-10-16 02:14:30,673][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 02:14:30,673][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 02:14:30,673][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 02:14:30,673][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 02:14:30,673][root][INFO] - ㄴ do_combination       : True
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 02:14:30,674][root][INFO] - 

[2024-10-16 02:14:30,674][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 02:14:30,674][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 02:14:30,674][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 02:14:30,674][root][INFO] - * tb interval   : 10000

[2024-10-16 02:14:30,674][root][INFO] - 

[2024-10-16 02:14:30,674][root][INFO] - Start the Training !
[2024-10-16 02:14:30,678][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 02:21:59,456][root][INFO] - Step: 768/7680  |  Loss: 0.6386  |  Score: 62.54 [%]  |  Seq Length: 256.0
[2024-10-16 02:22:08,374][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 02:22:08,374][root][INFO] - Score: 68.40 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 02:22:17,324][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 02:22:17,324][root][INFO] - Score: 66.23 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 02:22:17,325][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 02:22:17,327][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 02:29:45,161][root][INFO] - Step: 1536/7680  |  Loss: 0.5177  |  Score: 74.29 [%]  |  Seq Length: 256.0
[2024-10-16 02:29:54,066][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 02:29:54,067][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 02:30:03,092][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 02:30:03,092][root][INFO] - Score: 67.61 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 02:30:03,093][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 02:30:03,094][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 02:37:31,552][root][INFO] - Step: 2304/7680  |  Loss: 0.4565  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-16 02:37:40,465][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 02:37:40,465][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 02:37:49,437][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 02:37:49,437][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 02:37:49,438][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 02:37:49,439][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 02:45:18,294][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-16 02:45:27,506][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 02:45:27,506][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 02:45:36,482][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 02:45:36,482][root][INFO] - Score: 72.89 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 02:45:36,483][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 02:45:36,484][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 02:53:04,592][root][INFO] - Step: 3840/7680  |  Loss: 0.3670  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-16 02:53:13,564][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 02:53:13,565][root][INFO] - Score: 76.05 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 02:53:22,483][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 02:53:22,484][root][INFO] - Score: 73.63 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 02:53:22,485][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 02:53:22,486][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 03:00:50,088][root][INFO] - Step: 4608/7680  |  Loss: 0.3297  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-16 03:00:58,993][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 03:00:58,993][root][INFO] - Score: 75.79 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 03:01:07,918][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 03:01:07,918][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 03:01:07,919][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 03:01:07,920][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 03:06:13,954][root][INFO] - Step: 58932/73665  |  Loss: 0.5409  |  Score: 78.13 [%]  |  Seq Length: 256.0
[2024-10-16 03:06:24,164][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 03:06:24,164][root][INFO] - Score: 74.50 [%]  |  Evaluation Time: 10.21 [s]
[2024-10-16 03:06:44,150][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 03:06:44,150][root][INFO] - Score: 76.12 [%]  |  Evaluation Time: 19.98 [s]
[2024-10-16 03:06:44,151][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 03:06:44,152][root][INFO] - 
[5/ 5 Epoch]
[2024-10-16 03:08:36,001][root][INFO] - Step: 5376/7680  |  Loss: 0.2950  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-16 03:08:44,880][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 03:08:44,881][root][INFO] - Score: 75.40 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 03:08:53,913][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 03:08:53,913][root][INFO] - Score: 72.84 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-16 03:08:53,915][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 03:16:07,339][root][INFO] - Step: 60000/73665  |  Loss: 0.5080  |  Score: 79.59 [%]  |  Seq Length: 256.0
[2024-10-16 03:16:22,208][root][INFO] - Step: 6144/7680  |  Loss: 0.2654  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-16 03:16:31,110][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 03:16:31,110][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 03:16:40,035][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 03:16:40,035][root][INFO] - Score: 73.65 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 03:16:40,038][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 03:24:09,424][root][INFO] - Step: 6912/7680  |  Loss: 0.2486  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-16 03:24:18,352][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 03:24:18,353][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 8.93 [s]
[2024-10-16 03:24:27,365][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 03:24:27,365][root][INFO] - Score: 73.59 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 03:24:27,367][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 03:31:55,493][root][INFO] - Step: 7680/7680  |  Loss: 0.2369  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-16 03:32:04,379][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 03:32:04,380][root][INFO] - Score: 76.51 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 03:32:13,375][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 03:32:13,376][root][INFO] - Score: 73.88 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 03:32:13,377][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 03:32:13,378][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 03:32:13,378][root][INFO] - - Epoch: 10
[2024-10-16 03:32:13,378][root][INFO] - - DEV score: 76.51 [%]
[2024-10-16 03:32:13,378][root][INFO] - - TEST score: 73.88 [%]
[2024-10-16 03:32:13,380][root][INFO] - Fine-tuning is done!
[2024-10-16 03:32:25,147][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,148][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,149][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,149][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,150][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,150][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,151][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,152][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,152][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,153][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,154][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,155][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,156][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,157][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,158][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,158][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,159][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,159][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,160][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,160][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,161][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,162][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,163][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,163][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,165][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 03:32:25,385][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 03:32:25,387][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 03:32:25,389][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 03:32:25,562][root][INFO] - 

[2024-10-16 03:32:25,562][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 03:32:25,562][root][INFO] - Data Preprocessing
[2024-10-16 03:32:25,562][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 03:32:25,563][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 03:32:25,563][root][INFO] - ㄴ data_remove                False

[2024-10-16 03:32:25,563][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 03:32:25,571][root][INFO] - vocab size              : 51200
[2024-10-16 03:32:25,571][root][INFO] - device                  : gpu
[2024-10-16 03:32:25,571][root][INFO] - random seed             : 2
[2024-10-16 03:32:25,572][root][INFO] - train data size         : 49152
[2024-10-16 03:32:25,572][root][INFO] - max epochs              : 10
[2024-10-16 03:32:25,572][root][INFO] - total steps             : 7680
[2024-10-16 03:32:25,572][root][INFO] - warmup steps            : 768
[2024-10-16 03:32:25,572][root][INFO] - batch size              : 64
[2024-10-16 03:32:25,572][root][INFO] - accumulation steps      : 1
[2024-10-16 03:32:25,572][root][INFO] - optimizer               : adamwscale
[2024-10-16 03:32:25,572][root][INFO] - lr_scheduler            : cosine
[2024-10-16 03:32:25,572][root][INFO] - learning rate           : 0.02
[2024-10-16 03:32:25,572][root][INFO] - max length              : 256

[2024-10-16 03:32:25,572][root][INFO] - LoRA Configuration
[2024-10-16 03:32:25,573][root][INFO] - ㄴ r                    : 32
[2024-10-16 03:32:25,573][root][INFO] - ㄴ alpha                : 128
[2024-10-16 03:32:25,573][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 03:32:25,573][root][INFO] - KOMBO Configuration
[2024-10-16 03:32:25,573][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 03:32:25,573][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 03:32:25,573][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 03:32:25,573][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 03:32:25,573][root][INFO] - ㄴ do_combination       : True
[2024-10-16 03:32:25,573][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 03:32:25,574][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 03:32:25,574][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 03:32:25,574][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 03:32:25,574][root][INFO] - 

[2024-10-16 03:32:25,574][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 03:32:25,574][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 03:32:25,574][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 03:32:25,574][root][INFO] - * tb interval   : 10000

[2024-10-16 03:32:25,574][root][INFO] - 

[2024-10-16 03:32:25,574][root][INFO] - Start the Training !
[2024-10-16 03:32:25,577][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 03:39:55,762][root][INFO] - Step: 768/7680  |  Loss: 0.6222  |  Score: 64.46 [%]  |  Seq Length: 256.0
[2024-10-16 03:40:04,748][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 03:40:04,748][root][INFO] - Score: 67.73 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 03:40:13,841][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 03:40:13,842][root][INFO] - Score: 66.79 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 03:40:13,843][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 03:40:13,844][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 03:47:45,002][root][INFO] - Step: 1536/7680  |  Loss: 0.5210  |  Score: 74.06 [%]  |  Seq Length: 256.0
[2024-10-16 03:47:53,986][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 03:47:53,986][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 03:48:03,006][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 03:48:03,006][root][INFO] - Score: 67.05 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 03:48:03,007][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 03:48:03,009][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 03:55:35,397][root][INFO] - Step: 2304/7680  |  Loss: 0.4707  |  Score: 77.22 [%]  |  Seq Length: 256.0
[2024-10-16 03:55:44,390][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 03:55:44,390][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 03:55:53,620][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 03:55:53,620][root][INFO] - Score: 70.17 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 03:55:53,621][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 03:55:53,623][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 04:03:24,541][root][INFO] - Step: 3072/7680  |  Loss: 0.4338  |  Score: 79.22 [%]  |  Seq Length: 256.0
[2024-10-16 04:03:33,505][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 04:03:33,506][root][INFO] - Score: 74.96 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 04:03:42,509][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 04:03:42,509][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 04:03:42,510][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 04:03:42,512][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 04:11:16,499][root][INFO] - Step: 3840/7680  |  Loss: 0.3913  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-16 04:11:25,618][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 04:11:25,618][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-16 04:11:34,626][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 04:11:34,626][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 04:11:34,627][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 04:11:34,629][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 04:19:07,463][root][INFO] - Step: 4608/7680  |  Loss: 0.3479  |  Score: 84.10 [%]  |  Seq Length: 256.0
[2024-10-16 04:19:16,705][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 04:19:16,706][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 04:19:25,883][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 04:19:25,884][root][INFO] - Score: 72.64 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 04:19:25,885][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 04:19:25,886][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 04:27:00,315][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.63 [%]  |  Seq Length: 256.0
[2024-10-16 04:27:09,341][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 04:27:09,341][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 04:27:18,488][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 04:27:18,488][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 04:27:18,491][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 04:34:48,501][root][INFO] - Step: 6144/7680  |  Loss: 0.2514  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-16 04:34:57,506][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 04:34:57,506][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 04:35:06,571][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 04:35:06,571][root][INFO] - Score: 74.42 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 04:35:06,572][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 04:35:06,573][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 04:42:42,877][root][INFO] - Step: 6912/7680  |  Loss: 0.2204  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-16 04:42:52,120][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 04:42:52,120][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 04:43:01,387][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 04:43:01,387][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-16 04:43:01,389][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 04:44:43,440][root][INFO] - Step: 70000/73665  |  Loss: 0.5059  |  Score: 79.71 [%]  |  Seq Length: 256.0
[2024-10-16 04:50:31,462][root][INFO] - Step: 7680/7680  |  Loss: 0.1994  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-16 04:50:40,492][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 04:50:40,492][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-16 04:50:49,651][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 04:50:49,651][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 04:50:49,652][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 04:50:49,652][root][INFO] - - Epoch: 8
[2024-10-16 04:50:49,652][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 04:50:49,653][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 04:50:49,653][root][INFO] - Fine-tuning is done!
[2024-10-16 04:50:49,654][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 04:50:49,654][root][INFO] - - BEST LR: 0.02
[2024-10-16 04:50:49,654][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 04:50:49,654][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 04:50:55,467][root][INFO] - 

[2024-10-16 04:50:55,467][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 04:50:55,467][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 04:50:55,467][root][INFO] - 

[2024-10-16 04:50:55,467][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 04:51:07,829][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,829][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,830][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,830][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,831][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,831][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,832][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,832][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,832][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,833][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,833][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,834][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,834][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,835][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,835][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,836][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,836][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,837][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,837][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,838][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,838][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,839][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,839][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,840][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,841][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 04:51:07,845][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 04:51:08,038][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 04:51:08,040][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 04:51:08,228][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 04:51:11,204][root][INFO] - 

[2024-10-16 04:51:11,205][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 04:51:11,205][root][INFO] - Data Preprocessing
[2024-10-16 04:51:11,205][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 04:51:11,205][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 04:51:11,205][root][INFO] - ㄴ data_remove                False

[2024-10-16 04:51:11,205][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 04:51:11,213][root][INFO] - vocab size              : 51200
[2024-10-16 04:51:11,213][root][INFO] - device                  : gpu
[2024-10-16 04:51:11,213][root][INFO] - random seed             : 3
[2024-10-16 04:51:11,213][root][INFO] - train data size         : 49152
[2024-10-16 04:51:11,213][root][INFO] - max epochs              : 10
[2024-10-16 04:51:11,213][root][INFO] - total steps             : 7680
[2024-10-16 04:51:11,213][root][INFO] - warmup steps            : 768
[2024-10-16 04:51:11,213][root][INFO] - batch size              : 64
[2024-10-16 04:51:11,214][root][INFO] - accumulation steps      : 1
[2024-10-16 04:51:11,214][root][INFO] - optimizer               : adamwscale
[2024-10-16 04:51:11,214][root][INFO] - lr_scheduler            : cosine
[2024-10-16 04:51:11,214][root][INFO] - learning rate           : 0.01
[2024-10-16 04:51:11,214][root][INFO] - max length              : 256

[2024-10-16 04:51:11,214][root][INFO] - LoRA Configuration
[2024-10-16 04:51:11,214][root][INFO] - ㄴ r                    : 32
[2024-10-16 04:51:11,214][root][INFO] - ㄴ alpha                : 128
[2024-10-16 04:51:11,214][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 04:51:11,214][root][INFO] - KOMBO Configuration
[2024-10-16 04:51:11,214][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 04:51:11,215][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 04:51:11,215][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 04:51:11,215][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 04:51:11,215][root][INFO] - ㄴ do_combination       : True
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 04:51:11,215][root][INFO] - 

[2024-10-16 04:51:11,215][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 04:51:11,216][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 04:51:11,216][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 04:51:11,216][root][INFO] - * tb interval   : 10000

[2024-10-16 04:51:11,216][root][INFO] - 

[2024-10-16 04:51:11,216][root][INFO] - Start the Training !
[2024-10-16 04:51:11,219][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 04:58:40,231][root][INFO] - Step: 768/7680  |  Loss: 0.6403  |  Score: 62.30 [%]  |  Seq Length: 256.0
[2024-10-16 04:58:49,171][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 04:58:49,172][root][INFO] - Score: 65.99 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 04:58:58,155][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 04:58:58,156][root][INFO] - Score: 65.19 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 04:58:58,157][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 04:58:58,158][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 05:06:26,677][root][INFO] - Step: 1536/7680  |  Loss: 0.5201  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-16 05:06:35,656][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 05:06:35,656][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 05:06:44,618][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 05:06:44,619][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:06:44,620][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 05:06:44,621][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 05:14:14,847][root][INFO] - Step: 2304/7680  |  Loss: 0.4547  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-16 05:14:23,978][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 05:14:23,978][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-16 05:14:33,099][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 05:14:33,100][root][INFO] - Score: 70.54 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-16 05:14:33,101][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 05:14:33,102][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 05:17:14,697][root][INFO] - Step: 73665/73665  |  Loss: 0.5080  |  Score: 79.70 [%]  |  Seq Length: 256.0
[2024-10-16 05:17:24,885][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 05:17:24,885][root][INFO] - Score: 74.86 [%]  |  Evaluation Time: 10.18 [s]
[2024-10-16 05:17:45,017][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 05:17:45,017][root][INFO] - Score: 76.17 [%]  |  Evaluation Time: 20.13 [s]
[2024-10-16 05:17:45,018][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 05:17:45,018][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 05:17:45,018][root][INFO] - - Epoch: 5
[2024-10-16 05:17:45,018][root][INFO] - - DEV score: 74.86 [%]
[2024-10-16 05:17:45,018][root][INFO] - - TEST score: 76.17 [%]
[2024-10-16 05:17:45,019][root][INFO] - Fine-tuning is done!
[2024-10-16 05:19:44,938][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,938][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,939][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,939][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,940][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,940][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,941][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,941][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,942][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,942][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,943][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,943][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,944][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,944][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,945][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,945][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,946][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,946][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,947][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,947][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,948][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,948][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,949][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,949][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,951][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-16 05:19:45,157][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 05:19:45,159][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-16 05:19:45,160][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 05:19:45,347][root][INFO] - 

[2024-10-16 05:19:45,347][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-16 05:19:45,347][root][INFO] - Data Preprocessing
[2024-10-16 05:19:45,347][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-16 05:19:45,347][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 05:19:45,347][root][INFO] - ㄴ data_remove                False

[2024-10-16 05:19:45,347][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 05:19:45,359][root][INFO] - vocab size              : 51200
[2024-10-16 05:19:45,360][root][INFO] - device                  : gpu
[2024-10-16 05:19:45,360][root][INFO] - random seed             : 2
[2024-10-16 05:19:45,360][root][INFO] - train data size         : 942912
[2024-10-16 05:19:45,360][root][INFO] - max epochs              : 5
[2024-10-16 05:19:45,360][root][INFO] - total steps             : 73665
[2024-10-16 05:19:45,360][root][INFO] - warmup steps            : 7366
[2024-10-16 05:19:45,360][root][INFO] - batch size              : 64
[2024-10-16 05:19:45,360][root][INFO] - accumulation steps      : 1
[2024-10-16 05:19:45,360][root][INFO] - optimizer               : adamwscale
[2024-10-16 05:19:45,361][root][INFO] - lr_scheduler            : cosine
[2024-10-16 05:19:45,361][root][INFO] - learning rate           : 0.02
[2024-10-16 05:19:45,361][root][INFO] - max length              : 256

[2024-10-16 05:19:45,361][root][INFO] - LoRA Configuration
[2024-10-16 05:19:45,361][root][INFO] - ㄴ r                    : 32
[2024-10-16 05:19:45,361][root][INFO] - ㄴ alpha                : 128
[2024-10-16 05:19:45,361][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 05:19:45,361][root][INFO] - KOMBO Configuration
[2024-10-16 05:19:45,361][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 05:19:45,361][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 05:19:45,361][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 05:19:45,362][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 05:19:45,362][root][INFO] - ㄴ do_combination       : True
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 05:19:45,362][root][INFO] - 

[2024-10-16 05:19:45,362][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-16 05:19:45,362][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 05:19:45,362][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb
[2024-10-16 05:19:45,362][root][INFO] - * tb interval   : 10000

[2024-10-16 05:19:45,363][root][INFO] - 

[2024-10-16 05:19:45,363][root][INFO] - Start the Training !
[2024-10-16 05:19:45,365][root][INFO] - 
[1/ 5 Epoch]
[2024-10-16 05:22:02,159][root][INFO] - Step: 3072/7680  |  Loss: 0.4076  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-16 05:22:11,119][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 05:22:11,120][root][INFO] - Score: 73.46 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:22:20,132][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 05:22:20,132][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 05:22:20,133][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 05:22:20,134][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 05:29:48,004][root][INFO] - Step: 3840/7680  |  Loss: 0.3683  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-16 05:29:56,969][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 05:29:56,969][root][INFO] - Score: 75.77 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:30:05,932][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 05:30:05,932][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:30:05,933][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 05:30:05,934][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 05:37:34,353][root][INFO] - Step: 4608/7680  |  Loss: 0.3315  |  Score: 84.98 [%]  |  Seq Length: 256.0
[2024-10-16 05:37:43,327][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 05:37:43,327][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 05:37:52,326][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 05:37:52,326][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 05:37:52,327][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 05:37:52,328][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 05:45:20,438][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-16 05:45:29,366][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 05:45:29,366][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 05:45:38,436][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 05:45:38,436][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 05:45:38,437][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 05:45:38,438][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 05:53:08,577][root][INFO] - Step: 6144/7680  |  Loss: 0.2681  |  Score: 87.98 [%]  |  Seq Length: 256.0
[2024-10-16 05:53:17,717][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 05:53:17,717][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 05:53:26,805][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 05:53:26,805][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 05:53:26,806][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 05:53:26,807][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 06:00:54,226][root][INFO] - Step: 6912/7680  |  Loss: 0.2485  |  Score: 89.16 [%]  |  Seq Length: 256.0
[2024-10-16 06:01:03,161][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 06:01:03,161][root][INFO] - Score: 76.72 [%]  |  Evaluation Time: 8.93 [s]
[2024-10-16 06:01:12,118][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 06:01:12,119][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 06:01:12,120][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 06:01:12,121][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 06:08:40,221][root][INFO] - Step: 7680/7680  |  Loss: 0.2410  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-16 06:08:49,149][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 06:08:49,149][root][INFO] - Score: 76.46 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 06:08:58,111][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 06:08:58,111][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 06:08:58,112][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 06:08:58,112][root][INFO] - - Epoch: 9
[2024-10-16 06:08:58,112][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 06:08:58,112][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 06:08:58,113][root][INFO] - Fine-tuning is done!
[2024-10-16 06:09:10,131][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,131][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,132][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,133][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,133][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,134][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,135][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,136][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,136][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,137][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,138][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,138][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,139][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,140][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,141][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,142][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,142][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,149][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,150][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,150][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,151][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,151][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,152][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,152][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,154][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 06:09:10,372][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 06:09:10,374][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 06:09:10,375][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 06:09:10,543][root][INFO] - 

[2024-10-16 06:09:10,543][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 06:09:10,543][root][INFO] - Data Preprocessing
[2024-10-16 06:09:10,543][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 06:09:10,543][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 06:09:10,543][root][INFO] - ㄴ data_remove                False

[2024-10-16 06:09:10,543][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 06:09:10,552][root][INFO] - vocab size              : 51200
[2024-10-16 06:09:10,552][root][INFO] - device                  : gpu
[2024-10-16 06:09:10,552][root][INFO] - random seed             : 3
[2024-10-16 06:09:10,552][root][INFO] - train data size         : 49152
[2024-10-16 06:09:10,552][root][INFO] - max epochs              : 10
[2024-10-16 06:09:10,552][root][INFO] - total steps             : 7680
[2024-10-16 06:09:10,552][root][INFO] - warmup steps            : 768
[2024-10-16 06:09:10,552][root][INFO] - batch size              : 64
[2024-10-16 06:09:10,553][root][INFO] - accumulation steps      : 1
[2024-10-16 06:09:10,553][root][INFO] - optimizer               : adamwscale
[2024-10-16 06:09:10,553][root][INFO] - lr_scheduler            : cosine
[2024-10-16 06:09:10,553][root][INFO] - learning rate           : 0.02
[2024-10-16 06:09:10,553][root][INFO] - max length              : 256

[2024-10-16 06:09:10,553][root][INFO] - LoRA Configuration
[2024-10-16 06:09:10,553][root][INFO] - ㄴ r                    : 32
[2024-10-16 06:09:10,553][root][INFO] - ㄴ alpha                : 128
[2024-10-16 06:09:10,553][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 06:09:10,553][root][INFO] - KOMBO Configuration
[2024-10-16 06:09:10,553][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 06:09:10,553][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 06:09:10,554][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 06:09:10,554][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 06:09:10,554][root][INFO] - ㄴ do_combination       : True
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 06:09:10,554][root][INFO] - 

[2024-10-16 06:09:10,554][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 06:09:10,555][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 06:09:10,555][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 06:09:10,555][root][INFO] - * tb interval   : 10000

[2024-10-16 06:09:10,555][root][INFO] - 

[2024-10-16 06:09:10,555][root][INFO] - Start the Training !
[2024-10-16 06:09:10,557][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 06:16:40,681][root][INFO] - Step: 768/7680  |  Loss: 0.6252  |  Score: 64.13 [%]  |  Seq Length: 256.0
[2024-10-16 06:16:49,702][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 06:16:49,702][root][INFO] - Score: 68.57 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 06:16:58,695][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 06:16:58,696][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 06:16:58,696][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 06:16:58,698][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 06:24:29,143][root][INFO] - Step: 1536/7680  |  Loss: 0.5207  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-16 06:24:38,184][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 06:24:38,185][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 06:24:47,263][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 06:24:47,263][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 06:24:47,264][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 06:24:47,266][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 06:32:14,699][root][INFO] - Step: 2304/7680  |  Loss: 0.4711  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-16 06:32:23,669][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 06:32:23,670][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 06:32:32,711][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 06:32:32,711][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 06:32:32,712][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 06:32:32,714][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 06:40:02,487][root][INFO] - Step: 3072/7680  |  Loss: 0.4328  |  Score: 79.44 [%]  |  Seq Length: 256.0
[2024-10-16 06:40:11,461][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 06:40:11,461][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 06:40:20,519][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 06:40:20,519][root][INFO] - Score: 71.79 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 06:40:20,520][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 06:40:20,522][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 06:47:50,585][root][INFO] - Step: 3840/7680  |  Loss: 0.3889  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-16 06:47:59,645][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 06:47:59,645][root][INFO] - Score: 74.17 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 06:48:08,715][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 06:48:08,715][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 06:48:08,717][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 06:48:34,562][root][INFO] - Step: 10000/73665  |  Loss: 0.7587  |  Score: 66.92 [%]  |  Seq Length: 256.0
[2024-10-16 06:55:36,491][root][INFO] - Step: 4608/7680  |  Loss: 0.3400  |  Score: 84.52 [%]  |  Seq Length: 256.0
[2024-10-16 06:55:45,510][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 06:55:45,510][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 06:55:54,605][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 06:55:54,605][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 06:55:54,606][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 06:55:54,608][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 07:03:24,834][root][INFO] - Step: 5376/7680  |  Loss: 0.2948  |  Score: 86.84 [%]  |  Seq Length: 256.0
[2024-10-16 07:03:33,915][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 07:03:33,915][root][INFO] - Score: 75.16 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 07:03:42,995][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 07:03:42,995][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 07:03:42,998][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 07:11:10,294][root][INFO] - Step: 6144/7680  |  Loss: 0.2517  |  Score: 88.88 [%]  |  Seq Length: 256.0
[2024-10-16 07:11:19,176][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 07:11:19,176][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 07:11:28,054][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 07:11:28,054][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 07:11:28,055][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 07:11:28,057][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 07:18:56,285][root][INFO] - Step: 6912/7680  |  Loss: 0.2166  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-16 07:19:05,149][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 07:19:05,149][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 8.86 [s]
[2024-10-16 07:19:14,072][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 07:19:14,072][root][INFO] - Score: 73.41 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 07:19:14,073][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 07:19:14,074][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 07:26:40,499][root][INFO] - Step: 7680/7680  |  Loss: 0.1979  |  Score: 91.43 [%]  |  Seq Length: 256.0
[2024-10-16 07:26:49,390][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 07:26:49,390][root][INFO] - Score: 76.60 [%]  |  Evaluation Time: 8.89 [s]
[2024-10-16 07:26:58,289][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 07:26:58,289][root][INFO] - Score: 73.52 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 07:26:58,290][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 07:26:58,290][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 07:26:58,290][root][INFO] - - Epoch: 10
[2024-10-16 07:26:58,290][root][INFO] - - DEV score: 76.60 [%]
[2024-10-16 07:26:58,290][root][INFO] - - TEST score: 73.52 [%]
[2024-10-16 07:26:58,291][root][INFO] - Fine-tuning is done!
[2024-10-16 07:26:58,291][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 07:26:58,292][root][INFO] - - BEST LR: 0.01
[2024-10-16 07:26:58,292][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 07:26:58,292][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 07:27:03,909][root][INFO] - 

[2024-10-16 07:27:03,909][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 07:27:03,909][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 07:27:03,909][root][INFO] - 

[2024-10-16 07:27:03,910][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 07:27:11,299][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,300][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,300][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,301][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,302][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,302][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,303][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,303][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,304][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,304][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,305][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,305][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,306][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,307][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,307][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,308][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,308][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,309][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,309][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,310][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,312][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,312][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,313][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,313][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,315][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 07:27:11,320][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 07:27:11,512][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 07:27:11,514][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 07:27:11,698][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 07:27:14,629][root][INFO] - 

[2024-10-16 07:27:14,629][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 07:27:14,629][root][INFO] - Data Preprocessing
[2024-10-16 07:27:14,629][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 07:27:14,629][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 07:27:14,629][root][INFO] - ㄴ data_remove                True

[2024-10-16 07:27:14,629][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 07:27:14,637][root][INFO] - vocab size              : 51200
[2024-10-16 07:27:14,637][root][INFO] - device                  : gpu
[2024-10-16 07:27:14,637][root][INFO] - random seed             : 1
[2024-10-16 07:27:14,637][root][INFO] - train data size         : 24256
[2024-10-16 07:27:14,637][root][INFO] - max epochs              : 10
[2024-10-16 07:27:14,637][root][INFO] - total steps             : 3790
[2024-10-16 07:27:14,637][root][INFO] - warmup steps            : 379
[2024-10-16 07:27:14,637][root][INFO] - batch size              : 64
[2024-10-16 07:27:14,637][root][INFO] - accumulation steps      : 1
[2024-10-16 07:27:14,637][root][INFO] - optimizer               : adamwscale
[2024-10-16 07:27:14,638][root][INFO] - lr_scheduler            : cosine
[2024-10-16 07:27:14,638][root][INFO] - learning rate           : 0.01
[2024-10-16 07:27:14,638][root][INFO] - max length              : 256

[2024-10-16 07:27:14,638][root][INFO] - LoRA Configuration
[2024-10-16 07:27:14,638][root][INFO] - ㄴ r                    : 32
[2024-10-16 07:27:14,638][root][INFO] - ㄴ alpha                : 128
[2024-10-16 07:27:14,638][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 07:27:14,638][root][INFO] - KOMBO Configuration
[2024-10-16 07:27:14,638][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 07:27:14,638][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 07:27:14,638][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 07:27:14,639][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 07:27:14,639][root][INFO] - ㄴ do_combination       : True
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 07:27:14,639][root][INFO] - 

[2024-10-16 07:27:14,639][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 07:27:14,639][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 07:27:14,639][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 07:27:14,640][root][INFO] - * tb interval   : 10000

[2024-10-16 07:27:14,640][root][INFO] - 

[2024-10-16 07:27:14,640][root][INFO] - Start the Training !
[2024-10-16 07:27:14,642][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 07:30:34,592][root][INFO] - Step: 14733/73665  |  Loss: 0.8354  |  Score: 62.15 [%]  |  Seq Length: 256.0
[2024-10-16 07:30:45,059][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 07:30:45,059][root][INFO] - Score: 58.93 [%]  |  Evaluation Time: 10.46 [s]
[2024-10-16 07:30:53,603][root][INFO] - Step: 379/3790  |  Loss: 0.6989  |  Score: 54.10 [%]  |  Seq Length: 256.0
[2024-10-16 07:30:58,143][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 07:30:58,143][root][INFO] - Score: 58.98 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 07:31:02,615][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 07:31:02,615][root][INFO] - Score: 56.52 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 07:31:02,616][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 07:31:02,617][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 07:31:05,224][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 07:31:05,224][root][INFO] - Score: 58.80 [%]  |  Evaluation Time: 20.16 [s]
[2024-10-16 07:31:05,225][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 07:31:05,226][root][INFO] - 
[2/ 5 Epoch]
[2024-10-16 07:34:41,391][root][INFO] - Step: 758/3790  |  Loss: 0.5957  |  Score: 68.22 [%]  |  Seq Length: 256.0
[2024-10-16 07:34:45,907][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 07:34:45,907][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:34:50,325][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 07:34:50,326][root][INFO] - Score: 60.83 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 07:34:50,326][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 07:34:50,328][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 07:38:29,226][root][INFO] - Step: 1137/3790  |  Loss: 0.5221  |  Score: 73.95 [%]  |  Seq Length: 256.0
[2024-10-16 07:38:33,735][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 07:38:33,735][root][INFO] - Score: 65.33 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:38:38,166][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 07:38:38,167][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 07:38:38,168][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 07:38:38,169][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 07:42:16,662][root][INFO] - Step: 1516/3790  |  Loss: 0.4657  |  Score: 77.93 [%]  |  Seq Length: 256.0
[2024-10-16 07:42:21,181][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 07:42:21,181][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 07:42:25,671][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 07:42:25,671][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 07:42:25,672][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 07:42:25,674][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 07:46:03,629][root][INFO] - Step: 1895/3790  |  Loss: 0.4148  |  Score: 80.71 [%]  |  Seq Length: 256.0
[2024-10-16 07:46:08,156][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 07:46:08,156][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 07:46:12,592][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 07:46:12,592][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 07:46:12,593][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 07:46:12,594][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 07:49:47,230][root][INFO] - Step: 2274/3790  |  Loss: 0.3753  |  Score: 82.87 [%]  |  Seq Length: 256.0
[2024-10-16 07:49:51,751][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 07:49:51,752][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 07:49:56,181][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 07:49:56,181][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 07:49:56,182][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 07:49:56,183][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 07:53:34,664][root][INFO] - Step: 2653/3790  |  Loss: 0.3384  |  Score: 84.64 [%]  |  Seq Length: 256.0
[2024-10-16 07:53:39,174][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 07:53:39,175][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:53:43,612][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 07:53:43,612][root][INFO] - Score: 66.65 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-16 07:53:43,614][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 07:57:22,243][root][INFO] - Step: 3032/3790  |  Loss: 0.3095  |  Score: 86.36 [%]  |  Seq Length: 256.0
[2024-10-16 07:57:26,754][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 07:57:26,754][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:57:31,203][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 07:57:31,204][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-16 07:57:31,206][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 08:01:09,344][root][INFO] - Step: 3411/3790  |  Loss: 0.2896  |  Score: 87.03 [%]  |  Seq Length: 256.0
[2024-10-16 08:01:13,867][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 08:01:13,867][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:01:18,324][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 08:01:18,324][root][INFO] - Score: 66.61 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-16 08:01:18,326][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 08:04:56,648][root][INFO] - Step: 3790/3790  |  Loss: 0.2791  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-16 08:05:01,167][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 08:05:01,167][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:05:05,603][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 08:05:05,603][root][INFO] - Score: 67.19 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 08:05:05,604][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 08:05:05,604][root][INFO] - - Epoch: 6
[2024-10-16 08:05:05,604][root][INFO] - - DEV score: 73.34 [%]
[2024-10-16 08:05:05,604][root][INFO] - - TEST score: 66.74 [%]
[2024-10-16 08:05:05,605][root][INFO] - Fine-tuning is done!
[2024-10-16 08:05:12,554][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,555][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,555][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,556][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,557][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,557][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,558][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,559][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,559][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,560][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,561][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,562][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,563][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,563][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,564][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,564][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,565][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,565][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,566][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,566][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,567][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,567][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,568][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,568][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,570][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 08:05:12,770][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 08:05:12,772][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 08:05:12,773][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 08:05:12,935][root][INFO] - 

[2024-10-16 08:05:12,935][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 08:05:12,935][root][INFO] - Data Preprocessing
[2024-10-16 08:05:12,935][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 08:05:12,935][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 08:05:12,935][root][INFO] - ㄴ data_remove                True

[2024-10-16 08:05:12,935][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 08:05:12,943][root][INFO] - vocab size              : 51200
[2024-10-16 08:05:12,944][root][INFO] - device                  : gpu
[2024-10-16 08:05:12,944][root][INFO] - random seed             : 1
[2024-10-16 08:05:12,944][root][INFO] - train data size         : 24256
[2024-10-16 08:05:12,944][root][INFO] - max epochs              : 10
[2024-10-16 08:05:12,944][root][INFO] - total steps             : 3790
[2024-10-16 08:05:12,944][root][INFO] - warmup steps            : 379
[2024-10-16 08:05:12,944][root][INFO] - batch size              : 64
[2024-10-16 08:05:12,944][root][INFO] - accumulation steps      : 1
[2024-10-16 08:05:12,944][root][INFO] - optimizer               : adamwscale
[2024-10-16 08:05:12,944][root][INFO] - lr_scheduler            : cosine
[2024-10-16 08:05:12,944][root][INFO] - learning rate           : 0.02
[2024-10-16 08:05:12,945][root][INFO] - max length              : 256

[2024-10-16 08:05:12,945][root][INFO] - LoRA Configuration
[2024-10-16 08:05:12,945][root][INFO] - ㄴ r                    : 32
[2024-10-16 08:05:12,945][root][INFO] - ㄴ alpha                : 128
[2024-10-16 08:05:12,945][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 08:05:12,945][root][INFO] - KOMBO Configuration
[2024-10-16 08:05:12,945][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 08:05:12,945][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 08:05:12,945][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 08:05:12,945][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 08:05:12,945][root][INFO] - ㄴ do_combination       : True
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 08:05:12,946][root][INFO] - 

[2024-10-16 08:05:12,946][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 08:05:12,946][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 08:05:12,946][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 08:05:12,946][root][INFO] - * tb interval   : 10000

[2024-10-16 08:05:12,946][root][INFO] - 

[2024-10-16 08:05:12,946][root][INFO] - Start the Training !
[2024-10-16 08:05:12,948][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 08:08:46,119][root][INFO] - Step: 379/3790  |  Loss: 0.6780  |  Score: 57.60 [%]  |  Seq Length: 256.0
[2024-10-16 08:08:50,681][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 08:08:50,681][root][INFO] - Score: 64.06 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 08:08:55,171][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 08:08:55,172][root][INFO] - Score: 59.82 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 08:08:55,173][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 08:08:55,174][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 08:12:28,381][root][INFO] - Step: 758/3790  |  Loss: 0.5684  |  Score: 70.11 [%]  |  Seq Length: 256.0
[2024-10-16 08:12:32,942][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 08:12:32,942][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 08:12:37,421][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 08:12:37,421][root][INFO] - Score: 64.67 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:12:37,422][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 08:12:37,423][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 08:16:12,024][root][INFO] - Step: 1137/3790  |  Loss: 0.5130  |  Score: 74.31 [%]  |  Seq Length: 256.0
[2024-10-16 08:16:16,589][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 08:16:16,589][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 08:16:21,102][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 08:16:21,102][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 08:16:21,103][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 08:16:21,104][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 08:17:53,282][root][INFO] - Step: 20000/73665  |  Loss: 1.0400  |  Score: 44.93 [%]  |  Seq Length: 256.0
[2024-10-16 08:20:00,198][root][INFO] - Step: 1516/3790  |  Loss: 0.4611  |  Score: 77.89 [%]  |  Seq Length: 256.0
[2024-10-16 08:20:04,750][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 08:20:04,750][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 08:20:09,241][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 08:20:09,241][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 08:20:09,242][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 08:20:09,244][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 08:23:47,850][root][INFO] - Step: 1895/3790  |  Loss: 0.4025  |  Score: 81.25 [%]  |  Seq Length: 256.0
[2024-10-16 08:23:52,427][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 08:23:52,427][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 08:23:56,906][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 08:23:56,906][root][INFO] - Score: 65.55 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:23:56,909][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 08:27:35,234][root][INFO] - Step: 2274/3790  |  Loss: 0.3566  |  Score: 83.93 [%]  |  Seq Length: 256.0
[2024-10-16 08:27:39,804][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 08:27:39,804][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 08:27:44,282][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 08:27:44,282][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:27:44,285][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 08:31:23,145][root][INFO] - Step: 2653/3790  |  Loss: 0.3011  |  Score: 86.48 [%]  |  Seq Length: 256.0
[2024-10-16 08:31:27,741][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 08:31:27,741][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 08:31:32,240][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 08:31:32,240][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 08:31:32,242][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 08:35:10,553][root][INFO] - Step: 3032/3790  |  Loss: 0.2530  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-16 08:35:15,084][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 08:35:15,084][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 08:35:19,581][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 08:35:19,581][root][INFO] - Score: 67.99 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 08:35:19,583][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 08:38:58,415][root][INFO] - Step: 3411/3790  |  Loss: 0.2240  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-16 08:39:02,967][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 08:39:02,968][root][INFO] - Score: 68.85 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 08:39:07,493][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 08:39:07,494][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:39:07,495][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 08:42:46,658][root][INFO] - Step: 3790/3790  |  Loss: 0.2060  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-16 08:42:51,260][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 08:42:51,260][root][INFO] - Score: 70.21 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-16 08:42:55,745][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 08:42:55,746][root][INFO] - Score: 67.39 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:42:55,747][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 08:42:55,747][root][INFO] - - Epoch: 4
[2024-10-16 08:42:55,747][root][INFO] - - DEV score: 70.02 [%]
[2024-10-16 08:42:55,747][root][INFO] - - TEST score: 67.80 [%]
[2024-10-16 08:42:55,748][root][INFO] - Fine-tuning is done!
[2024-10-16 08:42:55,748][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 08:42:55,748][root][INFO] - - BEST LR: 0.01
[2024-10-16 08:42:55,748][root][INFO] - - DEV score: 73.34 [%]
[2024-10-16 08:42:55,748][root][INFO] - - TEST score: 66.74 [%]
[2024-10-16 08:43:01,497][root][INFO] - 

[2024-10-16 08:43:01,497][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 08:43:01,497][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 08:43:01,497][root][INFO] - 

[2024-10-16 08:43:01,497][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 08:43:08,960][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,961][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,961][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,962][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,962][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,963][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,963][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,964][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,964][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,965][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,965][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,966][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,966][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,967][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,967][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,968][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,968][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,969][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,969][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,970][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,971][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,972][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,972][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,973][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,975][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 08:43:08,979][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 08:43:09,176][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 08:43:09,179][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 08:43:09,373][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 08:43:12,432][root][INFO] - 

[2024-10-16 08:43:12,432][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 08:43:12,432][root][INFO] - Data Preprocessing
[2024-10-16 08:43:12,432][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 08:43:12,432][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 08:43:12,432][root][INFO] - ㄴ data_remove                True

[2024-10-16 08:43:12,433][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 08:43:12,440][root][INFO] - vocab size              : 51200
[2024-10-16 08:43:12,441][root][INFO] - device                  : gpu
[2024-10-16 08:43:12,441][root][INFO] - random seed             : 2
[2024-10-16 08:43:12,441][root][INFO] - train data size         : 24256
[2024-10-16 08:43:12,441][root][INFO] - max epochs              : 10
[2024-10-16 08:43:12,441][root][INFO] - total steps             : 3790
[2024-10-16 08:43:12,441][root][INFO] - warmup steps            : 379
[2024-10-16 08:43:12,441][root][INFO] - batch size              : 64
[2024-10-16 08:43:12,441][root][INFO] - accumulation steps      : 1
[2024-10-16 08:43:12,441][root][INFO] - optimizer               : adamwscale
[2024-10-16 08:43:12,441][root][INFO] - lr_scheduler            : cosine
[2024-10-16 08:43:12,441][root][INFO] - learning rate           : 0.01
[2024-10-16 08:43:12,441][root][INFO] - max length              : 256

[2024-10-16 08:43:12,442][root][INFO] - LoRA Configuration
[2024-10-16 08:43:12,442][root][INFO] - ㄴ r                    : 32
[2024-10-16 08:43:12,442][root][INFO] - ㄴ alpha                : 128
[2024-10-16 08:43:12,442][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 08:43:12,442][root][INFO] - KOMBO Configuration
[2024-10-16 08:43:12,442][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 08:43:12,442][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 08:43:12,442][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 08:43:12,442][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 08:43:12,442][root][INFO] - ㄴ do_combination       : True
[2024-10-16 08:43:12,442][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 08:43:12,443][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 08:43:12,443][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 08:43:12,443][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 08:43:12,443][root][INFO] - 

[2024-10-16 08:43:12,443][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 08:43:12,443][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 08:43:12,443][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 08:43:12,443][root][INFO] - * tb interval   : 10000

[2024-10-16 08:43:12,443][root][INFO] - 

[2024-10-16 08:43:12,443][root][INFO] - Start the Training !
[2024-10-16 08:43:12,446][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 08:46:51,490][root][INFO] - Step: 379/3790  |  Loss: 0.6820  |  Score: 57.01 [%]  |  Seq Length: 256.0
[2024-10-16 08:46:56,061][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 08:46:56,061][root][INFO] - Score: 62.79 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 08:47:00,539][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 08:47:00,539][root][INFO] - Score: 59.45 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:47:00,540][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 08:47:00,542][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 08:50:38,010][root][INFO] - Step: 758/3790  |  Loss: 0.5809  |  Score: 69.35 [%]  |  Seq Length: 256.0
[2024-10-16 08:50:42,536][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 08:50:42,536][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:50:46,936][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 08:50:46,937][root][INFO] - Score: 62.75 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-16 08:50:46,937][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 08:50:46,939][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 08:54:24,248][root][INFO] - Step: 1137/3790  |  Loss: 0.5210  |  Score: 74.19 [%]  |  Seq Length: 256.0
[2024-10-16 08:54:28,844][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 08:54:28,844][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 08:54:33,349][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 08:54:33,350][root][INFO] - Score: 64.53 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 08:54:33,351][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 08:54:33,352][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 08:58:11,488][root][INFO] - Step: 1516/3790  |  Loss: 0.4662  |  Score: 77.42 [%]  |  Seq Length: 256.0
[2024-10-16 08:58:15,966][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 08:58:15,966][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 08:58:20,392][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 08:58:20,392][root][INFO] - Score: 65.94 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 08:58:20,394][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 09:01:58,432][root][INFO] - Step: 1895/3790  |  Loss: 0.4199  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-16 09:02:02,960][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 09:02:02,960][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 09:02:07,383][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 09:02:07,383][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 09:02:07,384][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 09:02:07,385][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 09:05:43,701][root][INFO] - Step: 2274/3790  |  Loss: 0.3750  |  Score: 82.67 [%]  |  Seq Length: 256.0
[2024-10-16 09:05:48,226][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 09:05:48,226][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 09:05:52,820][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 09:05:52,820][root][INFO] - Score: 66.42 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:05:52,823][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 09:09:29,401][root][INFO] - Step: 2653/3790  |  Loss: 0.3405  |  Score: 84.53 [%]  |  Seq Length: 256.0
[2024-10-16 09:09:33,990][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 09:09:33,990][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:09:38,439][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 09:09:38,439][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-16 09:09:38,441][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 09:13:16,440][root][INFO] - Step: 3032/3790  |  Loss: 0.3098  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-16 09:13:20,921][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 09:13:20,921][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 09:13:25,332][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 09:13:25,333][root][INFO] - Score: 68.67 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-16 09:13:25,334][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 09:13:25,335][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 09:17:03,266][root][INFO] - Step: 3411/3790  |  Loss: 0.2952  |  Score: 86.68 [%]  |  Seq Length: 256.0
[2024-10-16 09:17:07,757][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 09:17:07,757][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 09:17:12,183][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 09:17:12,184][root][INFO] - Score: 67.27 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 09:17:12,186][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 09:20:50,240][root][INFO] - Step: 3790/3790  |  Loss: 0.2806  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-16 09:20:54,825][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 09:20:54,825][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:20:59,366][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 09:20:59,367][root][INFO] - Score: 68.42 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 09:20:59,368][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 09:20:59,368][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 09:20:59,368][root][INFO] - - Epoch: 10
[2024-10-16 09:20:59,368][root][INFO] - - DEV score: 72.75 [%]
[2024-10-16 09:20:59,368][root][INFO] - - TEST score: 68.42 [%]
[2024-10-16 09:20:59,369][root][INFO] - Fine-tuning is done!
[2024-10-16 09:21:06,146][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,147][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,147][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,148][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,148][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,149][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,150][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,150][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,151][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,151][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,152][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,152][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,153][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,153][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,154][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,154][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,155][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,155][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,156][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,156][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,157][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,158][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,158][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,159][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,161][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 09:21:06,355][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 09:21:06,357][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 09:21:06,358][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 09:21:06,523][root][INFO] - 

[2024-10-16 09:21:06,523][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 09:21:06,523][root][INFO] - Data Preprocessing
[2024-10-16 09:21:06,523][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 09:21:06,523][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 09:21:06,524][root][INFO] - ㄴ data_remove                True

[2024-10-16 09:21:06,524][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 09:21:06,531][root][INFO] - vocab size              : 51200
[2024-10-16 09:21:06,531][root][INFO] - device                  : gpu
[2024-10-16 09:21:06,532][root][INFO] - random seed             : 2
[2024-10-16 09:21:06,532][root][INFO] - train data size         : 24256
[2024-10-16 09:21:06,532][root][INFO] - max epochs              : 10
[2024-10-16 09:21:06,532][root][INFO] - total steps             : 3790
[2024-10-16 09:21:06,532][root][INFO] - warmup steps            : 379
[2024-10-16 09:21:06,532][root][INFO] - batch size              : 64
[2024-10-16 09:21:06,532][root][INFO] - accumulation steps      : 1
[2024-10-16 09:21:06,532][root][INFO] - optimizer               : adamwscale
[2024-10-16 09:21:06,532][root][INFO] - lr_scheduler            : cosine
[2024-10-16 09:21:06,532][root][INFO] - learning rate           : 0.02
[2024-10-16 09:21:06,532][root][INFO] - max length              : 256

[2024-10-16 09:21:06,532][root][INFO] - LoRA Configuration
[2024-10-16 09:21:06,533][root][INFO] - ㄴ r                    : 32
[2024-10-16 09:21:06,533][root][INFO] - ㄴ alpha                : 128
[2024-10-16 09:21:06,533][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 09:21:06,533][root][INFO] - KOMBO Configuration
[2024-10-16 09:21:06,533][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 09:21:06,533][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 09:21:06,533][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 09:21:06,533][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 09:21:06,533][root][INFO] - ㄴ do_combination       : True
[2024-10-16 09:21:06,533][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 09:21:06,534][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 09:21:06,534][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 09:21:06,534][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 09:21:06,534][root][INFO] - 

[2024-10-16 09:21:06,534][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 09:21:06,534][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 09:21:06,534][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 09:21:06,534][root][INFO] - * tb interval   : 10000

[2024-10-16 09:21:06,534][root][INFO] - 

[2024-10-16 09:21:06,534][root][INFO] - Start the Training !
[2024-10-16 09:21:06,536][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 09:24:45,719][root][INFO] - Step: 379/3790  |  Loss: 0.6703  |  Score: 59.12 [%]  |  Seq Length: 256.0
[2024-10-16 09:24:50,415][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 09:24:50,415][root][INFO] - Score: 66.41 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-16 09:24:54,891][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 09:24:54,891][root][INFO] - Score: 59.91 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 09:24:54,892][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 09:24:54,893][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 09:28:32,033][root][INFO] - Step: 758/3790  |  Loss: 0.5669  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-16 09:28:36,619][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 09:28:36,619][root][INFO] - Score: 67.58 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:28:41,212][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 09:28:41,212][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:28:41,213][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 09:28:41,214][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 09:32:18,244][root][INFO] - Step: 1137/3790  |  Loss: 0.5082  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-16 09:32:22,773][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 09:32:22,773][root][INFO] - Score: 65.53 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 09:32:27,227][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 09:32:27,227][root][INFO] - Score: 67.04 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-16 09:32:27,229][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 09:36:00,250][root][INFO] - Step: 1516/3790  |  Loss: 0.4569  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-16 09:36:04,809][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 09:36:04,809][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 09:36:09,394][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 09:36:09,394][root][INFO] - Score: 66.84 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:36:09,395][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 09:36:09,396][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 09:39:48,494][root][INFO] - Step: 1895/3790  |  Loss: 0.4079  |  Score: 81.11 [%]  |  Seq Length: 256.0
[2024-10-16 09:39:53,089][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 09:39:53,089][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:39:57,663][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 09:39:57,663][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:39:57,664][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 09:39:57,665][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 09:40:54,834][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.35 [%]  |  Seq Length: 256.0
[2024-10-16 09:41:04,927][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 09:41:04,927][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.09 [s]
[2024-10-16 09:41:24,741][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 09:41:24,741][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 19.81 [s]
[2024-10-16 09:41:24,743][root][INFO] - 
[3/ 5 Epoch]
[2024-10-16 09:43:35,952][root][INFO] - Step: 2274/3790  |  Loss: 0.3487  |  Score: 84.15 [%]  |  Seq Length: 256.0
[2024-10-16 09:43:40,525][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 09:43:40,525][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:43:45,053][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 09:43:45,053][root][INFO] - Score: 68.03 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 09:43:45,054][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 09:43:45,055][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 09:46:05,951][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.41 [%]  |  Seq Length: 256.0
[2024-10-16 09:47:24,007][root][INFO] - Step: 2653/3790  |  Loss: 0.2954  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-16 09:47:28,578][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 09:47:28,578][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:47:33,101][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 09:47:33,101][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 09:47:33,102][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 09:47:33,103][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 09:51:11,359][root][INFO] - Step: 3032/3790  |  Loss: 0.2463  |  Score: 89.20 [%]  |  Seq Length: 256.0
[2024-10-16 09:51:15,937][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 09:51:15,938][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:51:20,370][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 09:51:20,370][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 09:51:20,372][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 09:54:57,506][root][INFO] - Step: 3411/3790  |  Loss: 0.2186  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-16 09:55:02,035][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 09:55:02,035][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 09:55:06,477][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 09:55:06,477][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-16 09:55:06,479][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 09:58:45,016][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-16 09:58:49,591][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 09:58:49,591][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:58:54,050][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 09:58:54,050][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-16 09:58:54,051][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 09:58:54,051][root][INFO] - - Epoch: 7
[2024-10-16 09:58:54,051][root][INFO] - - DEV score: 71.29 [%]
[2024-10-16 09:58:54,051][root][INFO] - - TEST score: 69.32 [%]
[2024-10-16 09:58:54,053][root][INFO] - Fine-tuning is done!
[2024-10-16 09:58:54,053][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 09:58:54,053][root][INFO] - - BEST LR: 0.01
[2024-10-16 09:58:54,053][root][INFO] - - DEV score: 72.75 [%]
[2024-10-16 09:58:54,053][root][INFO] - - TEST score: 68.42 [%]
[2024-10-16 09:58:59,645][root][INFO] - 

[2024-10-16 09:58:59,645][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 09:58:59,645][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 09:58:59,645][root][INFO] - 

[2024-10-16 09:58:59,646][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 09:59:07,621][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,622][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,623][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,623][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,624][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,624][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,625][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,625][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,626][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,626][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,627][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,627][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,628][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,628][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,629][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,629][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,630][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,631][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,631][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,632][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,635][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,636][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,636][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,637][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,639][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 09:59:07,643][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 09:59:07,837][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 09:59:07,839][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 09:59:08,041][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 09:59:11,151][root][INFO] - 

[2024-10-16 09:59:11,151][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 09:59:11,151][root][INFO] - Data Preprocessing
[2024-10-16 09:59:11,151][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 09:59:11,151][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 09:59:11,151][root][INFO] - ㄴ data_remove                True

[2024-10-16 09:59:11,151][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 09:59:11,159][root][INFO] - vocab size              : 51200
[2024-10-16 09:59:11,159][root][INFO] - device                  : gpu
[2024-10-16 09:59:11,159][root][INFO] - random seed             : 3
[2024-10-16 09:59:11,159][root][INFO] - train data size         : 24256
[2024-10-16 09:59:11,159][root][INFO] - max epochs              : 10
[2024-10-16 09:59:11,159][root][INFO] - total steps             : 3790
[2024-10-16 09:59:11,160][root][INFO] - warmup steps            : 379
[2024-10-16 09:59:11,160][root][INFO] - batch size              : 64
[2024-10-16 09:59:11,160][root][INFO] - accumulation steps      : 1
[2024-10-16 09:59:11,160][root][INFO] - optimizer               : adamwscale
[2024-10-16 09:59:11,160][root][INFO] - lr_scheduler            : cosine
[2024-10-16 09:59:11,160][root][INFO] - learning rate           : 0.01
[2024-10-16 09:59:11,160][root][INFO] - max length              : 256

[2024-10-16 09:59:11,160][root][INFO] - LoRA Configuration
[2024-10-16 09:59:11,160][root][INFO] - ㄴ r                    : 32
[2024-10-16 09:59:11,160][root][INFO] - ㄴ alpha                : 128
[2024-10-16 09:59:11,160][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 09:59:11,160][root][INFO] - KOMBO Configuration
[2024-10-16 09:59:11,161][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 09:59:11,161][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 09:59:11,161][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 09:59:11,161][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 09:59:11,161][root][INFO] - ㄴ do_combination       : True
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 09:59:11,162][root][INFO] - 

[2024-10-16 09:59:11,162][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 09:59:11,162][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 09:59:11,162][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 09:59:11,162][root][INFO] - * tb interval   : 10000

[2024-10-16 09:59:11,162][root][INFO] - 

[2024-10-16 09:59:11,162][root][INFO] - Start the Training !
[2024-10-16 09:59:11,165][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 10:02:50,281][root][INFO] - Step: 379/3790  |  Loss: 0.6791  |  Score: 57.91 [%]  |  Seq Length: 256.0
[2024-10-16 10:02:54,789][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 10:02:54,789][root][INFO] - Score: 61.13 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 10:02:59,200][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 10:02:59,200][root][INFO] - Score: 60.72 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-16 10:02:59,201][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 10:02:59,203][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 10:06:37,073][root][INFO] - Step: 758/3790  |  Loss: 0.5750  |  Score: 69.89 [%]  |  Seq Length: 256.0
[2024-10-16 10:06:41,606][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 10:06:41,606][root][INFO] - Score: 66.02 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 10:06:46,046][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 10:06:46,046][root][INFO] - Score: 64.05 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-16 10:06:46,047][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 10:06:46,048][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 10:10:23,930][root][INFO] - Step: 1137/3790  |  Loss: 0.5122  |  Score: 74.67 [%]  |  Seq Length: 256.0
[2024-10-16 10:10:28,439][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 10:10:28,439][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 10:10:32,847][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 10:10:32,847][root][INFO] - Score: 64.39 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-16 10:10:32,848][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 10:10:32,849][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 10:14:10,400][root][INFO] - Step: 1516/3790  |  Loss: 0.4581  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-16 10:14:14,967][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 10:14:14,968][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 10:14:19,438][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 10:14:19,438][root][INFO] - Score: 63.62 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 10:14:19,443][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 10:17:57,544][root][INFO] - Step: 1895/3790  |  Loss: 0.4133  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-16 10:18:02,114][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 10:18:02,114][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 10:18:06,657][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 10:18:06,657][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:18:06,658][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 10:18:06,659][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 10:21:45,856][root][INFO] - Step: 2274/3790  |  Loss: 0.3714  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-16 10:21:50,397][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 10:21:50,398][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:21:54,825][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 10:21:54,825][root][INFO] - Score: 65.54 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 10:21:54,827][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 10:25:32,799][root][INFO] - Step: 2653/3790  |  Loss: 0.3333  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-16 10:25:37,269][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 10:25:37,269][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 10:25:41,832][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 10:25:41,832][root][INFO] - Score: 65.60 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 10:25:41,834][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 10:29:19,908][root][INFO] - Step: 3032/3790  |  Loss: 0.3040  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-16 10:29:24,466][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 10:29:24,466][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 10:29:28,868][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 10:29:28,868][root][INFO] - Score: 66.08 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-16 10:29:28,869][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 10:29:28,870][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 10:33:05,994][root][INFO] - Step: 3411/3790  |  Loss: 0.2838  |  Score: 87.23 [%]  |  Seq Length: 256.0
[2024-10-16 10:33:10,563][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 10:33:10,563][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 10:33:14,989][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 10:33:14,989][root][INFO] - Score: 65.73 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 10:33:14,992][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 10:36:53,181][root][INFO] - Step: 3790/3790  |  Loss: 0.2712  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-16 10:36:57,719][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 10:36:57,719][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 10:37:02,435][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 10:37:02,435][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-16 10:37:02,436][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 10:37:02,437][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 10:37:02,437][root][INFO] - - Epoch: 10
[2024-10-16 10:37:02,437][root][INFO] - - DEV score: 72.85 [%]
[2024-10-16 10:37:02,437][root][INFO] - - TEST score: 65.70 [%]
[2024-10-16 10:37:02,437][root][INFO] - Fine-tuning is done!
[2024-10-16 10:37:08,985][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,986][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,986][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,987][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,987][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,988][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,988][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,989][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,989][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,990][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,990][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,990][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,991][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,991][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,992][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,992][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,993][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,993][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,994][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,994][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,995][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,995][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,996][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,996][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,998][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 10:37:09,192][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 10:37:09,194][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 10:37:09,195][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 10:37:09,363][root][INFO] - 

[2024-10-16 10:37:09,363][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 10:37:09,363][root][INFO] - Data Preprocessing
[2024-10-16 10:37:09,363][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 10:37:09,363][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 10:37:09,363][root][INFO] - ㄴ data_remove                True

[2024-10-16 10:37:09,363][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 10:37:09,371][root][INFO] - vocab size              : 51200
[2024-10-16 10:37:09,371][root][INFO] - device                  : gpu
[2024-10-16 10:37:09,371][root][INFO] - random seed             : 3
[2024-10-16 10:37:09,372][root][INFO] - train data size         : 24256
[2024-10-16 10:37:09,372][root][INFO] - max epochs              : 10
[2024-10-16 10:37:09,372][root][INFO] - total steps             : 3790
[2024-10-16 10:37:09,372][root][INFO] - warmup steps            : 379
[2024-10-16 10:37:09,372][root][INFO] - batch size              : 64
[2024-10-16 10:37:09,372][root][INFO] - accumulation steps      : 1
[2024-10-16 10:37:09,372][root][INFO] - optimizer               : adamwscale
[2024-10-16 10:37:09,372][root][INFO] - lr_scheduler            : cosine
[2024-10-16 10:37:09,372][root][INFO] - learning rate           : 0.02
[2024-10-16 10:37:09,372][root][INFO] - max length              : 256

[2024-10-16 10:37:09,372][root][INFO] - LoRA Configuration
[2024-10-16 10:37:09,372][root][INFO] - ㄴ r                    : 32
[2024-10-16 10:37:09,373][root][INFO] - ㄴ alpha                : 128
[2024-10-16 10:37:09,373][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 10:37:09,373][root][INFO] - KOMBO Configuration
[2024-10-16 10:37:09,373][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 10:37:09,373][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 10:37:09,373][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 10:37:09,373][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 10:37:09,373][root][INFO] - ㄴ do_combination       : True
[2024-10-16 10:37:09,373][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 10:37:09,373][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 10:37:09,374][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 10:37:09,374][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 10:37:09,374][root][INFO] - 

[2024-10-16 10:37:09,374][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 10:37:09,374][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 10:37:09,374][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 10:37:09,374][root][INFO] - * tb interval   : 10000

[2024-10-16 10:37:09,374][root][INFO] - 

[2024-10-16 10:37:09,374][root][INFO] - Start the Training !
[2024-10-16 10:37:09,376][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 10:40:48,497][root][INFO] - Step: 379/3790  |  Loss: 0.6607  |  Score: 60.10 [%]  |  Seq Length: 256.0
[2024-10-16 10:40:53,047][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 10:40:53,048][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 10:40:57,543][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 10:40:57,543][root][INFO] - Score: 60.64 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 10:40:57,544][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 10:40:57,545][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 10:44:33,194][root][INFO] - Step: 758/3790  |  Loss: 0.5616  |  Score: 71.12 [%]  |  Seq Length: 256.0
[2024-10-16 10:44:37,735][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 10:44:37,735][root][INFO] - Score: 65.04 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:44:42,262][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 10:44:42,263][root][INFO] - Score: 62.68 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 10:44:42,265][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 10:48:20,669][root][INFO] - Step: 1137/3790  |  Loss: 0.4997  |  Score: 75.63 [%]  |  Seq Length: 256.0
[2024-10-16 10:48:25,271][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 10:48:25,272][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-16 10:48:29,742][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 10:48:29,742][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 10:48:29,743][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 10:48:29,744][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 10:52:08,422][root][INFO] - Step: 1516/3790  |  Loss: 0.4472  |  Score: 78.90 [%]  |  Seq Length: 256.0
[2024-10-16 10:52:13,014][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 10:52:13,014][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 10:52:17,517][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 10:52:17,517][root][INFO] - Score: 66.80 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 10:52:17,518][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 10:52:17,519][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 10:55:56,269][root][INFO] - Step: 1895/3790  |  Loss: 0.3977  |  Score: 81.23 [%]  |  Seq Length: 256.0
[2024-10-16 10:56:00,825][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 10:56:00,825][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 10:56:05,364][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 10:56:05,364][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:56:05,365][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 10:56:05,366][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 10:59:43,804][root][INFO] - Step: 2274/3790  |  Loss: 0.3445  |  Score: 84.26 [%]  |  Seq Length: 256.0
[2024-10-16 10:59:48,461][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 10:59:48,461][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-16 10:59:53,061][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 10:59:53,062][root][INFO] - Score: 66.36 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-16 10:59:53,064][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 11:03:33,573][root][INFO] - Step: 2653/3790  |  Loss: 0.2995  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-16 11:03:38,136][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 11:03:38,136][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 11:03:42,655][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 11:03:42,655][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 11:03:42,657][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 11:07:22,964][root][INFO] - Step: 3032/3790  |  Loss: 0.2495  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-16 11:07:27,516][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 11:07:27,517][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 11:07:31,991][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 11:07:31,991][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 11:07:31,992][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 11:07:31,993][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 11:11:11,234][root][INFO] - Step: 3411/3790  |  Loss: 0.2111  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-16 11:11:15,774][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 11:11:15,774][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 11:11:20,240][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 11:11:20,240][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-16 11:11:20,242][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 11:13:34,447][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-16 11:15:00,387][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.52 [%]  |  Seq Length: 256.0
[2024-10-16 11:15:05,115][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 11:15:05,115][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-16 11:15:09,870][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 11:15:09,870][root][INFO] - Score: 68.36 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-16 11:15:09,871][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 11:15:09,871][root][INFO] - - Epoch: 8
[2024-10-16 11:15:09,871][root][INFO] - - DEV score: 73.83 [%]
[2024-10-16 11:15:09,871][root][INFO] - - TEST score: 68.33 [%]
[2024-10-16 11:15:09,872][root][INFO] - Fine-tuning is done!
[2024-10-16 11:15:09,873][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 11:15:09,873][root][INFO] - - BEST LR: 0.02
[2024-10-16 11:15:09,873][root][INFO] - - DEV score: 73.83 [%]
[2024-10-16 11:15:09,873][root][INFO] - - TEST score: 68.33 [%]
[2024-10-16 11:15:16,039][root][INFO] - 

[2024-10-16 11:15:16,040][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 11:15:16,040][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 11:15:16,040][root][INFO] - 

[2024-10-16 11:15:16,040][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 11:15:28,974][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,974][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,975][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,975][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,975][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,976][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,976][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,977][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,977][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,978][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,978][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,978][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,979][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,979][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,980][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,980][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,981][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,981][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,982][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,982][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,983][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,983][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,984][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,984][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,986][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 11:15:28,990][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 11:15:29,192][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 11:15:29,195][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 11:15:29,385][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 11:15:32,613][root][INFO] - 

[2024-10-16 11:15:32,613][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 11:15:32,613][root][INFO] - Data Preprocessing
[2024-10-16 11:15:32,613][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 11:15:32,613][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 11:15:32,613][root][INFO] - ㄴ data_remove                False

[2024-10-16 11:15:32,613][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 11:15:32,621][root][INFO] - vocab size              : 51200
[2024-10-16 11:15:32,621][root][INFO] - device                  : gpu
[2024-10-16 11:15:32,621][root][INFO] - random seed             : 1
[2024-10-16 11:15:32,621][root][INFO] - train data size         : 49152
[2024-10-16 11:15:32,621][root][INFO] - max epochs              : 10
[2024-10-16 11:15:32,621][root][INFO] - total steps             : 7680
[2024-10-16 11:15:32,621][root][INFO] - warmup steps            : 768
[2024-10-16 11:15:32,622][root][INFO] - batch size              : 64
[2024-10-16 11:15:32,622][root][INFO] - accumulation steps      : 1
[2024-10-16 11:15:32,622][root][INFO] - optimizer               : adamwscale
[2024-10-16 11:15:32,622][root][INFO] - lr_scheduler            : cosine
[2024-10-16 11:15:32,622][root][INFO] - learning rate           : 0.01
[2024-10-16 11:15:32,622][root][INFO] - max length              : 256

[2024-10-16 11:15:32,622][root][INFO] - LoRA Configuration
[2024-10-16 11:15:32,622][root][INFO] - ㄴ r                    : 32
[2024-10-16 11:15:32,622][root][INFO] - ㄴ alpha                : 128
[2024-10-16 11:15:32,622][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 11:15:32,622][root][INFO] - KOMBO Configuration
[2024-10-16 11:15:32,623][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 11:15:32,623][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 11:15:32,623][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 11:15:32,623][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 11:15:32,623][root][INFO] - ㄴ do_combination       : True
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 11:15:32,623][root][INFO] - 

[2024-10-16 11:15:32,624][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 11:15:32,624][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 11:15:32,624][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 11:15:32,624][root][INFO] - * tb interval   : 10000

[2024-10-16 11:15:32,624][root][INFO] - 

[2024-10-16 11:15:32,624][root][INFO] - Start the Training !
[2024-10-16 11:15:32,627][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 11:23:01,966][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-16 11:23:11,033][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 11:23:11,033][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 11:23:20,051][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 11:23:20,052][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 11:23:20,053][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 11:23:20,054][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 11:30:47,940][root][INFO] - Step: 1536/7680  |  Loss: 0.5295  |  Score: 73.27 [%]  |  Seq Length: 256.0
[2024-10-16 11:30:56,685][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 11:30:56,685][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 11:31:05,430][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 11:31:05,430][root][INFO] - Score: 69.51 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 11:31:05,431][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 11:31:05,432][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 11:38:31,794][root][INFO] - Step: 2304/7680  |  Loss: 0.4638  |  Score: 77.33 [%]  |  Seq Length: 256.0
[2024-10-16 11:38:40,786][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 11:38:40,786][root][INFO] - Score: 72.97 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 11:38:49,798][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 11:38:49,798][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 11:38:49,800][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 11:38:49,801][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 11:46:16,186][root][INFO] - Step: 3072/7680  |  Loss: 0.4107  |  Score: 80.68 [%]  |  Seq Length: 256.0
[2024-10-16 11:46:24,927][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 11:46:24,927][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 11:46:33,743][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 11:46:33,743][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 11:46:33,744][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 11:46:33,746][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 11:50:33,938][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-16 11:50:44,240][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 11:50:44,240][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-16 11:51:04,369][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 11:51:04,369][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.13 [s]
[2024-10-16 11:51:04,371][root][INFO] - 
[4/ 5 Epoch]
[2024-10-16 11:53:59,611][root][INFO] - Step: 3840/7680  |  Loss: 0.3698  |  Score: 82.74 [%]  |  Seq Length: 256.0
[2024-10-16 11:54:08,389][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 11:54:08,389][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 11:54:17,211][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 11:54:17,211][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 8.82 [s]
[2024-10-16 11:54:17,213][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 12:01:44,288][root][INFO] - Step: 4608/7680  |  Loss: 0.3322  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-16 12:01:53,056][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 12:01:53,056][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 8.76 [s]
[2024-10-16 12:02:01,862][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 12:02:01,862][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 8.80 [s]
[2024-10-16 12:02:01,863][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 12:02:01,864][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 12:09:17,518][root][INFO] - Step: 5376/7680  |  Loss: 0.2993  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-16 12:09:26,246][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 12:09:26,247][root][INFO] - Score: 75.63 [%]  |  Evaluation Time: 8.73 [s]
[2024-10-16 12:09:35,205][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 12:09:35,205][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 12:09:35,206][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 12:09:35,207][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 12:17:01,753][root][INFO] - Step: 6144/7680  |  Loss: 0.2694  |  Score: 88.03 [%]  |  Seq Length: 256.0
[2024-10-16 12:17:10,478][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 12:17:10,479][root][INFO] - Score: 76.32 [%]  |  Evaluation Time: 8.72 [s]
[2024-10-16 12:17:19,247][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 12:17:19,247][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 12:17:19,248][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 12:17:19,249][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 12:24:44,747][root][INFO] - Step: 6912/7680  |  Loss: 0.2510  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-16 12:24:53,491][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 12:24:53,491][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 12:25:02,254][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 12:25:02,255][root][INFO] - Score: 72.82 [%]  |  Evaluation Time: 8.76 [s]
[2024-10-16 12:25:02,256][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 12:25:02,257][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 12:32:27,878][root][INFO] - Step: 7680/7680  |  Loss: 0.2422  |  Score: 89.34 [%]  |  Seq Length: 256.0
[2024-10-16 12:32:36,610][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 12:32:36,610][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 8.73 [s]
[2024-10-16 12:32:45,445][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 12:32:45,445][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 8.83 [s]
[2024-10-16 12:32:45,446][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 12:32:45,446][root][INFO] - - Epoch: 9
[2024-10-16 12:32:45,446][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 12:32:45,446][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 12:32:45,447][root][INFO] - Fine-tuning is done!
[2024-10-16 12:32:57,207][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,208][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,209][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,209][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,210][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,210][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,211][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,212][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,212][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,213][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,214][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,214][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,215][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,215][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,216][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,216][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,217][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,217][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,218][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,219][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,220][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,220][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,221][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,222][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,224][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 12:32:57,426][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 12:32:57,428][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 12:32:57,429][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 12:32:57,596][root][INFO] - 

[2024-10-16 12:32:57,597][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 12:32:57,597][root][INFO] - Data Preprocessing
[2024-10-16 12:32:57,597][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 12:32:57,597][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 12:32:57,597][root][INFO] - ㄴ data_remove                False

[2024-10-16 12:32:57,597][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 12:32:57,605][root][INFO] - vocab size              : 51200
[2024-10-16 12:32:57,605][root][INFO] - device                  : gpu
[2024-10-16 12:32:57,605][root][INFO] - random seed             : 1
[2024-10-16 12:32:57,605][root][INFO] - train data size         : 49152
[2024-10-16 12:32:57,605][root][INFO] - max epochs              : 10
[2024-10-16 12:32:57,605][root][INFO] - total steps             : 7680
[2024-10-16 12:32:57,605][root][INFO] - warmup steps            : 768
[2024-10-16 12:32:57,605][root][INFO] - batch size              : 64
[2024-10-16 12:32:57,605][root][INFO] - accumulation steps      : 1
[2024-10-16 12:32:57,605][root][INFO] - optimizer               : adamwscale
[2024-10-16 12:32:57,606][root][INFO] - lr_scheduler            : cosine
[2024-10-16 12:32:57,606][root][INFO] - learning rate           : 0.02
[2024-10-16 12:32:57,606][root][INFO] - max length              : 256

[2024-10-16 12:32:57,606][root][INFO] - LoRA Configuration
[2024-10-16 12:32:57,606][root][INFO] - ㄴ r                    : 32
[2024-10-16 12:32:57,606][root][INFO] - ㄴ alpha                : 128
[2024-10-16 12:32:57,606][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 12:32:57,606][root][INFO] - KOMBO Configuration
[2024-10-16 12:32:57,606][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 12:32:57,606][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 12:32:57,606][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 12:32:57,607][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 12:32:57,607][root][INFO] - ㄴ do_combination       : True
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 12:32:57,607][root][INFO] - 

[2024-10-16 12:32:57,607][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 12:32:57,607][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 12:32:57,608][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 12:32:57,608][root][INFO] - * tb interval   : 10000

[2024-10-16 12:32:57,608][root][INFO] - 

[2024-10-16 12:32:57,608][root][INFO] - Start the Training !
[2024-10-16 12:32:57,610][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 12:40:24,306][root][INFO] - Step: 768/7680  |  Loss: 0.6396  |  Score: 61.85 [%]  |  Seq Length: 256.0
[2024-10-16 12:40:33,207][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 12:40:33,207][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 12:40:42,029][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 12:40:42,029][root][INFO] - Score: 66.86 [%]  |  Evaluation Time: 8.82 [s]
[2024-10-16 12:40:42,030][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 12:40:42,032][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 12:42:08,321][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-16 12:47:56,988][root][INFO] - Step: 1536/7680  |  Loss: 0.5290  |  Score: 73.49 [%]  |  Seq Length: 256.0
[2024-10-16 12:48:05,930][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 12:48:05,931][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 12:48:14,711][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 12:48:14,711][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 8.78 [s]
[2024-10-16 12:48:14,712][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 12:48:14,713][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 12:55:36,490][root][INFO] - Step: 2304/7680  |  Loss: 0.4797  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-16 12:55:45,537][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 12:55:45,537][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 12:55:54,452][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 12:55:54,452][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 12:55:54,454][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 12:55:54,455][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 13:03:20,628][root][INFO] - Step: 3072/7680  |  Loss: 0.4315  |  Score: 79.38 [%]  |  Seq Length: 256.0
[2024-10-16 13:03:29,424][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 13:03:29,425][root][INFO] - Score: 72.79 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:03:38,236][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 13:03:38,236][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 13:03:38,237][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 13:03:38,238][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 13:11:05,064][root][INFO] - Step: 3840/7680  |  Loss: 0.3944  |  Score: 81.60 [%]  |  Seq Length: 256.0
[2024-10-16 13:11:13,840][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 13:11:13,840][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 13:11:22,714][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 13:11:22,715][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 8.87 [s]
[2024-10-16 13:11:22,716][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 13:11:22,717][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 13:18:50,205][root][INFO] - Step: 4608/7680  |  Loss: 0.3457  |  Score: 84.04 [%]  |  Seq Length: 256.0
[2024-10-16 13:18:59,067][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 13:18:59,067][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 8.86 [s]
[2024-10-16 13:19:07,905][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 13:19:07,905][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 8.84 [s]
[2024-10-16 13:19:07,906][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 13:19:07,908][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 13:26:34,392][root][INFO] - Step: 5376/7680  |  Loss: 0.2974  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-16 13:26:43,183][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 13:26:43,183][root][INFO] - Score: 75.11 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:26:52,013][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 13:26:52,013][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 8.83 [s]
[2024-10-16 13:26:52,015][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 13:34:12,252][root][INFO] - Step: 6144/7680  |  Loss: 0.2532  |  Score: 88.87 [%]  |  Seq Length: 256.0
[2024-10-16 13:34:21,085][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 13:34:21,085][root][INFO] - Score: 75.03 [%]  |  Evaluation Time: 8.83 [s]
[2024-10-16 13:34:29,882][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 13:34:29,882][root][INFO] - Score: 72.98 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:34:29,884][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 13:41:56,310][root][INFO] - Step: 6912/7680  |  Loss: 0.2230  |  Score: 90.33 [%]  |  Seq Length: 256.0
[2024-10-16 13:42:05,092][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 13:42:05,092][root][INFO] - Score: 75.21 [%]  |  Evaluation Time: 8.78 [s]
[2024-10-16 13:42:13,880][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 13:42:13,880][root][INFO] - Score: 72.91 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:42:13,882][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 13:49:39,255][root][INFO] - Step: 7680/7680  |  Loss: 0.2027  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-16 13:49:48,029][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 13:49:48,029][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 13:49:56,829][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 13:49:56,829][root][INFO] - Score: 73.03 [%]  |  Evaluation Time: 8.80 [s]
[2024-10-16 13:49:56,830][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 13:49:56,830][root][INFO] - - Epoch: 6
[2024-10-16 13:49:56,830][root][INFO] - - DEV score: 74.90 [%]
[2024-10-16 13:49:56,830][root][INFO] - - TEST score: 73.44 [%]
[2024-10-16 13:49:56,831][root][INFO] - Fine-tuning is done!
[2024-10-16 13:49:56,832][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 13:49:56,832][root][INFO] - - BEST LR: 0.01
[2024-10-16 13:49:56,832][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 13:49:56,832][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 13:50:02,559][root][INFO] - 

[2024-10-16 13:50:02,559][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 13:50:02,559][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 13:50:02,559][root][INFO] - 

[2024-10-16 13:50:02,559][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 13:50:15,068][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,069][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,069][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,070][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,070][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,071][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,071][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,072][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,072][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,073][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,073][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,074][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,074][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,075][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,075][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,076][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,076][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,077][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,077][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,078][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,078][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,079][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,079][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,080][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,082][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 13:50:15,086][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 13:50:15,280][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 13:50:15,283][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 13:50:15,466][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 13:50:18,339][root][INFO] - 

[2024-10-16 13:50:18,339][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 13:50:18,339][root][INFO] - Data Preprocessing
[2024-10-16 13:50:18,339][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 13:50:18,340][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 13:50:18,340][root][INFO] - ㄴ data_remove                False

[2024-10-16 13:50:18,340][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 13:50:18,347][root][INFO] - vocab size              : 51200
[2024-10-16 13:50:18,347][root][INFO] - device                  : gpu
[2024-10-16 13:50:18,347][root][INFO] - random seed             : 2
[2024-10-16 13:50:18,347][root][INFO] - train data size         : 49152
[2024-10-16 13:50:18,347][root][INFO] - max epochs              : 10
[2024-10-16 13:50:18,347][root][INFO] - total steps             : 7680
[2024-10-16 13:50:18,347][root][INFO] - warmup steps            : 768
[2024-10-16 13:50:18,348][root][INFO] - batch size              : 64
[2024-10-16 13:50:18,348][root][INFO] - accumulation steps      : 1
[2024-10-16 13:50:18,348][root][INFO] - optimizer               : adamwscale
[2024-10-16 13:50:18,348][root][INFO] - lr_scheduler            : cosine
[2024-10-16 13:50:18,348][root][INFO] - learning rate           : 0.01
[2024-10-16 13:50:18,348][root][INFO] - max length              : 256

[2024-10-16 13:50:18,348][root][INFO] - LoRA Configuration
[2024-10-16 13:50:18,348][root][INFO] - ㄴ r                    : 32
[2024-10-16 13:50:18,348][root][INFO] - ㄴ alpha                : 128
[2024-10-16 13:50:18,348][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 13:50:18,348][root][INFO] - KOMBO Configuration
[2024-10-16 13:50:18,348][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 13:50:18,349][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 13:50:18,349][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 13:50:18,349][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 13:50:18,349][root][INFO] - ㄴ do_combination       : True
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 13:50:18,349][root][INFO] - 

[2024-10-16 13:50:18,349][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 13:50:18,350][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 13:50:18,350][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 13:50:18,350][root][INFO] - * tb interval   : 10000

[2024-10-16 13:50:18,350][root][INFO] - 

[2024-10-16 13:50:18,350][root][INFO] - Start the Training !
[2024-10-16 13:50:18,353][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 13:57:45,261][root][INFO] - Step: 768/7680  |  Loss: 0.6386  |  Score: 62.54 [%]  |  Seq Length: 256.0
[2024-10-16 13:57:54,176][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 13:57:54,176][root][INFO] - Score: 68.40 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 13:58:03,140][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 13:58:03,140][root][INFO] - Score: 66.23 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 13:58:03,141][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 13:58:03,143][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 14:00:48,591][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-16 14:00:58,934][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 14:00:58,934][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-16 14:01:19,024][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 14:01:19,024][root][INFO] - Score: 33.23 [%]  |  Evaluation Time: 20.09 [s]
[2024-10-16 14:01:19,027][root][INFO] - 
[5/ 5 Epoch]
[2024-10-16 14:05:32,701][root][INFO] - Step: 1536/7680  |  Loss: 0.5177  |  Score: 74.29 [%]  |  Seq Length: 256.0
[2024-10-16 14:05:41,583][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 14:05:41,583][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 14:05:50,542][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 14:05:50,542][root][INFO] - Score: 67.61 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 14:05:50,544][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 14:05:50,547][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 14:10:43,934][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.36 [%]  |  Seq Length: 256.0
[2024-10-16 14:13:20,936][root][INFO] - Step: 2304/7680  |  Loss: 0.4565  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-16 14:13:29,943][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 14:13:29,943][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 14:13:38,944][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 14:13:38,944][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 14:13:38,945][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 14:13:38,946][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 14:21:10,305][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-16 14:21:19,115][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 14:21:19,115][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:21:27,928][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 14:21:27,928][root][INFO] - Score: 72.89 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:21:27,929][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 14:21:27,930][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 14:28:55,367][root][INFO] - Step: 3840/7680  |  Loss: 0.3670  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-16 14:29:04,149][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 14:29:04,149][root][INFO] - Score: 76.05 [%]  |  Evaluation Time: 8.78 [s]
[2024-10-16 14:29:12,948][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 14:29:12,949][root][INFO] - Score: 73.63 [%]  |  Evaluation Time: 8.80 [s]
[2024-10-16 14:29:12,950][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 14:29:12,951][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 14:36:40,376][root][INFO] - Step: 4608/7680  |  Loss: 0.3297  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-16 14:36:49,187][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 14:36:49,187][root][INFO] - Score: 75.79 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:36:57,998][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 14:36:57,999][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:36:57,999][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 14:36:58,000][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 14:44:25,722][root][INFO] - Step: 5376/7680  |  Loss: 0.2950  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-16 14:44:34,565][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 14:44:34,566][root][INFO] - Score: 75.40 [%]  |  Evaluation Time: 8.84 [s]
[2024-10-16 14:44:43,385][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 14:44:43,386][root][INFO] - Score: 72.84 [%]  |  Evaluation Time: 8.82 [s]
[2024-10-16 14:44:43,387][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 14:52:10,277][root][INFO] - Step: 6144/7680  |  Loss: 0.2654  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-16 14:52:19,135][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 14:52:19,135][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 8.86 [s]
[2024-10-16 14:52:28,077][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 14:52:28,078][root][INFO] - Score: 73.65 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 14:52:28,080][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 14:59:52,900][root][INFO] - Step: 6912/7680  |  Loss: 0.2486  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-16 15:00:01,817][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 15:00:01,817][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 15:00:10,612][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 15:00:10,612][root][INFO] - Score: 73.59 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 15:00:10,614][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 15:07:36,635][root][INFO] - Step: 7680/7680  |  Loss: 0.2369  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-16 15:07:45,575][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 15:07:45,575][root][INFO] - Score: 76.51 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 15:07:54,535][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 15:07:54,535][root][INFO] - Score: 73.88 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 15:07:54,536][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 15:07:54,536][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 15:07:54,536][root][INFO] - - Epoch: 10
[2024-10-16 15:07:54,536][root][INFO] - - DEV score: 76.51 [%]
[2024-10-16 15:07:54,536][root][INFO] - - TEST score: 73.88 [%]
[2024-10-16 15:07:54,537][root][INFO] - Fine-tuning is done!
[2024-10-16 15:08:06,649][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,650][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,650][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,651][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,651][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,652][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,652][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,653][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,654][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,654][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,655][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,655][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,656][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,657][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,657][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,658][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,658][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,659][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,659][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,660][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,660][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,661][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,661][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,662][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,664][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 15:08:06,868][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 15:08:06,871][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 15:08:06,872][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 15:08:07,038][root][INFO] - 

[2024-10-16 15:08:07,038][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 15:08:07,038][root][INFO] - Data Preprocessing
[2024-10-16 15:08:07,038][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 15:08:07,038][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 15:08:07,038][root][INFO] - ㄴ data_remove                False

[2024-10-16 15:08:07,038][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 15:08:07,046][root][INFO] - vocab size              : 51200
[2024-10-16 15:08:07,046][root][INFO] - device                  : gpu
[2024-10-16 15:08:07,046][root][INFO] - random seed             : 2
[2024-10-16 15:08:07,046][root][INFO] - train data size         : 49152
[2024-10-16 15:08:07,046][root][INFO] - max epochs              : 10
[2024-10-16 15:08:07,046][root][INFO] - total steps             : 7680
[2024-10-16 15:08:07,046][root][INFO] - warmup steps            : 768
[2024-10-16 15:08:07,047][root][INFO] - batch size              : 64
[2024-10-16 15:08:07,047][root][INFO] - accumulation steps      : 1
[2024-10-16 15:08:07,047][root][INFO] - optimizer               : adamwscale
[2024-10-16 15:08:07,047][root][INFO] - lr_scheduler            : cosine
[2024-10-16 15:08:07,047][root][INFO] - learning rate           : 0.02
[2024-10-16 15:08:07,047][root][INFO] - max length              : 256

[2024-10-16 15:08:07,047][root][INFO] - LoRA Configuration
[2024-10-16 15:08:07,047][root][INFO] - ㄴ r                    : 32
[2024-10-16 15:08:07,047][root][INFO] - ㄴ alpha                : 128
[2024-10-16 15:08:07,047][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 15:08:07,047][root][INFO] - KOMBO Configuration
[2024-10-16 15:08:07,048][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 15:08:07,048][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 15:08:07,048][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 15:08:07,048][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 15:08:07,048][root][INFO] - ㄴ do_combination       : True
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 15:08:07,048][root][INFO] - 

[2024-10-16 15:08:07,049][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 15:08:07,049][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 15:08:07,049][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 15:08:07,049][root][INFO] - * tb interval   : 10000

[2024-10-16 15:08:07,049][root][INFO] - 

[2024-10-16 15:08:07,049][root][INFO] - Start the Training !
[2024-10-16 15:08:07,051][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 15:15:35,186][root][INFO] - Step: 768/7680  |  Loss: 0.6222  |  Score: 64.46 [%]  |  Seq Length: 256.0
[2024-10-16 15:15:44,208][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 15:15:44,209][root][INFO] - Score: 67.73 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 15:15:53,121][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 15:15:53,121][root][INFO] - Score: 66.79 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 15:15:53,122][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 15:15:53,123][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 15:23:22,261][root][INFO] - Step: 1536/7680  |  Loss: 0.5210  |  Score: 74.06 [%]  |  Seq Length: 256.0
[2024-10-16 15:23:31,218][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 15:23:31,218][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 15:23:40,239][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 15:23:40,239][root][INFO] - Score: 67.05 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 15:23:40,241][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 15:23:40,242][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 15:31:16,247][root][INFO] - Step: 2304/7680  |  Loss: 0.4707  |  Score: 77.22 [%]  |  Seq Length: 256.0
[2024-10-16 15:31:25,478][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 15:31:25,478][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 15:31:34,761][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 15:31:34,762][root][INFO] - Score: 70.17 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-16 15:31:34,763][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 15:31:34,764][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 15:38:46,949][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-16 15:39:11,926][root][INFO] - Step: 3072/7680  |  Loss: 0.4338  |  Score: 79.22 [%]  |  Seq Length: 256.0
[2024-10-16 15:39:21,139][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 15:39:21,140][root][INFO] - Score: 74.96 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 15:39:30,301][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 15:39:30,301][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 15:39:30,302][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 15:39:30,304][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 15:47:13,284][root][INFO] - Step: 3840/7680  |  Loss: 0.3913  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-16 15:47:22,662][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 15:47:22,662][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 9.37 [s]
[2024-10-16 15:47:32,016][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 15:47:32,017][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 9.35 [s]
[2024-10-16 15:47:32,018][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 15:47:32,020][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 15:55:06,825][root][INFO] - Step: 4608/7680  |  Loss: 0.3479  |  Score: 84.10 [%]  |  Seq Length: 256.0
[2024-10-16 15:55:15,940][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 15:55:15,941][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 15:55:25,090][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 15:55:25,090][root][INFO] - Score: 72.64 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 15:55:25,091][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 15:55:25,092][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 16:02:58,877][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.63 [%]  |  Seq Length: 256.0
[2024-10-16 16:03:08,112][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 16:03:08,112][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 16:03:17,327][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 16:03:17,327][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 16:03:17,329][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 16:10:53,176][root][INFO] - Step: 6144/7680  |  Loss: 0.2514  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-16 16:11:02,408][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 16:11:02,409][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 16:11:11,693][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 16:11:11,693][root][INFO] - Score: 74.42 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-16 16:11:11,694][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 16:11:11,695][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 16:11:21,502][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.49 [%]  |  Seq Length: 256.0
[2024-10-16 16:11:31,902][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 16:11:31,902][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.40 [s]
[2024-10-16 16:11:52,196][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 16:11:52,196][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.29 [s]
[2024-10-16 16:11:52,197][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 16:11:52,197][root][INFO] - - Epoch: 1
[2024-10-16 16:11:52,197][root][INFO] - - DEV score: 58.93 [%]
[2024-10-16 16:11:52,197][root][INFO] - - TEST score: 58.80 [%]
[2024-10-16 16:11:52,198][root][INFO] - Fine-tuning is done!
[2024-10-16 16:11:52,199][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 16:11:52,199][root][INFO] - - BEST LR: 0.01
[2024-10-16 16:11:52,199][root][INFO] - - DEV score: 74.86 [%]
[2024-10-16 16:11:52,199][root][INFO] - - TEST score: 76.17 [%]
[2024-10-16 16:11:59,103][root][INFO] - 

[2024-10-16 16:11:59,103][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 16:11:59,103][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-16 16:11:59,104][root][INFO] - 

[2024-10-16 16:11:59,104][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 16:14:07,619][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,620][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,620][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,621][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,621][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,622][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,622][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,622][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,623][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,623][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,624][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,624][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,625][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,625][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,625][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,626][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,626][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,627][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,627][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,627][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,628][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,628][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,629][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,629][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,631][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-16 16:14:07,635][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 16:14:07,843][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 16:14:07,845][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-16 16:14:08,085][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 16:14:11,517][root][INFO] - 

[2024-10-16 16:14:11,517][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-16 16:14:11,518][root][INFO] - Data Preprocessing
[2024-10-16 16:14:11,518][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-16 16:14:11,518][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 16:14:11,518][root][INFO] - ㄴ data_remove                False

[2024-10-16 16:14:11,518][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 16:14:11,526][root][INFO] - vocab size              : 51200
[2024-10-16 16:14:11,526][root][INFO] - device                  : gpu
[2024-10-16 16:14:11,527][root][INFO] - random seed             : 3
[2024-10-16 16:14:11,527][root][INFO] - train data size         : 942912
[2024-10-16 16:14:11,527][root][INFO] - max epochs              : 5
[2024-10-16 16:14:11,527][root][INFO] - total steps             : 73665
[2024-10-16 16:14:11,527][root][INFO] - warmup steps            : 7366
[2024-10-16 16:14:11,527][root][INFO] - batch size              : 64
[2024-10-16 16:14:11,527][root][INFO] - accumulation steps      : 1
[2024-10-16 16:14:11,527][root][INFO] - optimizer               : adamwscale
[2024-10-16 16:14:11,527][root][INFO] - lr_scheduler            : cosine
[2024-10-16 16:14:11,527][root][INFO] - learning rate           : 0.01
[2024-10-16 16:14:11,527][root][INFO] - max length              : 256

[2024-10-16 16:14:11,528][root][INFO] - LoRA Configuration
[2024-10-16 16:14:11,528][root][INFO] - ㄴ r                    : 32
[2024-10-16 16:14:11,528][root][INFO] - ㄴ alpha                : 128
[2024-10-16 16:14:11,528][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 16:14:11,528][root][INFO] - KOMBO Configuration
[2024-10-16 16:14:11,528][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 16:14:11,528][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 16:14:11,528][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 16:14:11,528][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 16:14:11,528][root][INFO] - ㄴ do_combination       : True
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 16:14:11,529][root][INFO] - 

[2024-10-16 16:14:11,529][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-16 16:14:11,529][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 16:14:11,529][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb
[2024-10-16 16:14:11,529][root][INFO] - * tb interval   : 10000

[2024-10-16 16:14:11,529][root][INFO] - 

[2024-10-16 16:14:11,529][root][INFO] - Start the Training !
[2024-10-16 16:14:11,533][root][INFO] - 
[1/ 5 Epoch]
[2024-10-16 16:18:46,441][root][INFO] - Step: 6912/7680  |  Loss: 0.2204  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-16 16:18:55,619][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 16:18:55,619][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-16 16:19:04,793][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 16:19:04,793][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-16 16:19:04,795][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 16:26:37,307][root][INFO] - Step: 7680/7680  |  Loss: 0.1994  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-16 16:26:46,461][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 16:26:46,461][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 16:26:55,683][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 16:26:55,684][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-16 16:26:55,685][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 16:26:55,685][root][INFO] - - Epoch: 8
[2024-10-16 16:26:55,685][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 16:26:55,685][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 16:26:55,686][root][INFO] - Fine-tuning is done!
[2024-10-16 16:26:55,686][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 16:26:55,686][root][INFO] - - BEST LR: 0.02
[2024-10-16 16:26:55,686][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 16:26:55,686][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 16:27:02,012][root][INFO] - 

[2024-10-16 16:27:02,012][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 16:27:02,012][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 16:27:02,013][root][INFO] - 

[2024-10-16 16:27:02,013][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 16:27:16,006][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,007][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,007][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,008][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,008][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,009][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,009][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,009][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,010][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,010][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,011][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,011][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,012][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,012][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,013][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,013][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,014][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,014][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,014][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,015][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,016][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,016][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,017][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,017][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,019][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 16:27:16,025][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 16:27:16,231][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 16:27:16,233][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 16:27:16,427][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 16:27:19,842][root][INFO] - 

[2024-10-16 16:27:19,842][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 16:27:19,842][root][INFO] - Data Preprocessing
[2024-10-16 16:27:19,842][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 16:27:19,842][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 16:27:19,842][root][INFO] - ㄴ data_remove                False

[2024-10-16 16:27:19,842][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 16:27:19,850][root][INFO] - vocab size              : 51200
[2024-10-16 16:27:19,850][root][INFO] - device                  : gpu
[2024-10-16 16:27:19,851][root][INFO] - random seed             : 3
[2024-10-16 16:27:19,851][root][INFO] - train data size         : 49152
[2024-10-16 16:27:19,851][root][INFO] - max epochs              : 10
[2024-10-16 16:27:19,851][root][INFO] - total steps             : 7680
[2024-10-16 16:27:19,851][root][INFO] - warmup steps            : 768
[2024-10-16 16:27:19,851][root][INFO] - batch size              : 64
[2024-10-16 16:27:19,851][root][INFO] - accumulation steps      : 1
[2024-10-16 16:27:19,851][root][INFO] - optimizer               : adamwscale
[2024-10-16 16:27:19,851][root][INFO] - lr_scheduler            : cosine
[2024-10-16 16:27:19,851][root][INFO] - learning rate           : 0.01
[2024-10-16 16:27:19,851][root][INFO] - max length              : 256

[2024-10-16 16:27:19,852][root][INFO] - LoRA Configuration
[2024-10-16 16:27:19,852][root][INFO] - ㄴ r                    : 32
[2024-10-16 16:27:19,852][root][INFO] - ㄴ alpha                : 128
[2024-10-16 16:27:19,852][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 16:27:19,852][root][INFO] - KOMBO Configuration
[2024-10-16 16:27:19,852][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 16:27:19,852][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 16:27:19,852][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 16:27:19,852][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 16:27:19,852][root][INFO] - ㄴ do_combination       : True
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 16:27:19,853][root][INFO] - 

[2024-10-16 16:27:19,853][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 16:27:19,853][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 16:27:19,853][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 16:27:19,853][root][INFO] - * tb interval   : 10000

[2024-10-16 16:27:19,853][root][INFO] - 

[2024-10-16 16:27:19,853][root][INFO] - Start the Training !
[2024-10-16 16:27:19,857][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 16:34:55,728][root][INFO] - Step: 768/7680  |  Loss: 0.6403  |  Score: 62.30 [%]  |  Seq Length: 256.0
[2024-10-16 16:35:04,842][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 16:35:04,842][root][INFO] - Score: 65.99 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 16:35:13,998][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 16:35:13,998][root][INFO] - Score: 65.19 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 16:35:13,999][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 16:35:14,001][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 16:42:48,822][root][INFO] - Step: 1536/7680  |  Loss: 0.5201  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-16 16:42:57,945][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 16:42:57,945][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-16 16:43:07,141][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 16:43:07,141][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-16 16:43:07,142][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 16:43:07,144][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 16:50:41,525][root][INFO] - Step: 2304/7680  |  Loss: 0.4547  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-16 16:50:50,615][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 16:50:50,616][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 16:50:59,703][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 16:50:59,703][root][INFO] - Score: 70.54 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 16:50:59,704][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 16:50:59,705][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 16:58:35,788][root][INFO] - Step: 3072/7680  |  Loss: 0.4076  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-16 16:58:44,928][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 16:58:44,928][root][INFO] - Score: 73.46 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 16:58:54,043][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 16:58:54,043][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 16:58:54,044][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 16:58:54,045][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 17:06:22,358][root][INFO] - Step: 3840/7680  |  Loss: 0.3683  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-16 17:06:31,453][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 17:06:31,453][root][INFO] - Score: 75.77 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 17:06:40,639][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 17:06:40,640][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 17:06:40,641][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 17:06:40,642][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 17:14:13,217][root][INFO] - Step: 4608/7680  |  Loss: 0.3315  |  Score: 84.98 [%]  |  Seq Length: 256.0
[2024-10-16 17:14:22,464][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 17:14:22,465][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 17:14:31,508][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 17:14:31,508][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 17:14:31,509][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 17:14:31,511][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 17:22:05,689][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-16 17:22:14,837][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 17:22:14,837][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 17:22:23,972][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 17:22:23,972][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-16 17:22:23,973][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 17:22:23,975][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 17:29:58,555][root][INFO] - Step: 6144/7680  |  Loss: 0.2681  |  Score: 87.98 [%]  |  Seq Length: 256.0
[2024-10-16 17:30:07,617][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 17:30:07,617][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 17:30:16,796][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 17:30:16,796][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 17:30:16,797][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 17:30:16,798][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 17:37:51,092][root][INFO] - Step: 6912/7680  |  Loss: 0.2485  |  Score: 89.16 [%]  |  Seq Length: 256.0
[2024-10-16 17:38:00,242][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 17:38:00,242][root][INFO] - Score: 76.72 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 17:38:09,263][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 17:38:09,263][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 17:38:09,264][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 17:38:09,266][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 17:43:29,009][root][INFO] - Step: 10000/73665  |  Loss: 0.7362  |  Score: 67.99 [%]  |  Seq Length: 256.0
[2024-10-16 17:45:42,729][root][INFO] - Step: 7680/7680  |  Loss: 0.2410  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-16 17:45:51,841][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 17:45:51,841][root][INFO] - Score: 76.46 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 17:46:00,952][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 17:46:00,953][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 17:46:00,954][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 17:46:00,954][root][INFO] - - Epoch: 9
[2024-10-16 17:46:00,954][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 17:46:00,954][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 17:46:00,955][root][INFO] - Fine-tuning is done!
[2024-10-16 17:46:12,751][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,752][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,752][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,753][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,753][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,754][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,754][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,755][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,756][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,756][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,757][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,757][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,758][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,758][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,759][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,760][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,760][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,760][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,761][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,761][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,762][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,763][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,763][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,764][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,766][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 17:46:12,970][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 17:46:12,972][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 17:46:12,973][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 17:46:13,139][root][INFO] - 

[2024-10-16 17:46:13,139][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 17:46:13,139][root][INFO] - Data Preprocessing
[2024-10-16 17:46:13,139][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 17:46:13,139][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 17:46:13,139][root][INFO] - ㄴ data_remove                False

[2024-10-16 17:46:13,139][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 17:46:13,147][root][INFO] - vocab size              : 51200
[2024-10-16 17:46:13,147][root][INFO] - device                  : gpu
[2024-10-16 17:46:13,147][root][INFO] - random seed             : 3
[2024-10-16 17:46:13,148][root][INFO] - train data size         : 49152
[2024-10-16 17:46:13,148][root][INFO] - max epochs              : 10
[2024-10-16 17:46:13,148][root][INFO] - total steps             : 7680
[2024-10-16 17:46:13,148][root][INFO] - warmup steps            : 768
[2024-10-16 17:46:13,148][root][INFO] - batch size              : 64
[2024-10-16 17:46:13,148][root][INFO] - accumulation steps      : 1
[2024-10-16 17:46:13,148][root][INFO] - optimizer               : adamwscale
[2024-10-16 17:46:13,148][root][INFO] - lr_scheduler            : cosine
[2024-10-16 17:46:13,148][root][INFO] - learning rate           : 0.02
[2024-10-16 17:46:13,148][root][INFO] - max length              : 256

[2024-10-16 17:46:13,148][root][INFO] - LoRA Configuration
[2024-10-16 17:46:13,148][root][INFO] - ㄴ r                    : 32
[2024-10-16 17:46:13,149][root][INFO] - ㄴ alpha                : 128
[2024-10-16 17:46:13,149][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 17:46:13,149][root][INFO] - KOMBO Configuration
[2024-10-16 17:46:13,149][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 17:46:13,149][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 17:46:13,149][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 17:46:13,149][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 17:46:13,149][root][INFO] - ㄴ do_combination       : True
[2024-10-16 17:46:13,149][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 17:46:13,149][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 17:46:13,150][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 17:46:13,150][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 17:46:13,150][root][INFO] - 

[2024-10-16 17:46:13,150][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 17:46:13,150][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 17:46:13,150][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 17:46:13,150][root][INFO] - * tb interval   : 10000

[2024-10-16 17:46:13,150][root][INFO] - 

[2024-10-16 17:46:13,150][root][INFO] - Start the Training !
[2024-10-16 17:46:13,152][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 17:53:45,487][root][INFO] - Step: 768/7680  |  Loss: 0.6252  |  Score: 64.13 [%]  |  Seq Length: 256.0
[2024-10-16 17:53:54,704][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 17:53:54,704][root][INFO] - Score: 68.57 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-16 17:54:03,849][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 17:54:03,849][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 17:54:03,850][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 17:54:03,852][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 18:01:38,585][root][INFO] - Step: 1536/7680  |  Loss: 0.5207  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-16 18:01:47,724][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 18:01:47,724][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 18:01:56,955][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 18:01:56,955][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 18:01:56,956][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 18:01:56,957][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 18:09:31,422][root][INFO] - Step: 2304/7680  |  Loss: 0.4711  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-16 18:09:40,532][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 18:09:40,532][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 18:09:49,717][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 18:09:49,717][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 18:09:49,718][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 18:09:49,720][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 18:17:24,846][root][INFO] - Step: 3072/7680  |  Loss: 0.4328  |  Score: 79.44 [%]  |  Seq Length: 256.0
[2024-10-16 18:17:34,037][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 18:17:34,037][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-16 18:17:43,264][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 18:17:43,265][root][INFO] - Score: 71.79 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 18:17:43,266][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 18:17:43,267][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 18:25:18,089][root][INFO] - Step: 3840/7680  |  Loss: 0.3889  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-16 18:25:27,270][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 18:25:27,270][root][INFO] - Score: 74.17 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 18:25:36,400][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 18:25:36,400][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-16 18:25:36,402][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 18:25:39,020][root][INFO] - Step: 14733/73665  |  Loss: 0.6625  |  Score: 72.18 [%]  |  Seq Length: 256.0
[2024-10-16 18:25:49,326][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 18:25:49,327][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-16 18:26:09,628][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 18:26:09,628][root][INFO] - Score: 72.65 [%]  |  Evaluation Time: 20.30 [s]
[2024-10-16 18:26:09,629][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 18:26:09,631][root][INFO] - 
[2/ 5 Epoch]
[2024-10-16 18:33:10,976][root][INFO] - Step: 4608/7680  |  Loss: 0.3400  |  Score: 84.52 [%]  |  Seq Length: 256.0
[2024-10-16 18:33:20,073][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 18:33:20,074][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 18:33:29,173][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 18:33:29,173][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-16 18:33:29,174][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 18:33:29,175][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 18:41:02,849][root][INFO] - Step: 5376/7680  |  Loss: 0.2948  |  Score: 86.84 [%]  |  Seq Length: 256.0
[2024-10-16 18:41:12,008][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 18:41:12,009][root][INFO] - Score: 75.16 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 18:41:21,160][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 18:41:21,160][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 18:41:21,163][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 18:48:58,220][root][INFO] - Step: 6144/7680  |  Loss: 0.2517  |  Score: 88.88 [%]  |  Seq Length: 256.0
[2024-10-16 18:49:07,318][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 18:49:07,318][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 18:49:16,468][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 18:49:16,468][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 18:49:16,469][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 18:49:16,470][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 18:56:50,852][root][INFO] - Step: 6912/7680  |  Loss: 0.2166  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-16 18:57:00,067][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 18:57:00,068][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 18:57:09,305][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 18:57:09,305][root][INFO] - Score: 73.41 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 18:57:09,306][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 18:57:09,307][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 19:04:42,240][root][INFO] - Step: 7680/7680  |  Loss: 0.1979  |  Score: 91.43 [%]  |  Seq Length: 256.0
[2024-10-16 19:04:51,503][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 19:04:51,503][root][INFO] - Score: 76.60 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-16 19:05:00,665][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 19:05:00,665][root][INFO] - Score: 73.52 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 19:05:00,666][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 19:05:00,666][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 19:05:00,666][root][INFO] - - Epoch: 10
[2024-10-16 19:05:00,666][root][INFO] - - DEV score: 76.60 [%]
[2024-10-16 19:05:00,666][root][INFO] - - TEST score: 73.52 [%]
[2024-10-16 19:05:00,667][root][INFO] - Fine-tuning is done!
[2024-10-16 19:05:00,667][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 19:05:00,667][root][INFO] - - BEST LR: 0.01
[2024-10-16 19:05:00,668][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 19:05:00,668][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 19:13:08,210][root][INFO] - Step: 20000/73665  |  Loss: 0.6357  |  Score: 73.67 [%]  |  Seq Length: 256.0
[2024-10-16 20:37:04,106][root][INFO] - Step: 29466/73665  |  Loss: 0.6306  |  Score: 73.81 [%]  |  Seq Length: 256.0
[2024-10-16 20:37:14,262][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 20:37:14,262][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 10.15 [s]
[2024-10-16 20:37:34,198][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 20:37:34,198][root][INFO] - Score: 72.95 [%]  |  Evaluation Time: 19.93 [s]
[2024-10-16 20:37:34,199][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 20:37:34,201][root][INFO] - 
[3/ 5 Epoch]
[2024-10-16 20:42:19,093][root][INFO] - Step: 30000/73665  |  Loss: 0.6061  |  Score: 75.16 [%]  |  Seq Length: 256.0
[2024-10-16 22:11:29,456][root][INFO] - Step: 40000/73665  |  Loss: 0.5994  |  Score: 75.39 [%]  |  Seq Length: 256.0
[2024-10-16 22:48:58,756][root][INFO] - Step: 44199/73665  |  Loss: 0.5837  |  Score: 76.03 [%]  |  Seq Length: 256.0
[2024-10-16 22:49:09,168][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 22:49:09,168][root][INFO] - Score: 73.35 [%]  |  Evaluation Time: 10.41 [s]
[2024-10-16 22:49:29,278][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 22:49:29,278][root][INFO] - Score: 75.25 [%]  |  Evaluation Time: 20.11 [s]
[2024-10-16 22:49:29,279][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 22:49:29,280][root][INFO] - 
[4/ 5 Epoch]
[2024-10-16 23:41:13,237][root][INFO] - Step: 50000/73665  |  Loss: 0.5542  |  Score: 77.51 [%]  |  Seq Length: 256.0
[2024-10-17 01:00:59,902][root][INFO] - Step: 58932/73665  |  Loss: 0.5405  |  Score: 78.15 [%]  |  Seq Length: 256.0
[2024-10-17 01:01:10,206][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 01:01:10,206][root][INFO] - Score: 74.48 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-17 01:01:30,309][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 01:01:30,309][root][INFO] - Score: 75.88 [%]  |  Evaluation Time: 20.10 [s]
[2024-10-17 01:01:30,310][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 01:01:30,311][root][INFO] - 
[5/ 5 Epoch]
[2024-10-17 01:11:00,731][root][INFO] - Step: 60000/73665  |  Loss: 0.5087  |  Score: 79.58 [%]  |  Seq Length: 256.0
[2024-10-17 02:40:02,435][root][INFO] - Step: 70000/73665  |  Loss: 0.5067  |  Score: 79.69 [%]  |  Seq Length: 256.0
[2024-10-17 03:12:44,846][root][INFO] - Step: 73665/73665  |  Loss: 0.5061  |  Score: 79.67 [%]  |  Seq Length: 256.0
[2024-10-17 03:12:55,165][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 03:12:55,166][root][INFO] - Score: 74.55 [%]  |  Evaluation Time: 10.32 [s]
[2024-10-17 03:13:15,343][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 03:13:15,344][root][INFO] - Score: 76.55 [%]  |  Evaluation Time: 20.18 [s]
[2024-10-17 03:13:15,346][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 03:13:15,346][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 03:13:15,346][root][INFO] - - Epoch: 5
[2024-10-17 03:13:15,346][root][INFO] - - DEV score: 74.55 [%]
[2024-10-17 03:13:15,346][root][INFO] - - TEST score: 76.55 [%]
[2024-10-17 03:13:15,347][root][INFO] - Fine-tuning is done!
[2024-10-17 03:15:21,887][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,887][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,888][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,888][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,889][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,889][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,890][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,890][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,891][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,891][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,892][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,892][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,893][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,893][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,894][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,894][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,895][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,895][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,896][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,896][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,897][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,897][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,898][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,898][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,900][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-17 03:15:22,115][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 03:15:22,121][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-17 03:15:22,124][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 03:15:22,314][root][INFO] - 

[2024-10-17 03:15:22,314][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-17 03:15:22,314][root][INFO] - Data Preprocessing
[2024-10-17 03:15:22,314][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-17 03:15:22,314][root][INFO] - ㄴ do_hangeulize              False
[2024-10-17 03:15:22,314][root][INFO] - ㄴ data_remove                False

[2024-10-17 03:15:22,314][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 03:15:22,327][root][INFO] - vocab size              : 51200
[2024-10-17 03:15:22,328][root][INFO] - device                  : gpu
[2024-10-17 03:15:22,328][root][INFO] - random seed             : 3
[2024-10-17 03:15:22,328][root][INFO] - train data size         : 942912
[2024-10-17 03:15:22,328][root][INFO] - max epochs              : 5
[2024-10-17 03:15:22,328][root][INFO] - total steps             : 73665
[2024-10-17 03:15:22,328][root][INFO] - warmup steps            : 7366
[2024-10-17 03:15:22,328][root][INFO] - batch size              : 64
[2024-10-17 03:15:22,328][root][INFO] - accumulation steps      : 1
[2024-10-17 03:15:22,328][root][INFO] - optimizer               : adamwscale
[2024-10-17 03:15:22,329][root][INFO] - lr_scheduler            : cosine
[2024-10-17 03:15:22,329][root][INFO] - learning rate           : 0.02
[2024-10-17 03:15:22,329][root][INFO] - max length              : 256

[2024-10-17 03:15:22,329][root][INFO] - LoRA Configuration
[2024-10-17 03:15:22,329][root][INFO] - ㄴ r                    : 32
[2024-10-17 03:15:22,329][root][INFO] - ㄴ alpha                : 128
[2024-10-17 03:15:22,329][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 03:15:22,329][root][INFO] - KOMBO Configuration
[2024-10-17 03:15:22,329][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 03:15:22,330][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 03:15:22,330][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 03:15:22,330][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 03:15:22,330][root][INFO] - ㄴ do_combination       : True
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 03:15:22,330][root][INFO] - 

[2024-10-17 03:15:22,331][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-17 03:15:22,331][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-17 03:15:22,331][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb
[2024-10-17 03:15:22,331][root][INFO] - * tb interval   : 10000

[2024-10-17 03:15:22,331][root][INFO] - 

[2024-10-17 03:15:22,331][root][INFO] - Start the Training !
[2024-10-17 03:15:22,333][root][INFO] - 
[1/ 5 Epoch]
[2024-10-17 04:44:01,343][root][INFO] - Step: 10000/73665  |  Loss: 0.7611  |  Score: 66.76 [%]  |  Seq Length: 256.0
[2024-10-17 05:26:11,330][root][INFO] - Step: 14733/73665  |  Loss: 0.8295  |  Score: 62.59 [%]  |  Seq Length: 256.0
[2024-10-17 05:26:21,764][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 05:26:21,764][root][INFO] - Score: 57.00 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-17 05:26:41,983][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 05:26:41,983][root][INFO] - Score: 57.65 [%]  |  Evaluation Time: 20.22 [s]
[2024-10-17 05:26:41,984][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 05:26:41,985][root][INFO] - 
[2/ 5 Epoch]
[2024-10-17 06:13:23,149][root][INFO] - Step: 20000/73665  |  Loss: 1.0191  |  Score: 46.71 [%]  |  Seq Length: 256.0
[2024-10-17 07:36:38,403][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-17 07:36:48,694][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 07:36:48,695][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.29 [s]
[2024-10-17 07:37:08,706][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 07:37:08,706][root][INFO] - Score: 33.38 [%]  |  Evaluation Time: 20.01 [s]
[2024-10-17 07:37:08,708][root][INFO] - 
[3/ 5 Epoch]
[2024-10-17 07:41:50,533][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.52 [%]  |  Seq Length: 256.0
[2024-10-17 09:09:24,976][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-17 09:34:58,321][root][INFO] - 

[2024-10-17 09:34:58,322][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 09:34:58,322][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-17 09:34:58,322][root][INFO] - 

[2024-10-17 09:34:58,322][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 09:35:06,305][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,306][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,306][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,307][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,309][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,309][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,310][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,310][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,311][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,312][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,312][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,313][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,313][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,314][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,314][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,315][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,316][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,316][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,317][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,317][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,319][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,320][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,320][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,321][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,323][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 09:35:06,327][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 09:35:06,533][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 09:35:06,535][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 09:35:06,716][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 09:41:19,306][root][INFO] - 

[2024-10-17 09:41:19,306][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 09:41:19,306][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:41:19,306][root][INFO] - 

[2024-10-17 09:41:19,306][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 09:41:24,998][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:24,999][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:24,999][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,000][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,000][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,001][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,001][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,002][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,002][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,003][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,004][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,004][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,005][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,005][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,006][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,006][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,007][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,007][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,008][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,008][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,009][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,010][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,010][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,011][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,013][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 09:41:25,017][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 09:41:25,217][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 09:41:25,219][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 09:41:25,400][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 09:41:28,414][root][INFO] - 

[2024-10-17 09:41:28,414][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 09:41:28,414][root][INFO] - Data Preprocessing
[2024-10-17 09:41:28,414][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-17 09:41:28,414][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 09:41:28,414][root][INFO] - ㄴ data_remove                True

[2024-10-17 09:41:28,415][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 09:41:28,422][root][INFO] - vocab size              : 51200
[2024-10-17 09:41:28,422][root][INFO] - device                  : gpu
[2024-10-17 09:41:28,422][root][INFO] - random seed             : 1
[2024-10-17 09:41:28,422][root][INFO] - train data size         : 6464
[2024-10-17 09:41:28,423][root][INFO] - max epochs              : 10
[2024-10-17 09:41:28,423][root][INFO] - total steps             : 1010
[2024-10-17 09:41:28,423][root][INFO] - warmup steps            : 101
[2024-10-17 09:41:28,423][root][INFO] - batch size              : 64
[2024-10-17 09:41:28,423][root][INFO] - accumulation steps      : 1
[2024-10-17 09:41:28,423][root][INFO] - optimizer               : adamwscale
[2024-10-17 09:41:28,423][root][INFO] - lr_scheduler            : cosine
[2024-10-17 09:41:28,423][root][INFO] - learning rate           : 0.01
[2024-10-17 09:41:28,423][root][INFO] - max length              : 256

[2024-10-17 09:41:28,423][root][INFO] - LoRA Configuration
[2024-10-17 09:41:28,423][root][INFO] - ㄴ r                    : 32
[2024-10-17 09:41:28,423][root][INFO] - ㄴ alpha                : 128
[2024-10-17 09:41:28,424][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 09:41:28,424][root][INFO] - KOMBO Configuration
[2024-10-17 09:41:28,424][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 09:41:28,424][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 09:41:28,424][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 09:41:28,424][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 09:41:28,424][root][INFO] - ㄴ do_combination       : True
[2024-10-17 09:41:28,424][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 09:41:28,424][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 09:41:28,425][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 09:41:28,425][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 09:41:28,425][root][INFO] - 

[2024-10-17 09:41:28,425][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:41:28,425][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/ckpt
[2024-10-17 09:41:28,425][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/tb
[2024-10-17 09:41:28,425][root][INFO] - * tb interval   : 10000

[2024-10-17 09:41:28,425][root][INFO] - 

[2024-10-17 09:41:28,425][root][INFO] - Start the Training !
[2024-10-17 09:41:28,428][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 09:41:52,265][root][INFO] - 

[2024-10-17 09:41:52,265][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 09:41:52,266][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:41:52,266][root][INFO] - 

[2024-10-17 09:41:52,266][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 09:42:00,060][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,060][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,061][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,061][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,062][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,062][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,062][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,063][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,063][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,064][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,064][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,064][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,065][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,065][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,066][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,066][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,067][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,067][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,067][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,068][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,069][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,070][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,070][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,070][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,072][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 09:42:00,076][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 09:42:00,271][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 09:42:00,274][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 09:42:00,456][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 09:42:03,538][root][INFO] - 

[2024-10-17 09:42:03,538][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 09:42:03,538][root][INFO] - Data Preprocessing
[2024-10-17 09:42:03,538][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 09:42:03,538][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 09:42:03,539][root][INFO] - ㄴ data_remove                True

[2024-10-17 09:42:03,539][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 09:42:03,547][root][INFO] - vocab size              : 51200
[2024-10-17 09:42:03,547][root][INFO] - device                  : gpu
[2024-10-17 09:42:03,547][root][INFO] - random seed             : 1
[2024-10-17 09:42:03,547][root][INFO] - train data size         : 24256
[2024-10-17 09:42:03,547][root][INFO] - max epochs              : 10
[2024-10-17 09:42:03,547][root][INFO] - total steps             : 3790
[2024-10-17 09:42:03,547][root][INFO] - warmup steps            : 379
[2024-10-17 09:42:03,547][root][INFO] - batch size              : 64
[2024-10-17 09:42:03,547][root][INFO] - accumulation steps      : 1
[2024-10-17 09:42:03,547][root][INFO] - optimizer               : adamwscale
[2024-10-17 09:42:03,548][root][INFO] - lr_scheduler            : cosine
[2024-10-17 09:42:03,548][root][INFO] - learning rate           : 0.01
[2024-10-17 09:42:03,548][root][INFO] - max length              : 256

[2024-10-17 09:42:03,548][root][INFO] - LoRA Configuration
[2024-10-17 09:42:03,548][root][INFO] - ㄴ r                    : 32
[2024-10-17 09:42:03,548][root][INFO] - ㄴ alpha                : 128
[2024-10-17 09:42:03,548][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 09:42:03,548][root][INFO] - KOMBO Configuration
[2024-10-17 09:42:03,548][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 09:42:03,548][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 09:42:03,548][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 09:42:03,549][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 09:42:03,549][root][INFO] - ㄴ do_combination       : True
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 09:42:03,549][root][INFO] - 

[2024-10-17 09:42:03,549][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:42:03,549][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/ckpt
[2024-10-17 09:42:03,550][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/tb
[2024-10-17 09:42:03,550][root][INFO] - * tb interval   : 10000

[2024-10-17 09:42:03,550][root][INFO] - 

[2024-10-17 09:42:03,550][root][INFO] - Start the Training !
[2024-10-17 09:42:03,553][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 09:45:44,136][root][INFO] - Step: 379/3790  |  Loss: 0.6939  |  Score: 54.83 [%]  |  Seq Length: 256.0
[2024-10-17 09:45:48,739][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 09:45:48,740][root][INFO] - Score: 60.90 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-17 09:45:53,269][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 09:45:53,270][root][INFO] - Score: 55.12 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-17 09:45:53,271][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 09:45:53,272][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 09:46:12,983][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-17 09:46:23,339][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 09:46:23,339][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.35 [s]
[2024-10-17 09:46:43,341][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 09:46:43,341][root][INFO] - Score: 33.54 [%]  |  Evaluation Time: 20.00 [s]
[2024-10-17 09:46:43,343][root][INFO] - 
[4/ 5 Epoch]
[2024-10-17 09:49:34,167][root][INFO] - Step: 758/3790  |  Loss: 0.5890  |  Score: 68.39 [%]  |  Seq Length: 256.0
[2024-10-17 09:49:38,960][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 09:49:38,961][root][INFO] - Score: 63.61 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 09:49:43,656][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 09:49:43,656][root][INFO] - Score: 63.09 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-17 09:49:43,658][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 09:49:43,659][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 09:53:24,373][root][INFO] - Step: 1137/3790  |  Loss: 0.5120  |  Score: 74.95 [%]  |  Seq Length: 256.0
[2024-10-17 09:53:29,024][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 09:53:29,024][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-17 09:53:33,587][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 09:53:33,587][root][INFO] - Score: 65.92 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-17 09:53:33,588][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 09:53:33,589][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 09:57:13,309][root][INFO] - Step: 1516/3790  |  Loss: 0.4643  |  Score: 78.11 [%]  |  Seq Length: 256.0
[2024-10-17 09:57:17,975][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 09:57:17,976][root][INFO] - Score: 69.79 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 09:57:22,540][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 09:57:22,540][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-17 09:57:22,541][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 09:57:22,542][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 10:01:04,439][root][INFO] - Step: 1895/3790  |  Loss: 0.4223  |  Score: 80.32 [%]  |  Seq Length: 256.0
[2024-10-17 10:01:09,154][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 10:01:09,154][root][INFO] - Score: 72.66 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-17 10:01:13,721][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 10:01:13,721][root][INFO] - Score: 68.90 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-17 10:01:13,722][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 10:01:13,725][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 10:04:56,129][root][INFO] - Step: 2274/3790  |  Loss: 0.3759  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-17 10:05:00,936][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 10:05:00,937][root][INFO] - Score: 75.29 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 10:05:05,630][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 10:05:05,630][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-17 10:05:05,631][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 10:05:05,633][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 10:08:48,288][root][INFO] - Step: 2653/3790  |  Loss: 0.3397  |  Score: 84.68 [%]  |  Seq Length: 256.0
[2024-10-17 10:08:52,996][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 10:08:52,997][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 10:08:57,619][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 10:08:57,619][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 10:08:57,621][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 10:12:40,078][root][INFO] - Step: 3032/3790  |  Loss: 0.3080  |  Score: 86.27 [%]  |  Seq Length: 256.0
[2024-10-17 10:12:44,758][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 10:12:44,758][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 10:12:49,341][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 10:12:49,342][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 10:12:49,342][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-17 10:12:49,344][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 10:16:31,580][root][INFO] - Step: 3411/3790  |  Loss: 0.2905  |  Score: 87.10 [%]  |  Seq Length: 256.0
[2024-10-17 10:16:36,275][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 10:16:36,275][root][INFO] - Score: 72.72 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-17 10:16:40,892][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 10:16:40,893][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 10:16:40,895][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 10:20:21,734][root][INFO] - Step: 3790/3790  |  Loss: 0.2808  |  Score: 87.65 [%]  |  Seq Length: 256.0
[2024-10-17 10:20:26,417][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 10:20:26,417][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 10:20:31,001][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 10:20:31,001][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 10:20:31,002][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 10:20:31,002][root][INFO] - - Epoch: 8
[2024-10-17 10:20:31,002][root][INFO] - - DEV score: 74.90 [%]
[2024-10-17 10:20:31,002][root][INFO] - - TEST score: 70.76 [%]
[2024-10-17 10:20:31,003][root][INFO] - Fine-tuning is done!
[2024-10-17 10:20:37,771][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,772][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,773][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,773][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,774][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,774][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,775][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,775][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,776][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,776][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,777][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,778][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,778][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,779][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,779][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,780][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,780][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,781][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,782][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,782][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,783][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,783][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,784][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,784][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,786][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 10:20:37,996][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 10:20:37,998][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 10:20:37,999][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 10:20:38,167][root][INFO] - 

[2024-10-17 10:20:38,167][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 10:20:38,167][root][INFO] - Data Preprocessing
[2024-10-17 10:20:38,167][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 10:20:38,167][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 10:20:38,167][root][INFO] - ㄴ data_remove                True

[2024-10-17 10:20:38,167][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 10:20:38,175][root][INFO] - vocab size              : 51200
[2024-10-17 10:20:38,176][root][INFO] - device                  : gpu
[2024-10-17 10:20:38,176][root][INFO] - random seed             : 1
[2024-10-17 10:20:38,176][root][INFO] - train data size         : 24256
[2024-10-17 10:20:38,176][root][INFO] - max epochs              : 10
[2024-10-17 10:20:38,176][root][INFO] - total steps             : 3790
[2024-10-17 10:20:38,176][root][INFO] - warmup steps            : 379
[2024-10-17 10:20:38,176][root][INFO] - batch size              : 64
[2024-10-17 10:20:38,176][root][INFO] - accumulation steps      : 1
[2024-10-17 10:20:38,176][root][INFO] - optimizer               : adamwscale
[2024-10-17 10:20:38,176][root][INFO] - lr_scheduler            : cosine
[2024-10-17 10:20:38,177][root][INFO] - learning rate           : 0.02
[2024-10-17 10:20:38,177][root][INFO] - max length              : 256

[2024-10-17 10:20:38,177][root][INFO] - LoRA Configuration
[2024-10-17 10:20:38,177][root][INFO] - ㄴ r                    : 32
[2024-10-17 10:20:38,177][root][INFO] - ㄴ alpha                : 128
[2024-10-17 10:20:38,177][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 10:20:38,177][root][INFO] - KOMBO Configuration
[2024-10-17 10:20:38,177][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 10:20:38,177][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 10:20:38,177][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 10:20:38,177][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 10:20:38,178][root][INFO] - ㄴ do_combination       : True
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 10:20:38,178][root][INFO] - 

[2024-10-17 10:20:38,178][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs
[2024-10-17 10:20:38,178][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/ckpt
[2024-10-17 10:20:38,178][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/tb
[2024-10-17 10:20:38,178][root][INFO] - * tb interval   : 10000

[2024-10-17 10:20:38,178][root][INFO] - 

[2024-10-17 10:20:38,179][root][INFO] - Start the Training !
[2024-10-17 10:20:38,181][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 10:24:20,944][root][INFO] - Step: 379/3790  |  Loss: 0.6768  |  Score: 57.28 [%]  |  Seq Length: 256.0
[2024-10-17 10:24:25,686][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 10:24:25,686][root][INFO] - Score: 62.76 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:24:30,389][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 10:24:30,389][root][INFO] - Score: 61.12 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 10:24:30,390][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 10:24:30,392][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 10:28:13,177][root][INFO] - Step: 758/3790  |  Loss: 0.5723  |  Score: 70.23 [%]  |  Seq Length: 256.0
[2024-10-17 10:28:17,927][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 10:28:17,927][root][INFO] - Score: 66.57 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 10:28:22,557][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 10:28:22,557][root][INFO] - Score: 64.41 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 10:28:22,558][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 10:28:22,560][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 10:32:05,600][root][INFO] - Step: 1137/3790  |  Loss: 0.5078  |  Score: 75.27 [%]  |  Seq Length: 256.0
[2024-10-17 10:32:10,313][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 10:32:10,313][root][INFO] - Score: 68.75 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-17 10:32:14,988][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 10:32:14,988][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-17 10:32:14,989][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 10:32:14,991][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 10:35:57,484][root][INFO] - Step: 1516/3790  |  Loss: 0.4583  |  Score: 78.41 [%]  |  Seq Length: 256.0
[2024-10-17 10:36:02,224][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 10:36:02,224][root][INFO] - Score: 70.28 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:36:06,834][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 10:36:06,834][root][INFO] - Score: 65.83 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-17 10:36:06,835][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 10:36:06,836][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 10:37:55,155][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-17 10:39:48,968][root][INFO] - Step: 1895/3790  |  Loss: 0.4172  |  Score: 80.57 [%]  |  Seq Length: 256.0
[2024-10-17 10:39:53,701][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 10:39:53,701][root][INFO] - Score: 72.36 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 10:39:58,342][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 10:39:58,342][root][INFO] - Score: 67.96 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 10:39:58,343][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 10:39:58,344][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 10:43:40,980][root][INFO] - Step: 2274/3790  |  Loss: 0.3611  |  Score: 83.62 [%]  |  Seq Length: 256.0
[2024-10-17 10:43:45,703][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 10:43:45,703][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-17 10:43:50,341][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 10:43:50,341][root][INFO] - Score: 68.43 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 10:43:50,343][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 10:47:32,281][root][INFO] - Step: 2653/3790  |  Loss: 0.3075  |  Score: 86.41 [%]  |  Seq Length: 256.0
[2024-10-17 10:47:37,091][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 10:47:37,091][root][INFO] - Score: 69.01 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-17 10:47:41,835][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 10:47:41,835][root][INFO] - Score: 67.87 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:47:41,838][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 10:51:24,130][root][INFO] - Step: 3032/3790  |  Loss: 0.2640  |  Score: 88.37 [%]  |  Seq Length: 256.0
[2024-10-17 10:51:28,902][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 10:51:28,902][root][INFO] - Score: 70.38 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-17 10:51:33,541][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 10:51:33,541][root][INFO] - Score: 68.64 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 10:51:33,543][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 10:55:15,128][root][INFO] - Step: 3411/3790  |  Loss: 0.2307  |  Score: 90.07 [%]  |  Seq Length: 256.0
[2024-10-17 10:55:19,953][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 10:55:19,953][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 10:55:24,698][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 10:55:24,698][root][INFO] - Score: 67.64 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:55:24,699][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 10:55:24,700][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 10:59:07,571][root][INFO] - Step: 3790/3790  |  Loss: 0.2155  |  Score: 90.80 [%]  |  Seq Length: 256.0
[2024-10-17 10:59:12,258][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 10:59:12,258][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 10:59:16,854][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 10:59:16,854][root][INFO] - Score: 68.06 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-17 10:59:16,855][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 10:59:16,855][root][INFO] - - Epoch: 9
[2024-10-17 10:59:16,855][root][INFO] - - DEV score: 72.85 [%]
[2024-10-17 10:59:16,855][root][INFO] - - TEST score: 67.64 [%]
[2024-10-17 10:59:16,856][root][INFO] - Fine-tuning is done!
[2024-10-17 10:59:16,857][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 10:59:16,857][root][INFO] - - BEST LR: 0.01
[2024-10-17 10:59:16,857][root][INFO] - - DEV score: 74.90 [%]
[2024-10-17 10:59:16,857][root][INFO] - - TEST score: 70.76 [%]
[2024-10-17 10:59:23,036][root][INFO] - 

[2024-10-17 10:59:23,036][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 10:59:23,036][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs
[2024-10-17 10:59:23,036][root][INFO] - 

[2024-10-17 10:59:23,036][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 10:59:30,885][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,885][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,886][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,886][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,887][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,887][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,888][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,888][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,889][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,889][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,889][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,890][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,890][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,891][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,891][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,891][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,892][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,892][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,893][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,893][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,895][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,895][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,895][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,896][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,897][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 10:59:30,901][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 10:59:31,107][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 10:59:31,109][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 10:59:31,296][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 10:59:34,388][root][INFO] - 

[2024-10-17 10:59:34,389][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 10:59:34,389][root][INFO] - Data Preprocessing
[2024-10-17 10:59:34,389][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 10:59:34,389][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 10:59:34,389][root][INFO] - ㄴ data_remove                True

[2024-10-17 10:59:34,389][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 10:59:34,396][root][INFO] - vocab size              : 51200
[2024-10-17 10:59:34,397][root][INFO] - device                  : gpu
[2024-10-17 10:59:34,397][root][INFO] - random seed             : 2
[2024-10-17 10:59:34,397][root][INFO] - train data size         : 24256
[2024-10-17 10:59:34,397][root][INFO] - max epochs              : 10
[2024-10-17 10:59:34,397][root][INFO] - total steps             : 3790
[2024-10-17 10:59:34,397][root][INFO] - warmup steps            : 379
[2024-10-17 10:59:34,397][root][INFO] - batch size              : 64
[2024-10-17 10:59:34,397][root][INFO] - accumulation steps      : 1
[2024-10-17 10:59:34,397][root][INFO] - optimizer               : adamwscale
[2024-10-17 10:59:34,397][root][INFO] - lr_scheduler            : cosine
[2024-10-17 10:59:34,397][root][INFO] - learning rate           : 0.01
[2024-10-17 10:59:34,398][root][INFO] - max length              : 256

[2024-10-17 10:59:34,398][root][INFO] - LoRA Configuration
[2024-10-17 10:59:34,398][root][INFO] - ㄴ r                    : 32
[2024-10-17 10:59:34,398][root][INFO] - ㄴ alpha                : 128
[2024-10-17 10:59:34,398][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 10:59:34,398][root][INFO] - KOMBO Configuration
[2024-10-17 10:59:34,398][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 10:59:34,398][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 10:59:34,398][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 10:59:34,398][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 10:59:34,398][root][INFO] - ㄴ do_combination       : True
[2024-10-17 10:59:34,399][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 10:59:34,399][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 10:59:34,399][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 10:59:34,402][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 10:59:34,402][root][INFO] - 

[2024-10-17 10:59:34,403][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs
[2024-10-17 10:59:34,403][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/ckpt
[2024-10-17 10:59:34,403][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/tb
[2024-10-17 10:59:34,403][root][INFO] - * tb interval   : 10000

[2024-10-17 10:59:34,403][root][INFO] - 

[2024-10-17 10:59:34,403][root][INFO] - Start the Training !
[2024-10-17 10:59:34,406][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 11:03:12,069][root][INFO] - Step: 379/3790  |  Loss: 0.6867  |  Score: 56.25 [%]  |  Seq Length: 256.0
[2024-10-17 11:03:16,730][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 11:03:16,730][root][INFO] - Score: 64.36 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 11:03:21,310][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 11:03:21,310][root][INFO] - Score: 59.70 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 11:03:21,311][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 11:03:21,312][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 11:07:02,252][root][INFO] - Step: 758/3790  |  Loss: 0.5783  |  Score: 69.93 [%]  |  Seq Length: 256.0
[2024-10-17 11:07:07,042][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 11:07:07,042][root][INFO] - Score: 65.27 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 11:07:11,619][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 11:07:11,619][root][INFO] - Score: 63.70 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 11:07:11,620][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 11:07:11,621][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 11:10:53,236][root][INFO] - Step: 1137/3790  |  Loss: 0.5107  |  Score: 74.97 [%]  |  Seq Length: 256.0
[2024-10-17 11:10:57,900][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 11:10:57,900][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 11:11:02,547][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 11:11:02,547][root][INFO] - Score: 65.26 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 11:11:02,548][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 11:11:02,550][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 11:14:44,027][root][INFO] - Step: 1516/3790  |  Loss: 0.4598  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-17 11:14:48,775][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 11:14:48,776][root][INFO] - Score: 63.96 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 11:14:53,403][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 11:14:53,403][root][INFO] - Score: 67.67 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 11:14:53,405][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 11:18:35,332][root][INFO] - Step: 1895/3790  |  Loss: 0.4140  |  Score: 80.92 [%]  |  Seq Length: 256.0
[2024-10-17 11:18:39,975][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 11:18:39,975][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 11:18:44,547][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 11:18:44,547][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-17 11:18:44,547][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 11:18:44,549][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 11:22:25,856][root][INFO] - Step: 2274/3790  |  Loss: 0.3670  |  Score: 83.35 [%]  |  Seq Length: 256.0
[2024-10-17 11:22:30,697][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 11:22:30,698][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 11:22:35,289][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 11:22:35,289][root][INFO] - Score: 66.72 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-17 11:22:35,290][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 11:22:35,291][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 11:26:17,337][root][INFO] - Step: 2653/3790  |  Loss: 0.3304  |  Score: 85.14 [%]  |  Seq Length: 256.0
[2024-10-17 11:26:22,163][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 11:26:22,163][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 11:26:26,884][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 11:26:26,884][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-17 11:26:26,885][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 11:26:26,887][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 11:30:09,826][root][INFO] - Step: 3032/3790  |  Loss: 0.2999  |  Score: 86.83 [%]  |  Seq Length: 256.0
[2024-10-17 11:30:14,468][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 11:30:14,469][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 11:30:19,071][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 11:30:19,071][root][INFO] - Score: 68.09 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-17 11:30:19,072][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-17 11:30:19,074][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 11:33:59,742][root][INFO] - Step: 3411/3790  |  Loss: 0.2759  |  Score: 87.94 [%]  |  Seq Length: 256.0
[2024-10-17 11:34:04,482][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 11:34:04,483][root][INFO] - Score: 72.66 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 11:34:09,092][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 11:34:09,092][root][INFO] - Score: 68.02 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-17 11:34:09,093][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 11:34:09,096][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 11:37:50,588][root][INFO] - Step: 3790/3790  |  Loss: 0.2722  |  Score: 88.09 [%]  |  Seq Length: 256.0
[2024-10-17 11:37:55,308][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 11:37:55,309][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-17 11:38:00,038][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 11:38:00,039][root][INFO] - Score: 67.48 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 11:38:00,040][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 11:38:00,040][root][INFO] - - Epoch: 9
[2024-10-17 11:38:00,040][root][INFO] - - DEV score: 72.66 [%]
[2024-10-17 11:38:00,040][root][INFO] - - TEST score: 68.02 [%]
[2024-10-17 11:38:00,041][root][INFO] - Fine-tuning is done!
[2024-10-17 11:38:07,057][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,058][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,059][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,059][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,060][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,061][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,062][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,063][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,063][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,064][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,065][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,066][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,066][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,067][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,068][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,068][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,069][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,070][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,070][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,071][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,072][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,072][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,073][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,074][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,076][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 11:38:07,326][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 11:38:07,329][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 11:38:07,330][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 11:38:07,500][root][INFO] - 

[2024-10-17 11:38:07,500][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 11:38:07,500][root][INFO] - Data Preprocessing
[2024-10-17 11:38:07,501][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 11:38:07,501][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 11:38:07,501][root][INFO] - ㄴ data_remove                True

[2024-10-17 11:38:07,501][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 11:38:07,509][root][INFO] - vocab size              : 51200
[2024-10-17 11:38:07,509][root][INFO] - device                  : gpu
[2024-10-17 11:38:07,509][root][INFO] - random seed             : 2
[2024-10-17 11:38:07,509][root][INFO] - train data size         : 24256
[2024-10-17 11:38:07,509][root][INFO] - max epochs              : 10
[2024-10-17 11:38:07,509][root][INFO] - total steps             : 3790
[2024-10-17 11:38:07,509][root][INFO] - warmup steps            : 379
[2024-10-17 11:38:07,509][root][INFO] - batch size              : 64
[2024-10-17 11:38:07,509][root][INFO] - accumulation steps      : 1
[2024-10-17 11:38:07,510][root][INFO] - optimizer               : adamwscale
[2024-10-17 11:38:07,510][root][INFO] - lr_scheduler            : cosine
[2024-10-17 11:38:07,510][root][INFO] - learning rate           : 0.02
[2024-10-17 11:38:07,510][root][INFO] - max length              : 256

[2024-10-17 11:38:07,510][root][INFO] - LoRA Configuration
[2024-10-17 11:38:07,510][root][INFO] - ㄴ r                    : 32
[2024-10-17 11:38:07,510][root][INFO] - ㄴ alpha                : 128
[2024-10-17 11:38:07,510][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 11:38:07,510][root][INFO] - KOMBO Configuration
[2024-10-17 11:38:07,510][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 11:38:07,510][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 11:38:07,511][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 11:38:07,511][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 11:38:07,511][root][INFO] - ㄴ do_combination       : True
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 11:38:07,511][root][INFO] - 

[2024-10-17 11:38:07,511][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs
[2024-10-17 11:38:07,511][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/ckpt
[2024-10-17 11:38:07,512][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/tb
[2024-10-17 11:38:07,512][root][INFO] - * tb interval   : 10000

[2024-10-17 11:38:07,512][root][INFO] - 

[2024-10-17 11:38:07,512][root][INFO] - Start the Training !
[2024-10-17 11:38:07,514][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 11:41:49,783][root][INFO] - Step: 379/3790  |  Loss: 0.6785  |  Score: 57.20 [%]  |  Seq Length: 256.0
[2024-10-17 11:41:54,695][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 11:41:54,695][root][INFO] - Score: 64.36 [%]  |  Evaluation Time: 4.91 [s]
[2024-10-17 11:41:59,466][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 11:41:59,466][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-17 11:41:59,467][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 11:41:59,468][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 11:45:42,285][root][INFO] - Step: 758/3790  |  Loss: 0.5734  |  Score: 69.73 [%]  |  Seq Length: 256.0
[2024-10-17 11:45:47,028][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 11:45:47,028][root][INFO] - Score: 67.42 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 11:45:51,663][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 11:45:51,663][root][INFO] - Score: 62.49 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 11:45:51,664][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 11:45:51,665][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 11:49:34,853][root][INFO] - Step: 1137/3790  |  Loss: 0.5098  |  Score: 74.89 [%]  |  Seq Length: 256.0
[2024-10-17 11:49:39,651][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 11:49:39,651][root][INFO] - Score: 69.34 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 11:49:44,441][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 11:49:44,442][root][INFO] - Score: 66.66 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 11:49:44,443][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 11:49:44,444][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 11:53:27,229][root][INFO] - Step: 1516/3790  |  Loss: 0.4597  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-17 11:53:32,068][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 11:53:32,068][root][INFO] - Score: 63.87 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 11:53:36,747][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 11:53:36,748][root][INFO] - Score: 65.92 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 11:53:36,750][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 11:56:56,836][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-17 11:57:07,445][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 11:57:07,445][root][INFO] - Score: 33.31 [%]  |  Evaluation Time: 10.61 [s]
[2024-10-17 11:57:17,040][root][INFO] - Step: 1895/3790  |  Loss: 0.4097  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-17 11:57:21,794][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 11:57:21,794][root][INFO] - Score: 69.89 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 11:57:26,416][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 11:57:26,416][root][INFO] - Score: 67.64 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 11:57:26,417][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 11:57:26,418][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 11:57:27,740][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 11:57:27,740][root][INFO] - Score: 33.23 [%]  |  Evaluation Time: 20.29 [s]
[2024-10-17 11:57:27,742][root][INFO] - 
[5/ 5 Epoch]
[2024-10-17 12:01:10,013][root][INFO] - Step: 2274/3790  |  Loss: 0.3553  |  Score: 83.82 [%]  |  Seq Length: 256.0
[2024-10-17 12:01:14,832][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 12:01:14,833][root][INFO] - Score: 72.56 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 12:01:19,602][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 12:01:19,602][root][INFO] - Score: 68.86 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-17 12:01:19,603][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 12:01:19,605][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 12:05:03,063][root][INFO] - Step: 2653/3790  |  Loss: 0.2951  |  Score: 86.95 [%]  |  Seq Length: 256.0
[2024-10-17 12:05:07,860][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 12:05:07,860][root][INFO] - Score: 74.22 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 12:05:12,597][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 12:05:12,597][root][INFO] - Score: 68.70 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 12:05:12,599][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 12:05:12,600][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 12:06:52,938][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.46 [%]  |  Seq Length: 256.0
[2024-10-17 12:08:55,978][root][INFO] - Step: 3032/3790  |  Loss: 0.2516  |  Score: 89.30 [%]  |  Seq Length: 256.0
[2024-10-17 12:09:00,769][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 12:09:00,769][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 12:09:05,430][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 12:09:05,430][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 12:09:05,433][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 12:12:48,165][root][INFO] - Step: 3411/3790  |  Loss: 0.2138  |  Score: 90.67 [%]  |  Seq Length: 256.0
[2024-10-17 12:12:52,933][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 12:12:52,933][root][INFO] - Score: 71.06 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-17 12:12:57,687][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 12:12:57,687][root][INFO] - Score: 68.59 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 12:12:57,690][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 12:16:40,484][root][INFO] - Step: 3790/3790  |  Loss: 0.2026  |  Score: 91.35 [%]  |  Seq Length: 256.0
[2024-10-17 12:16:45,265][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 12:16:45,265][root][INFO] - Score: 69.76 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-17 12:16:49,963][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 12:16:49,963][root][INFO] - Score: 68.55 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 12:16:49,964][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 12:16:49,964][root][INFO] - - Epoch: 7
[2024-10-17 12:16:49,964][root][INFO] - - DEV score: 74.22 [%]
[2024-10-17 12:16:49,964][root][INFO] - - TEST score: 68.70 [%]
[2024-10-17 12:16:49,966][root][INFO] - Fine-tuning is done!
[2024-10-17 12:16:49,966][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 12:16:49,966][root][INFO] - - BEST LR: 0.02
[2024-10-17 12:16:49,966][root][INFO] - - DEV score: 74.22 [%]
[2024-10-17 12:16:49,966][root][INFO] - - TEST score: 68.70 [%]
[2024-10-17 12:16:56,182][root][INFO] - 

[2024-10-17 12:16:56,182][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 12:16:56,183][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs
[2024-10-17 12:16:56,183][root][INFO] - 

[2024-10-17 12:16:56,183][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 12:17:04,450][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,451][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,451][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,452][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,452][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,453][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,453][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,454][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,454][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,455][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,455][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,456][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,456][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,457][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,457][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,458][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,458][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,459][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,459][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,460][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,462][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,462][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,463][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,463][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,464][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 12:17:04,469][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 12:17:04,672][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 12:17:04,674][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 12:17:04,868][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 12:17:08,114][root][INFO] - 

[2024-10-17 12:17:08,115][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 12:17:08,115][root][INFO] - Data Preprocessing
[2024-10-17 12:17:08,115][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 12:17:08,115][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 12:17:08,115][root][INFO] - ㄴ data_remove                True

[2024-10-17 12:17:08,115][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 12:17:08,123][root][INFO] - vocab size              : 51200
[2024-10-17 12:17:08,123][root][INFO] - device                  : gpu
[2024-10-17 12:17:08,123][root][INFO] - random seed             : 3
[2024-10-17 12:17:08,123][root][INFO] - train data size         : 24256
[2024-10-17 12:17:08,123][root][INFO] - max epochs              : 10
[2024-10-17 12:17:08,123][root][INFO] - total steps             : 3790
[2024-10-17 12:17:08,124][root][INFO] - warmup steps            : 379
[2024-10-17 12:17:08,124][root][INFO] - batch size              : 64
[2024-10-17 12:17:08,124][root][INFO] - accumulation steps      : 1
[2024-10-17 12:17:08,124][root][INFO] - optimizer               : adamwscale
[2024-10-17 12:17:08,124][root][INFO] - lr_scheduler            : cosine
[2024-10-17 12:17:08,124][root][INFO] - learning rate           : 0.01
[2024-10-17 12:17:08,124][root][INFO] - max length              : 256

[2024-10-17 12:17:08,124][root][INFO] - LoRA Configuration
[2024-10-17 12:17:08,124][root][INFO] - ㄴ r                    : 32
[2024-10-17 12:17:08,124][root][INFO] - ㄴ alpha                : 128
[2024-10-17 12:17:08,124][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 12:17:08,124][root][INFO] - KOMBO Configuration
[2024-10-17 12:17:08,125][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 12:17:08,125][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 12:17:08,125][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 12:17:08,125][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 12:17:08,125][root][INFO] - ㄴ do_combination       : True
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 12:17:08,125][root][INFO] - 

[2024-10-17 12:17:08,126][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs
[2024-10-17 12:17:08,126][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/ckpt
[2024-10-17 12:17:08,126][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/tb
[2024-10-17 12:17:08,126][root][INFO] - * tb interval   : 10000

[2024-10-17 12:17:08,126][root][INFO] - 

[2024-10-17 12:17:08,126][root][INFO] - Start the Training !
[2024-10-17 12:17:08,129][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 12:20:51,457][root][INFO] - Step: 379/3790  |  Loss: 0.6845  |  Score: 56.77 [%]  |  Seq Length: 256.0
[2024-10-17 12:20:56,194][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 12:20:56,195][root][INFO] - Score: 59.44 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:21:00,840][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 12:21:00,840][root][INFO] - Score: 58.31 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 12:21:00,841][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 12:21:00,842][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 12:24:42,876][root][INFO] - Step: 758/3790  |  Loss: 0.5793  |  Score: 69.78 [%]  |  Seq Length: 256.0
[2024-10-17 12:24:47,680][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 12:24:47,680][root][INFO] - Score: 67.25 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 12:24:52,341][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 12:24:52,341][root][INFO] - Score: 64.57 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 12:24:52,342][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 12:24:52,344][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 12:28:35,950][root][INFO] - Step: 1137/3790  |  Loss: 0.5077  |  Score: 75.23 [%]  |  Seq Length: 256.0
[2024-10-17 12:28:40,755][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 12:28:40,755][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 12:28:45,323][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 12:28:45,323][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-17 12:28:45,324][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 12:28:45,326][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 12:32:27,975][root][INFO] - Step: 1516/3790  |  Loss: 0.4589  |  Score: 78.43 [%]  |  Seq Length: 256.0
[2024-10-17 12:32:32,787][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 12:32:32,787][root][INFO] - Score: 68.72 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-17 12:32:37,485][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 12:32:37,486][root][INFO] - Score: 64.49 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 12:32:37,489][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 12:36:19,845][root][INFO] - Step: 1895/3790  |  Loss: 0.4165  |  Score: 80.56 [%]  |  Seq Length: 256.0
[2024-10-17 12:36:24,691][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 12:36:24,691][root][INFO] - Score: 66.93 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 12:36:29,427][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 12:36:29,427][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:36:29,429][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 12:40:12,109][root][INFO] - Step: 2274/3790  |  Loss: 0.3719  |  Score: 82.93 [%]  |  Seq Length: 256.0
[2024-10-17 12:40:16,946][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 12:40:16,946][root][INFO] - Score: 69.99 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-17 12:40:21,695][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 12:40:21,696][root][INFO] - Score: 68.06 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 12:40:21,698][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 12:44:03,817][root][INFO] - Step: 2653/3790  |  Loss: 0.3372  |  Score: 84.78 [%]  |  Seq Length: 256.0
[2024-10-17 12:44:08,517][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 12:44:08,517][root][INFO] - Score: 69.47 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 12:44:13,422][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 12:44:13,423][root][INFO] - Score: 68.38 [%]  |  Evaluation Time: 4.90 [s]
[2024-10-17 12:44:13,425][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 12:47:55,701][root][INFO] - Step: 3032/3790  |  Loss: 0.3036  |  Score: 86.35 [%]  |  Seq Length: 256.0
[2024-10-17 12:48:00,441][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 12:48:00,441][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 12:48:05,067][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 12:48:05,067][root][INFO] - Score: 67.34 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 12:48:05,070][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 12:51:46,404][root][INFO] - Step: 3411/3790  |  Loss: 0.2828  |  Score: 87.34 [%]  |  Seq Length: 256.0
[2024-10-17 12:51:51,216][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 12:51:51,216][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-17 12:51:55,943][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 12:51:55,944][root][INFO] - Score: 68.44 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:51:55,945][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 12:51:55,946][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 12:55:41,228][root][INFO] - Step: 3790/3790  |  Loss: 0.2764  |  Score: 87.84 [%]  |  Seq Length: 256.0
[2024-10-17 12:55:45,960][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 12:55:45,960][root][INFO] - Score: 70.38 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:55:50,600][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 12:55:50,600][root][INFO] - Score: 67.95 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 12:55:50,601][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 12:55:50,601][root][INFO] - - Epoch: 9
[2024-10-17 12:55:50,601][root][INFO] - - DEV score: 70.18 [%]
[2024-10-17 12:55:50,601][root][INFO] - - TEST score: 68.44 [%]
[2024-10-17 12:55:50,602][root][INFO] - Fine-tuning is done!
[2024-10-17 12:55:58,392][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,393][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,394][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,394][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,395][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,395][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,396][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,396][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,397][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,397][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,398][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,398][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,399][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,399][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,400][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,400][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,401][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,401][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,402][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,402][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,403][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,404][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,404][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,405][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,407][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 12:55:58,612][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 12:55:58,615][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 12:55:58,616][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 12:55:58,784][root][INFO] - 

[2024-10-17 12:55:58,784][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 12:55:58,784][root][INFO] - Data Preprocessing
[2024-10-17 12:55:58,784][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 12:55:58,785][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 12:55:58,785][root][INFO] - ㄴ data_remove                True

[2024-10-17 12:55:58,785][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 12:55:58,793][root][INFO] - vocab size              : 51200
[2024-10-17 12:55:58,793][root][INFO] - device                  : gpu
[2024-10-17 12:55:58,793][root][INFO] - random seed             : 3
[2024-10-17 12:55:58,793][root][INFO] - train data size         : 24256
[2024-10-17 12:55:58,793][root][INFO] - max epochs              : 10
[2024-10-17 12:55:58,794][root][INFO] - total steps             : 3790
[2024-10-17 12:55:58,794][root][INFO] - warmup steps            : 379
[2024-10-17 12:55:58,794][root][INFO] - batch size              : 64
[2024-10-17 12:55:58,794][root][INFO] - accumulation steps      : 1
[2024-10-17 12:55:58,794][root][INFO] - optimizer               : adamwscale
[2024-10-17 12:55:58,794][root][INFO] - lr_scheduler            : cosine
[2024-10-17 12:55:58,794][root][INFO] - learning rate           : 0.02
[2024-10-17 12:55:58,794][root][INFO] - max length              : 256

[2024-10-17 12:55:58,794][root][INFO] - LoRA Configuration
[2024-10-17 12:55:58,794][root][INFO] - ㄴ r                    : 32
[2024-10-17 12:55:58,794][root][INFO] - ㄴ alpha                : 128
[2024-10-17 12:55:58,794][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 12:55:58,795][root][INFO] - KOMBO Configuration
[2024-10-17 12:55:58,795][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 12:55:58,795][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 12:55:58,795][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 12:55:58,795][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 12:55:58,795][root][INFO] - ㄴ do_combination       : True
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 12:55:58,796][root][INFO] - 

[2024-10-17 12:55:58,796][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs
[2024-10-17 12:55:58,796][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/ckpt
[2024-10-17 12:55:58,796][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/tb
[2024-10-17 12:55:58,796][root][INFO] - * tb interval   : 10000

[2024-10-17 12:55:58,796][root][INFO] - 

[2024-10-17 12:55:58,796][root][INFO] - Start the Training !
[2024-10-17 12:55:58,798][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 12:59:41,174][root][INFO] - Step: 379/3790  |  Loss: 0.6737  |  Score: 58.41 [%]  |  Seq Length: 256.0
[2024-10-17 12:59:45,975][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 12:59:45,975][root][INFO] - Score: 60.68 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 12:59:50,638][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 12:59:50,638][root][INFO] - Score: 61.57 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 12:59:50,639][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 12:59:50,641][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 13:03:32,559][root][INFO] - Step: 758/3790  |  Loss: 0.5624  |  Score: 71.23 [%]  |  Seq Length: 256.0
[2024-10-17 13:03:37,443][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 13:03:37,443][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-17 13:03:42,080][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 13:03:42,080][root][INFO] - Score: 65.00 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 13:03:42,081][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 13:03:42,082][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 13:07:25,655][root][INFO] - Step: 1137/3790  |  Loss: 0.5084  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-17 13:07:30,492][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 13:07:30,492][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-17 13:07:35,167][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 13:07:35,167][root][INFO] - Score: 66.67 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-17 13:07:35,169][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 13:07:35,170][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 13:11:18,725][root][INFO] - Step: 1516/3790  |  Loss: 0.4567  |  Score: 78.53 [%]  |  Seq Length: 256.0
[2024-10-17 13:11:23,527][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 13:11:23,528][root][INFO] - Score: 68.23 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 13:11:28,276][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 13:11:28,277][root][INFO] - Score: 65.49 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 13:11:28,279][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 13:15:10,481][root][INFO] - Step: 1895/3790  |  Loss: 0.4081  |  Score: 81.07 [%]  |  Seq Length: 256.0
[2024-10-17 13:15:15,271][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 13:15:15,271][root][INFO] - Score: 67.12 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 13:15:19,941][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 13:15:19,941][root][INFO] - Score: 66.59 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-17 13:15:19,943][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 13:19:01,577][root][INFO] - Step: 2274/3790  |  Loss: 0.3490  |  Score: 84.35 [%]  |  Seq Length: 256.0
[2024-10-17 13:19:06,374][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 13:19:06,374][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 13:19:11,055][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 13:19:11,056][root][INFO] - Score: 68.32 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 13:19:11,056][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 13:19:11,058][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 13:22:51,239][root][INFO] - Step: 2653/3790  |  Loss: 0.2972  |  Score: 86.89 [%]  |  Seq Length: 256.0
[2024-10-17 13:22:56,081][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 13:22:56,082][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 13:23:00,740][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 13:23:00,740][root][INFO] - Score: 68.66 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-17 13:23:00,741][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 13:23:00,742][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 13:26:43,105][root][INFO] - Step: 3032/3790  |  Loss: 0.2483  |  Score: 89.00 [%]  |  Seq Length: 256.0
[2024-10-17 13:26:47,884][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 13:26:47,884][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-17 13:26:52,678][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 13:26:52,678][root][INFO] - Score: 68.81 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 13:26:52,680][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 13:30:36,203][root][INFO] - Step: 3411/3790  |  Loss: 0.2160  |  Score: 90.82 [%]  |  Seq Length: 256.0
[2024-10-17 13:30:41,029][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 13:30:41,030][root][INFO] - Score: 69.17 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 13:30:45,730][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 13:30:45,730][root][INFO] - Score: 68.69 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 13:30:45,733][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 13:34:28,852][root][INFO] - Step: 3790/3790  |  Loss: 0.1951  |  Score: 91.70 [%]  |  Seq Length: 256.0
[2024-10-17 13:34:33,732][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 13:34:33,732][root][INFO] - Score: 69.37 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-17 13:34:38,475][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 13:34:38,476][root][INFO] - Score: 69.13 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 13:34:38,477][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 13:34:38,477][root][INFO] - - Epoch: 7
[2024-10-17 13:34:38,477][root][INFO] - - DEV score: 71.65 [%]
[2024-10-17 13:34:38,477][root][INFO] - - TEST score: 68.66 [%]
[2024-10-17 13:34:38,478][root][INFO] - Fine-tuning is done!
[2024-10-17 13:34:38,479][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 13:34:38,479][root][INFO] - - BEST LR: 0.02
[2024-10-17 13:34:38,479][root][INFO] - - DEV score: 71.65 [%]
[2024-10-17 13:34:38,479][root][INFO] - - TEST score: 68.66 [%]
[2024-10-17 13:34:44,886][root][INFO] - 

[2024-10-17 13:34:44,886][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 13:34:44,886][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs
[2024-10-17 13:34:44,886][root][INFO] - 

[2024-10-17 13:34:44,887][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 13:35:06,081][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-17 14:07:24,060][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-17 14:07:34,475][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 14:07:34,476][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.41 [s]
[2024-10-17 14:07:54,685][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 14:07:54,685][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.21 [s]
[2024-10-17 14:07:54,686][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 14:07:54,686][root][INFO] - - Epoch: 1
[2024-10-17 14:07:54,686][root][INFO] - - DEV score: 57.00 [%]
[2024-10-17 14:07:54,686][root][INFO] - - TEST score: 57.65 [%]
[2024-10-17 14:07:54,687][root][INFO] - Fine-tuning is done!
[2024-10-17 14:07:54,688][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 14:07:54,688][root][INFO] - - BEST LR: 0.01
[2024-10-17 14:07:54,688][root][INFO] - - DEV score: 74.55 [%]
[2024-10-17 14:07:54,688][root][INFO] - - TEST score: 76.55 [%]
[2024-10-17 16:22:45,625][root][INFO] - 

[2024-10-17 16:22:45,625][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 16:22:45,625][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:22:45,626][root][INFO] - 

[2024-10-17 16:22:45,626][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 16:22:54,281][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,281][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,282][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,282][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,283][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,283][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,283][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,284][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,284][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,285][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,285][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,285][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,286][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,286][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,287][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,287][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,288][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,288][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,288][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,289][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,292][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,292][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,293][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,293][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,295][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 16:22:54,477][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 16:22:56,603][root][INFO] - 

[2024-10-17 16:22:56,603][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 16:22:56,603][root][INFO] - Data Preprocessing
[2024-10-17 16:22:56,603][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 16:22:56,603][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 16:22:56,603][root][INFO] - ㄴ data_remove                True

[2024-10-17 16:22:56,603][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 16:22:56,613][root][INFO] - vocab size              : 51200
[2024-10-17 16:22:56,614][root][INFO] - device                  : gpu
[2024-10-17 16:22:56,614][root][INFO] - random seed             : 1
[2024-10-17 16:22:56,614][root][INFO] - train data size         : 24256
[2024-10-17 16:22:56,614][root][INFO] - max epochs              : 10
[2024-10-17 16:22:56,614][root][INFO] - total steps             : 3790
[2024-10-17 16:22:56,614][root][INFO] - warmup steps            : 379
[2024-10-17 16:22:56,614][root][INFO] - batch size              : 64
[2024-10-17 16:22:56,614][root][INFO] - accumulation steps      : 1
[2024-10-17 16:22:56,614][root][INFO] - optimizer               : adamwscale
[2024-10-17 16:22:56,614][root][INFO] - lr_scheduler            : cosine
[2024-10-17 16:22:56,614][root][INFO] - learning rate           : 0.01
[2024-10-17 16:22:56,614][root][INFO] - max length              : 256

[2024-10-17 16:22:56,615][root][INFO] - LoRA Configuration
[2024-10-17 16:22:56,615][root][INFO] - ㄴ r                    : 32
[2024-10-17 16:22:56,615][root][INFO] - ㄴ alpha                : 128
[2024-10-17 16:22:56,615][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 16:22:56,615][root][INFO] - 

[2024-10-17 16:22:56,615][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:22:56,615][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 16:22:56,615][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb
[2024-10-17 16:22:56,615][root][INFO] - * tb interval   : 10000

[2024-10-17 16:22:56,615][root][INFO] - 

[2024-10-17 16:22:56,615][root][INFO] - Start the Training !
[2024-10-17 16:22:56,618][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 16:29:10,112][root][INFO] - 

[2024-10-17 16:29:10,112][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 16:29:10,112][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:29:10,113][root][INFO] - 

[2024-10-17 16:29:10,113][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 16:29:18,867][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,868][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,868][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,868][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,869][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,869][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,870][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,870][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,871][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,871][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,871][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,872][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,872][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,873][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,873][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,873][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,874][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,874][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,875][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,875][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,878][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,878][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,879][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,879][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,880][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 16:29:19,057][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 16:29:21,003][root][INFO] - 

[2024-10-17 16:29:21,003][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 16:29:21,003][root][INFO] - Data Preprocessing
[2024-10-17 16:29:21,003][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 16:29:21,003][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 16:29:21,003][root][INFO] - ㄴ data_remove                True

[2024-10-17 16:29:21,003][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 16:29:21,011][root][INFO] - vocab size              : 51200
[2024-10-17 16:29:21,012][root][INFO] - device                  : gpu
[2024-10-17 16:29:21,012][root][INFO] - random seed             : 1
[2024-10-17 16:29:21,012][root][INFO] - train data size         : 24256
[2024-10-17 16:29:21,012][root][INFO] - max epochs              : 10
[2024-10-17 16:29:21,012][root][INFO] - total steps             : 3790
[2024-10-17 16:29:21,012][root][INFO] - warmup steps            : 379
[2024-10-17 16:29:21,012][root][INFO] - batch size              : 64
[2024-10-17 16:29:21,012][root][INFO] - accumulation steps      : 1
[2024-10-17 16:29:21,012][root][INFO] - optimizer               : adamwscale
[2024-10-17 16:29:21,012][root][INFO] - lr_scheduler            : cosine
[2024-10-17 16:29:21,013][root][INFO] - learning rate           : 0.01
[2024-10-17 16:29:21,013][root][INFO] - max length              : 256

[2024-10-17 16:29:21,013][root][INFO] - LoRA Configuration
[2024-10-17 16:29:21,013][root][INFO] - ㄴ r                    : 32
[2024-10-17 16:29:21,013][root][INFO] - ㄴ alpha                : 128
[2024-10-17 16:29:21,013][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 16:29:21,013][root][INFO] - 

[2024-10-17 16:29:21,013][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:29:21,013][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 16:29:21,013][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb
[2024-10-17 16:29:21,013][root][INFO] - * tb interval   : 10000

[2024-10-17 16:29:21,013][root][INFO] - 

[2024-10-17 16:29:21,014][root][INFO] - Start the Training !
[2024-10-17 16:29:21,017][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 16:31:40,514][root][INFO] - Step: 379/3790  |  Loss: 0.7029  |  Score: 53.75 [%]  |  Seq Length: 256.0
[2024-10-17 16:31:43,050][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 16:31:43,050][root][INFO] - Score: 60.16 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 16:31:45,554][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 16:31:45,554][root][INFO] - Score: 57.08 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 16:31:45,555][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 16:31:45,556][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 16:34:04,421][root][INFO] - Step: 758/3790  |  Loss: 0.6006  |  Score: 67.44 [%]  |  Seq Length: 256.0
[2024-10-17 16:34:07,056][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 16:34:07,057][root][INFO] - Score: 68.23 [%]  |  Evaluation Time: 2.63 [s]
[2024-10-17 16:34:09,543][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 16:34:09,543][root][INFO] - Score: 63.58 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 16:34:09,544][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 16:34:09,545][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 16:36:28,423][root][INFO] - Step: 1137/3790  |  Loss: 0.5230  |  Score: 74.08 [%]  |  Seq Length: 256.0
[2024-10-17 16:36:31,003][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 16:36:31,003][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 16:36:33,470][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 16:36:33,471][root][INFO] - Score: 64.03 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 16:36:33,472][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 16:36:33,473][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 16:38:52,364][root][INFO] - Step: 1516/3790  |  Loss: 0.4670  |  Score: 77.70 [%]  |  Seq Length: 256.0
[2024-10-17 16:38:54,887][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 16:38:54,888][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:38:57,361][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 16:38:57,361][root][INFO] - Score: 68.09 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 16:38:57,362][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 16:38:57,363][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 16:41:16,142][root][INFO] - Step: 1895/3790  |  Loss: 0.4237  |  Score: 80.24 [%]  |  Seq Length: 256.0
[2024-10-17 16:41:18,669][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 16:41:18,669][root][INFO] - Score: 69.37 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:41:21,137][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 16:41:21,138][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 16:41:21,140][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 16:43:39,915][root][INFO] - Step: 2274/3790  |  Loss: 0.3759  |  Score: 82.97 [%]  |  Seq Length: 256.0
[2024-10-17 16:43:42,451][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 16:43:42,451][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 16:43:44,947][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 16:43:44,947][root][INFO] - Score: 66.24 [%]  |  Evaluation Time: 2.49 [s]
[2024-10-17 16:43:44,948][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 16:43:44,949][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 16:46:03,828][root][INFO] - Step: 2653/3790  |  Loss: 0.3394  |  Score: 84.74 [%]  |  Seq Length: 256.0
[2024-10-17 16:46:06,355][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 16:46:06,355][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:46:08,821][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 16:46:08,821][root][INFO] - Score: 67.15 [%]  |  Evaluation Time: 2.46 [s]
[2024-10-17 16:46:08,822][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 16:46:08,823][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 16:48:27,450][root][INFO] - Step: 3032/3790  |  Loss: 0.3115  |  Score: 86.27 [%]  |  Seq Length: 256.0
[2024-10-17 16:48:29,993][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 16:48:29,993][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 2.54 [s]
[2024-10-17 16:48:32,477][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 16:48:32,477][root][INFO] - Score: 67.47 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 16:48:32,479][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 16:50:51,269][root][INFO] - Step: 3411/3790  |  Loss: 0.2943  |  Score: 87.07 [%]  |  Seq Length: 256.0
[2024-10-17 16:50:53,829][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 16:50:53,829][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 2.56 [s]
[2024-10-17 16:50:56,355][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 16:50:56,356][root][INFO] - Score: 67.24 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:50:56,358][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 16:53:15,149][root][INFO] - Step: 3790/3790  |  Loss: 0.2820  |  Score: 87.75 [%]  |  Seq Length: 256.0
[2024-10-17 16:53:17,673][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 16:53:17,673][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:53:20,199][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 16:53:20,200][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:53:20,201][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 16:53:20,201][root][INFO] - - Epoch: 7
[2024-10-17 16:53:20,201][root][INFO] - - DEV score: 73.05 [%]
[2024-10-17 16:53:20,201][root][INFO] - - TEST score: 67.15 [%]
[2024-10-17 16:53:20,202][root][INFO] - Fine-tuning is done!
[2024-10-17 16:53:27,024][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,024][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,025][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,025][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,025][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,026][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,026][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,027][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,027][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,028][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,028][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,029][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,029][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,029][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,030][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,030][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,031][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,031][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,032][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,032][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,033][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,033][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,034][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,034][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,036][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 16:53:27,037][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 16:53:27,189][root][INFO] - 

[2024-10-17 16:53:27,189][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 16:53:27,190][root][INFO] - Data Preprocessing
[2024-10-17 16:53:27,190][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 16:53:27,190][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 16:53:27,190][root][INFO] - ㄴ data_remove                True

[2024-10-17 16:53:27,190][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 16:53:27,197][root][INFO] - vocab size              : 51200
[2024-10-17 16:53:27,197][root][INFO] - device                  : gpu
[2024-10-17 16:53:27,197][root][INFO] - random seed             : 1
[2024-10-17 16:53:27,197][root][INFO] - train data size         : 24256
[2024-10-17 16:53:27,197][root][INFO] - max epochs              : 10
[2024-10-17 16:53:27,197][root][INFO] - total steps             : 3790
[2024-10-17 16:53:27,197][root][INFO] - warmup steps            : 379
[2024-10-17 16:53:27,197][root][INFO] - batch size              : 64
[2024-10-17 16:53:27,198][root][INFO] - accumulation steps      : 1
[2024-10-17 16:53:27,198][root][INFO] - optimizer               : adamwscale
[2024-10-17 16:53:27,198][root][INFO] - lr_scheduler            : cosine
[2024-10-17 16:53:27,198][root][INFO] - learning rate           : 0.02
[2024-10-17 16:53:27,198][root][INFO] - max length              : 256

[2024-10-17 16:53:27,198][root][INFO] - LoRA Configuration
[2024-10-17 16:53:27,198][root][INFO] - ㄴ r                    : 32
[2024-10-17 16:53:27,198][root][INFO] - ㄴ alpha                : 128
[2024-10-17 16:53:27,198][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 16:53:27,198][root][INFO] - 

[2024-10-17 16:53:27,198][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:53:27,198][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 16:53:27,199][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb
[2024-10-17 16:53:27,199][root][INFO] - * tb interval   : 10000

[2024-10-17 16:53:27,199][root][INFO] - 

[2024-10-17 16:53:27,199][root][INFO] - Start the Training !
[2024-10-17 16:53:27,201][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 16:55:46,075][root][INFO] - Step: 379/3790  |  Loss: 0.6819  |  Score: 57.42 [%]  |  Seq Length: 256.0
[2024-10-17 16:55:48,687][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 16:55:48,687][root][INFO] - Score: 65.43 [%]  |  Evaluation Time: 2.61 [s]
[2024-10-17 16:55:51,247][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 16:55:51,247][root][INFO] - Score: 61.00 [%]  |  Evaluation Time: 2.56 [s]
[2024-10-17 16:55:51,248][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 16:55:51,250][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 16:58:10,129][root][INFO] - Step: 758/3790  |  Loss: 0.5792  |  Score: 69.58 [%]  |  Seq Length: 256.0
[2024-10-17 16:58:12,720][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 16:58:12,720][root][INFO] - Score: 67.15 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 16:58:15,246][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 16:58:15,246][root][INFO] - Score: 63.58 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:58:15,246][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 16:58:15,248][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:00:34,246][root][INFO] - Step: 1137/3790  |  Loss: 0.5135  |  Score: 74.62 [%]  |  Seq Length: 256.0
[2024-10-17 17:00:36,857][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:00:36,857][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 2.61 [s]
[2024-10-17 17:00:39,394][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:00:39,394][root][INFO] - Score: 65.34 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 17:00:39,395][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 17:00:39,396][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:02:08,639][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,639][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,640][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,640][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,641][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,641][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,642][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,642][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,643][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,643][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,644][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,644][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,645][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,646][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,646][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,647][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,647][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,648][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,648][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,649][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,650][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,650][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,651][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,651][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,653][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 17:02:08,658][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 17:02:08,860][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 17:02:08,862][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 17:02:09,053][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 17:02:12,158][root][INFO] - 

[2024-10-17 17:02:12,158][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 17:02:12,158][root][INFO] - Data Preprocessing
[2024-10-17 17:02:12,158][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 17:02:12,158][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 17:02:12,158][root][INFO] - ㄴ data_remove                False

[2024-10-17 17:02:12,158][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 17:02:12,166][root][INFO] - vocab size              : 51200
[2024-10-17 17:02:12,166][root][INFO] - device                  : gpu
[2024-10-17 17:02:12,166][root][INFO] - random seed             : 1
[2024-10-17 17:02:12,166][root][INFO] - train data size         : 49152
[2024-10-17 17:02:12,166][root][INFO] - max epochs              : 10
[2024-10-17 17:02:12,166][root][INFO] - total steps             : 7680
[2024-10-17 17:02:12,166][root][INFO] - warmup steps            : 768
[2024-10-17 17:02:12,167][root][INFO] - batch size              : 64
[2024-10-17 17:02:12,167][root][INFO] - accumulation steps      : 1
[2024-10-17 17:02:12,167][root][INFO] - optimizer               : adamwscale
[2024-10-17 17:02:12,167][root][INFO] - lr_scheduler            : cosine
[2024-10-17 17:02:12,167][root][INFO] - learning rate           : 0.01
[2024-10-17 17:02:12,167][root][INFO] - max length              : 256

[2024-10-17 17:02:12,167][root][INFO] - LoRA Configuration
[2024-10-17 17:02:12,167][root][INFO] - ㄴ r                    : 32
[2024-10-17 17:02:12,167][root][INFO] - ㄴ alpha                : 128
[2024-10-17 17:02:12,167][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 17:02:12,167][root][INFO] - KOMBO Configuration
[2024-10-17 17:02:12,168][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 17:02:12,168][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 17:02:12,168][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 17:02:12,168][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 17:02:12,168][root][INFO] - ㄴ do_combination       : True
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 17:02:12,168][root][INFO] - 

[2024-10-17 17:02:12,169][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs
[2024-10-17 17:02:12,169][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/ckpt
[2024-10-17 17:02:12,169][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/tb
[2024-10-17 17:02:12,169][root][INFO] - * tb interval   : 10000

[2024-10-17 17:02:12,169][root][INFO] - 

[2024-10-17 17:02:12,169][root][INFO] - Start the Training !
[2024-10-17 17:02:12,172][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 17:02:58,378][root][INFO] - Step: 1516/3790  |  Loss: 0.4617  |  Score: 77.90 [%]  |  Seq Length: 256.0
[2024-10-17 17:03:00,945][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:03:00,946][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:03:03,531][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:03:03,532][root][INFO] - Score: 69.59 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 17:03:03,534][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:03:03,536][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:05:22,603][root][INFO] - Step: 1895/3790  |  Loss: 0.4109  |  Score: 81.01 [%]  |  Seq Length: 256.0
[2024-10-17 17:05:25,199][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:05:25,199][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 17:05:27,755][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:05:27,755][root][INFO] - Score: 69.33 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:05:27,756][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:05:27,757][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:07:46,876][root][INFO] - Step: 2274/3790  |  Loss: 0.3518  |  Score: 83.90 [%]  |  Seq Length: 256.0
[2024-10-17 17:07:49,506][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:07:49,506][root][INFO] - Score: 73.93 [%]  |  Evaluation Time: 2.63 [s]
[2024-10-17 17:07:52,088][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:07:52,089][root][INFO] - Score: 69.44 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 17:07:52,091][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:07:52,093][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:09:42,107][root][INFO] - Step: 768/7680  |  Loss: 0.6529  |  Score: 60.43 [%]  |  Seq Length: 256.0
[2024-10-17 17:09:51,270][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 17:09:51,270][root][INFO] - Score: 68.76 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-17 17:10:00,208][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 17:10:00,208][root][INFO] - Score: 65.64 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-17 17:10:00,209][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 17:10:00,211][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 17:10:11,182][root][INFO] - Step: 2653/3790  |  Loss: 0.3040  |  Score: 86.50 [%]  |  Seq Length: 256.0
[2024-10-17 17:10:13,779][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 17:10:13,780][root][INFO] - Score: 74.02 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 17:10:16,330][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 17:10:16,331][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:10:16,333][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 17:12:35,739][root][INFO] - Step: 3032/3790  |  Loss: 0.2500  |  Score: 88.91 [%]  |  Seq Length: 256.0
[2024-10-17 17:12:38,383][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 17:12:38,384][root][INFO] - Score: 72.72 [%]  |  Evaluation Time: 2.64 [s]
[2024-10-17 17:12:40,955][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 17:12:40,956][root][INFO] - Score: 69.52 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:12:40,958][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 17:15:00,568][root][INFO] - Step: 3411/3790  |  Loss: 0.2193  |  Score: 90.55 [%]  |  Seq Length: 256.0
[2024-10-17 17:15:03,254][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 17:15:03,254][root][INFO] - Score: 75.78 [%]  |  Evaluation Time: 2.68 [s]
[2024-10-17 17:15:05,855][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 17:15:05,856][root][INFO] - Score: 70.43 [%]  |  Evaluation Time: 2.60 [s]
[2024-10-17 17:15:05,858][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 17:15:05,861][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 17:17:25,565][root][INFO] - Step: 3790/3790  |  Loss: 0.2008  |  Score: 91.39 [%]  |  Seq Length: 256.0
[2024-10-17 17:17:26,425][root][INFO] - Step: 1536/7680  |  Loss: 0.5336  |  Score: 73.19 [%]  |  Seq Length: 256.0
[2024-10-17 17:17:28,241][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 17:17:28,241][root][INFO] - Score: 73.70 [%]  |  Evaluation Time: 2.67 [s]
[2024-10-17 17:17:30,841][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 17:17:30,841][root][INFO] - Score: 69.76 [%]  |  Evaluation Time: 2.60 [s]
[2024-10-17 17:17:30,842][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 17:17:30,842][root][INFO] - - Epoch: 9
[2024-10-17 17:17:30,843][root][INFO] - - DEV score: 75.78 [%]
[2024-10-17 17:17:30,843][root][INFO] - - TEST score: 70.43 [%]
[2024-10-17 17:17:30,845][root][INFO] - Fine-tuning is done!
[2024-10-17 17:17:30,845][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 17:17:30,845][root][INFO] - - BEST LR: 0.02
[2024-10-17 17:17:30,845][root][INFO] - - DEV score: 75.78 [%]
[2024-10-17 17:17:30,845][root][INFO] - - TEST score: 70.43 [%]
[2024-10-17 17:17:35,462][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 17:17:35,463][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-17 17:17:36,656][root][INFO] - 

[2024-10-17 17:17:36,656][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 17:17:36,656][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs
[2024-10-17 17:17:36,656][root][INFO] - 

[2024-10-17 17:17:36,656][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 17:17:44,433][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 17:17:44,433][root][INFO] - Score: 67.71 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-17 17:17:44,434][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 17:17:44,435][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:17:45,623][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,624][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,624][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,624][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,625][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,625][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,626][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,626][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,627][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,627][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,627][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,628][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,628][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,629][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,629][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,629][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,630][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,630][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,631][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,631][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,632][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,633][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,633][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,633][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,635][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 17:17:45,807][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 17:17:47,706][root][INFO] - 

[2024-10-17 17:17:47,706][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 17:17:47,706][root][INFO] - Data Preprocessing
[2024-10-17 17:17:47,706][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 17:17:47,707][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 17:17:47,707][root][INFO] - ㄴ data_remove                True

[2024-10-17 17:17:47,707][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 17:17:47,714][root][INFO] - vocab size              : 51200
[2024-10-17 17:17:47,715][root][INFO] - device                  : gpu
[2024-10-17 17:17:47,715][root][INFO] - random seed             : 2
[2024-10-17 17:17:47,715][root][INFO] - train data size         : 24256
[2024-10-17 17:17:47,715][root][INFO] - max epochs              : 10
[2024-10-17 17:17:47,715][root][INFO] - total steps             : 3790
[2024-10-17 17:17:47,715][root][INFO] - warmup steps            : 379
[2024-10-17 17:17:47,715][root][INFO] - batch size              : 64
[2024-10-17 17:17:47,715][root][INFO] - accumulation steps      : 1
[2024-10-17 17:17:47,715][root][INFO] - optimizer               : adamwscale
[2024-10-17 17:17:47,715][root][INFO] - lr_scheduler            : cosine
[2024-10-17 17:17:47,715][root][INFO] - learning rate           : 0.01
[2024-10-17 17:17:47,715][root][INFO] - max length              : 256

[2024-10-17 17:17:47,716][root][INFO] - LoRA Configuration
[2024-10-17 17:17:47,716][root][INFO] - ㄴ r                    : 32
[2024-10-17 17:17:47,716][root][INFO] - ㄴ alpha                : 128
[2024-10-17 17:17:47,716][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 17:17:47,716][root][INFO] - 

[2024-10-17 17:17:47,716][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs
[2024-10-17 17:17:47,716][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/ckpt
[2024-10-17 17:17:47,716][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/tb
[2024-10-17 17:17:47,716][root][INFO] - * tb interval   : 10000

[2024-10-17 17:17:47,716][root][INFO] - 

[2024-10-17 17:17:47,716][root][INFO] - Start the Training !
[2024-10-17 17:17:47,719][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 17:20:07,859][root][INFO] - Step: 379/3790  |  Loss: 0.6762  |  Score: 57.66 [%]  |  Seq Length: 256.0
[2024-10-17 17:20:10,409][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 17:20:10,409][root][INFO] - Score: 61.91 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:20:12,852][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 17:20:12,852][root][INFO] - Score: 58.93 [%]  |  Evaluation Time: 2.44 [s]
[2024-10-17 17:20:12,853][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 17:20:12,854][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 17:22:32,207][root][INFO] - Step: 758/3790  |  Loss: 0.5810  |  Score: 69.58 [%]  |  Seq Length: 256.0
[2024-10-17 17:22:34,726][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 17:22:34,726][root][INFO] - Score: 68.23 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 17:22:37,180][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 17:22:37,181][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 2.45 [s]
[2024-10-17 17:22:37,182][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 17:22:37,183][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:24:56,134][root][INFO] - Step: 1137/3790  |  Loss: 0.5150  |  Score: 74.66 [%]  |  Seq Length: 256.0
[2024-10-17 17:24:58,648][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:24:58,648][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 2.51 [s]
[2024-10-17 17:25:01,084][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:25:01,084][root][INFO] - Score: 64.35 [%]  |  Evaluation Time: 2.43 [s]
[2024-10-17 17:25:01,085][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 17:25:01,086][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:25:12,920][root][INFO] - Step: 2304/7680  |  Loss: 0.4719  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-17 17:25:21,981][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:25:21,982][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-17 17:25:31,032][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:25:31,032][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-17 17:25:31,033][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 17:25:31,035][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:27:19,771][root][INFO] - Step: 1516/3790  |  Loss: 0.4594  |  Score: 78.18 [%]  |  Seq Length: 256.0
[2024-10-17 17:27:22,277][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:27:22,278][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:27:24,746][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:27:24,746][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 17:27:24,747][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:27:24,748][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:29:43,343][root][INFO] - Step: 1895/3790  |  Loss: 0.4093  |  Score: 80.92 [%]  |  Seq Length: 256.0
[2024-10-17 17:29:45,901][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:29:45,901][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:29:48,377][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:29:48,378][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 17:29:48,379][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:29:48,380][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:32:07,751][root][INFO] - Step: 2274/3790  |  Loss: 0.3701  |  Score: 83.06 [%]  |  Seq Length: 256.0
[2024-10-17 17:32:10,257][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:32:10,257][root][INFO] - Score: 71.97 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:32:12,713][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:32:12,713][root][INFO] - Score: 67.13 [%]  |  Evaluation Time: 2.45 [s]
[2024-10-17 17:32:12,715][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:32:12,716][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:32:58,908][root][INFO] - Step: 3072/7680  |  Loss: 0.4236  |  Score: 79.95 [%]  |  Seq Length: 256.0
[2024-10-17 17:33:07,908][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:33:07,908][root][INFO] - Score: 73.43 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-17 17:33:16,953][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:33:16,953][root][INFO] - Score: 70.65 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-17 17:33:16,954][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:33:16,956][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:34:31,311][root][INFO] - Step: 2653/3790  |  Loss: 0.3335  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-17 17:34:33,848][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 17:34:33,848][root][INFO] - Score: 69.11 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 17:34:36,305][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 17:34:36,305][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 2.45 [s]
[2024-10-17 17:34:36,307][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 17:36:55,130][root][INFO] - Step: 3032/3790  |  Loss: 0.3051  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-17 17:36:57,617][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 17:36:57,617][root][INFO] - Score: 70.28 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 17:37:00,091][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 17:37:00,091][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 17:37:00,093][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 17:39:18,852][root][INFO] - Step: 3411/3790  |  Loss: 0.2800  |  Score: 87.68 [%]  |  Seq Length: 256.0
[2024-10-17 17:39:21,337][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 17:39:21,337][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 17:39:23,781][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 17:39:23,781][root][INFO] - Score: 69.27 [%]  |  Evaluation Time: 2.44 [s]
[2024-10-17 17:39:23,782][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 17:39:23,783][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 17:40:45,172][root][INFO] - Step: 3840/7680  |  Loss: 0.3822  |  Score: 82.26 [%]  |  Seq Length: 256.0
[2024-10-17 17:40:54,193][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:40:54,193][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-17 17:41:03,170][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:41:03,171][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-17 17:41:03,171][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:41:03,173][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:41:42,645][root][INFO] - Step: 3790/3790  |  Loss: 0.2717  |  Score: 88.04 [%]  |  Seq Length: 256.0
[2024-10-17 17:41:45,152][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 17:41:45,152][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:41:47,592][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 17:41:47,592][root][INFO] - Score: 68.90 [%]  |  Evaluation Time: 2.44 [s]
[2024-10-17 17:41:47,593][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-17 17:41:47,593][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 17:41:47,593][root][INFO] - - Epoch: 10
[2024-10-17 17:41:47,593][root][INFO] - - DEV score: 72.46 [%]
[2024-10-17 17:41:47,593][root][INFO] - - TEST score: 68.90 [%]
[2024-10-17 17:41:47,594][root][INFO] - Fine-tuning is done!
[2024-10-17 17:41:54,355][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,356][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,356][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,357][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,357][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,358][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,358][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,359][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,359][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,360][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,360][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,361][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,361][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,362][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,362][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,363][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,364][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,364][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,364][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,365][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,366][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,366][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,367][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,367][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,369][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 17:41:54,370][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 17:41:54,527][root][INFO] - 

[2024-10-17 17:41:54,527][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 17:41:54,528][root][INFO] - Data Preprocessing
[2024-10-17 17:41:54,528][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 17:41:54,528][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 17:41:54,528][root][INFO] - ㄴ data_remove                True

[2024-10-17 17:41:54,528][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 17:41:54,535][root][INFO] - vocab size              : 51200
[2024-10-17 17:41:54,535][root][INFO] - device                  : gpu
[2024-10-17 17:41:54,535][root][INFO] - random seed             : 2
[2024-10-17 17:41:54,536][root][INFO] - train data size         : 24256
[2024-10-17 17:41:54,536][root][INFO] - max epochs              : 10
[2024-10-17 17:41:54,536][root][INFO] - total steps             : 3790
[2024-10-17 17:41:54,536][root][INFO] - warmup steps            : 379
[2024-10-17 17:41:54,536][root][INFO] - batch size              : 64
[2024-10-17 17:41:54,536][root][INFO] - accumulation steps      : 1
[2024-10-17 17:41:54,536][root][INFO] - optimizer               : adamwscale
[2024-10-17 17:41:54,536][root][INFO] - lr_scheduler            : cosine
[2024-10-17 17:41:54,536][root][INFO] - learning rate           : 0.02
[2024-10-17 17:41:54,536][root][INFO] - max length              : 256

[2024-10-17 17:41:54,536][root][INFO] - LoRA Configuration
[2024-10-17 17:41:54,537][root][INFO] - ㄴ r                    : 32
[2024-10-17 17:41:54,537][root][INFO] - ㄴ alpha                : 128
[2024-10-17 17:41:54,537][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 17:41:54,537][root][INFO] - 

[2024-10-17 17:41:54,537][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs
[2024-10-17 17:41:54,537][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/ckpt
[2024-10-17 17:41:54,537][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/tb
[2024-10-17 17:41:54,537][root][INFO] - * tb interval   : 10000

[2024-10-17 17:41:54,537][root][INFO] - 

[2024-10-17 17:41:54,537][root][INFO] - Start the Training !
[2024-10-17 17:41:54,539][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 17:44:13,394][root][INFO] - Step: 379/3790  |  Loss: 0.6682  |  Score: 59.30 [%]  |  Seq Length: 256.0
[2024-10-17 17:44:15,934][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 17:44:15,934][root][INFO] - Score: 60.61 [%]  |  Evaluation Time: 2.54 [s]
[2024-10-17 17:44:18,427][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 17:44:18,427][root][INFO] - Score: 60.66 [%]  |  Evaluation Time: 2.49 [s]
[2024-10-17 17:44:18,428][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 17:44:18,429][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 17:46:37,838][root][INFO] - Step: 758/3790  |  Loss: 0.5719  |  Score: 70.28 [%]  |  Seq Length: 256.0
[2024-10-17 17:46:40,407][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 17:46:40,408][root][INFO] - Score: 67.94 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:46:42,906][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 17:46:42,906][root][INFO] - Score: 65.30 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:46:42,907][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 17:46:42,908][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:48:30,881][root][INFO] - Step: 4608/7680  |  Loss: 0.3455  |  Score: 84.17 [%]  |  Seq Length: 256.0
[2024-10-17 17:48:39,923][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:48:39,923][root][INFO] - Score: 73.15 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-17 17:48:48,909][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:48:48,909][root][INFO] - Score: 71.54 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-17 17:48:48,910][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:48:48,912][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:49:02,768][root][INFO] - Step: 1137/3790  |  Loss: 0.5114  |  Score: 74.53 [%]  |  Seq Length: 256.0
[2024-10-17 17:49:05,342][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:49:05,342][root][INFO] - Score: 66.93 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:49:07,859][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:49:07,859][root][INFO] - Score: 63.97 [%]  |  Evaluation Time: 2.51 [s]
[2024-10-17 17:49:07,861][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:51:26,922][root][INFO] - Step: 1516/3790  |  Loss: 0.4578  |  Score: 78.19 [%]  |  Seq Length: 256.0
[2024-10-17 17:51:29,502][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:51:29,502][root][INFO] - Score: 67.81 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 17:51:32,038][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:51:32,038][root][INFO] - Score: 67.42 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 17:51:32,040][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:51:32,041][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:53:50,829][root][INFO] - Step: 1895/3790  |  Loss: 0.3992  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-17 17:53:53,429][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:53:53,429][root][INFO] - Score: 70.38 [%]  |  Evaluation Time: 2.60 [s]
[2024-10-17 17:53:55,933][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:53:55,933][root][INFO] - Score: 67.94 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:53:55,934][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:53:55,935][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:56:14,753][root][INFO] - Step: 2274/3790  |  Loss: 0.3456  |  Score: 84.28 [%]  |  Seq Length: 256.0
[2024-10-17 17:56:17,343][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:56:17,343][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 17:56:17,746][root][INFO] - Step: 5376/7680  |  Loss: 0.3096  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-17 17:56:19,845][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:56:19,845][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:56:19,847][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:56:19,848][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:56:27,054][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 17:56:27,054][root][INFO] - Score: 74.28 [%]  |  Evaluation Time: 9.30 [s]
[2024-10-17 17:56:36,055][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 17:56:36,055][root][INFO] - Score: 71.55 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-17 17:56:36,056][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 17:56:36,057][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 18:00:27,601][root][INFO] - 

[2024-10-17 18:00:27,601][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 18:00:27,602][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-17 18:00:27,602][root][INFO] - 

[2024-10-17 18:00:27,602][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 18:00:39,080][root][INFO] - 

[2024-10-17 18:00:39,081][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 18:00:39,081][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-17 18:00:39,081][root][INFO] - 

[2024-10-17 18:00:39,082][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 18:02:48,671][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,672][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,672][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,672][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,673][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,673][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,674][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,674][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,675][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,675][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,675][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,676][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,676][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,677][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,677][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,678][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,678][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,678][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,679][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,679][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,680][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,680][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,681][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,681][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,683][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-17 18:02:48,911][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 18:02:50,809][root][INFO] - 

[2024-10-17 18:02:50,809][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-17 18:02:50,809][root][INFO] - Data Preprocessing
[2024-10-17 18:02:50,809][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 18:02:50,809][root][INFO] - ㄴ do_hangeulize              False
[2024-10-17 18:02:50,810][root][INFO] - ㄴ data_remove                True

[2024-10-17 18:02:50,810][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 18:02:50,817][root][INFO] - vocab size              : 51200
[2024-10-17 18:02:50,818][root][INFO] - device                  : gpu
[2024-10-17 18:02:50,818][root][INFO] - random seed             : 1
[2024-10-17 18:02:50,818][root][INFO] - train data size         : 845696
[2024-10-17 18:02:50,818][root][INFO] - max epochs              : 5
[2024-10-17 18:02:50,818][root][INFO] - total steps             : 66070
[2024-10-17 18:02:50,818][root][INFO] - warmup steps            : 6607
[2024-10-17 18:02:50,818][root][INFO] - batch size              : 64
[2024-10-17 18:02:50,818][root][INFO] - accumulation steps      : 1
[2024-10-17 18:02:50,818][root][INFO] - optimizer               : adamwscale
[2024-10-17 18:02:50,818][root][INFO] - lr_scheduler            : cosine
[2024-10-17 18:02:50,819][root][INFO] - learning rate           : 0.01
[2024-10-17 18:02:50,819][root][INFO] - max length              : 256

[2024-10-17 18:02:50,819][root][INFO] - LoRA Configuration
[2024-10-17 18:02:50,819][root][INFO] - ㄴ r                    : 32
[2024-10-17 18:02:50,819][root][INFO] - ㄴ alpha                : 128
[2024-10-17 18:02:50,819][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 18:02:50,819][root][INFO] - 

[2024-10-17 18:02:50,819][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-17 18:02:50,819][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 18:02:50,819][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-17 18:02:50,819][root][INFO] - * tb interval   : 10000

[2024-10-17 18:02:50,820][root][INFO] - 

[2024-10-17 18:02:50,820][root][INFO] - Start the Training !
[2024-10-17 18:02:50,822][root][INFO] - 
[1/ 5 Epoch]
[2024-10-17 18:03:04,858][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,859][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,859][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,860][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,860][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,861][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,861][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,862][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,863][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,863][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,864][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,864][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,865][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,865][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,866][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,866][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,867][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,868][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,868][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,869][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,869][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,870][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,871][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,871][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,873][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-17 18:03:05,116][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 18:03:07,052][root][INFO] - 

[2024-10-17 18:03:07,053][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-17 18:03:07,053][root][INFO] - Data Preprocessing
[2024-10-17 18:03:07,053][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 18:03:07,053][root][INFO] - ㄴ do_hangeulize              False
[2024-10-17 18:03:07,053][root][INFO] - ㄴ data_remove                False

[2024-10-17 18:03:07,053][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 18:03:07,061][root][INFO] - vocab size              : 51200
[2024-10-17 18:03:07,061][root][INFO] - device                  : gpu
[2024-10-17 18:03:07,061][root][INFO] - random seed             : 1
[2024-10-17 18:03:07,061][root][INFO] - train data size         : 942912
[2024-10-17 18:03:07,061][root][INFO] - max epochs              : 5
[2024-10-17 18:03:07,061][root][INFO] - total steps             : 73665
[2024-10-17 18:03:07,061][root][INFO] - warmup steps            : 7366
[2024-10-17 18:03:07,061][root][INFO] - batch size              : 64
[2024-10-17 18:03:07,061][root][INFO] - accumulation steps      : 1
[2024-10-17 18:03:07,062][root][INFO] - optimizer               : adamwscale
[2024-10-17 18:03:07,062][root][INFO] - lr_scheduler            : cosine
[2024-10-17 18:03:07,062][root][INFO] - learning rate           : 0.01
[2024-10-17 18:03:07,062][root][INFO] - max length              : 256

[2024-10-17 18:03:07,062][root][INFO] - LoRA Configuration
[2024-10-17 18:03:07,062][root][INFO] - ㄴ r                    : 32
[2024-10-17 18:03:07,062][root][INFO] - ㄴ alpha                : 128
[2024-10-17 18:03:07,062][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 18:03:07,062][root][INFO] - 

[2024-10-17 18:03:07,062][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-17 18:03:07,062][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-17 18:03:07,062][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-17 18:03:07,063][root][INFO] - * tb interval   : 10000

[2024-10-17 18:03:07,063][root][INFO] - 

[2024-10-17 18:03:07,063][root][INFO] - Start the Training !
[2024-10-17 18:03:07,066][root][INFO] - 
[1/ 5 Epoch]
[2024-10-17 19:04:13,467][root][INFO] - Step: 10000/73665  |  Loss: 0.7315  |  Score: 68.32 [%]  |  Seq Length: 256.0
[2024-10-17 19:04:22,254][root][INFO] - Step: 10000/66070  |  Loss: 0.7213  |  Score: 68.88 [%]  |  Seq Length: 256.0
[2024-10-17 19:24:09,049][root][INFO] - Step: 13214/66070  |  Loss: 0.6525  |  Score: 72.69 [%]  |  Seq Length: 256.0
[2024-10-17 19:24:13,937][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 19:24:13,938][root][INFO] - Score: 70.66 [%]  |  Evaluation Time: 4.89 [s]
[2024-10-17 19:24:22,997][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 19:24:22,997][root][INFO] - Score: 70.93 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-17 19:24:22,998][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 19:24:22,999][root][INFO] - 
[2/ 5 Epoch]
[2024-10-17 19:33:09,056][root][INFO] - Step: 14733/73665  |  Loss: 0.6617  |  Score: 72.26 [%]  |  Seq Length: 256.0
[2024-10-17 19:33:15,161][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 19:33:15,161][root][INFO] - Score: 71.49 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-17 19:33:26,938][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 19:33:26,939][root][INFO] - Score: 73.01 [%]  |  Evaluation Time: 11.77 [s]
[2024-10-17 19:33:26,940][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 19:33:26,941][root][INFO] - 
[2/ 5 Epoch]
[2024-10-17 20:05:39,283][root][INFO] - Step: 20000/73665  |  Loss: 0.6365  |  Score: 73.57 [%]  |  Seq Length: 256.0
[2024-10-17 20:06:10,603][root][INFO] - Step: 20000/66070  |  Loss: 0.6259  |  Score: 74.08 [%]  |  Seq Length: 256.0
[2024-10-17 20:45:45,711][root][INFO] - Step: 26428/66070  |  Loss: 0.6189  |  Score: 74.44 [%]  |  Seq Length: 256.0
[2024-10-17 20:45:50,600][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 20:45:50,601][root][INFO] - Score: 71.96 [%]  |  Evaluation Time: 4.89 [s]
[2024-10-17 20:45:59,774][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 20:45:59,774][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-17 20:45:59,775][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 20:45:59,776][root][INFO] - 
[3/ 5 Epoch]
[2024-10-17 21:03:33,252][root][INFO] - Step: 29466/73665  |  Loss: 0.6283  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-17 21:03:39,358][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 21:03:39,359][root][INFO] - Score: 72.30 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-17 21:03:51,075][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 21:03:51,075][root][INFO] - Score: 73.57 [%]  |  Evaluation Time: 11.71 [s]
[2024-10-17 21:03:51,076][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 21:03:51,077][root][INFO] - 
[3/ 5 Epoch]
[2024-10-17 21:07:07,401][root][INFO] - Step: 30000/73665  |  Loss: 0.5979  |  Score: 75.57 [%]  |  Seq Length: 256.0
[2024-10-17 21:08:00,477][root][INFO] - Step: 30000/66070  |  Loss: 0.5910  |  Score: 75.75 [%]  |  Seq Length: 256.0
[2024-10-17 22:07:15,546][root][INFO] - Step: 39642/66070  |  Loss: 0.5808  |  Score: 76.24 [%]  |  Seq Length: 256.0
[2024-10-17 22:07:20,410][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 22:07:20,411][root][INFO] - Score: 73.16 [%]  |  Evaluation Time: 4.86 [s]
[2024-10-17 22:07:29,458][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 22:07:29,458][root][INFO] - Score: 73.95 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-17 22:07:29,459][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 22:07:29,460][root][INFO] - 
[4/ 5 Epoch]
[2024-10-17 22:08:14,766][root][INFO] - Step: 40000/73665  |  Loss: 0.5976  |  Score: 75.48 [%]  |  Seq Length: 256.0
[2024-10-17 22:09:42,019][root][INFO] - Step: 40000/66070  |  Loss: 0.5465  |  Score: 77.66 [%]  |  Seq Length: 256.0
[2024-10-17 22:33:54,478][root][INFO] - Step: 44199/73665  |  Loss: 0.5852  |  Score: 75.95 [%]  |  Seq Length: 256.0
[2024-10-17 22:34:00,579][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 22:34:00,579][root][INFO] - Score: 73.68 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-17 22:34:12,385][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 22:34:12,385][root][INFO] - Score: 75.01 [%]  |  Evaluation Time: 11.80 [s]
[2024-10-17 22:34:12,386][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 22:34:12,388][root][INFO] - 
[4/ 5 Epoch]
[2024-10-17 23:09:39,607][root][INFO] - Step: 50000/73665  |  Loss: 0.5525  |  Score: 77.53 [%]  |  Seq Length: 256.0
[2024-10-17 23:11:10,287][root][INFO] - Step: 50000/66070  |  Loss: 0.5364  |  Score: 78.40 [%]  |  Seq Length: 256.0
[2024-10-17 23:28:42,970][root][INFO] - Step: 52856/66070  |  Loss: 0.5261  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-17 23:28:47,806][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 23:28:47,807][root][INFO] - Score: 74.76 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-17 23:28:56,850][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 23:28:56,851][root][INFO] - Score: 75.42 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-17 23:28:56,852][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 23:28:56,853][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 00:04:14,695][root][INFO] - Step: 58932/73665  |  Loss: 0.5409  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-18 00:04:20,815][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 00:04:20,815][root][INFO] - Score: 75.52 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-18 00:04:32,581][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 00:04:32,581][root][INFO] - Score: 76.29 [%]  |  Evaluation Time: 11.76 [s]
[2024-10-18 00:04:32,582][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 00:04:32,583][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 00:11:04,845][root][INFO] - Step: 60000/73665  |  Loss: 0.5099  |  Score: 79.35 [%]  |  Seq Length: 256.0
[2024-10-18 00:12:50,865][root][INFO] - Step: 60000/66070  |  Loss: 0.4990  |  Score: 80.08 [%]  |  Seq Length: 256.0
[2024-10-18 00:50:11,419][root][INFO] - Step: 66070/66070  |  Loss: 0.4948  |  Score: 80.21 [%]  |  Seq Length: 256.0
[2024-10-18 00:50:16,269][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 00:50:16,269][root][INFO] - Score: 75.13 [%]  |  Evaluation Time: 4.85 [s]
[2024-10-18 00:50:25,312][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 00:50:25,312][root][INFO] - Score: 75.64 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-18 00:50:25,313][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 00:50:25,313][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 00:50:25,313][root][INFO] - - Epoch: 5
[2024-10-18 00:50:25,314][root][INFO] - - DEV score: 75.13 [%]
[2024-10-18 00:50:25,314][root][INFO] - - TEST score: 75.64 [%]
[2024-10-18 00:50:25,314][root][INFO] - Fine-tuning is done!
[2024-10-18 00:52:05,008][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,008][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,009][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,009][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,010][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,011][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,011][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,012][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,012][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,013][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,013][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,014][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,014][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,015][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,015][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,016][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,016][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,016][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,017][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,017][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,018][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,019][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,019][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,020][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,022][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 00:52:05,023][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 00:52:05,191][root][INFO] - 

[2024-10-18 00:52:05,192][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 00:52:05,192][root][INFO] - Data Preprocessing
[2024-10-18 00:52:05,192][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 00:52:05,192][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 00:52:05,192][root][INFO] - ㄴ data_remove                True

[2024-10-18 00:52:05,192][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 00:52:05,203][root][INFO] - vocab size              : 51200
[2024-10-18 00:52:05,204][root][INFO] - device                  : gpu
[2024-10-18 00:52:05,204][root][INFO] - random seed             : 1
[2024-10-18 00:52:05,205][root][INFO] - train data size         : 845696
[2024-10-18 00:52:05,205][root][INFO] - max epochs              : 5
[2024-10-18 00:52:05,205][root][INFO] - total steps             : 66070
[2024-10-18 00:52:05,205][root][INFO] - warmup steps            : 6607
[2024-10-18 00:52:05,205][root][INFO] - batch size              : 64
[2024-10-18 00:52:05,205][root][INFO] - accumulation steps      : 1
[2024-10-18 00:52:05,205][root][INFO] - optimizer               : adamwscale
[2024-10-18 00:52:05,205][root][INFO] - lr_scheduler            : cosine
[2024-10-18 00:52:05,205][root][INFO] - learning rate           : 0.02
[2024-10-18 00:52:05,205][root][INFO] - max length              : 256

[2024-10-18 00:52:05,205][root][INFO] - LoRA Configuration
[2024-10-18 00:52:05,205][root][INFO] - ㄴ r                    : 32
[2024-10-18 00:52:05,205][root][INFO] - ㄴ alpha                : 128
[2024-10-18 00:52:05,206][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 00:52:05,206][root][INFO] - 

[2024-10-18 00:52:05,206][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 00:52:05,206][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 00:52:05,206][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 00:52:05,206][root][INFO] - * tb interval   : 10000

[2024-10-18 00:52:05,206][root][INFO] - 

[2024-10-18 00:52:05,206][root][INFO] - Start the Training !
[2024-10-18 00:52:05,208][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 01:12:11,841][root][INFO] - Step: 70000/73665  |  Loss: 0.5071  |  Score: 79.69 [%]  |  Seq Length: 256.0
[2024-10-18 01:34:35,373][root][INFO] - Step: 73665/73665  |  Loss: 0.5052  |  Score: 79.80 [%]  |  Seq Length: 256.0
[2024-10-18 01:34:41,534][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 01:34:41,534][root][INFO] - Score: 75.90 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-18 01:34:53,338][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 01:34:53,339][root][INFO] - Score: 76.35 [%]  |  Evaluation Time: 11.80 [s]
[2024-10-18 01:34:53,340][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 01:34:53,340][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 01:34:53,340][root][INFO] - - Epoch: 5
[2024-10-18 01:34:53,340][root][INFO] - - DEV score: 75.90 [%]
[2024-10-18 01:34:53,340][root][INFO] - - TEST score: 76.35 [%]
[2024-10-18 01:34:53,341][root][INFO] - Fine-tuning is done!
[2024-10-18 01:36:52,707][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,708][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,709][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,709][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,710][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,710][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,711][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,712][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,713][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,714][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,714][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,715][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,716][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,716][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,717][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,717][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,718][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,718][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,719][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,719][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,720][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,721][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,721][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,722][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,724][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 01:36:52,726][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 01:36:52,897][root][INFO] - 

[2024-10-18 01:36:52,897][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 01:36:52,897][root][INFO] - Data Preprocessing
[2024-10-18 01:36:52,897][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 01:36:52,897][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 01:36:52,897][root][INFO] - ㄴ data_remove                False

[2024-10-18 01:36:52,897][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 01:36:52,908][root][INFO] - vocab size              : 51200
[2024-10-18 01:36:52,909][root][INFO] - device                  : gpu
[2024-10-18 01:36:52,910][root][INFO] - random seed             : 1
[2024-10-18 01:36:52,910][root][INFO] - train data size         : 942912
[2024-10-18 01:36:52,910][root][INFO] - max epochs              : 5
[2024-10-18 01:36:52,910][root][INFO] - total steps             : 73665
[2024-10-18 01:36:52,910][root][INFO] - warmup steps            : 7366
[2024-10-18 01:36:52,910][root][INFO] - batch size              : 64
[2024-10-18 01:36:52,910][root][INFO] - accumulation steps      : 1
[2024-10-18 01:36:52,910][root][INFO] - optimizer               : adamwscale
[2024-10-18 01:36:52,910][root][INFO] - lr_scheduler            : cosine
[2024-10-18 01:36:52,910][root][INFO] - learning rate           : 0.02
[2024-10-18 01:36:52,910][root][INFO] - max length              : 256

[2024-10-18 01:36:52,910][root][INFO] - LoRA Configuration
[2024-10-18 01:36:52,911][root][INFO] - ㄴ r                    : 32
[2024-10-18 01:36:52,911][root][INFO] - ㄴ alpha                : 128
[2024-10-18 01:36:52,911][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 01:36:52,911][root][INFO] - 

[2024-10-18 01:36:52,911][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 01:36:52,911][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-18 01:36:52,911][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-18 01:36:52,911][root][INFO] - * tb interval   : 10000

[2024-10-18 01:36:52,911][root][INFO] - 

[2024-10-18 01:36:52,911][root][INFO] - Start the Training !
[2024-10-18 01:36:52,913][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 01:53:34,154][root][INFO] - Step: 10000/66070  |  Loss: 0.7531  |  Score: 67.21 [%]  |  Seq Length: 256.0
[2024-10-18 02:13:22,062][root][INFO] - Step: 13214/66070  |  Loss: 0.8103  |  Score: 63.81 [%]  |  Seq Length: 256.0
[2024-10-18 02:13:27,033][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 02:13:27,033][root][INFO] - Score: 59.01 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-18 02:13:36,187][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 02:13:36,187][root][INFO] - Score: 58.16 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-18 02:13:36,188][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 02:13:36,189][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 02:37:53,105][root][INFO] - Step: 10000/73665  |  Loss: 0.7567  |  Score: 67.02 [%]  |  Seq Length: 256.0
[2024-10-18 02:55:21,744][root][INFO] - Step: 20000/66070  |  Loss: 1.0251  |  Score: 45.97 [%]  |  Seq Length: 256.0
[2024-10-18 03:06:47,601][root][INFO] - Step: 14733/73665  |  Loss: 0.8287  |  Score: 62.68 [%]  |  Seq Length: 256.0
[2024-10-18 03:06:53,922][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 03:06:53,922][root][INFO] - Score: 57.14 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-18 03:07:05,959][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 03:07:05,959][root][INFO] - Score: 57.83 [%]  |  Evaluation Time: 12.03 [s]
[2024-10-18 03:07:05,960][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 03:07:05,961][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 03:34:52,191][root][INFO] - Step: 26428/66070  |  Loss: 1.1534  |  Score: 33.74 [%]  |  Seq Length: 256.0
[2024-10-18 03:34:57,168][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 03:34:57,168][root][INFO] - Score: 37.70 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-18 03:35:06,330][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 03:35:06,331][root][INFO] - Score: 37.54 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-18 03:35:06,333][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 03:39:17,049][root][INFO] - Step: 20000/73665  |  Loss: 1.0358  |  Score: 44.59 [%]  |  Seq Length: 256.0
[2024-10-18 03:57:05,134][root][INFO] - Step: 30000/66070  |  Loss: 1.1588  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-18 04:37:06,623][root][INFO] - Step: 29466/73665  |  Loss: 1.1741  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-18 04:37:12,941][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 04:37:12,942][root][INFO] - Score: 32.90 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-18 04:37:24,879][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 04:37:24,879][root][INFO] - Score: 32.44 [%]  |  Evaluation Time: 11.94 [s]
[2024-10-18 04:37:24,881][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 04:40:40,875][root][INFO] - Step: 30000/73665  |  Loss: 1.1753  |  Score: 34.07 [%]  |  Seq Length: 256.0
[2024-10-18 04:56:24,980][root][INFO] - Step: 39642/66070  |  Loss: 1.1630  |  Score: 33.48 [%]  |  Seq Length: 256.0
[2024-10-18 04:56:29,961][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 04:56:29,961][root][INFO] - Score: 33.74 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-18 04:56:39,109][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 04:56:39,109][root][INFO] - Score: 32.80 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-18 04:56:39,111][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 04:58:52,760][root][INFO] - Step: 40000/66070  |  Loss: 1.1563  |  Score: 33.51 [%]  |  Seq Length: 256.0
[2024-10-18 05:41:46,227][root][INFO] - Step: 40000/73665  |  Loss: 1.2144  |  Score: 34.02 [%]  |  Seq Length: 256.0
[2024-10-18 06:00:22,894][root][INFO] - Step: 50000/66070  |  Loss: 1.1575  |  Score: 33.48 [%]  |  Seq Length: 256.0
[2024-10-18 06:07:25,521][root][INFO] - Step: 44199/73665  |  Loss: 1.1946  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-18 06:07:31,827][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 06:07:31,827][root][INFO] - Score: 34.82 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-18 06:07:43,836][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 06:07:43,836][root][INFO] - Score: 34.04 [%]  |  Evaluation Time: 12.01 [s]
[2024-10-18 06:07:43,838][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 06:17:56,678][root][INFO] - Step: 52856/66070  |  Loss: 1.1556  |  Score: 33.63 [%]  |  Seq Length: 256.0
[2024-10-18 06:18:01,645][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 06:18:01,646][root][INFO] - Score: 33.85 [%]  |  Evaluation Time: 4.96 [s]
[2024-10-18 06:18:10,777][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 06:18:10,777][root][INFO] - Score: 34.81 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-18 06:18:10,779][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 06:43:10,505][root][INFO] - Step: 50000/73665  |  Loss: 1.1758  |  Score: 33.17 [%]  |  Seq Length: 256.0
[2024-10-18 07:02:08,556][root][INFO] - Step: 60000/66070  |  Loss: 1.1555  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-18 07:37:44,816][root][INFO] - Step: 58932/73665  |  Loss: 1.1660  |  Score: 33.17 [%]  |  Seq Length: 256.0
[2024-10-18 07:37:51,196][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 07:37:51,197][root][INFO] - Score: 32.95 [%]  |  Evaluation Time: 6.38 [s]
[2024-10-18 07:38:03,093][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 07:38:03,094][root][INFO] - Score: 32.12 [%]  |  Evaluation Time: 11.89 [s]
[2024-10-18 07:38:03,096][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 07:39:33,799][root][INFO] - Step: 66070/66070  |  Loss: 1.1555  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-18 07:39:38,763][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 07:39:38,763][root][INFO] - Score: 36.12 [%]  |  Evaluation Time: 4.96 [s]
[2024-10-18 07:39:47,906][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 07:39:47,906][root][INFO] - Score: 34.03 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-18 07:39:47,907][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 07:39:47,907][root][INFO] - - Epoch: 1
[2024-10-18 07:39:47,907][root][INFO] - - DEV score: 59.01 [%]
[2024-10-18 07:39:47,907][root][INFO] - - TEST score: 58.16 [%]
[2024-10-18 07:39:47,909][root][INFO] - Fine-tuning is done!
[2024-10-18 07:39:47,909][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-18 07:39:47,909][root][INFO] - - BEST LR: 0.01
[2024-10-18 07:39:47,909][root][INFO] - - DEV score: 75.13 [%]
[2024-10-18 07:39:47,909][root][INFO] - - TEST score: 75.64 [%]
[2024-10-18 07:39:53,817][root][INFO] - 

[2024-10-18 07:39:53,817][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-18 07:39:53,817][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 07:39:53,817][root][INFO] - 

[2024-10-18 07:39:53,817][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-18 07:41:38,988][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,988][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,989][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,989][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,990][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,990][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,991][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,992][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,992][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,993][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,993][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,994][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,994][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,995][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,995][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,996][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,996][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,997][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,997][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,998][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,998][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,999][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,999][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:39,000][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:39,002][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 07:41:39,007][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-18 07:41:39,208][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 07:41:39,211][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 07:41:39,463][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 07:41:42,658][root][INFO] - 

[2024-10-18 07:41:42,658][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 07:41:42,658][root][INFO] - Data Preprocessing
[2024-10-18 07:41:42,658][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 07:41:42,658][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 07:41:42,659][root][INFO] - ㄴ data_remove                True

[2024-10-18 07:41:42,659][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 07:41:42,666][root][INFO] - vocab size              : 51200
[2024-10-18 07:41:42,666][root][INFO] - device                  : gpu
[2024-10-18 07:41:42,666][root][INFO] - random seed             : 1
[2024-10-18 07:41:42,667][root][INFO] - train data size         : 845696
[2024-10-18 07:41:42,667][root][INFO] - max epochs              : 5
[2024-10-18 07:41:42,667][root][INFO] - total steps             : 66070
[2024-10-18 07:41:42,667][root][INFO] - warmup steps            : 6607
[2024-10-18 07:41:42,667][root][INFO] - batch size              : 64
[2024-10-18 07:41:42,667][root][INFO] - accumulation steps      : 1
[2024-10-18 07:41:42,667][root][INFO] - optimizer               : adamwscale
[2024-10-18 07:41:42,667][root][INFO] - lr_scheduler            : cosine
[2024-10-18 07:41:42,667][root][INFO] - learning rate           : 0.01
[2024-10-18 07:41:42,667][root][INFO] - max length              : 256

[2024-10-18 07:41:42,667][root][INFO] - LoRA Configuration
[2024-10-18 07:41:42,667][root][INFO] - ㄴ r                    : 32
[2024-10-18 07:41:42,668][root][INFO] - ㄴ alpha                : 128
[2024-10-18 07:41:42,668][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 07:41:42,668][root][INFO] - KOMBO Configuration
[2024-10-18 07:41:42,668][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 07:41:42,668][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 07:41:42,668][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 07:41:42,668][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 07:41:42,668][root][INFO] - ㄴ do_combination       : True
[2024-10-18 07:41:42,668][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 07:41:42,669][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 07:41:42,669][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 07:41:42,669][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 07:41:42,669][root][INFO] - 

[2024-10-18 07:41:42,669][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 07:41:42,669][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 07:41:42,669][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 07:41:42,669][root][INFO] - * tb interval   : 10000

[2024-10-18 07:41:42,669][root][INFO] - 

[2024-10-18 07:41:42,669][root][INFO] - Start the Training !
[2024-10-18 07:41:42,672][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 07:44:35,382][root][INFO] - Step: 60000/73665  |  Loss: 1.3883  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-18 08:45:40,485][root][INFO] - Step: 70000/73665  |  Loss: 1.1804  |  Score: 33.40 [%]  |  Seq Length: 256.0
[2024-10-18 09:07:58,702][root][INFO] - Step: 73665/73665  |  Loss: 1.1627  |  Score: 33.49 [%]  |  Seq Length: 256.0
[2024-10-18 09:08:05,059][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 09:08:05,074][root][INFO] - Score: 31.67 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-18 09:08:17,056][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 09:08:17,056][root][INFO] - Score: 32.66 [%]  |  Evaluation Time: 11.98 [s]
[2024-10-18 09:08:17,058][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 09:08:17,058][root][INFO] - - Epoch: 1
[2024-10-18 09:08:17,058][root][INFO] - - DEV score: 57.14 [%]
[2024-10-18 09:08:17,058][root][INFO] - - TEST score: 57.83 [%]
[2024-10-18 09:08:17,061][root][INFO] - Fine-tuning is done!
[2024-10-18 09:08:17,061][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-18 09:08:17,061][root][INFO] - - BEST LR: 0.01
[2024-10-18 09:08:17,061][root][INFO] - - DEV score: 75.90 [%]
[2024-10-18 09:08:17,061][root][INFO] - - TEST score: 76.35 [%]
[2024-10-18 09:08:23,599][root][INFO] - 

[2024-10-18 09:08:23,599][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-18 09:08:23,599][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 09:08:23,599][root][INFO] - 

[2024-10-18 09:08:23,600][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-18 09:09:18,127][root][INFO] - Step: 10000/66070  |  Loss: 0.7222  |  Score: 68.83 [%]  |  Seq Length: 256.0
[2024-10-18 09:10:22,617][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,618][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,618][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,619][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,619][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,619][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,620][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,620][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,621][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,621][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,621][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,622][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,622][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,623][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,623][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,623][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,624][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,624][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,625][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,625][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,626][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,626][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,626][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,627][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,628][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 09:10:22,633][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-18 09:10:22,828][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 09:10:22,830][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 09:10:23,098][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 09:10:26,171][root][INFO] - 

[2024-10-18 09:10:26,171][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 09:10:26,171][root][INFO] - Data Preprocessing
[2024-10-18 09:10:26,171][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 09:10:26,171][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 09:10:26,171][root][INFO] - ㄴ data_remove                False

[2024-10-18 09:10:26,171][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 09:10:26,179][root][INFO] - vocab size              : 51200
[2024-10-18 09:10:26,179][root][INFO] - device                  : gpu
[2024-10-18 09:10:26,179][root][INFO] - random seed             : 1
[2024-10-18 09:10:26,179][root][INFO] - train data size         : 942912
[2024-10-18 09:10:26,180][root][INFO] - max epochs              : 5
[2024-10-18 09:10:26,180][root][INFO] - total steps             : 73665
[2024-10-18 09:10:26,180][root][INFO] - warmup steps            : 7366
[2024-10-18 09:10:26,180][root][INFO] - batch size              : 64
[2024-10-18 09:10:26,180][root][INFO] - accumulation steps      : 1
[2024-10-18 09:10:26,180][root][INFO] - optimizer               : adamwscale
[2024-10-18 09:10:26,180][root][INFO] - lr_scheduler            : cosine
[2024-10-18 09:10:26,180][root][INFO] - learning rate           : 0.01
[2024-10-18 09:10:26,180][root][INFO] - max length              : 256

[2024-10-18 09:10:26,180][root][INFO] - LoRA Configuration
[2024-10-18 09:10:26,180][root][INFO] - ㄴ r                    : 32
[2024-10-18 09:10:26,180][root][INFO] - ㄴ alpha                : 128
[2024-10-18 09:10:26,181][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 09:10:26,181][root][INFO] - KOMBO Configuration
[2024-10-18 09:10:26,181][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 09:10:26,181][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 09:10:26,181][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 09:10:26,181][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 09:10:26,181][root][INFO] - ㄴ do_combination       : True
[2024-10-18 09:10:26,181][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 09:10:26,181][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 09:10:26,181][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 09:10:26,182][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 09:10:26,182][root][INFO] - 

[2024-10-18 09:10:26,182][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 09:10:26,182][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-18 09:10:26,182][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-18 09:10:26,182][root][INFO] - * tb interval   : 10000

[2024-10-18 09:10:26,182][root][INFO] - 

[2024-10-18 09:10:26,182][root][INFO] - Start the Training !
[2024-10-18 09:10:26,186][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 09:34:24,794][root][INFO] - 

[2024-10-18 09:34:24,795][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-18 09:34:24,795][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-18 09:34:24,796][root][INFO] - 

[2024-10-18 09:34:24,796][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-18 09:36:32,413][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,414][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,414][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,414][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,415][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,415][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,416][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,416][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,417][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,417][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,417][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,418][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,418][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,419][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,421][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,422][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,422][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,422][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,423][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,423][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,424][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,424][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,425][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,425][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,427][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 09:36:32,672][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 09:36:34,732][root][INFO] - 

[2024-10-18 09:36:34,732][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 09:36:34,732][root][INFO] - Data Preprocessing
[2024-10-18 09:36:34,732][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-18 09:36:34,733][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 09:36:34,733][root][INFO] - ㄴ data_remove                True

[2024-10-18 09:36:34,733][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 09:36:34,740][root][INFO] - vocab size              : 51200
[2024-10-18 09:36:34,741][root][INFO] - device                  : gpu
[2024-10-18 09:36:34,741][root][INFO] - random seed             : 1
[2024-10-18 09:36:34,741][root][INFO] - train data size         : 806400
[2024-10-18 09:36:34,741][root][INFO] - max epochs              : 5
[2024-10-18 09:36:34,741][root][INFO] - total steps             : 63000
[2024-10-18 09:36:34,741][root][INFO] - warmup steps            : 6300
[2024-10-18 09:36:34,741][root][INFO] - batch size              : 64
[2024-10-18 09:36:34,741][root][INFO] - accumulation steps      : 1
[2024-10-18 09:36:34,741][root][INFO] - optimizer               : adamwscale
[2024-10-18 09:36:34,742][root][INFO] - lr_scheduler            : cosine
[2024-10-18 09:36:34,742][root][INFO] - learning rate           : 0.01
[2024-10-18 09:36:34,742][root][INFO] - max length              : 256

[2024-10-18 09:36:34,742][root][INFO] - LoRA Configuration
[2024-10-18 09:36:34,742][root][INFO] - ㄴ r                    : 32
[2024-10-18 09:36:34,742][root][INFO] - ㄴ alpha                : 128
[2024-10-18 09:36:34,742][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 09:36:34,742][root][INFO] - 

[2024-10-18 09:36:34,742][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-18 09:36:34,742][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 09:36:34,742][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 09:36:34,743][root][INFO] - * tb interval   : 10000

[2024-10-18 09:36:34,743][root][INFO] - 

[2024-10-18 09:36:34,743][root][INFO] - Start the Training !
[2024-10-18 09:36:34,745][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 09:37:32,570][root][INFO] - Step: 13214/66070  |  Loss: 0.6528  |  Score: 72.75 [%]  |  Seq Length: 256.0
[2024-10-18 09:37:40,736][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 09:37:40,736][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 8.16 [s]
[2024-10-18 09:37:55,996][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 09:37:55,996][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 15.26 [s]
[2024-10-18 09:37:55,997][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 09:37:55,998][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 10:37:33,871][root][INFO] - Step: 10000/63000  |  Loss: 0.7208  |  Score: 68.89 [%]  |  Seq Length: 256.0
[2024-10-18 10:38:14,885][root][INFO] - Step: 20000/66070  |  Loss: 0.6243  |  Score: 74.15 [%]  |  Seq Length: 256.0
[2024-10-18 10:38:55,798][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.44 [%]  |  Seq Length: 256.0
[2024-10-18 10:53:26,454][root][INFO] - Step: 12600/63000  |  Loss: 0.6512  |  Score: 72.77 [%]  |  Seq Length: 256.0
[2024-10-18 10:53:30,806][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 10:53:30,806][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-18 10:53:38,691][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 10:53:38,691][root][INFO] - Score: 72.06 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 10:53:38,692][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 10:53:38,693][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 11:21:21,080][root][INFO] - Step: 14733/73665  |  Loss: 0.6592  |  Score: 72.33 [%]  |  Seq Length: 256.0
[2024-10-18 11:21:31,691][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 11:21:31,692][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 10.61 [s]
[2024-10-18 11:21:52,275][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 11:21:52,276][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 20.58 [s]
[2024-10-18 11:21:52,277][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 11:21:52,278][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 11:35:23,702][root][INFO] - Step: 26428/66070  |  Loss: 0.6170  |  Score: 74.49 [%]  |  Seq Length: 256.0
[2024-10-18 11:35:31,887][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 11:35:31,887][root][INFO] - Score: 71.53 [%]  |  Evaluation Time: 8.18 [s]
[2024-10-18 11:35:47,354][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 11:35:47,354][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 15.46 [s]
[2024-10-18 11:35:47,355][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-18 11:35:47,357][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 11:38:51,898][root][INFO] - Step: 20000/63000  |  Loss: 0.6252  |  Score: 74.09 [%]  |  Seq Length: 256.0
[2024-10-18 12:07:33,896][root][INFO] - Step: 30000/66070  |  Loss: 0.5897  |  Score: 75.76 [%]  |  Seq Length: 256.0
[2024-10-18 12:09:01,044][root][INFO] - Step: 20000/73665  |  Loss: 0.6348  |  Score: 73.69 [%]  |  Seq Length: 256.0
[2024-10-18 12:10:37,971][root][INFO] - Step: 25200/63000  |  Loss: 0.6145  |  Score: 74.78 [%]  |  Seq Length: 256.0
[2024-10-18 12:10:42,302][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 12:10:42,303][root][INFO] - Score: 72.02 [%]  |  Evaluation Time: 4.33 [s]
[2024-10-18 12:10:50,181][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 12:10:50,181][root][INFO] - Score: 72.68 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 12:10:50,182][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-18 12:10:50,183][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 12:40:09,692][root][INFO] - Step: 30000/63000  |  Loss: 0.5870  |  Score: 76.00 [%]  |  Seq Length: 256.0
[2024-10-18 13:27:51,951][root][INFO] - Step: 37800/63000  |  Loss: 0.5768  |  Score: 76.42 [%]  |  Seq Length: 256.0
[2024-10-18 13:27:56,272][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 13:27:56,272][root][INFO] - Score: 73.81 [%]  |  Evaluation Time: 4.32 [s]
[2024-10-18 13:28:04,192][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 13:28:04,192][root][INFO] - Score: 74.15 [%]  |  Evaluation Time: 7.92 [s]
[2024-10-18 13:28:04,193][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-18 13:28:04,194][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 13:33:14,871][root][INFO] - Step: 39642/66070  |  Loss: 0.5793  |  Score: 76.31 [%]  |  Seq Length: 256.0
[2024-10-18 13:33:23,068][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 13:33:23,069][root][INFO] - Score: 73.90 [%]  |  Evaluation Time: 8.19 [s]
[2024-10-18 13:33:29,773][root][INFO] - Step: 29466/73665  |  Loss: 0.6277  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-18 13:33:38,630][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 13:33:38,630][root][INFO] - Score: 73.92 [%]  |  Evaluation Time: 15.56 [s]
[2024-10-18 13:33:38,631][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-18 13:33:38,632][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 13:33:40,162][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 13:33:40,162][root][INFO] - Score: 73.23 [%]  |  Evaluation Time: 10.39 [s]
[2024-10-18 13:34:00,523][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 13:34:00,523][root][INFO] - Score: 73.97 [%]  |  Evaluation Time: 20.36 [s]
[2024-10-18 13:34:00,524][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-18 13:34:00,525][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 13:36:50,265][root][INFO] - Step: 40000/66070  |  Loss: 0.5400  |  Score: 78.06 [%]  |  Seq Length: 256.0
[2024-10-18 13:38:48,551][root][INFO] - Step: 30000/73665  |  Loss: 0.5975  |  Score: 75.59 [%]  |  Seq Length: 256.0
[2024-10-18 13:41:32,436][root][INFO] - Step: 40000/63000  |  Loss: 0.5433  |  Score: 78.04 [%]  |  Seq Length: 256.0
[2024-10-18 14:42:41,339][root][INFO] - Step: 50000/63000  |  Loss: 0.5296  |  Score: 78.65 [%]  |  Seq Length: 256.0
[2024-10-18 14:45:07,718][root][INFO] - Step: 50400/63000  |  Loss: 0.5262  |  Score: 78.71 [%]  |  Seq Length: 256.0
[2024-10-18 14:45:12,001][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 14:45:12,001][root][INFO] - Score: 74.05 [%]  |  Evaluation Time: 4.28 [s]
[2024-10-18 14:45:19,882][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 14:45:19,882][root][INFO] - Score: 75.07 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 14:45:19,883][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 14:45:19,884][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 15:05:25,665][root][INFO] - Step: 50000/66070  |  Loss: 0.5357  |  Score: 78.38 [%]  |  Seq Length: 256.0
[2024-10-18 15:08:00,235][root][INFO] - Step: 40000/73665  |  Loss: 0.5971  |  Score: 75.45 [%]  |  Seq Length: 256.0
[2024-10-18 15:30:42,963][root][INFO] - Step: 52856/66070  |  Loss: 0.5238  |  Score: 78.83 [%]  |  Seq Length: 256.0
[2024-10-18 15:30:51,071][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 15:30:51,072][root][INFO] - Score: 74.36 [%]  |  Evaluation Time: 8.11 [s]
[2024-10-18 15:31:06,369][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 15:31:06,369][root][INFO] - Score: 75.31 [%]  |  Evaluation Time: 15.30 [s]
[2024-10-18 15:31:06,370][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 15:31:06,372][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 15:44:04,609][root][INFO] - Step: 60000/63000  |  Loss: 0.4953  |  Score: 80.27 [%]  |  Seq Length: 256.0
[2024-10-18 15:45:21,356][root][INFO] - Step: 44199/73665  |  Loss: 0.5820  |  Score: 76.20 [%]  |  Seq Length: 256.0
[2024-10-18 15:45:31,790][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 15:45:31,790][root][INFO] - Score: 74.93 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-18 15:45:51,949][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 15:45:51,949][root][INFO] - Score: 75.74 [%]  |  Evaluation Time: 20.16 [s]
[2024-10-18 15:45:51,950][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-18 15:45:51,952][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 16:02:23,902][root][INFO] - Step: 63000/63000  |  Loss: 0.4937  |  Score: 80.29 [%]  |  Seq Length: 256.0
[2024-10-18 16:02:28,203][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 16:02:28,203][root][INFO] - Score: 74.72 [%]  |  Evaluation Time: 4.30 [s]
[2024-10-18 16:02:36,088][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 16:02:36,088][root][INFO] - Score: 75.88 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 16:02:36,089][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 16:02:36,089][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 16:02:36,090][root][INFO] - - Epoch: 5
[2024-10-18 16:02:36,090][root][INFO] - - DEV score: 74.72 [%]
[2024-10-18 16:02:36,090][root][INFO] - - TEST score: 75.88 [%]
[2024-10-18 16:02:36,090][root][INFO] - Fine-tuning is done!
[2024-10-18 16:04:12,101][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,102][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,102][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,103][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,103][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,104][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,104][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,105][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,105][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,106][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,107][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,107][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,108][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,108][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,109][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,109][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,110][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,110][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,111][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,112][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,112][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,113][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,113][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,114][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,116][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 16:04:12,117][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 16:04:12,286][root][INFO] - 

[2024-10-18 16:04:12,286][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 16:04:12,286][root][INFO] - Data Preprocessing
[2024-10-18 16:04:12,286][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-18 16:04:12,286][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 16:04:12,286][root][INFO] - ㄴ data_remove                True

[2024-10-18 16:04:12,286][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 16:04:12,297][root][INFO] - vocab size              : 51200
[2024-10-18 16:04:12,298][root][INFO] - device                  : gpu
[2024-10-18 16:04:12,298][root][INFO] - random seed             : 1
[2024-10-18 16:04:12,298][root][INFO] - train data size         : 806400
[2024-10-18 16:04:12,298][root][INFO] - max epochs              : 5
[2024-10-18 16:04:12,298][root][INFO] - total steps             : 63000
[2024-10-18 16:04:12,298][root][INFO] - warmup steps            : 6300
[2024-10-18 16:04:12,299][root][INFO] - batch size              : 64
[2024-10-18 16:04:12,299][root][INFO] - accumulation steps      : 1
[2024-10-18 16:04:12,299][root][INFO] - optimizer               : adamwscale
[2024-10-18 16:04:12,299][root][INFO] - lr_scheduler            : cosine
[2024-10-18 16:04:12,299][root][INFO] - learning rate           : 0.02
[2024-10-18 16:04:12,299][root][INFO] - max length              : 256

[2024-10-18 16:04:12,299][root][INFO] - LoRA Configuration
[2024-10-18 16:04:12,299][root][INFO] - ㄴ r                    : 32
[2024-10-18 16:04:12,299][root][INFO] - ㄴ alpha                : 128
[2024-10-18 16:04:12,299][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 16:04:12,299][root][INFO] - 

[2024-10-18 16:04:12,300][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-18 16:04:12,300][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 16:04:12,300][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 16:04:12,300][root][INFO] - * tb interval   : 10000

[2024-10-18 16:04:12,300][root][INFO] - 

[2024-10-18 16:04:12,300][root][INFO] - Start the Training !
[2024-10-18 16:04:12,302][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 16:34:30,391][root][INFO] - Step: 60000/66070  |  Loss: 0.4965  |  Score: 80.24 [%]  |  Seq Length: 256.0
[2024-10-18 16:37:28,310][root][INFO] - Step: 50000/73665  |  Loss: 0.5498  |  Score: 77.61 [%]  |  Seq Length: 256.0
[2024-10-18 17:05:21,789][root][INFO] - Step: 10000/63000  |  Loss: 0.7534  |  Score: 67.20 [%]  |  Seq Length: 256.0
[2024-10-18 17:21:16,234][root][INFO] - Step: 12600/63000  |  Loss: 0.8022  |  Score: 64.24 [%]  |  Seq Length: 256.0
[2024-10-18 17:21:20,636][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 17:21:20,637][root][INFO] - Score: 61.22 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-18 17:21:28,602][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 17:21:28,602][root][INFO] - Score: 59.99 [%]  |  Evaluation Time: 7.96 [s]
[2024-10-18 17:21:28,603][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 17:21:28,604][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 17:28:12,379][root][INFO] - Step: 66070/66070  |  Loss: 0.4945  |  Score: 80.27 [%]  |  Seq Length: 256.0
[2024-10-18 17:28:20,484][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 17:28:20,484][root][INFO] - Score: 75.53 [%]  |  Evaluation Time: 8.10 [s]
[2024-10-18 17:28:35,792][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 17:28:35,792][root][INFO] - Score: 75.81 [%]  |  Evaluation Time: 15.31 [s]
[2024-10-18 17:28:35,793][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 17:28:35,793][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 17:28:35,793][root][INFO] - - Epoch: 5
[2024-10-18 17:28:35,793][root][INFO] - - DEV score: 75.53 [%]
[2024-10-18 17:28:35,793][root][INFO] - - TEST score: 75.81 [%]
[2024-10-18 17:28:35,794][root][INFO] - Fine-tuning is done!
[2024-10-18 17:30:21,975][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,976][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,977][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,977][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,978][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,978][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,979][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,979][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,980][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,980][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,981][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,981][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,982][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,982][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,982][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,983][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,983][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,984][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,984][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,985][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,986][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,986][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,987][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,987][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,989][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 17:30:22,189][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 17:30:22,191][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 17:30:22,192][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 17:30:22,377][root][INFO] - 

[2024-10-18 17:30:22,378][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 17:30:22,378][root][INFO] - Data Preprocessing
[2024-10-18 17:30:22,378][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 17:30:22,378][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 17:30:22,378][root][INFO] - ㄴ data_remove                True

[2024-10-18 17:30:22,378][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 17:30:22,389][root][INFO] - vocab size              : 51200
[2024-10-18 17:30:22,390][root][INFO] - device                  : gpu
[2024-10-18 17:30:22,390][root][INFO] - random seed             : 1
[2024-10-18 17:30:22,390][root][INFO] - train data size         : 845696
[2024-10-18 17:30:22,390][root][INFO] - max epochs              : 5
[2024-10-18 17:30:22,390][root][INFO] - total steps             : 66070
[2024-10-18 17:30:22,390][root][INFO] - warmup steps            : 6607
[2024-10-18 17:30:22,390][root][INFO] - batch size              : 64
[2024-10-18 17:30:22,390][root][INFO] - accumulation steps      : 1
[2024-10-18 17:30:22,390][root][INFO] - optimizer               : adamwscale
[2024-10-18 17:30:22,391][root][INFO] - lr_scheduler            : cosine
[2024-10-18 17:30:22,391][root][INFO] - learning rate           : 0.02
[2024-10-18 17:30:22,391][root][INFO] - max length              : 256

[2024-10-18 17:30:22,391][root][INFO] - LoRA Configuration
[2024-10-18 17:30:22,391][root][INFO] - ㄴ r                    : 32
[2024-10-18 17:30:22,391][root][INFO] - ㄴ alpha                : 128
[2024-10-18 17:30:22,391][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 17:30:22,391][root][INFO] - KOMBO Configuration
[2024-10-18 17:30:22,391][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 17:30:22,391][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 17:30:22,391][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 17:30:22,392][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 17:30:22,392][root][INFO] - ㄴ do_combination       : True
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 17:30:22,392][root][INFO] - 

[2024-10-18 17:30:22,392][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 17:30:22,392][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 17:30:22,392][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 17:30:22,392][root][INFO] - * tb interval   : 10000

[2024-10-18 17:30:22,393][root][INFO] - 

[2024-10-18 17:30:22,393][root][INFO] - Start the Training !
[2024-10-18 17:30:22,395][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 17:57:15,410][root][INFO] - Step: 58932/73665  |  Loss: 0.5401  |  Score: 78.25 [%]  |  Seq Length: 256.0
[2024-10-18 17:57:25,812][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 17:57:25,812][root][INFO] - Score: 74.43 [%]  |  Evaluation Time: 10.40 [s]
[2024-10-18 17:57:46,136][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 17:57:46,136][root][INFO] - Score: 76.33 [%]  |  Evaluation Time: 20.32 [s]
[2024-10-18 17:57:46,137][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 17:57:46,138][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 18:06:52,816][root][INFO] - Step: 20000/63000  |  Loss: 0.9975  |  Score: 48.04 [%]  |  Seq Length: 256.0
[2024-10-18 18:07:17,563][root][INFO] - Step: 60000/73665  |  Loss: 0.5116  |  Score: 79.42 [%]  |  Seq Length: 256.0
[2024-10-18 18:38:44,573][root][INFO] - Step: 25200/63000  |  Loss: 1.1402  |  Score: 33.54 [%]  |  Seq Length: 256.0
[2024-10-18 18:38:49,088][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 18:38:49,088][root][INFO] - Score: 32.58 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-18 18:38:57,092][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 18:38:57,092][root][INFO] - Score: 31.22 [%]  |  Evaluation Time: 8.00 [s]
[2024-10-18 18:38:57,095][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 18:59:50,105][root][INFO] - Step: 10000/66070  |  Loss: 0.7526  |  Score: 67.26 [%]  |  Seq Length: 256.0
[2024-10-18 19:08:22,209][root][INFO] - Step: 30000/63000  |  Loss: 1.1617  |  Score: 33.20 [%]  |  Seq Length: 256.0
[2024-10-18 19:28:22,968][root][INFO] - Step: 13214/66070  |  Loss: 0.8030  |  Score: 64.31 [%]  |  Seq Length: 256.0
[2024-10-18 19:28:31,444][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 19:28:31,444][root][INFO] - Score: 59.61 [%]  |  Evaluation Time: 8.47 [s]
[2024-10-18 19:28:47,232][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 19:28:47,233][root][INFO] - Score: 59.62 [%]  |  Evaluation Time: 15.79 [s]
[2024-10-18 19:28:47,234][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 19:28:47,235][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 19:36:22,547][root][INFO] - Step: 70000/73665  |  Loss: 0.5054  |  Score: 79.74 [%]  |  Seq Length: 256.0
[2024-10-18 19:56:10,618][root][INFO] - Step: 37800/63000  |  Loss: 1.1919  |  Score: 33.39 [%]  |  Seq Length: 256.0
[2024-10-18 19:56:15,012][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 19:56:15,013][root][INFO] - Score: 34.53 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-18 19:56:23,035][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 19:56:23,035][root][INFO] - Score: 33.24 [%]  |  Evaluation Time: 8.02 [s]
[2024-10-18 19:56:23,037][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 20:09:07,536][root][INFO] - Step: 73665/73665  |  Loss: 0.5026  |  Score: 79.99 [%]  |  Seq Length: 256.0
[2024-10-18 20:09:17,970][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 20:09:17,970][root][INFO] - Score: 74.99 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-18 20:09:38,252][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 20:09:38,252][root][INFO] - Score: 76.27 [%]  |  Evaluation Time: 20.28 [s]
[2024-10-18 20:09:38,253][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 20:09:38,253][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 20:09:38,254][root][INFO] - - Epoch: 5
[2024-10-18 20:09:38,254][root][INFO] - - DEV score: 74.99 [%]
[2024-10-18 20:09:38,254][root][INFO] - - TEST score: 76.27 [%]
[2024-10-18 20:09:38,254][root][INFO] - Fine-tuning is done!
[2024-10-18 20:09:52,211][root][INFO] - Step: 40000/63000  |  Loss: 1.3049  |  Score: 33.71 [%]  |  Seq Length: 256.0
[2024-10-18 20:11:42,975][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,976][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,977][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,977][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,978][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,978][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,979][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,979][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,980][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,980][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,981][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,982][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,982][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,983][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,989][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,989][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,990][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,990][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,991][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,991][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,992][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,993][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,993][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,994][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,996][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 20:11:43,204][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 20:11:43,207][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 20:11:43,208][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 20:11:43,408][root][INFO] - 

[2024-10-18 20:11:43,408][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 20:11:43,408][root][INFO] - Data Preprocessing
[2024-10-18 20:11:43,408][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 20:11:43,409][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 20:11:43,409][root][INFO] - ㄴ data_remove                False

[2024-10-18 20:11:43,409][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 20:11:43,425][root][INFO] - vocab size              : 51200
[2024-10-18 20:11:43,426][root][INFO] - device                  : gpu
[2024-10-18 20:11:43,426][root][INFO] - random seed             : 1
[2024-10-18 20:11:43,427][root][INFO] - train data size         : 942912
[2024-10-18 20:11:43,427][root][INFO] - max epochs              : 5
[2024-10-18 20:11:43,427][root][INFO] - total steps             : 73665
[2024-10-18 20:11:43,427][root][INFO] - warmup steps            : 7366
[2024-10-18 20:11:43,427][root][INFO] - batch size              : 64
[2024-10-18 20:11:43,427][root][INFO] - accumulation steps      : 1
[2024-10-18 20:11:43,427][root][INFO] - optimizer               : adamwscale
[2024-10-18 20:11:43,427][root][INFO] - lr_scheduler            : cosine
[2024-10-18 20:11:43,427][root][INFO] - learning rate           : 0.02
[2024-10-18 20:11:43,427][root][INFO] - max length              : 256

[2024-10-18 20:11:43,427][root][INFO] - LoRA Configuration
[2024-10-18 20:11:43,427][root][INFO] - ㄴ r                    : 32
[2024-10-18 20:11:43,428][root][INFO] - ㄴ alpha                : 128
[2024-10-18 20:11:43,428][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 20:11:43,428][root][INFO] - KOMBO Configuration
[2024-10-18 20:11:43,428][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 20:11:43,428][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 20:11:43,428][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 20:11:43,428][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 20:11:43,428][root][INFO] - ㄴ do_combination       : True
[2024-10-18 20:11:43,428][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 20:11:43,428][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 20:11:43,429][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 20:11:43,429][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 20:11:43,429][root][INFO] - 

[2024-10-18 20:11:43,429][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 20:11:43,429][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-18 20:11:43,429][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-18 20:11:43,429][root][INFO] - * tb interval   : 10000

[2024-10-18 20:11:43,429][root][INFO] - 

[2024-10-18 20:11:43,429][root][INFO] - Start the Training !
[2024-10-18 20:11:43,432][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 20:29:23,128][root][INFO] - Step: 20000/66070  |  Loss: 0.9842  |  Score: 49.33 [%]  |  Seq Length: 256.0
[2024-10-18 21:11:09,152][root][INFO] - Step: 50000/63000  |  Loss: 1.2927  |  Score: 33.24 [%]  |  Seq Length: 256.0
[2024-10-18 21:13:36,203][root][INFO] - Step: 50400/63000  |  Loss: 1.3330  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-18 21:13:40,705][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 21:13:40,705][root][INFO] - Score: 30.60 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-18 21:13:48,759][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 21:13:48,760][root][INFO] - Score: 31.27 [%]  |  Evaluation Time: 8.05 [s]
[2024-10-18 21:13:48,762][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 21:26:08,051][root][INFO] - Step: 26428/66070  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-18 21:26:16,447][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 21:26:16,448][root][INFO] - Score: 34.57 [%]  |  Evaluation Time: 8.39 [s]
[2024-10-18 21:26:32,435][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 21:26:32,435][root][INFO] - Score: 34.86 [%]  |  Evaluation Time: 15.98 [s]
[2024-10-18 21:26:32,437][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 21:41:02,746][root][INFO] - Step: 10000/73665  |  Loss: 0.7559  |  Score: 67.09 [%]  |  Seq Length: 256.0
[2024-10-18 21:57:55,738][root][INFO] - Step: 30000/66070  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-18 22:12:40,327][root][INFO] - Step: 60000/63000  |  Loss: 1.3151  |  Score: 33.36 [%]  |  Seq Length: 256.0
[2024-10-18 22:23:19,333][root][INFO] - Step: 14733/73665  |  Loss: 0.8257  |  Score: 62.91 [%]  |  Seq Length: 256.0
[2024-10-18 22:23:30,019][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 22:23:30,019][root][INFO] - Score: 56.10 [%]  |  Evaluation Time: 10.68 [s]
[2024-10-18 22:23:50,469][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 22:23:50,469][root][INFO] - Score: 56.93 [%]  |  Evaluation Time: 20.45 [s]
[2024-10-18 22:23:50,470][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 22:23:50,471][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 22:31:03,620][root][INFO] - Step: 63000/63000  |  Loss: 1.2929  |  Score: 33.21 [%]  |  Seq Length: 256.0
[2024-10-18 22:31:08,067][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 22:31:08,067][root][INFO] - Score: 31.57 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-18 22:31:16,092][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 22:31:16,092][root][INFO] - Score: 31.13 [%]  |  Evaluation Time: 8.02 [s]
[2024-10-18 22:31:16,093][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 22:31:16,094][root][INFO] - - Epoch: 1
[2024-10-18 22:31:16,094][root][INFO] - - DEV score: 61.22 [%]
[2024-10-18 22:31:16,094][root][INFO] - - TEST score: 59.99 [%]
[2024-10-18 22:31:16,095][root][INFO] - Fine-tuning is done!
[2024-10-18 22:31:16,096][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-18 22:31:16,096][root][INFO] - - BEST LR: 0.01
[2024-10-18 22:31:16,096][root][INFO] - - DEV score: 74.72 [%]
[2024-10-18 22:31:16,096][root][INFO] - - TEST score: 75.88 [%]
[2024-10-18 23:10:53,322][root][INFO] - Step: 20000/73665  |  Loss: 1.0698  |  Score: 41.69 [%]  |  Seq Length: 256.0
[2024-10-18 23:22:56,894][root][INFO] - Step: 39642/66070  |  Loss: nan  |  Score: 33.64 [%]  |  Seq Length: 256.0
[2024-10-18 23:23:05,588][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 23:23:05,588][root][INFO] - Score: 34.91 [%]  |  Evaluation Time: 8.69 [s]
[2024-10-18 23:23:21,572][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 23:23:21,572][root][INFO] - Score: 34.91 [%]  |  Evaluation Time: 15.98 [s]
[2024-10-18 23:23:21,578][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 23:26:32,827][root][INFO] - Step: 40000/66070  |  Loss: nan  |  Score: 34.24 [%]  |  Seq Length: 256.0
[2024-10-19 00:34:39,137][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-19 00:34:49,668][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-19 00:34:49,668][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.53 [s]
[2024-10-19 00:35:09,962][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-19 00:35:09,963][root][INFO] - Score: 33.59 [%]  |  Evaluation Time: 20.29 [s]
[2024-10-19 00:35:09,965][root][INFO] - 
[3/ 5 Epoch]
[2024-10-19 00:39:54,012][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-19 00:54:30,349][root][INFO] - Step: 50000/66070  |  Loss: nan  |  Score: 33.59 [%]  |  Seq Length: 256.0
[2024-10-19 01:19:28,653][root][INFO] - Step: 52856/66070  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-19 01:19:36,943][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-19 01:19:36,944][root][INFO] - Score: 34.97 [%]  |  Evaluation Time: 8.29 [s]
[2024-10-19 01:19:52,445][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-19 01:19:52,446][root][INFO] - Score: 34.86 [%]  |  Evaluation Time: 15.50 [s]
[2024-10-19 01:19:52,448][root][INFO] - 
[5/ 5 Epoch]
[2024-10-19 02:08:05,412][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-19 02:22:42,506][root][INFO] - Step: 60000/66070  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-19 02:45:02,898][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-19 02:45:13,333][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-19 02:45:13,333][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-19 02:45:33,782][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-19 02:45:33,782][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.45 [s]
[2024-10-19 02:45:33,784][root][INFO] - 
[4/ 5 Epoch]
[2024-10-19 03:15:49,993][root][INFO] - Step: 66070/66070  |  Loss: nan  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-19 03:15:58,317][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-19 03:15:58,317][root][INFO] - Score: 34.68 [%]  |  Evaluation Time: 8.32 [s]
[2024-10-19 03:16:13,830][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-19 03:16:13,830][root][INFO] - Score: 34.74 [%]  |  Evaluation Time: 15.51 [s]
[2024-10-19 03:16:13,831][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-19 03:16:13,831][root][INFO] - - Epoch: 1
[2024-10-19 03:16:13,831][root][INFO] - - DEV score: 59.61 [%]
[2024-10-19 03:16:13,831][root][INFO] - - TEST score: 59.62 [%]
[2024-10-19 03:16:13,832][root][INFO] - Fine-tuning is done!
[2024-10-19 03:16:13,833][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-19 03:16:13,833][root][INFO] - - BEST LR: 0.01
[2024-10-19 03:16:13,833][root][INFO] - - DEV score: 75.53 [%]
[2024-10-19 03:16:13,833][root][INFO] - - TEST score: 75.81 [%]
[2024-10-19 03:36:47,095][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-19 04:55:31,987][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-19 04:55:42,464][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-19 04:55:42,464][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.47 [s]
[2024-10-19 04:56:02,923][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-19 04:56:02,923][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.46 [s]
[2024-10-19 04:56:02,925][root][INFO] - 
[5/ 5 Epoch]
[2024-10-19 05:05:20,139][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-19 06:33:16,518][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.26 [%]  |  Seq Length: 256.0
[2024-10-19 07:05:19,028][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.45 [%]  |  Seq Length: 256.0
[2024-10-19 07:05:29,351][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-19 07:05:29,351][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.32 [s]
[2024-10-19 07:05:49,359][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-19 07:05:49,359][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 20.01 [s]
[2024-10-19 07:05:49,360][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-19 07:05:49,360][root][INFO] - - Epoch: 1
[2024-10-19 07:05:49,360][root][INFO] - - DEV score: 56.10 [%]
[2024-10-19 07:05:49,360][root][INFO] - - TEST score: 56.93 [%]
[2024-10-19 07:05:49,361][root][INFO] - Fine-tuning is done!
[2024-10-19 07:05:49,362][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-19 07:05:49,362][root][INFO] - - BEST LR: 0.01
[2024-10-19 07:05:49,362][root][INFO] - - DEV score: 74.99 [%]
[2024-10-19 07:05:49,362][root][INFO] - - TEST score: 76.27 [%]
[2024-10-20 06:19:13,631][root][INFO] - 

[2024-10-20 06:19:13,632][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:19:13,632][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:19:13,632][root][INFO] - 

[2024-10-20 06:19:13,632][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:19:16,496][root][INFO] - 

[2024-10-20 06:19:16,496][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:19:16,496][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-20 06:19:16,496][root][INFO] - 

[2024-10-20 06:19:16,496][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:19:31,428][root][INFO] - 

[2024-10-20 06:19:31,428][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:19:31,428][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:19:31,428][root][INFO] - 

[2024-10-20 06:19:31,428][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:20:06,856][root][INFO] - 

[2024-10-20 06:20:06,856][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:20:06,856][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:20:06,856][root][INFO] - 

[2024-10-20 06:20:06,856][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:20:10,920][root][INFO] - 

[2024-10-20 06:20:10,920][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:20:10,920][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 06:20:10,920][root][INFO] - 

[2024-10-20 06:20:10,920][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:20:29,449][root][INFO] - 

[2024-10-20 06:20:29,449][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:20:29,449][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:20:29,449][root][INFO] - 

[2024-10-20 06:20:29,449][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

