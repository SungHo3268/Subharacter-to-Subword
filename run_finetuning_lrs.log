[2024-10-14 14:41:45,837][root][INFO] - 

[2024-10-14 14:41:45,837][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:41:45,837][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs
[2024-10-14 14:41:45,837][root][INFO] - 

[2024-10-14 14:41:45,837][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:41:52,124][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,125][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,126][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,126][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,128][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,128][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,129][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,129][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,130][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,130][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,131][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,132][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,132][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,133][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,133][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,134][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,134][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,135][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,136][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,136][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,137][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,137][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,138][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:41:52,139][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:41:52,141][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:41:52,153][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:41:52,349][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:41:52,351][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:41:52,526][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:42:12,543][root][INFO] - 

[2024-10-14 14:42:12,544][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:42:12,544][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs
[2024-10-14 14:42:12,544][root][INFO] - 

[2024-10-14 14:42:12,544][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:42:17,212][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,213][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,213][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,213][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,214][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,214][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,215][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,215][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,216][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,216][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,216][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,217][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,217][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,218][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,218][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,218][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,219][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,219][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,220][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,220][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,221][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,221][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,221][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:42:17,222][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:42:17,223][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:42:17,230][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:42:17,430][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:42:17,432][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:42:17,610][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:42:21,919][root][INFO] - 

[2024-10-14 14:42:21,919][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 14:42:21,919][root][INFO] - Data Preprocessing
[2024-10-14 14:42:21,919][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 14:42:21,919][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 14:42:21,919][root][INFO] - ㄴ data_remove                False

[2024-10-14 14:42:21,920][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 14:42:21,929][root][INFO] - vocab size              : 51200
[2024-10-14 14:42:21,929][root][INFO] - device                  : gpu
[2024-10-14 14:42:21,929][root][INFO] - random seed             : 1
[2024-10-14 14:42:21,929][root][INFO] - train data size         : 5760
[2024-10-14 14:42:21,929][root][INFO] - max epochs              : 15
[2024-10-14 14:42:21,929][root][INFO] - total steps             : 1350
[2024-10-14 14:42:21,929][root][INFO] - warmup steps            : 135
[2024-10-14 14:42:21,929][root][INFO] - batch size              : 64
[2024-10-14 14:42:21,929][root][INFO] - accumulation steps      : 1
[2024-10-14 14:42:21,930][root][INFO] - optimizer               : adamwscale
[2024-10-14 14:42:21,930][root][INFO] - lr_scheduler            : cosine
[2024-10-14 14:42:21,930][root][INFO] - learning rate           : 0.01
[2024-10-14 14:42:21,930][root][INFO] - max length              : 256

[2024-10-14 14:42:21,930][root][INFO] - LoRA Configuration
[2024-10-14 14:42:21,930][root][INFO] - ㄴ r                    : 32
[2024-10-14 14:42:21,930][root][INFO] - ㄴ alpha                : 128
[2024-10-14 14:42:21,930][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 14:42:21,930][root][INFO] - KOMBO Configuration
[2024-10-14 14:42:21,930][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 14:42:21,930][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 14:42:21,931][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 14:42:21,931][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 14:42:21,931][root][INFO] - ㄴ do_combination       : True
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 14:42:21,931][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 14:42:21,931][root][INFO] - 

[2024-10-14 14:42:21,931][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs
[2024-10-14 14:42:21,931][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/ckpt
[2024-10-14 14:42:21,932][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks/KorSTS/ko_punc/256t_64b_1s_5e-05lr_1rs/tb
[2024-10-14 14:42:21,932][root][INFO] - * tb interval   : 10000

[2024-10-14 14:42:21,932][root][INFO] - 

[2024-10-14 14:42:21,932][root][INFO] - Start the Training !
[2024-10-14 14:42:21,935][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 14:44:20,042][root][INFO] - 

[2024-10-14 14:44:20,042][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:44:20,042][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:44:20,042][root][INFO] - 

[2024-10-14 14:44:20,042][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:44:24,925][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,926][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,926][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,927][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,927][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,928][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,928][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,929][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,929][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,929][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,930][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,930][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,931][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,931][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,932][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,932][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,933][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,933][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,933][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,934][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,934][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,935][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,935][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:44:24,936][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:44:24,937][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:44:24,941][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:44:25,149][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:44:25,152][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:44:25,316][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:44:28,568][root][INFO] - 

[2024-10-14 14:44:28,569][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 14:44:28,569][root][INFO] - Data Preprocessing
[2024-10-14 14:44:28,569][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 14:44:28,569][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 14:44:28,569][root][INFO] - ㄴ data_remove                False

[2024-10-14 14:44:28,569][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 14:44:28,577][root][INFO] - vocab size              : 51200
[2024-10-14 14:44:28,578][root][INFO] - device                  : gpu
[2024-10-14 14:44:28,578][root][INFO] - random seed             : 1
[2024-10-14 14:44:28,578][root][INFO] - train data size         : 5760
[2024-10-14 14:44:28,578][root][INFO] - max epochs              : 15
[2024-10-14 14:44:28,578][root][INFO] - total steps             : 1350
[2024-10-14 14:44:28,578][root][INFO] - warmup steps            : 135
[2024-10-14 14:44:28,578][root][INFO] - batch size              : 64
[2024-10-14 14:44:28,578][root][INFO] - accumulation steps      : 1
[2024-10-14 14:44:28,578][root][INFO] - optimizer               : adamwscale
[2024-10-14 14:44:28,578][root][INFO] - lr_scheduler            : cosine
[2024-10-14 14:44:28,578][root][INFO] - learning rate           : 0.01
[2024-10-14 14:44:28,579][root][INFO] - max length              : 256

[2024-10-14 14:44:28,579][root][INFO] - LoRA Configuration
[2024-10-14 14:44:28,579][root][INFO] - ㄴ r                    : 32
[2024-10-14 14:44:28,579][root][INFO] - ㄴ alpha                : 128
[2024-10-14 14:44:28,579][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 14:44:28,579][root][INFO] - KOMBO Configuration
[2024-10-14 14:44:28,579][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 14:44:28,579][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 14:44:28,579][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 14:44:28,579][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 14:44:28,580][root][INFO] - ㄴ do_combination       : True
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 14:44:28,580][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 14:44:28,580][root][INFO] - 

[2024-10-14 14:44:28,580][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:44:28,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt
[2024-10-14 14:44:28,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_1rs/tb
[2024-10-14 14:44:28,580][root][INFO] - * tb interval   : 10000

[2024-10-14 14:44:28,580][root][INFO] - 

[2024-10-14 14:44:28,581][root][INFO] - Start the Training !
[2024-10-14 14:44:28,587][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 14:45:13,851][root][INFO] - 

[2024-10-14 14:45:13,851][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:45:13,851][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:45:13,851][root][INFO] - 

[2024-10-14 14:45:13,851][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:45:16,831][root][INFO] - Step: 90/1350  |  Loss: 2.5073  |  Score: 31.28 [%]  |  Seq Length: 256.0
[2024-10-14 14:45:23,037][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 14:45:23,038][root][INFO] - Score: 70.72 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 14:45:28,547][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 14:45:28,547][root][INFO] - Score: 62.83 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 14:45:28,549][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 14:45:28,550][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 14:45:36,423][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,424][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,424][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,425][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,425][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,425][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,426][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,426][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,427][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,427][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,428][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,428][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,429][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,429][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,429][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,430][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,430][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,431][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,431][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,432][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,432][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,432][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,433][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:45:36,433][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:45:36,435][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 14:45:36,439][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:45:36,641][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:45:36,643][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 14:45:36,827][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:45:44,626][root][INFO] - 

[2024-10-14 14:45:44,626][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:45:44,626][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 14:45:44,626][root][INFO] - 

[2024-10-14 14:45:44,627][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:46:02,717][root][INFO] - 

[2024-10-14 14:46:02,717][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:46:02,717][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs
[2024-10-14 14:46:02,717][root][INFO] - 

[2024-10-14 14:46:02,718][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:46:09,303][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,304][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,305][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,305][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,306][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,306][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,307][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,307][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,308][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,308][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,309][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,309][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,310][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,310][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,311][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,311][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,312][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,312][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,313][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,313][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,314][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,315][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,315][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:09,316][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:09,318][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 14:46:09,324][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:46:09,555][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:46:09,558][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 14:46:09,744][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:46:16,986][root][INFO] - Step: 180/1350  |  Loss: 1.2407  |  Score: 64.58 [%]  |  Seq Length: 256.0
[2024-10-14 14:46:18,072][root][INFO] - 

[2024-10-14 14:46:18,072][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:46:18,072][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 14:46:18,072][root][INFO] - 

[2024-10-14 14:46:18,073][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:46:23,270][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 14:46:23,270][root][INFO] - Score: 76.63 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 14:46:28,990][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 14:46:28,991][root][INFO] - Score: 68.81 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 14:46:28,992][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 14:46:28,993][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 14:46:41,295][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,295][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,296][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,296][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,297][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,297][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,298][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,298][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,299][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,299][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,300][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,300][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,301][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,301][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,302][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,302][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,303][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,303][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,304][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,304][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,305][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,305][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,306][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:46:41,306][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:46:41,308][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 14:46:41,312][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:46:41,509][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:46:41,511][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 14:46:41,700][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:47:16,870][root][INFO] - Step: 270/1350  |  Loss: 1.0314  |  Score: 70.38 [%]  |  Seq Length: 256.0
[2024-10-14 14:47:23,051][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 14:47:23,051][root][INFO] - Score: 77.01 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 14:47:28,621][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 14:47:28,621][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 14:47:28,622][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 14:47:28,623][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 14:48:08,263][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,264][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,264][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,265][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,265][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,265][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,266][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,266][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,267][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,267][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,267][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,268][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,268][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,269][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,269][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,269][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,270][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,270][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,271][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,271][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,272][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,272][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,272][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:48:08,273][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:48:08,274][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 14:48:08,279][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:48:08,478][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:48:08,480][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 14:48:08,703][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:48:16,247][root][INFO] - Step: 360/1350  |  Loss: 0.8744  |  Score: 74.83 [%]  |  Seq Length: 256.0
[2024-10-14 14:48:16,773][root][INFO] - 

[2024-10-14 14:48:16,774][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:48:16,774][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 14:48:16,774][root][INFO] - 

[2024-10-14 14:48:16,774][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:48:22,335][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 14:48:22,336][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 14:48:27,902][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 14:48:27,902][root][INFO] - Score: 71.12 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 14:48:27,904][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 14:48:27,905][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 14:49:16,334][root][INFO] - Step: 450/1350  |  Loss: 0.7951  |  Score: 78.43 [%]  |  Seq Length: 256.0
[2024-10-14 14:49:22,501][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 14:49:22,501][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 14:49:28,021][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 14:49:28,021][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 14:49:28,022][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 14:49:28,023][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 14:50:15,967][root][INFO] - Step: 540/1350  |  Loss: 0.6585  |  Score: 81.06 [%]  |  Seq Length: 256.0
[2024-10-14 14:50:19,065][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,066][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,066][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,067][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,067][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,068][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,068][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,068][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,069][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,069][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,070][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,070][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,071][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,071][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,071][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,072][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,072][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,073][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,073][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,073][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,074][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,074][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,075][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:50:19,075][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:50:19,077][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 14:50:19,081][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:50:19,281][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:50:19,283][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 14:50:19,514][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:50:22,177][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 14:50:22,177][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 14:50:27,571][root][INFO] - 

[2024-10-14 14:50:27,571][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:50:27,571][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 14:50:27,571][root][INFO] - 

[2024-10-14 14:50:27,571][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 14:50:27,818][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 14:50:27,818][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 14:50:27,821][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 14:51:15,968][root][INFO] - Step: 630/1350  |  Loss: 0.5899  |  Score: 83.37 [%]  |  Seq Length: 256.0
[2024-10-14 14:51:22,170][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 14:51:22,170][root][INFO] - Score: 79.15 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 14:51:27,719][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 14:51:27,720][root][INFO] - Score: 71.80 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 14:51:27,721][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 14:51:27,722][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 14:52:16,116][root][INFO] - Step: 720/1350  |  Loss: 0.5440  |  Score: 85.10 [%]  |  Seq Length: 256.0
[2024-10-14 14:52:22,269][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 14:52:22,269][root][INFO] - Score: 78.00 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 14:52:27,806][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 14:52:27,806][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 14:52:27,808][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 14:52:31,741][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,742][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,743][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,743][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,744][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,744][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,745][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,745][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,746][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,746][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,747][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,747][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,748][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,748][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,749][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,749][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,750][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,750][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,751][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,751][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,752][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,752][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,753][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:52:31,753][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:52:31,755][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 14:52:31,760][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 14:52:31,962][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:52:31,964][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 14:52:32,207][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:53:15,596][root][INFO] - Step: 810/1350  |  Loss: 0.4735  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 14:53:21,739][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 14:53:21,739][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 14:53:27,210][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 14:53:27,210][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 5.47 [s]
[2024-10-14 14:53:27,213][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 14:54:14,877][root][INFO] - Step: 900/1350  |  Loss: 0.4182  |  Score: 87.59 [%]  |  Seq Length: 256.0
[2024-10-14 14:54:20,926][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 14:54:20,926][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 14:54:26,450][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 14:54:26,451][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 14:54:26,453][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 14:55:14,068][root][INFO] - Step: 990/1350  |  Loss: 0.3806  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-14 14:55:20,210][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 14:55:20,210][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 14:55:25,789][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 14:55:25,789][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 14:55:25,790][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-14 14:55:25,791][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 14:56:13,166][root][INFO] - Step: 1080/1350  |  Loss: 0.3530  |  Score: 89.42 [%]  |  Seq Length: 256.0
[2024-10-14 14:56:19,125][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 14:56:19,125][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 5.96 [s]
[2024-10-14 14:56:24,507][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 14:56:24,507][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 5.38 [s]
[2024-10-14 14:56:24,509][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 14:57:11,887][root][INFO] - Step: 1170/1350  |  Loss: 0.3506  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 14:57:17,814][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 14:57:17,815][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 5.92 [s]
[2024-10-14 14:57:23,242][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 14:57:23,242][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.43 [s]
[2024-10-14 14:57:23,244][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 14:58:10,900][root][INFO] - Step: 1260/1350  |  Loss: 0.3270  |  Score: 90.01 [%]  |  Seq Length: 256.0
[2024-10-14 14:58:16,990][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 14:58:16,991][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 14:58:22,518][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 14:58:22,518][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 14:58:22,521][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 14:59:10,306][root][INFO] - Step: 1350/1350  |  Loss: 0.3227  |  Score: 90.36 [%]  |  Seq Length: 256.0
[2024-10-14 14:59:16,428][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 14:59:16,428][root][INFO] - Score: 79.37 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 14:59:21,994][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 14:59:21,994][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 14:59:21,995][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 14:59:21,995][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 14:59:21,995][root][INFO] - - Epoch: 15
[2024-10-14 14:59:21,995][root][INFO] - - DEV score: 79.37 [%]
[2024-10-14 14:59:21,995][root][INFO] - - TEST score: 72.09 [%]
[2024-10-14 14:59:21,997][root][INFO] - Fine-tuning is done!
[2024-10-14 14:59:22,000][root][INFO] - 

[2024-10-14 14:59:22,000][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 14:59:22,000][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs
[2024-10-14 14:59:22,000][root][INFO] - 

[2024-10-14 14:59:22,000][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 14:59:25,260][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,260][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,261][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,262][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,262][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,263][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,263][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,264][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,265][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,265][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,265][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,266][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,266][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,267][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,267][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,268][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,268][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,269][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,269][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,270][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,270][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,271][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,271][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 14:59:25,272][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 14:59:25,273][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 14:59:25,473][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 14:59:25,476][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 14:59:25,477][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 14:59:25,654][root][INFO] - 

[2024-10-14 14:59:25,654][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 14:59:25,654][root][INFO] - Data Preprocessing
[2024-10-14 14:59:25,654][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 14:59:25,654][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 14:59:25,654][root][INFO] - ㄴ data_remove                False

[2024-10-14 14:59:25,654][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 14:59:25,662][root][INFO] - vocab size              : 51200
[2024-10-14 14:59:25,662][root][INFO] - device                  : gpu
[2024-10-14 14:59:25,662][root][INFO] - random seed             : 1
[2024-10-14 14:59:25,662][root][INFO] - train data size         : 5760
[2024-10-14 14:59:25,662][root][INFO] - max epochs              : 15
[2024-10-14 14:59:25,662][root][INFO] - total steps             : 1350
[2024-10-14 14:59:25,662][root][INFO] - warmup steps            : 135
[2024-10-14 14:59:25,663][root][INFO] - batch size              : 64
[2024-10-14 14:59:25,663][root][INFO] - accumulation steps      : 1
[2024-10-14 14:59:25,663][root][INFO] - optimizer               : adamwscale
[2024-10-14 14:59:25,663][root][INFO] - lr_scheduler            : cosine
[2024-10-14 14:59:25,663][root][INFO] - learning rate           : 0.02
[2024-10-14 14:59:25,663][root][INFO] - max length              : 256

[2024-10-14 14:59:25,663][root][INFO] - LoRA Configuration
[2024-10-14 14:59:25,663][root][INFO] - ㄴ r                    : 32
[2024-10-14 14:59:25,663][root][INFO] - ㄴ alpha                : 128
[2024-10-14 14:59:25,663][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 14:59:25,663][root][INFO] - KOMBO Configuration
[2024-10-14 14:59:25,664][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 14:59:25,664][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 14:59:25,664][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 14:59:25,664][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 14:59:25,664][root][INFO] - ㄴ do_combination       : True
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 14:59:25,664][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 14:59:25,665][root][INFO] - 

[2024-10-14 14:59:25,665][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs
[2024-10-14 14:59:25,665][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/ckpt
[2024-10-14 14:59:25,665][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_1rs/tb
[2024-10-14 14:59:25,665][root][INFO] - * tb interval   : 10000

[2024-10-14 14:59:25,665][root][INFO] - 

[2024-10-14 14:59:25,665][root][INFO] - Start the Training !
[2024-10-14 14:59:25,668][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:00:13,930][root][INFO] - Step: 90/1350  |  Loss: 2.0438  |  Score: 42.57 [%]  |  Seq Length: 256.0
[2024-10-14 15:00:20,126][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:00:20,126][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 15:00:25,680][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:00:25,680][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 15:00:25,682][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:00:25,683][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:01:13,654][root][INFO] - Step: 180/1350  |  Loss: 1.1176  |  Score: 68.59 [%]  |  Seq Length: 256.0
[2024-10-14 15:01:19,830][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:01:19,830][root][INFO] - Score: 76.90 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 15:01:25,406][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:01:25,406][root][INFO] - Score: 71.33 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 15:01:25,408][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:01:25,410][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:02:13,496][root][INFO] - Step: 270/1350  |  Loss: 0.9518  |  Score: 73.80 [%]  |  Seq Length: 256.0
[2024-10-14 15:02:19,664][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:02:19,664][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 15:02:25,204][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:02:25,205][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:02:25,206][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:02:25,207][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:03:13,222][root][INFO] - Step: 360/1350  |  Loss: 0.7880  |  Score: 78.92 [%]  |  Seq Length: 256.0
[2024-10-14 15:03:19,496][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:03:19,497][root][INFO] - Score: 78.09 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 15:03:25,158][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:03:25,159][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-14 15:03:25,163][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:04:13,299][root][INFO] - Step: 450/1350  |  Loss: 0.6588  |  Score: 81.87 [%]  |  Seq Length: 256.0
[2024-10-14 15:04:19,504][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:04:19,505][root][INFO] - Score: 78.11 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 15:04:25,116][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:04:25,116][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 15:04:25,119][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:05:13,102][root][INFO] - Step: 540/1350  |  Loss: 0.5402  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-14 15:05:19,357][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:05:19,358][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 15:05:25,011][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:05:25,011][root][INFO] - Score: 69.96 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 15:05:25,014][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:06:12,983][root][INFO] - Step: 630/1350  |  Loss: 0.4341  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-14 15:06:19,098][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:06:19,099][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:06:24,624][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:06:24,624][root][INFO] - Score: 70.39 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 15:06:24,627][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:07:12,222][root][INFO] - Step: 720/1350  |  Loss: 0.3781  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 15:07:18,370][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:07:18,370][root][INFO] - Score: 79.06 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:07:23,867][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:07:23,867][root][INFO] - Score: 70.59 [%]  |  Evaluation Time: 5.49 [s]
[2024-10-14 15:07:23,869][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:08:11,413][root][INFO] - Step: 810/1350  |  Loss: 0.3292  |  Score: 90.54 [%]  |  Seq Length: 256.0
[2024-10-14 15:08:17,445][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:08:17,445][root][INFO] - Score: 77.71 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-14 15:08:22,946][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:08:22,946][root][INFO] - Score: 70.83 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 15:08:22,950][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:09:10,553][root][INFO] - Step: 900/1350  |  Loss: 0.2628  |  Score: 92.09 [%]  |  Seq Length: 256.0
[2024-10-14 15:09:16,610][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:09:16,610][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 15:09:22,130][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:09:22,130][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 15:09:22,132][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:10:09,718][root][INFO] - Step: 990/1350  |  Loss: 0.2322  |  Score: 93.24 [%]  |  Seq Length: 256.0
[2024-10-14 15:10:15,782][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:10:15,782][root][INFO] - Score: 79.01 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:10:21,214][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:10:21,215][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 5.43 [s]
[2024-10-14 15:10:21,217][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:11:08,775][root][INFO] - Step: 1080/1350  |  Loss: 0.2070  |  Score: 93.90 [%]  |  Seq Length: 256.0
[2024-10-14 15:11:14,822][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:11:14,822][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.04 [s]
[2024-10-14 15:11:20,308][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:11:20,308][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 15:11:20,311][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:12:07,876][root][INFO] - Step: 1170/1350  |  Loss: 0.1930  |  Score: 94.23 [%]  |  Seq Length: 256.0
[2024-10-14 15:12:14,025][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:12:14,026][root][INFO] - Score: 78.67 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 15:12:19,608][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:12:19,608][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 15:12:19,611][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:13:07,435][root][INFO] - Step: 1260/1350  |  Loss: 0.1804  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-14 15:13:13,471][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:13:13,472][root][INFO] - Score: 78.84 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-14 15:13:18,914][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:13:18,914][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 5.44 [s]
[2024-10-14 15:13:18,915][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-14 15:13:18,916][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:14:06,315][root][INFO] - Step: 1350/1350  |  Loss: 0.1678  |  Score: 94.86 [%]  |  Seq Length: 256.0
[2024-10-14 15:14:12,434][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:14:12,435][root][INFO] - Score: 79.30 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 15:14:17,987][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:14:17,987][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 15:14:17,989][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 15:14:17,989][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:14:17,989][root][INFO] - - Epoch: 15
[2024-10-14 15:14:17,989][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 15:14:17,989][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 15:14:17,990][root][INFO] - Fine-tuning is done!
[2024-10-14 15:14:17,990][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 15:14:17,991][root][INFO] - - BEST LR: 0.02
[2024-10-14 15:14:17,991][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 15:14:17,991][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 15:14:24,493][root][INFO] - 

[2024-10-14 15:14:24,493][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:14:24,493][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 15:14:24,493][root][INFO] - 

[2024-10-14 15:14:24,493][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 15:14:28,834][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,835][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,835][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,835][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,836][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,836][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,837][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,837][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,838][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,838][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,838][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,839][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,839][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,840][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,840][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,840][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,841][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,841][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,842][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,842][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,843][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,843][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,844][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:14:28,844][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:14:28,845][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:14:28,849][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 15:14:29,045][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:14:29,047][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:14:29,238][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:14:32,150][root][INFO] - 

[2024-10-14 15:14:32,151][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:14:32,151][root][INFO] - Data Preprocessing
[2024-10-14 15:14:32,151][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:14:32,151][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:14:32,151][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:14:32,151][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:14:32,159][root][INFO] - vocab size              : 51200
[2024-10-14 15:14:32,159][root][INFO] - device                  : gpu
[2024-10-14 15:14:32,159][root][INFO] - random seed             : 2
[2024-10-14 15:14:32,159][root][INFO] - train data size         : 5760
[2024-10-14 15:14:32,159][root][INFO] - max epochs              : 15
[2024-10-14 15:14:32,159][root][INFO] - total steps             : 1350
[2024-10-14 15:14:32,159][root][INFO] - warmup steps            : 135
[2024-10-14 15:14:32,160][root][INFO] - batch size              : 64
[2024-10-14 15:14:32,160][root][INFO] - accumulation steps      : 1
[2024-10-14 15:14:32,160][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:14:32,160][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:14:32,160][root][INFO] - learning rate           : 0.01
[2024-10-14 15:14:32,160][root][INFO] - max length              : 256

[2024-10-14 15:14:32,160][root][INFO] - LoRA Configuration
[2024-10-14 15:14:32,160][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:14:32,160][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:14:32,160][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:14:32,160][root][INFO] - KOMBO Configuration
[2024-10-14 15:14:32,161][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:14:32,161][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:14:32,161][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:14:32,161][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:14:32,161][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:14:32,161][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:14:32,161][root][INFO] - 

[2024-10-14 15:14:32,162][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs
[2024-10-14 15:14:32,162][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/ckpt
[2024-10-14 15:14:32,162][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_2rs/tb
[2024-10-14 15:14:32,162][root][INFO] - * tb interval   : 10000

[2024-10-14 15:14:32,162][root][INFO] - 

[2024-10-14 15:14:32,162][root][INFO] - Start the Training !
[2024-10-14 15:14:32,165][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:15:20,888][root][INFO] - Step: 90/1350  |  Loss: 2.0541  |  Score: 36.26 [%]  |  Seq Length: 256.0
[2024-10-14 15:15:27,098][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:15:27,099][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 15:15:32,995][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:15:32,995][root][INFO] - Score: 60.42 [%]  |  Evaluation Time: 5.89 [s]
[2024-10-14 15:15:32,997][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:15:32,998][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:16:21,089][root][INFO] - Step: 180/1350  |  Loss: 1.3146  |  Score: 64.93 [%]  |  Seq Length: 256.0
[2024-10-14 15:16:27,311][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:16:27,312][root][INFO] - Score: 75.98 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 15:16:32,955][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:16:32,955][root][INFO] - Score: 67.24 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 15:16:32,956][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:16:32,958][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:17:20,611][root][INFO] - Step: 270/1350  |  Loss: 1.0223  |  Score: 70.27 [%]  |  Seq Length: 256.0
[2024-10-14 15:17:26,755][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:17:26,756][root][INFO] - Score: 77.93 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:17:32,308][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:17:32,309][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 15:17:32,309][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:17:32,311][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:18:20,135][root][INFO] - Step: 360/1350  |  Loss: 0.8770  |  Score: 75.04 [%]  |  Seq Length: 256.0
[2024-10-14 15:18:26,280][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:18:26,280][root][INFO] - Score: 77.97 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:18:31,813][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:18:31,813][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:18:31,815][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:19:19,383][root][INFO] - Step: 450/1350  |  Loss: 0.7471  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-14 15:19:25,450][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:19:25,450][root][INFO] - Score: 79.34 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:19:30,924][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:19:30,924][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 5.47 [s]
[2024-10-14 15:19:30,925][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 15:19:30,926][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:20:18,902][root][INFO] - Step: 540/1350  |  Loss: 0.6158  |  Score: 82.27 [%]  |  Seq Length: 256.0
[2024-10-14 15:20:24,988][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:20:24,988][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-14 15:20:30,503][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:20:30,503][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:20:30,505][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:21:18,313][root][INFO] - Step: 630/1350  |  Loss: 0.5640  |  Score: 83.65 [%]  |  Seq Length: 256.0
[2024-10-14 15:21:24,401][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:21:24,401][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-14 15:21:29,898][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:21:29,898][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 15:21:29,900][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:22:17,681][root][INFO] - Step: 720/1350  |  Loss: 0.5180  |  Score: 85.66 [%]  |  Seq Length: 256.0
[2024-10-14 15:22:23,781][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:22:23,781][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:22:29,314][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:22:29,315][root][INFO] - Score: 71.89 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:22:29,317][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:23:17,125][root][INFO] - Step: 810/1350  |  Loss: 0.4363  |  Score: 87.48 [%]  |  Seq Length: 256.0
[2024-10-14 15:23:23,192][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:23:23,192][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:23:28,716][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:23:28,716][root][INFO] - Score: 71.63 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 15:23:28,718][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:24:16,527][root][INFO] - Step: 900/1350  |  Loss: 0.3983  |  Score: 88.50 [%]  |  Seq Length: 256.0
[2024-10-14 15:24:22,688][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:24:22,688][root][INFO] - Score: 78.40 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 15:24:28,252][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:24:28,252][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 15:24:28,254][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:25:16,103][root][INFO] - Step: 990/1350  |  Loss: 0.3682  |  Score: 89.09 [%]  |  Seq Length: 256.0
[2024-10-14 15:25:22,288][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:25:22,288][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 15:25:27,747][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:25:27,747][root][INFO] - Score: 70.98 [%]  |  Evaluation Time: 5.46 [s]
[2024-10-14 15:25:27,749][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:26:15,445][root][INFO] - Step: 1080/1350  |  Loss: 0.3299  |  Score: 90.28 [%]  |  Seq Length: 256.0
[2024-10-14 15:26:21,543][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:26:21,543][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:26:27,057][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:26:27,057][root][INFO] - Score: 71.50 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:26:27,059][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:27:14,572][root][INFO] - Step: 1170/1350  |  Loss: 0.3276  |  Score: 90.29 [%]  |  Seq Length: 256.0
[2024-10-14 15:27:20,707][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:27:20,707][root][INFO] - Score: 78.51 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 15:27:26,274][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:27:26,275][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 15:27:26,277][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:28:14,150][root][INFO] - Step: 1260/1350  |  Loss: 0.3079  |  Score: 90.56 [%]  |  Seq Length: 256.0
[2024-10-14 15:28:20,273][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:28:20,274][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 15:28:25,906][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:28:25,906][root][INFO] - Score: 71.46 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 15:28:25,908][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:29:13,568][root][INFO] - Step: 1350/1350  |  Loss: 0.3049  |  Score: 90.66 [%]  |  Seq Length: 256.0
[2024-10-14 15:29:19,710][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:29:19,710][root][INFO] - Score: 78.18 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:29:25,392][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:29:25,392][root][INFO] - Score: 71.20 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:29:25,393][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:29:25,393][root][INFO] - - Epoch: 5
[2024-10-14 15:29:25,393][root][INFO] - - DEV score: 79.34 [%]
[2024-10-14 15:29:25,393][root][INFO] - - TEST score: 71.45 [%]
[2024-10-14 15:29:25,394][root][INFO] - Fine-tuning is done!
[2024-10-14 15:29:25,398][root][INFO] - 

[2024-10-14 15:29:25,399][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:29:25,399][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs
[2024-10-14 15:29:25,399][root][INFO] - 

[2024-10-14 15:29:25,399][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 15:29:28,650][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,650][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,651][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,652][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,652][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,653][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,653][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,654][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,654][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,655][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,655][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,656][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,656][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,657][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,658][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,658][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,665][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,666][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,666][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,667][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,667][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,668][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,669][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:29:28,669][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:29:28,672][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:29:28,885][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:29:28,888][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:29:28,889][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:29:29,075][root][INFO] - 

[2024-10-14 15:29:29,075][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:29:29,075][root][INFO] - Data Preprocessing
[2024-10-14 15:29:29,075][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:29:29,076][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:29:29,076][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:29:29,076][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:29:29,083][root][INFO] - vocab size              : 51200
[2024-10-14 15:29:29,083][root][INFO] - device                  : gpu
[2024-10-14 15:29:29,084][root][INFO] - random seed             : 2
[2024-10-14 15:29:29,084][root][INFO] - train data size         : 5760
[2024-10-14 15:29:29,084][root][INFO] - max epochs              : 15
[2024-10-14 15:29:29,084][root][INFO] - total steps             : 1350
[2024-10-14 15:29:29,084][root][INFO] - warmup steps            : 135
[2024-10-14 15:29:29,084][root][INFO] - batch size              : 64
[2024-10-14 15:29:29,084][root][INFO] - accumulation steps      : 1
[2024-10-14 15:29:29,084][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:29:29,084][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:29:29,084][root][INFO] - learning rate           : 0.02
[2024-10-14 15:29:29,084][root][INFO] - max length              : 256

[2024-10-14 15:29:29,085][root][INFO] - LoRA Configuration
[2024-10-14 15:29:29,085][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:29:29,085][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:29:29,085][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:29:29,085][root][INFO] - KOMBO Configuration
[2024-10-14 15:29:29,085][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:29:29,085][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:29:29,085][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:29:29,085][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:29:29,085][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:29:29,086][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:29:29,086][root][INFO] - 

[2024-10-14 15:29:29,086][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs
[2024-10-14 15:29:29,086][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/ckpt
[2024-10-14 15:29:29,086][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_2rs/tb
[2024-10-14 15:29:29,086][root][INFO] - * tb interval   : 10000

[2024-10-14 15:29:29,086][root][INFO] - 

[2024-10-14 15:29:29,087][root][INFO] - Start the Training !
[2024-10-14 15:29:29,089][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:30:16,597][root][INFO] - Step: 90/1350  |  Loss: 1.8191  |  Score: 45.29 [%]  |  Seq Length: 256.0
[2024-10-14 15:30:22,666][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:30:22,666][root][INFO] - Score: 74.54 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 15:30:28,165][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:30:28,165][root][INFO] - Score: 64.35 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 15:30:28,166][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:30:28,167][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:31:15,657][root][INFO] - Step: 180/1350  |  Loss: 1.1164  |  Score: 67.84 [%]  |  Seq Length: 256.0
[2024-10-14 15:31:21,721][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:31:21,721][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 15:31:27,306][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:31:27,306][root][INFO] - Score: 67.89 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 15:31:27,307][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:31:27,308][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:32:14,894][root][INFO] - Step: 270/1350  |  Loss: 0.9153  |  Score: 74.49 [%]  |  Seq Length: 256.0
[2024-10-14 15:32:21,066][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:32:21,067][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 15:32:26,692][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:32:26,693][root][INFO] - Score: 70.82 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 15:32:26,694][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:32:26,695][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:33:14,479][root][INFO] - Step: 360/1350  |  Loss: 0.7498  |  Score: 79.16 [%]  |  Seq Length: 256.0
[2024-10-14 15:33:20,592][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:33:20,593][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:33:26,223][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:33:26,223][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 15:33:26,225][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:34:14,126][root][INFO] - Step: 450/1350  |  Loss: 0.6405  |  Score: 82.18 [%]  |  Seq Length: 256.0
[2024-10-14 15:34:20,354][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:34:20,355][root][INFO] - Score: 78.36 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 15:34:26,034][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:34:26,034][root][INFO] - Score: 69.69 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:34:26,036][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:35:13,661][root][INFO] - Step: 540/1350  |  Loss: 0.5123  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 15:35:19,778][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:35:19,778][root][INFO] - Score: 76.26 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:35:25,311][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:35:25,311][root][INFO] - Score: 69.61 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:35:25,313][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:36:13,087][root][INFO] - Step: 630/1350  |  Loss: 0.4074  |  Score: 88.00 [%]  |  Seq Length: 256.0
[2024-10-14 15:36:19,323][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:36:19,324][root][INFO] - Score: 77.46 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 15:36:25,009][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:36:25,009][root][INFO] - Score: 69.58 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:36:25,012][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:37:12,680][root][INFO] - Step: 720/1350  |  Loss: 0.3572  |  Score: 89.95 [%]  |  Seq Length: 256.0
[2024-10-14 15:37:18,838][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:37:18,838][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 15:37:24,352][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:37:24,352][root][INFO] - Score: 70.79 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:37:24,354][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:38:12,132][root][INFO] - Step: 810/1350  |  Loss: 0.2877  |  Score: 91.92 [%]  |  Seq Length: 256.0
[2024-10-14 15:38:18,334][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:38:18,335][root][INFO] - Score: 77.69 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 15:38:23,878][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:38:23,878][root][INFO] - Score: 70.37 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:38:23,880][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:39:11,502][root][INFO] - Step: 900/1350  |  Loss: 0.2515  |  Score: 92.90 [%]  |  Seq Length: 256.0
[2024-10-14 15:39:17,550][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:39:17,550][root][INFO] - Score: 77.30 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 15:39:23,028][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:39:23,028][root][INFO] - Score: 69.35 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 15:39:23,030][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:40:10,702][root][INFO] - Step: 990/1350  |  Loss: 0.2210  |  Score: 93.44 [%]  |  Seq Length: 256.0
[2024-10-14 15:40:16,921][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:40:16,921][root][INFO] - Score: 78.83 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 15:40:22,596][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:40:22,596][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 15:40:22,598][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:41:10,189][root][INFO] - Step: 1080/1350  |  Loss: 0.1857  |  Score: 94.43 [%]  |  Seq Length: 256.0
[2024-10-14 15:41:16,329][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:41:16,329][root][INFO] - Score: 78.58 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 15:41:21,897][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:41:21,898][root][INFO] - Score: 69.91 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 15:41:21,900][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:42:09,673][root][INFO] - Step: 1170/1350  |  Loss: 0.1870  |  Score: 94.50 [%]  |  Seq Length: 256.0
[2024-10-14 15:42:15,893][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:42:15,894][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 15:42:21,580][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:42:21,580][root][INFO] - Score: 69.71 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 15:42:21,582][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:43:09,330][root][INFO] - Step: 1260/1350  |  Loss: 0.1734  |  Score: 94.72 [%]  |  Seq Length: 256.0
[2024-10-14 15:43:15,400][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:43:15,400][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 15:43:20,933][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:43:20,934][root][INFO] - Score: 69.90 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:43:20,936][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:44:08,507][root][INFO] - Step: 1350/1350  |  Loss: 0.1596  |  Score: 95.08 [%]  |  Seq Length: 256.0
[2024-10-14 15:44:14,756][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:44:14,757][root][INFO] - Score: 78.07 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 15:44:20,358][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:44:20,358][root][INFO] - Score: 69.29 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 15:44:20,359][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:44:20,359][root][INFO] - - Epoch: 3
[2024-10-14 15:44:20,360][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 15:44:20,360][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 15:44:20,361][root][INFO] - Fine-tuning is done!
[2024-10-14 15:44:20,361][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 15:44:20,361][root][INFO] - - BEST LR: 0.02
[2024-10-14 15:44:20,361][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 15:44:20,361][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 15:44:26,910][root][INFO] - 

[2024-10-14 15:44:26,911][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:44:26,911][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 15:44:26,911][root][INFO] - 

[2024-10-14 15:44:26,911][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 15:44:31,424][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,424][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,425][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,425][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,425][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,426][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,426][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,427][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,427][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,428][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,428][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,429][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,429][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,430][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,430][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,430][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,431][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,431][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,432][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,432][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,433][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,433][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,434][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:44:31,434][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:44:31,436][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:44:31,439][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 15:44:31,634][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:44:31,636][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:44:31,820][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:44:34,930][root][INFO] - 

[2024-10-14 15:44:34,931][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:44:34,931][root][INFO] - Data Preprocessing
[2024-10-14 15:44:34,931][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:44:34,931][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:44:34,931][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:44:34,931][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:44:34,941][root][INFO] - vocab size              : 51200
[2024-10-14 15:44:34,941][root][INFO] - device                  : gpu
[2024-10-14 15:44:34,941][root][INFO] - random seed             : 3
[2024-10-14 15:44:34,941][root][INFO] - train data size         : 5760
[2024-10-14 15:44:34,941][root][INFO] - max epochs              : 15
[2024-10-14 15:44:34,941][root][INFO] - total steps             : 1350
[2024-10-14 15:44:34,942][root][INFO] - warmup steps            : 135
[2024-10-14 15:44:34,942][root][INFO] - batch size              : 64
[2024-10-14 15:44:34,942][root][INFO] - accumulation steps      : 1
[2024-10-14 15:44:34,942][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:44:34,942][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:44:34,942][root][INFO] - learning rate           : 0.01
[2024-10-14 15:44:34,942][root][INFO] - max length              : 256

[2024-10-14 15:44:34,942][root][INFO] - LoRA Configuration
[2024-10-14 15:44:34,942][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:44:34,942][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:44:34,942][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:44:34,942][root][INFO] - KOMBO Configuration
[2024-10-14 15:44:34,943][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:44:34,943][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:44:34,943][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:44:34,943][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:44:34,943][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:44:34,943][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:44:34,944][root][INFO] - 

[2024-10-14 15:44:34,944][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs
[2024-10-14 15:44:34,944][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/ckpt
[2024-10-14 15:44:34,944][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.01lr_3rs/tb
[2024-10-14 15:44:34,944][root][INFO] - * tb interval   : 10000

[2024-10-14 15:44:34,944][root][INFO] - 

[2024-10-14 15:44:34,944][root][INFO] - Start the Training !
[2024-10-14 15:44:34,947][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 15:45:23,124][root][INFO] - Step: 90/1350  |  Loss: 2.2949  |  Score: 31.76 [%]  |  Seq Length: 256.0
[2024-10-14 15:45:29,388][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 15:45:29,388][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 15:45:34,999][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 15:45:34,999][root][INFO] - Score: 62.43 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 15:45:35,000][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 15:45:35,001][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 15:46:22,683][root][INFO] - Step: 180/1350  |  Loss: 1.1927  |  Score: 65.08 [%]  |  Seq Length: 256.0
[2024-10-14 15:46:28,882][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 15:46:28,882][root][INFO] - Score: 76.18 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 15:46:34,551][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 15:46:34,551][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 15:46:34,553][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 15:46:34,554][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 15:47:22,099][root][INFO] - Step: 270/1350  |  Loss: 1.0312  |  Score: 70.51 [%]  |  Seq Length: 256.0
[2024-10-14 15:47:28,206][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 15:47:28,206][root][INFO] - Score: 77.05 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:47:33,803][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 15:47:33,804][root][INFO] - Score: 68.79 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 15:47:33,804][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 15:47:33,806][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 15:48:21,550][root][INFO] - Step: 360/1350  |  Loss: 0.9194  |  Score: 74.60 [%]  |  Seq Length: 256.0
[2024-10-14 15:48:27,811][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 15:48:27,811][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 15:48:33,465][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 15:48:33,465][root][INFO] - Score: 71.35 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 15:48:33,467][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 15:48:33,468][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 15:49:21,489][root][INFO] - Step: 450/1350  |  Loss: 0.7997  |  Score: 77.85 [%]  |  Seq Length: 256.0
[2024-10-14 15:49:27,582][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 15:49:27,583][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 15:49:33,128][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 15:49:33,128][root][INFO] - Score: 71.53 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:49:33,130][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 15:49:33,131][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 15:50:20,308][root][INFO] - Step: 540/1350  |  Loss: 0.6629  |  Score: 80.50 [%]  |  Seq Length: 256.0
[2024-10-14 15:50:26,400][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 15:50:26,400][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 15:50:31,960][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 15:50:31,960][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 15:50:31,961][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 15:50:31,962][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 15:51:19,620][root][INFO] - Step: 630/1350  |  Loss: 0.6011  |  Score: 83.08 [%]  |  Seq Length: 256.0
[2024-10-14 15:51:25,803][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 15:51:25,804][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 15:51:31,297][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 15:51:31,297][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.49 [s]
[2024-10-14 15:51:31,298][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 15:51:31,299][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 15:52:18,834][root][INFO] - Step: 720/1350  |  Loss: 0.5142  |  Score: 84.76 [%]  |  Seq Length: 256.0
[2024-10-14 15:52:24,935][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 15:52:24,935][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 15:52:30,450][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 15:52:30,450][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:52:30,451][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-14 15:52:30,453][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 15:53:18,134][root][INFO] - Step: 810/1350  |  Loss: 0.4585  |  Score: 86.44 [%]  |  Seq Length: 256.0
[2024-10-14 15:53:24,329][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 15:53:24,329][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 15:53:29,875][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 15:53:29,875][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:53:29,878][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 15:54:17,424][root][INFO] - Step: 900/1350  |  Loss: 0.4325  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-14 15:54:23,460][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 15:54:23,460][root][INFO] - Score: 78.37 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-14 15:54:28,947][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 15:54:28,947][root][INFO] - Score: 71.26 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 15:54:28,949][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 15:55:16,679][root][INFO] - Step: 990/1350  |  Loss: 0.3816  |  Score: 88.82 [%]  |  Seq Length: 256.0
[2024-10-14 15:55:22,800][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 15:55:22,800][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 15:55:28,392][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 15:55:28,392][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-14 15:55:28,394][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 15:56:16,094][root][INFO] - Step: 1080/1350  |  Loss: 0.3515  |  Score: 89.60 [%]  |  Seq Length: 256.0
[2024-10-14 15:56:22,203][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 15:56:22,203][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 15:56:27,716][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 15:56:27,716][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 15:56:27,718][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 15:57:15,704][root][INFO] - Step: 1170/1350  |  Loss: 0.3390  |  Score: 89.75 [%]  |  Seq Length: 256.0
[2024-10-14 15:57:21,883][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 15:57:21,883][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 15:57:27,420][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 15:57:27,420][root][INFO] - Score: 71.90 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:57:27,422][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 15:58:15,168][root][INFO] - Step: 1260/1350  |  Loss: 0.3323  |  Score: 89.91 [%]  |  Seq Length: 256.0
[2024-10-14 15:58:21,485][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 15:58:21,486][root][INFO] - Score: 78.93 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 15:58:27,024][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 15:58:27,025][root][INFO] - Score: 70.96 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 15:58:27,027][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 15:59:14,330][root][INFO] - Step: 1350/1350  |  Loss: 0.3222  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-14 15:59:20,404][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 15:59:20,404][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 15:59:25,937][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 15:59:25,937][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 15:59:25,938][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 15:59:25,938][root][INFO] - - Epoch: 8
[2024-10-14 15:59:25,938][root][INFO] - - DEV score: 79.59 [%]
[2024-10-14 15:59:25,938][root][INFO] - - TEST score: 72.16 [%]
[2024-10-14 15:59:25,939][root][INFO] - Fine-tuning is done!
[2024-10-14 15:59:25,943][root][INFO] - 

[2024-10-14 15:59:25,943][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 15:59:25,943][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs
[2024-10-14 15:59:25,943][root][INFO] - 

[2024-10-14 15:59:25,944][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 15:59:29,371][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,371][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,372][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,372][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,373][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,374][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,375][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,375][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,376][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,376][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,377][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,377][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,378][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,378][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,379][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,379][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,380][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,380][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,381][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,381][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,382][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,383][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,383][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 15:59:29,384][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 15:59:29,386][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 15:59:29,593][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 15:59:29,595][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 15:59:29,597][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 15:59:29,707][root][INFO] - 

[2024-10-14 15:59:29,707][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 15:59:29,708][root][INFO] - Data Preprocessing
[2024-10-14 15:59:29,708][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 15:59:29,708][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 15:59:29,708][root][INFO] - ㄴ data_remove                False

[2024-10-14 15:59:29,708][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 15:59:29,715][root][INFO] - vocab size              : 51200
[2024-10-14 15:59:29,715][root][INFO] - device                  : gpu
[2024-10-14 15:59:29,715][root][INFO] - random seed             : 3
[2024-10-14 15:59:29,715][root][INFO] - train data size         : 5760
[2024-10-14 15:59:29,716][root][INFO] - max epochs              : 15
[2024-10-14 15:59:29,716][root][INFO] - total steps             : 1350
[2024-10-14 15:59:29,716][root][INFO] - warmup steps            : 135
[2024-10-14 15:59:29,716][root][INFO] - batch size              : 64
[2024-10-14 15:59:29,716][root][INFO] - accumulation steps      : 1
[2024-10-14 15:59:29,716][root][INFO] - optimizer               : adamwscale
[2024-10-14 15:59:29,716][root][INFO] - lr_scheduler            : cosine
[2024-10-14 15:59:29,716][root][INFO] - learning rate           : 0.02
[2024-10-14 15:59:29,716][root][INFO] - max length              : 256

[2024-10-14 15:59:29,716][root][INFO] - LoRA Configuration
[2024-10-14 15:59:29,716][root][INFO] - ㄴ r                    : 32
[2024-10-14 15:59:29,716][root][INFO] - ㄴ alpha                : 128
[2024-10-14 15:59:29,717][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 15:59:29,717][root][INFO] - KOMBO Configuration
[2024-10-14 15:59:29,717][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 15:59:29,717][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 15:59:29,717][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 15:59:29,717][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 15:59:29,717][root][INFO] - ㄴ do_combination       : True
[2024-10-14 15:59:29,717][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 15:59:29,717][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 15:59:29,718][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 15:59:29,718][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 15:59:29,718][root][INFO] - 

[2024-10-14 15:59:29,718][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs
[2024-10-14 15:59:29,718][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/ckpt
[2024-10-14 15:59:29,718][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_0.02lr_3rs/tb
[2024-10-14 15:59:29,718][root][INFO] - * tb interval   : 10000

[2024-10-14 15:59:29,718][root][INFO] - 

[2024-10-14 15:59:29,718][root][INFO] - Start the Training !
[2024-10-14 15:59:29,720][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 16:00:17,492][root][INFO] - Step: 90/1350  |  Loss: 2.0019  |  Score: 41.72 [%]  |  Seq Length: 256.0
[2024-10-14 16:00:23,678][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 16:00:23,678][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 16:00:29,192][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 16:00:29,193][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 16:00:29,193][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 16:00:29,194][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 16:01:16,870][root][INFO] - Step: 180/1350  |  Loss: 1.1405  |  Score: 67.73 [%]  |  Seq Length: 256.0
[2024-10-14 16:01:22,975][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 16:01:22,976][root][INFO] - Score: 77.70 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 16:01:28,555][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 16:01:28,555][root][INFO] - Score: 69.25 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 16:01:28,556][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 16:01:28,557][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 16:02:16,249][root][INFO] - Step: 270/1350  |  Loss: 0.9414  |  Score: 73.77 [%]  |  Seq Length: 256.0
[2024-10-14 16:02:22,460][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 16:02:22,460][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 16:02:28,073][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 16:02:28,073][root][INFO] - Score: 70.45 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 16:02:28,074][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 16:02:28,076][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 16:03:15,605][root][INFO] - Step: 360/1350  |  Loss: 0.7943  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-14 16:03:21,702][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 16:03:21,702][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-14 16:03:27,229][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 16:03:27,229][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 16:03:27,231][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 16:04:14,604][root][INFO] - Step: 450/1350  |  Loss: 0.6279  |  Score: 82.66 [%]  |  Seq Length: 256.0
[2024-10-14 16:04:20,805][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 16:04:20,805][root][INFO] - Score: 76.10 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 16:04:26,389][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 16:04:26,389][root][INFO] - Score: 69.41 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 16:04:26,391][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 16:05:13,949][root][INFO] - Step: 540/1350  |  Loss: 0.5174  |  Score: 85.44 [%]  |  Seq Length: 256.0
[2024-10-14 16:05:20,115][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 16:05:20,115][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 16:05:25,684][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 16:05:25,684][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 16:05:25,686][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 16:06:13,102][root][INFO] - Step: 630/1350  |  Loss: 0.4309  |  Score: 87.86 [%]  |  Seq Length: 256.0
[2024-10-14 16:06:19,239][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 16:06:19,240][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 16:06:24,803][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 16:06:24,803][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 16:06:24,804][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 16:06:24,805][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 16:07:12,515][root][INFO] - Step: 720/1350  |  Loss: 0.3530  |  Score: 89.82 [%]  |  Seq Length: 256.0
[2024-10-14 16:07:18,703][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 16:07:18,703][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 16:07:24,313][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 16:07:24,313][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 16:07:24,315][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 16:08:11,779][root][INFO] - Step: 810/1350  |  Loss: 0.3051  |  Score: 91.04 [%]  |  Seq Length: 256.0
[2024-10-14 16:08:17,865][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 16:08:17,866][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-14 16:08:23,423][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 16:08:23,423][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 16:08:23,425][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 16:09:10,786][root][INFO] - Step: 900/1350  |  Loss: 0.2657  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 16:09:16,991][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 16:09:16,991][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 16:09:22,600][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 16:09:22,601][root][INFO] - Score: 70.10 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 16:09:22,603][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 16:10:10,337][root][INFO] - Step: 990/1350  |  Loss: 0.2278  |  Score: 93.40 [%]  |  Seq Length: 256.0
[2024-10-14 16:10:16,515][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 16:10:16,516][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 16:10:22,065][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 16:10:22,065][root][INFO] - Score: 70.20 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 16:10:22,067][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 16:11:09,797][root][INFO] - Step: 1080/1350  |  Loss: 0.1936  |  Score: 94.11 [%]  |  Seq Length: 256.0
[2024-10-14 16:11:15,945][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 16:11:15,945][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 16:11:21,540][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 16:11:21,540][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-14 16:11:21,542][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 16:12:09,267][root][INFO] - Step: 1170/1350  |  Loss: 0.1861  |  Score: 94.22 [%]  |  Seq Length: 256.0
[2024-10-14 16:12:15,412][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 16:12:15,412][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 16:12:20,929][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 16:12:20,929][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 16:12:20,931][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 16:13:08,587][root][INFO] - Step: 1260/1350  |  Loss: 0.1743  |  Score: 94.73 [%]  |  Seq Length: 256.0
[2024-10-14 16:13:14,871][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 16:13:14,872][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 16:13:20,525][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 16:13:20,525][root][INFO] - Score: 70.50 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 16:13:20,527][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 16:14:08,616][root][INFO] - Step: 1350/1350  |  Loss: 0.1664  |  Score: 95.00 [%]  |  Seq Length: 256.0
[2024-10-14 16:14:14,913][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 16:14:14,914][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 16:14:20,566][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 16:14:20,566][root][INFO] - Score: 70.95 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 16:14:20,567][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 16:14:20,568][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 16:14:20,568][root][INFO] - - Epoch: 15
[2024-10-14 16:14:20,568][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 16:14:20,568][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 16:14:20,569][root][INFO] - Fine-tuning is done!
[2024-10-14 16:14:20,569][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 16:14:20,569][root][INFO] - - BEST LR: 0.02
[2024-10-14 16:14:20,570][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 16:14:20,570][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 17:47:44,735][root][INFO] - 

[2024-10-14 17:47:44,735][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 17:47:44,735][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:47:44,735][root][INFO] - 

[2024-10-14 17:47:44,736][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 17:47:51,249][root][INFO] - 

[2024-10-14 17:47:51,249][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 17:47:51,249][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:47:51,249][root][INFO] - 

[2024-10-14 17:47:51,249][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 17:48:16,162][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,163][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,163][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,164][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,164][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,164][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,165][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,165][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,166][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,166][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,167][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,167][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,167][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,168][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,168][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,169][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,169][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,169][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,170][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,170][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,171][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,171][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,172][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 17:48:16,172][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 17:48:16,174][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 17:48:16,180][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 17:48:16,382][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 17:48:16,385][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 17:48:16,560][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 17:48:19,646][root][INFO] - 

[2024-10-14 17:48:19,646][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 17:48:19,646][root][INFO] - Data Preprocessing
[2024-10-14 17:48:19,646][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 17:48:19,647][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 17:48:19,647][root][INFO] - ㄴ data_remove                False

[2024-10-14 17:48:19,647][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 17:48:19,655][root][INFO] - vocab size              : 51200
[2024-10-14 17:48:19,655][root][INFO] - device                  : gpu
[2024-10-14 17:48:19,655][root][INFO] - random seed             : 1
[2024-10-14 17:48:19,655][root][INFO] - train data size         : 135040
[2024-10-14 17:48:19,655][root][INFO] - max epochs              : 5
[2024-10-14 17:48:19,655][root][INFO] - total steps             : 10550
[2024-10-14 17:48:19,655][root][INFO] - warmup steps            : 1055
[2024-10-14 17:48:19,655][root][INFO] - batch size              : 64
[2024-10-14 17:48:19,655][root][INFO] - accumulation steps      : 1
[2024-10-14 17:48:19,655][root][INFO] - optimizer               : adamwscale
[2024-10-14 17:48:19,656][root][INFO] - lr_scheduler            : cosine
[2024-10-14 17:48:19,656][root][INFO] - learning rate           : 0.01
[2024-10-14 17:48:19,656][root][INFO] - max length              : 256

[2024-10-14 17:48:19,656][root][INFO] - LoRA Configuration
[2024-10-14 17:48:19,656][root][INFO] - ㄴ r                    : 32
[2024-10-14 17:48:19,656][root][INFO] - ㄴ alpha                : 128
[2024-10-14 17:48:19,656][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 17:48:19,656][root][INFO] - KOMBO Configuration
[2024-10-14 17:48:19,656][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 17:48:19,656][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 17:48:19,656][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 17:48:19,657][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 17:48:19,657][root][INFO] - ㄴ do_combination       : True
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 17:48:19,657][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 17:48:19,657][root][INFO] - 

[2024-10-14 17:48:19,657][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:48:19,657][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 17:48:19,657][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 17:48:19,658][root][INFO] - * tb interval   : 10000

[2024-10-14 17:48:19,658][root][INFO] - 

[2024-10-14 17:48:19,658][root][INFO] - Start the Training !
[2024-10-14 17:48:19,661][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 17:49:49,077][root][INFO] - 

[2024-10-14 17:49:49,077][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 17:49:49,077][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:49:49,077][root][INFO] - 

[2024-10-14 17:49:49,077][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 17:49:53,899][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,900][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,900][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,901][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,901][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,902][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,902][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,902][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,903][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,903][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,904][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,904][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,905][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,905][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,906][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,906][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,907][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,907][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,908][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,908][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,909][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,909][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,910][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:53,910][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:53,912][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 17:49:53,916][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 17:49:54,121][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 17:49:54,123][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 17:49:54,294][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 17:49:56,038][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,039][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,039][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,040][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,040][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,041][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,041][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,042][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,042][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,043][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,044][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,044][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,045][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,045][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,046][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,046][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,047][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,047][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,048][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,048][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,049][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,049][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,050][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 17:49:56,050][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 17:49:56,052][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 17:49:56,057][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 17:49:56,263][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 17:49:56,265][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 17:49:56,480][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 17:49:57,553][root][INFO] - 

[2024-10-14 17:49:57,553][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 17:49:57,553][root][INFO] - Data Preprocessing
[2024-10-14 17:49:57,553][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 17:49:57,554][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 17:49:57,554][root][INFO] - ㄴ data_remove                False

[2024-10-14 17:49:57,554][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 17:49:57,563][root][INFO] - vocab size              : 51200
[2024-10-14 17:49:57,563][root][INFO] - device                  : gpu
[2024-10-14 17:49:57,563][root][INFO] - random seed             : 1
[2024-10-14 17:49:57,563][root][INFO] - train data size         : 5760
[2024-10-14 17:49:57,563][root][INFO] - max epochs              : 15
[2024-10-14 17:49:57,563][root][INFO] - total steps             : 1350
[2024-10-14 17:49:57,563][root][INFO] - warmup steps            : 135
[2024-10-14 17:49:57,564][root][INFO] - batch size              : 64
[2024-10-14 17:49:57,564][root][INFO] - accumulation steps      : 1
[2024-10-14 17:49:57,564][root][INFO] - optimizer               : adamwscale
[2024-10-14 17:49:57,564][root][INFO] - lr_scheduler            : cosine
[2024-10-14 17:49:57,564][root][INFO] - learning rate           : 0.01
[2024-10-14 17:49:57,564][root][INFO] - max length              : 256

[2024-10-14 17:49:57,564][root][INFO] - LoRA Configuration
[2024-10-14 17:49:57,564][root][INFO] - ㄴ r                    : 32
[2024-10-14 17:49:57,564][root][INFO] - ㄴ alpha                : 128
[2024-10-14 17:49:57,565][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 17:49:57,565][root][INFO] - KOMBO Configuration
[2024-10-14 17:49:57,565][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 17:49:57,565][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 17:49:57,565][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 17:49:57,565][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 17:49:57,565][root][INFO] - ㄴ do_combination       : True
[2024-10-14 17:49:57,565][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 17:49:57,566][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 17:49:57,566][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 17:49:57,566][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 17:49:57,566][root][INFO] - 

[2024-10-14 17:49:57,566][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:49:57,566][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 17:49:57,566][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 17:49:57,566][root][INFO] - * tb interval   : 10000

[2024-10-14 17:49:57,566][root][INFO] - 

[2024-10-14 17:49:57,566][root][INFO] - Start the Training !
[2024-10-14 17:49:57,570][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 17:49:59,687][root][INFO] - 

[2024-10-14 17:49:59,688][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-14 17:49:59,688][root][INFO] - Data Preprocessing
[2024-10-14 17:49:59,688][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 17:49:59,688][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 17:49:59,688][root][INFO] - ㄴ data_remove                False

[2024-10-14 17:49:59,688][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 17:49:59,696][root][INFO] - vocab size              : 51200
[2024-10-14 17:49:59,696][root][INFO] - device                  : gpu
[2024-10-14 17:49:59,696][root][INFO] - random seed             : 1
[2024-10-14 17:49:59,696][root][INFO] - train data size         : 942912
[2024-10-14 17:49:59,696][root][INFO] - max epochs              : 5
[2024-10-14 17:49:59,696][root][INFO] - total steps             : 73665
[2024-10-14 17:49:59,696][root][INFO] - warmup steps            : 7366
[2024-10-14 17:49:59,696][root][INFO] - batch size              : 64
[2024-10-14 17:49:59,696][root][INFO] - accumulation steps      : 1
[2024-10-14 17:49:59,696][root][INFO] - optimizer               : adamwscale
[2024-10-14 17:49:59,697][root][INFO] - lr_scheduler            : cosine
[2024-10-14 17:49:59,697][root][INFO] - learning rate           : 0.01
[2024-10-14 17:49:59,697][root][INFO] - max length              : 256

[2024-10-14 17:49:59,697][root][INFO] - LoRA Configuration
[2024-10-14 17:49:59,697][root][INFO] - ㄴ r                    : 32
[2024-10-14 17:49:59,697][root][INFO] - ㄴ alpha                : 128
[2024-10-14 17:49:59,697][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 17:49:59,697][root][INFO] - KOMBO Configuration
[2024-10-14 17:49:59,697][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 17:49:59,697][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 17:49:59,697][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 17:49:59,697][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 17:49:59,698][root][INFO] - ㄴ do_combination       : True
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 17:49:59,698][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 17:49:59,698][root][INFO] - 

[2024-10-14 17:49:59,698][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 17:49:59,698][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 17:49:59,698][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 17:49:59,698][root][INFO] - * tb interval   : 10000

[2024-10-14 17:49:59,699][root][INFO] - 

[2024-10-14 17:49:59,699][root][INFO] - Start the Training !
[2024-10-14 17:49:59,702][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 17:50:45,559][root][INFO] - Step: 90/1350  |  Loss: 2.5073  |  Score: 31.28 [%]  |  Seq Length: 256.0
[2024-10-14 17:50:51,671][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 17:50:51,671][root][INFO] - Score: 70.72 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 17:50:57,235][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 17:50:57,235][root][INFO] - Score: 62.83 [%]  |  Evaluation Time: 5.56 [s]
[2024-10-14 17:50:57,237][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 17:50:57,238][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 17:51:45,042][root][INFO] - Step: 180/1350  |  Loss: 1.2407  |  Score: 64.58 [%]  |  Seq Length: 256.0
[2024-10-14 17:51:51,329][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 17:51:51,329][root][INFO] - Score: 76.63 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 17:51:56,953][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 17:51:56,953][root][INFO] - Score: 68.81 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 17:51:56,954][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 17:51:56,955][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 17:52:45,205][root][INFO] - Step: 270/1350  |  Loss: 1.0314  |  Score: 70.38 [%]  |  Seq Length: 256.0
[2024-10-14 17:52:51,428][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 17:52:51,428][root][INFO] - Score: 77.01 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 17:52:57,041][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 17:52:57,041][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 17:52:57,043][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 17:52:57,044][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 17:53:45,243][root][INFO] - Step: 360/1350  |  Loss: 0.8744  |  Score: 74.83 [%]  |  Seq Length: 256.0
[2024-10-14 17:53:51,371][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 17:53:51,371][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 17:53:57,004][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 17:53:57,004][root][INFO] - Score: 71.12 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 17:53:57,005][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 17:53:57,007][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 17:54:45,250][root][INFO] - Step: 450/1350  |  Loss: 0.7951  |  Score: 78.43 [%]  |  Seq Length: 256.0
[2024-10-14 17:54:51,435][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 17:54:51,436][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 17:54:57,064][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 17:54:57,064][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 17:54:57,065][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 17:54:57,066][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 17:55:45,162][root][INFO] - Step: 540/1350  |  Loss: 0.6585  |  Score: 81.06 [%]  |  Seq Length: 256.0
[2024-10-14 17:55:51,388][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 17:55:51,388][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 17:55:57,026][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 17:55:57,027][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 17:55:57,029][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 17:56:45,076][root][INFO] - Step: 630/1350  |  Loss: 0.5899  |  Score: 83.37 [%]  |  Seq Length: 256.0
[2024-10-14 17:56:51,284][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 17:56:51,285][root][INFO] - Score: 79.15 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 17:56:56,884][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 17:56:56,885][root][INFO] - Score: 71.80 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 17:56:56,886][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 17:56:56,887][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 17:57:44,549][root][INFO] - Step: 720/1350  |  Loss: 0.5440  |  Score: 85.10 [%]  |  Seq Length: 256.0
[2024-10-14 17:57:50,719][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 17:57:50,719][root][INFO] - Score: 78.00 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 17:57:56,289][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 17:57:56,289][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 17:57:56,292][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 17:58:44,611][root][INFO] - Step: 810/1350  |  Loss: 0.4735  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 17:58:50,687][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 17:58:50,688][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 17:58:56,206][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 17:58:56,206][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 17:58:56,208][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 17:59:44,186][root][INFO] - Step: 900/1350  |  Loss: 0.4182  |  Score: 87.59 [%]  |  Seq Length: 256.0
[2024-10-14 17:59:50,390][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 17:59:50,390][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-14 17:59:56,046][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 17:59:56,046][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 17:59:56,049][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:00:44,351][root][INFO] - Step: 990/1350  |  Loss: 0.3806  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-14 18:00:50,583][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:00:50,583][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 18:00:56,301][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:00:56,302][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 18:00:56,303][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-14 18:00:56,305][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:01:44,643][root][INFO] - Step: 1080/1350  |  Loss: 0.3530  |  Score: 89.42 [%]  |  Seq Length: 256.0
[2024-10-14 18:01:50,886][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:01:50,886][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-14 18:01:56,557][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:01:56,558][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 18:01:56,561][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:02:44,744][root][INFO] - Step: 1170/1350  |  Loss: 0.3506  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 18:02:50,890][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:02:50,890][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:02:56,527][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:02:56,527][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:02:56,530][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:03:44,680][root][INFO] - Step: 1260/1350  |  Loss: 0.3270  |  Score: 90.01 [%]  |  Seq Length: 256.0
[2024-10-14 18:03:50,799][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:03:50,799][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:03:56,401][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:03:56,401][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 18:03:56,403][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:04:44,737][root][INFO] - Step: 1350/1350  |  Loss: 0.3227  |  Score: 90.36 [%]  |  Seq Length: 256.0
[2024-10-14 18:04:50,891][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:04:50,891][root][INFO] - Score: 79.37 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:04:56,523][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:04:56,523][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:04:56,524][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 18:04:56,524][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:04:56,524][root][INFO] - - Epoch: 15
[2024-10-14 18:04:56,524][root][INFO] - - DEV score: 79.37 [%]
[2024-10-14 18:04:56,524][root][INFO] - - TEST score: 72.09 [%]
[2024-10-14 18:04:56,525][root][INFO] - Fine-tuning is done!
[2024-10-14 18:04:56,529][root][INFO] - 

[2024-10-14 18:04:56,529][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:04:56,529][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 18:04:56,529][root][INFO] - 

[2024-10-14 18:04:56,529][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 18:04:59,888][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,888][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,889][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,890][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,890][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,891][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,892][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,892][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,893][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,893][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,894][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,895][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,895][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,896][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,896][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,897][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,897][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,898][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,898][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,899][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,899][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,900][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,900][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:04:59,901][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:04:59,903][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:05:00,113][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:05:00,115][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:05:00,117][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:05:00,287][root][INFO] - 

[2024-10-14 18:05:00,287][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:05:00,287][root][INFO] - Data Preprocessing
[2024-10-14 18:05:00,287][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:05:00,287][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:05:00,287][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:05:00,287][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:05:00,295][root][INFO] - vocab size              : 51200
[2024-10-14 18:05:00,295][root][INFO] - device                  : gpu
[2024-10-14 18:05:00,295][root][INFO] - random seed             : 1
[2024-10-14 18:05:00,295][root][INFO] - train data size         : 5760
[2024-10-14 18:05:00,295][root][INFO] - max epochs              : 15
[2024-10-14 18:05:00,295][root][INFO] - total steps             : 1350
[2024-10-14 18:05:00,295][root][INFO] - warmup steps            : 135
[2024-10-14 18:05:00,295][root][INFO] - batch size              : 64
[2024-10-14 18:05:00,295][root][INFO] - accumulation steps      : 1
[2024-10-14 18:05:00,296][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:05:00,296][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:05:00,296][root][INFO] - learning rate           : 0.02
[2024-10-14 18:05:00,296][root][INFO] - max length              : 256

[2024-10-14 18:05:00,296][root][INFO] - LoRA Configuration
[2024-10-14 18:05:00,296][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:05:00,296][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:05:00,296][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:05:00,296][root][INFO] - KOMBO Configuration
[2024-10-14 18:05:00,296][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:05:00,297][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:05:00,297][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:05:00,297][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:05:00,297][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:05:00,297][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:05:00,297][root][INFO] - 

[2024-10-14 18:05:00,298][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-14 18:05:00,298][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 18:05:00,298][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 18:05:00,298][root][INFO] - * tb interval   : 10000

[2024-10-14 18:05:00,298][root][INFO] - 

[2024-10-14 18:05:00,298][root][INFO] - Start the Training !
[2024-10-14 18:05:00,300][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:05:48,365][root][INFO] - Step: 90/1350  |  Loss: 2.0438  |  Score: 42.57 [%]  |  Seq Length: 256.0
[2024-10-14 18:05:54,539][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:05:54,539][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:06:00,144][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:06:00,144][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.60 [s]
[2024-10-14 18:06:00,145][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:06:00,146][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:06:16,647][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-14 18:06:48,222][root][INFO] - Step: 180/1350  |  Loss: 1.1176  |  Score: 68.59 [%]  |  Seq Length: 256.0
[2024-10-14 18:06:54,437][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:06:54,438][root][INFO] - Score: 76.90 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 18:07:00,191][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:07:00,191][root][INFO] - Score: 71.33 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-14 18:07:00,193][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:07:00,194][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:07:10,372][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:07:10,373][root][INFO] - Score: 86.43 [%]  |  Evaluation Time: 53.72 [s]
[2024-10-14 18:07:48,448][root][INFO] - Step: 270/1350  |  Loss: 0.9518  |  Score: 73.80 [%]  |  Seq Length: 256.0
[2024-10-14 18:07:54,713][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:07:54,713][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 18:08:00,417][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:08:00,417][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:08:00,418][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:08:00,420][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:08:48,417][root][INFO] - Step: 360/1350  |  Loss: 0.7880  |  Score: 78.92 [%]  |  Seq Length: 256.0
[2024-10-14 18:08:54,714][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:08:54,715][root][INFO] - Score: 78.09 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:09:00,389][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:09:00,389][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 18:09:00,392][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:09:48,786][root][INFO] - Step: 450/1350  |  Loss: 0.6588  |  Score: 81.87 [%]  |  Seq Length: 256.0
[2024-10-14 18:09:55,091][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:09:55,092][root][INFO] - Score: 78.11 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 18:10:00,793][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:10:00,794][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:10:00,796][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:10:08,856][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:10:08,856][root][INFO] - Score: 86.52 [%]  |  Evaluation Time: 178.48 [s]
[2024-10-14 18:10:08,857][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:10:08,859][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 18:10:48,963][root][INFO] - Step: 540/1350  |  Loss: 0.5402  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-14 18:10:55,240][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:10:55,240][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 18:11:00,862][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:11:00,862][root][INFO] - Score: 69.96 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 18:11:00,865][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:11:48,819][root][INFO] - Step: 630/1350  |  Loss: 0.4341  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-14 18:11:54,987][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:11:54,987][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:12:00,652][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:12:00,652][root][INFO] - Score: 70.39 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-14 18:12:00,655][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:12:48,984][root][INFO] - Step: 720/1350  |  Loss: 0.3781  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-14 18:12:55,235][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:12:55,235][root][INFO] - Score: 79.06 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 18:13:00,868][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:13:00,868][root][INFO] - Score: 70.59 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:13:00,871][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:13:49,133][root][INFO] - Step: 810/1350  |  Loss: 0.3292  |  Score: 90.54 [%]  |  Seq Length: 256.0
[2024-10-14 18:13:55,375][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:13:55,375][root][INFO] - Score: 77.71 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-14 18:14:01,029][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:14:01,029][root][INFO] - Score: 70.83 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 18:14:01,032][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 18:14:49,482][root][INFO] - Step: 900/1350  |  Loss: 0.2628  |  Score: 92.09 [%]  |  Seq Length: 256.0
[2024-10-14 18:14:55,810][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 18:14:55,811][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-14 18:15:01,493][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 18:15:01,493][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 18:15:01,496][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:15:49,632][root][INFO] - Step: 990/1350  |  Loss: 0.2322  |  Score: 93.24 [%]  |  Seq Length: 256.0
[2024-10-14 18:15:56,034][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:15:56,035][root][INFO] - Score: 79.01 [%]  |  Evaluation Time: 6.40 [s]
[2024-10-14 18:16:01,735][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:16:01,735][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:16:01,738][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:16:50,011][root][INFO] - Step: 1080/1350  |  Loss: 0.2070  |  Score: 93.90 [%]  |  Seq Length: 256.0
[2024-10-14 18:16:56,342][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:16:56,343][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-14 18:17:02,026][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:17:02,027][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 18:17:02,030][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:17:50,263][root][INFO] - Step: 1170/1350  |  Loss: 0.1930  |  Score: 94.23 [%]  |  Seq Length: 256.0
[2024-10-14 18:17:56,542][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:17:56,542][root][INFO] - Score: 78.67 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 18:18:02,267][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:18:02,267][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 18:18:02,270][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:18:50,520][root][INFO] - Step: 1260/1350  |  Loss: 0.1804  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-14 18:18:56,697][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:18:56,698][root][INFO] - Score: 78.84 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:19:02,318][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:19:02,318][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-14 18:19:02,319][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-14 18:19:02,321][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:19:50,511][root][INFO] - Step: 1350/1350  |  Loss: 0.1678  |  Score: 94.86 [%]  |  Seq Length: 256.0
[2024-10-14 18:19:56,874][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:19:56,874][root][INFO] - Score: 79.30 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-14 18:20:02,541][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:20:02,542][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-14 18:20:02,543][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 18:20:02,543][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:20:02,543][root][INFO] - - Epoch: 15
[2024-10-14 18:20:02,543][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 18:20:02,543][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 18:20:02,545][root][INFO] - Fine-tuning is done!
[2024-10-14 18:20:02,545][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 18:20:02,545][root][INFO] - - BEST LR: 0.02
[2024-10-14 18:20:02,545][root][INFO] - - DEV score: 79.30 [%]
[2024-10-14 18:20:02,545][root][INFO] - - TEST score: 70.64 [%]
[2024-10-14 18:20:09,029][root][INFO] - 

[2024-10-14 18:20:09,029][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:20:09,029][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:20:09,029][root][INFO] - 

[2024-10-14 18:20:09,029][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 18:20:13,601][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,602][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,603][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,603][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,603][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,604][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,604][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,605][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,605][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,606][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,606][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,607][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,607][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,608][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,608][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,608][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,609][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,609][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,610][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,610][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,611][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,611][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,612][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:20:13,612][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:20:13,614][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:20:13,618][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 18:20:13,814][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:20:13,816][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:20:14,003][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:20:17,123][root][INFO] - 

[2024-10-14 18:20:17,123][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:20:17,123][root][INFO] - Data Preprocessing
[2024-10-14 18:20:17,123][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:20:17,123][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:20:17,124][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:20:17,124][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:20:17,132][root][INFO] - vocab size              : 51200
[2024-10-14 18:20:17,132][root][INFO] - device                  : gpu
[2024-10-14 18:20:17,132][root][INFO] - random seed             : 2
[2024-10-14 18:20:17,132][root][INFO] - train data size         : 5760
[2024-10-14 18:20:17,132][root][INFO] - max epochs              : 15
[2024-10-14 18:20:17,132][root][INFO] - total steps             : 1350
[2024-10-14 18:20:17,132][root][INFO] - warmup steps            : 135
[2024-10-14 18:20:17,132][root][INFO] - batch size              : 64
[2024-10-14 18:20:17,132][root][INFO] - accumulation steps      : 1
[2024-10-14 18:20:17,133][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:20:17,133][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:20:17,133][root][INFO] - learning rate           : 0.01
[2024-10-14 18:20:17,133][root][INFO] - max length              : 256

[2024-10-14 18:20:17,133][root][INFO] - LoRA Configuration
[2024-10-14 18:20:17,133][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:20:17,133][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:20:17,133][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:20:17,133][root][INFO] - KOMBO Configuration
[2024-10-14 18:20:17,133][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:20:17,133][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:20:17,134][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:20:17,134][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:20:17,134][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:20:17,134][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:20:17,134][root][INFO] - 

[2024-10-14 18:20:17,134][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:20:17,134][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-14 18:20:17,135][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb
[2024-10-14 18:20:17,135][root][INFO] - * tb interval   : 10000

[2024-10-14 18:20:17,135][root][INFO] - 

[2024-10-14 18:20:17,135][root][INFO] - Start the Training !
[2024-10-14 18:20:17,138][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:21:05,409][root][INFO] - Step: 90/1350  |  Loss: 2.0541  |  Score: 36.26 [%]  |  Seq Length: 256.0
[2024-10-14 18:21:11,542][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:21:11,542][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:21:17,063][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:21:17,063][root][INFO] - Score: 60.42 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:21:17,064][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:21:17,065][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:22:04,863][root][INFO] - Step: 180/1350  |  Loss: 1.3146  |  Score: 64.93 [%]  |  Seq Length: 256.0
[2024-10-14 18:22:10,971][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:22:10,971][root][INFO] - Score: 75.98 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 18:22:16,516][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:22:16,516][root][INFO] - Score: 67.24 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 18:22:16,518][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:22:16,519][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:23:04,491][root][INFO] - Step: 270/1350  |  Loss: 1.0223  |  Score: 70.27 [%]  |  Seq Length: 256.0
[2024-10-14 18:23:10,658][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:23:10,658][root][INFO] - Score: 77.93 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-14 18:23:16,464][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:23:16,465][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-14 18:23:16,466][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:23:16,467][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:24:04,396][root][INFO] - Step: 360/1350  |  Loss: 0.8770  |  Score: 75.04 [%]  |  Seq Length: 256.0
[2024-10-14 18:24:10,497][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:24:10,498][root][INFO] - Score: 77.97 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-14 18:24:16,024][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:24:16,025][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:24:16,027][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:25:03,941][root][INFO] - Step: 450/1350  |  Loss: 0.7471  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-14 18:25:10,070][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:25:10,071][root][INFO] - Score: 79.34 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:25:15,570][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:25:15,570][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-14 18:25:15,571][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 18:25:15,573][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:26:03,310][root][INFO] - Step: 540/1350  |  Loss: 0.6158  |  Score: 82.27 [%]  |  Seq Length: 256.0
[2024-10-14 18:26:09,369][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:26:09,369][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 18:26:14,886][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:26:14,886][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 18:26:14,889][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:27:02,890][root][INFO] - Step: 630/1350  |  Loss: 0.5640  |  Score: 83.65 [%]  |  Seq Length: 256.0
[2024-10-14 18:27:09,005][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:27:09,005][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 18:27:14,545][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:27:14,545][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 18:27:14,547][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:28:02,328][root][INFO] - Step: 4220/10550  |  Loss: 0.2897  |  Score: 87.70 [%]  |  Seq Length: 256.0
[2024-10-14 18:28:02,339][root][INFO] - Step: 720/1350  |  Loss: 0.5180  |  Score: 85.66 [%]  |  Seq Length: 256.0
[2024-10-14 18:28:08,521][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:28:08,522][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-14 18:28:14,077][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:28:14,077][root][INFO] - Score: 71.89 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:28:14,079][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:28:55,307][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:28:55,307][root][INFO] - Score: 88.08 [%]  |  Evaluation Time: 52.98 [s]
[2024-10-14 18:29:01,927][root][INFO] - Step: 810/1350  |  Loss: 0.4363  |  Score: 87.48 [%]  |  Seq Length: 256.0
[2024-10-14 18:29:07,996][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:29:07,996][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 18:29:13,461][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:29:13,462][root][INFO] - Score: 71.63 [%]  |  Evaluation Time: 5.46 [s]
[2024-10-14 18:29:13,464][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 18:30:01,258][root][INFO] - Step: 900/1350  |  Loss: 0.3983  |  Score: 88.50 [%]  |  Seq Length: 256.0
[2024-10-14 18:30:07,328][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 18:30:07,328][root][INFO] - Score: 78.40 [%]  |  Evaluation Time: 6.07 [s]
[2024-10-14 18:30:12,807][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 18:30:12,807][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 18:30:12,809][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:31:00,498][root][INFO] - Step: 990/1350  |  Loss: 0.3682  |  Score: 89.09 [%]  |  Seq Length: 256.0
[2024-10-14 18:31:06,687][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:31:06,687][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-14 18:31:12,199][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:31:12,199][root][INFO] - Score: 70.98 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 18:31:12,204][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:31:51,229][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:31:51,229][root][INFO] - Score: 88.12 [%]  |  Evaluation Time: 175.92 [s]
[2024-10-14 18:31:51,230][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:31:51,232][root][INFO] - 
[3/ 5 Epoch]
[2024-10-14 18:32:00,230][root][INFO] - Step: 1080/1350  |  Loss: 0.3299  |  Score: 90.28 [%]  |  Seq Length: 256.0
[2024-10-14 18:32:06,281][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:32:06,281][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.05 [s]
[2024-10-14 18:32:11,806][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:32:11,806][root][INFO] - Score: 71.50 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:32:11,808][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:32:59,535][root][INFO] - Step: 1170/1350  |  Loss: 0.3276  |  Score: 90.29 [%]  |  Seq Length: 256.0
[2024-10-14 18:33:05,662][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:33:05,662][root][INFO] - Score: 78.51 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:33:11,170][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:33:11,170][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-14 18:33:11,173][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:33:58,980][root][INFO] - Step: 1260/1350  |  Loss: 0.3079  |  Score: 90.56 [%]  |  Seq Length: 256.0
[2024-10-14 18:34:05,041][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:34:05,041][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-14 18:34:10,520][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:34:10,520][root][INFO] - Score: 71.46 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-14 18:34:10,522][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:34:57,578][root][INFO] - Step: 1350/1350  |  Loss: 0.3049  |  Score: 90.66 [%]  |  Seq Length: 256.0
[2024-10-14 18:35:03,721][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:35:03,721][root][INFO] - Score: 78.18 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:35:09,255][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:35:09,255][root][INFO] - Score: 71.20 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 18:35:09,256][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:35:09,256][root][INFO] - - Epoch: 5
[2024-10-14 18:35:09,256][root][INFO] - - DEV score: 79.34 [%]
[2024-10-14 18:35:09,256][root][INFO] - - TEST score: 71.45 [%]
[2024-10-14 18:35:09,257][root][INFO] - Fine-tuning is done!
[2024-10-14 18:35:09,261][root][INFO] - 

[2024-10-14 18:35:09,261][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:35:09,261][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:35:09,261][root][INFO] - 

[2024-10-14 18:35:09,262][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 18:35:12,496][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,497][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,498][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,499][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,500][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,500][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,501][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,502][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,503][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,503][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,504][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,505][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,506][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,506][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,507][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,507][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,508][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,509][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,509][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,510][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,511][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,512][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,512][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:35:12,513][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:35:12,514][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:35:12,718][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:35:12,721][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:35:12,722][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:35:12,892][root][INFO] - 

[2024-10-14 18:35:12,892][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:35:12,892][root][INFO] - Data Preprocessing
[2024-10-14 18:35:12,892][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:35:12,892][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:35:12,893][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:35:12,893][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:35:12,900][root][INFO] - vocab size              : 51200
[2024-10-14 18:35:12,900][root][INFO] - device                  : gpu
[2024-10-14 18:35:12,900][root][INFO] - random seed             : 2
[2024-10-14 18:35:12,900][root][INFO] - train data size         : 5760
[2024-10-14 18:35:12,900][root][INFO] - max epochs              : 15
[2024-10-14 18:35:12,900][root][INFO] - total steps             : 1350
[2024-10-14 18:35:12,901][root][INFO] - warmup steps            : 135
[2024-10-14 18:35:12,901][root][INFO] - batch size              : 64
[2024-10-14 18:35:12,901][root][INFO] - accumulation steps      : 1
[2024-10-14 18:35:12,901][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:35:12,901][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:35:12,901][root][INFO] - learning rate           : 0.02
[2024-10-14 18:35:12,901][root][INFO] - max length              : 256

[2024-10-14 18:35:12,901][root][INFO] - LoRA Configuration
[2024-10-14 18:35:12,901][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:35:12,901][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:35:12,901][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:35:12,901][root][INFO] - KOMBO Configuration
[2024-10-14 18:35:12,902][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:35:12,902][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:35:12,902][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:35:12,902][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:35:12,902][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:35:12,902][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:35:12,903][root][INFO] - 

[2024-10-14 18:35:12,903][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-14 18:35:12,903][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-14 18:35:12,903][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb
[2024-10-14 18:35:12,903][root][INFO] - * tb interval   : 10000

[2024-10-14 18:35:12,903][root][INFO] - 

[2024-10-14 18:35:12,903][root][INFO] - Start the Training !
[2024-10-14 18:35:12,905][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:36:00,753][root][INFO] - Step: 90/1350  |  Loss: 1.8191  |  Score: 45.29 [%]  |  Seq Length: 256.0
[2024-10-14 18:36:06,927][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:36:06,927][root][INFO] - Score: 74.54 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:36:12,519][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:36:12,519][root][INFO] - Score: 64.35 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-14 18:36:12,521][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:36:12,522][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:37:00,441][root][INFO] - Step: 180/1350  |  Loss: 1.1164  |  Score: 67.84 [%]  |  Seq Length: 256.0
[2024-10-14 18:37:06,571][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:37:06,571][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:37:12,101][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:37:12,101][root][INFO] - Score: 67.89 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 18:37:12,102][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:37:12,103][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:37:59,863][root][INFO] - Step: 270/1350  |  Loss: 0.9153  |  Score: 74.49 [%]  |  Seq Length: 256.0
[2024-10-14 18:38:05,985][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:38:05,985][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:38:11,682][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:38:11,682][root][INFO] - Score: 70.82 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:38:11,684][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:38:11,685][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:38:59,837][root][INFO] - Step: 360/1350  |  Loss: 0.7498  |  Score: 79.16 [%]  |  Seq Length: 256.0
[2024-10-14 18:39:05,953][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:39:05,953][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-14 18:39:11,524][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:39:11,524][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:39:11,526][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:39:59,328][root][INFO] - Step: 450/1350  |  Loss: 0.6405  |  Score: 82.18 [%]  |  Seq Length: 256.0
[2024-10-14 18:40:05,477][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:40:05,477][root][INFO] - Score: 78.36 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:40:11,025][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:40:11,025][root][INFO] - Score: 69.69 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:40:11,027][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:40:58,876][root][INFO] - Step: 540/1350  |  Loss: 0.5123  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-14 18:41:04,995][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:41:04,995][root][INFO] - Score: 76.26 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-14 18:41:10,564][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:41:10,564][root][INFO] - Score: 69.61 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:41:10,566][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:41:58,455][root][INFO] - Step: 630/1350  |  Loss: 0.4074  |  Score: 88.00 [%]  |  Seq Length: 256.0
[2024-10-14 18:42:04,689][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:42:04,689][root][INFO] - Score: 77.46 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-14 18:42:10,236][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:42:10,236][root][INFO] - Score: 69.58 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:42:10,238][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:42:58,084][root][INFO] - Step: 720/1350  |  Loss: 0.3572  |  Score: 89.95 [%]  |  Seq Length: 256.0
[2024-10-14 18:43:04,238][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:43:04,239][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:43:09,813][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:43:09,813][root][INFO] - Score: 70.79 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:43:09,816][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:43:57,793][root][INFO] - Step: 810/1350  |  Loss: 0.2877  |  Score: 91.92 [%]  |  Seq Length: 256.0
[2024-10-14 18:44:03,932][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:44:03,932][root][INFO] - Score: 77.69 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:44:09,488][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:44:09,489][root][INFO] - Score: 70.37 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:44:09,493][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 18:44:57,771][root][INFO] - Step: 900/1350  |  Loss: 0.2515  |  Score: 92.90 [%]  |  Seq Length: 256.0
[2024-10-14 18:45:03,919][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 18:45:03,920][root][INFO] - Score: 77.30 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-14 18:45:09,506][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 18:45:09,506][root][INFO] - Score: 69.35 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-14 18:45:09,509][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 18:45:57,117][root][INFO] - Step: 990/1350  |  Loss: 0.2210  |  Score: 93.44 [%]  |  Seq Length: 256.0
[2024-10-14 18:46:03,263][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 18:46:03,263][root][INFO] - Score: 78.83 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:46:08,837][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 18:46:08,837][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-14 18:46:08,840][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 18:46:56,704][root][INFO] - Step: 1080/1350  |  Loss: 0.1857  |  Score: 94.43 [%]  |  Seq Length: 256.0
[2024-10-14 18:47:02,841][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 18:47:02,842][root][INFO] - Score: 78.58 [%]  |  Evaluation Time: 6.13 [s]
[2024-10-14 18:47:08,397][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 18:47:08,397][root][INFO] - Score: 69.91 [%]  |  Evaluation Time: 5.55 [s]
[2024-10-14 18:47:08,399][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 18:47:56,263][root][INFO] - Step: 1170/1350  |  Loss: 0.1870  |  Score: 94.50 [%]  |  Seq Length: 256.0
[2024-10-14 18:48:02,475][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 18:48:02,475][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-14 18:48:08,021][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 18:48:08,022][root][INFO] - Score: 69.71 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-14 18:48:08,024][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 18:48:56,062][root][INFO] - Step: 1260/1350  |  Loss: 0.1734  |  Score: 94.72 [%]  |  Seq Length: 256.0
[2024-10-14 18:49:02,201][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 18:49:02,201][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-14 18:49:07,733][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 18:49:07,733][root][INFO] - Score: 69.90 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-14 18:49:07,735][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 18:49:40,354][root][INFO] - Step: 6330/10550  |  Loss: 0.2514  |  Score: 89.56 [%]  |  Seq Length: 256.0
[2024-10-14 18:49:54,364][root][INFO] - Step: 1350/1350  |  Loss: 0.1596  |  Score: 95.08 [%]  |  Seq Length: 256.0
[2024-10-14 18:50:00,535][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 18:50:00,535][root][INFO] - Score: 78.07 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-14 18:50:06,057][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 18:50:06,057][root][INFO] - Score: 69.29 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-14 18:50:06,058][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 18:50:06,058][root][INFO] - - Epoch: 3
[2024-10-14 18:50:06,058][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 18:50:06,058][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 18:50:06,059][root][INFO] - Fine-tuning is done!
[2024-10-14 18:50:06,060][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 18:50:06,060][root][INFO] - - BEST LR: 0.02
[2024-10-14 18:50:06,060][root][INFO] - - DEV score: 79.11 [%]
[2024-10-14 18:50:06,060][root][INFO] - - TEST score: 70.82 [%]
[2024-10-14 18:50:12,409][root][INFO] - 

[2024-10-14 18:50:12,409][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 18:50:12,409][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 18:50:12,409][root][INFO] - 

[2024-10-14 18:50:12,409][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 18:50:17,129][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,129][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,130][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,130][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,131][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,131][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,131][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,132][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,132][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,133][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,133][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,133][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,134][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,134][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,135][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,135][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,136][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,136][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,136][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,137][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,137][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,138][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,138][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 18:50:17,139][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 18:50:17,140][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 18:50:17,144][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 18:50:17,346][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 18:50:17,349][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 18:50:17,532][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 18:50:20,676][root][INFO] - 

[2024-10-14 18:50:20,676][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 18:50:20,676][root][INFO] - Data Preprocessing
[2024-10-14 18:50:20,676][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 18:50:20,676][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 18:50:20,676][root][INFO] - ㄴ data_remove                False

[2024-10-14 18:50:20,677][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 18:50:20,696][root][INFO] - vocab size              : 51200
[2024-10-14 18:50:20,697][root][INFO] - device                  : gpu
[2024-10-14 18:50:20,697][root][INFO] - random seed             : 3
[2024-10-14 18:50:20,697][root][INFO] - train data size         : 5760
[2024-10-14 18:50:20,697][root][INFO] - max epochs              : 15
[2024-10-14 18:50:20,698][root][INFO] - total steps             : 1350
[2024-10-14 18:50:20,698][root][INFO] - warmup steps            : 135
[2024-10-14 18:50:20,698][root][INFO] - batch size              : 64
[2024-10-14 18:50:20,698][root][INFO] - accumulation steps      : 1
[2024-10-14 18:50:20,698][root][INFO] - optimizer               : adamwscale
[2024-10-14 18:50:20,698][root][INFO] - lr_scheduler            : cosine
[2024-10-14 18:50:20,698][root][INFO] - learning rate           : 0.01
[2024-10-14 18:50:20,698][root][INFO] - max length              : 256

[2024-10-14 18:50:20,699][root][INFO] - LoRA Configuration
[2024-10-14 18:50:20,699][root][INFO] - ㄴ r                    : 32
[2024-10-14 18:50:20,699][root][INFO] - ㄴ alpha                : 128
[2024-10-14 18:50:20,699][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 18:50:20,699][root][INFO] - KOMBO Configuration
[2024-10-14 18:50:20,699][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 18:50:20,700][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 18:50:20,700][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 18:50:20,700][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 18:50:20,700][root][INFO] - ㄴ do_combination       : True
[2024-10-14 18:50:20,700][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 18:50:20,701][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 18:50:20,701][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 18:50:20,701][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 18:50:20,701][root][INFO] - 

[2024-10-14 18:50:20,701][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 18:50:20,701][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-14 18:50:20,702][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb
[2024-10-14 18:50:20,702][root][INFO] - * tb interval   : 10000

[2024-10-14 18:50:20,702][root][INFO] - 

[2024-10-14 18:50:20,702][root][INFO] - Start the Training !
[2024-10-14 18:50:20,707][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 18:50:33,803][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:50:33,803][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 53.45 [s]
[2024-10-14 18:51:09,354][root][INFO] - Step: 90/1350  |  Loss: 2.2949  |  Score: 31.76 [%]  |  Seq Length: 256.0
[2024-10-14 18:51:15,653][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 18:51:15,654][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:51:21,347][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 18:51:21,347][root][INFO] - Score: 62.43 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-14 18:51:21,349][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 18:51:21,351][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 18:52:09,654][root][INFO] - Step: 180/1350  |  Loss: 1.1927  |  Score: 65.08 [%]  |  Seq Length: 256.0
[2024-10-14 18:52:15,950][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 18:52:15,950][root][INFO] - Score: 76.18 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:52:21,594][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 18:52:21,594][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-14 18:52:21,595][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 18:52:21,596][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 18:53:09,895][root][INFO] - Step: 270/1350  |  Loss: 1.0312  |  Score: 70.51 [%]  |  Seq Length: 256.0
[2024-10-14 18:53:16,187][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 18:53:16,187][root][INFO] - Score: 77.05 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:53:21,920][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:53:21,920][root][INFO] - Score: 68.79 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-14 18:53:21,921][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:53:21,923][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 18:53:30,935][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 18:53:30,936][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 177.13 [s]
[2024-10-14 18:53:30,937][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 18:53:30,938][root][INFO] - 
[4/ 5 Epoch]
[2024-10-14 18:54:10,157][root][INFO] - Step: 360/1350  |  Loss: 0.9194  |  Score: 74.60 [%]  |  Seq Length: 256.0
[2024-10-14 18:54:16,377][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 18:54:16,378][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-14 18:54:22,012][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 18:54:22,012][root][INFO] - Score: 71.35 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-14 18:54:22,013][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 18:54:22,014][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 18:55:10,088][root][INFO] - Step: 450/1350  |  Loss: 0.7997  |  Score: 77.85 [%]  |  Seq Length: 256.0
[2024-10-14 18:55:16,378][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 18:55:16,378][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-14 18:55:22,144][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 18:55:22,145][root][INFO] - Score: 71.53 [%]  |  Evaluation Time: 5.76 [s]
[2024-10-14 18:55:22,146][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 18:55:22,148][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 18:56:10,271][root][INFO] - Step: 540/1350  |  Loss: 0.6629  |  Score: 80.50 [%]  |  Seq Length: 256.0
[2024-10-14 18:56:16,578][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 18:56:16,578][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 18:56:22,298][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 18:56:22,298][root][INFO] - Score: 72.08 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 18:56:22,300][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 18:56:22,301][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 18:57:10,746][root][INFO] - Step: 630/1350  |  Loss: 0.6011  |  Score: 83.08 [%]  |  Seq Length: 256.0
[2024-10-14 18:57:17,032][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 18:57:17,032][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 18:57:22,738][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 18:57:22,738][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 18:57:22,739][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 18:57:22,741][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 18:58:10,996][root][INFO] - Step: 720/1350  |  Loss: 0.5142  |  Score: 84.76 [%]  |  Seq Length: 256.0
[2024-10-14 18:58:17,280][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 18:58:17,281][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 18:58:23,103][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 18:58:23,104][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 5.82 [s]
[2024-10-14 18:58:23,105][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-14 18:58:23,106][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 18:59:11,339][root][INFO] - Step: 810/1350  |  Loss: 0.4585  |  Score: 86.44 [%]  |  Seq Length: 256.0
[2024-10-14 18:59:17,691][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 18:59:17,691][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-14 18:59:23,446][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 18:59:23,447][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-14 18:59:23,449][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 19:00:11,614][root][INFO] - Step: 900/1350  |  Loss: 0.4325  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-14 19:00:17,878][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 19:00:17,878][root][INFO] - Score: 78.37 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 19:00:23,605][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 19:00:23,606][root][INFO] - Score: 71.26 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 19:00:23,608][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 19:01:11,876][root][INFO] - Step: 990/1350  |  Loss: 0.3816  |  Score: 88.82 [%]  |  Seq Length: 256.0
[2024-10-14 19:01:18,142][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 19:01:18,142][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 19:01:23,818][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 19:01:23,819][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-14 19:01:23,821][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 19:02:11,968][root][INFO] - Step: 1080/1350  |  Loss: 0.3515  |  Score: 89.60 [%]  |  Seq Length: 256.0
[2024-10-14 19:02:18,254][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 19:02:18,254][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 19:02:24,047][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 19:02:24,047][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-14 19:02:24,050][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 19:03:12,184][root][INFO] - Step: 1170/1350  |  Loss: 0.3390  |  Score: 89.75 [%]  |  Seq Length: 256.0
[2024-10-14 19:03:18,541][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 19:03:18,541][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-14 19:03:24,154][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 19:03:24,154][root][INFO] - Score: 71.90 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 19:03:24,157][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 19:04:12,536][root][INFO] - Step: 1260/1350  |  Loss: 0.3323  |  Score: 89.91 [%]  |  Seq Length: 256.0
[2024-10-14 19:04:18,808][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 19:04:18,808][root][INFO] - Score: 78.93 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-14 19:04:24,564][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 19:04:24,564][root][INFO] - Score: 70.96 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-14 19:04:24,567][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 19:05:13,021][root][INFO] - Step: 1350/1350  |  Loss: 0.3222  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-14 19:05:19,288][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 19:05:19,288][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-14 19:05:24,905][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 19:05:24,905][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-14 19:05:24,906][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 19:05:24,906][root][INFO] - - Epoch: 8
[2024-10-14 19:05:24,906][root][INFO] - - DEV score: 79.59 [%]
[2024-10-14 19:05:24,906][root][INFO] - - TEST score: 72.16 [%]
[2024-10-14 19:05:24,907][root][INFO] - Fine-tuning is done!
[2024-10-14 19:05:24,911][root][INFO] - 

[2024-10-14 19:05:24,911][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 19:05:24,911][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 19:05:24,911][root][INFO] - 

[2024-10-14 19:05:24,911][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 1350, 'epochs': 15, 'warmup_steps': 135, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 19:05:28,219][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,219][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,220][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,221][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,222][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,222][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,223][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,223][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,224][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,224][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,225][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,225][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,226][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,226][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,227][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,227][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,228][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,229][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,229][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,229][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,230][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,230][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,231][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 19:05:28,231][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 19:05:28,233][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-14 19:05:28,441][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 19:05:28,443][root][INFO] - Trainable params: 17254656 || all params: 142419456 || trainable: 12.12 %
[2024-10-14 19:05:28,445][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 19:05:28,570][root][INFO] - 

[2024-10-14 19:05:28,570][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-14 19:05:28,570][root][INFO] - Data Preprocessing
[2024-10-14 19:05:28,570][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 19:05:28,570][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 19:05:28,570][root][INFO] - ㄴ data_remove                False

[2024-10-14 19:05:28,571][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 19:05:28,578][root][INFO] - vocab size              : 51200
[2024-10-14 19:05:28,578][root][INFO] - device                  : gpu
[2024-10-14 19:05:28,578][root][INFO] - random seed             : 3
[2024-10-14 19:05:28,578][root][INFO] - train data size         : 5760
[2024-10-14 19:05:28,579][root][INFO] - max epochs              : 15
[2024-10-14 19:05:28,579][root][INFO] - total steps             : 1350
[2024-10-14 19:05:28,579][root][INFO] - warmup steps            : 135
[2024-10-14 19:05:28,579][root][INFO] - batch size              : 64
[2024-10-14 19:05:28,579][root][INFO] - accumulation steps      : 1
[2024-10-14 19:05:28,579][root][INFO] - optimizer               : adamwscale
[2024-10-14 19:05:28,579][root][INFO] - lr_scheduler            : cosine
[2024-10-14 19:05:28,579][root][INFO] - learning rate           : 0.02
[2024-10-14 19:05:28,579][root][INFO] - max length              : 256

[2024-10-14 19:05:28,579][root][INFO] - LoRA Configuration
[2024-10-14 19:05:28,580][root][INFO] - ㄴ r                    : 32
[2024-10-14 19:05:28,580][root][INFO] - ㄴ alpha                : 128
[2024-10-14 19:05:28,580][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 19:05:28,580][root][INFO] - KOMBO Configuration
[2024-10-14 19:05:28,580][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 19:05:28,580][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 19:05:28,580][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 19:05:28,580][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 19:05:28,580][root][INFO] - ㄴ do_combination       : True
[2024-10-14 19:05:28,580][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 19:05:28,581][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 19:05:28,581][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 19:05:28,581][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 19:05:28,581][root][INFO] - 

[2024-10-14 19:05:28,581][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-14 19:05:28,581][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-14 19:05:28,581][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb
[2024-10-14 19:05:28,581][root][INFO] - * tb interval   : 10000

[2024-10-14 19:05:28,581][root][INFO] - 

[2024-10-14 19:05:28,581][root][INFO] - Start the Training !
[2024-10-14 19:05:28,584][root][INFO] - 
[1/ 15 Epoch]
[2024-10-14 19:06:17,097][root][INFO] - Step: 90/1350  |  Loss: 2.0019  |  Score: 41.72 [%]  |  Seq Length: 256.0
[2024-10-14 19:06:23,408][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 19:06:23,409][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 19:06:29,349][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 19:06:29,350][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 5.94 [s]
[2024-10-14 19:06:29,351][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 19:06:29,353][root][INFO] - 
[2/ 15 Epoch]
[2024-10-14 19:07:17,804][root][INFO] - Step: 180/1350  |  Loss: 1.1405  |  Score: 67.73 [%]  |  Seq Length: 256.0
[2024-10-14 19:07:24,147][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 19:07:24,147][root][INFO] - Score: 77.70 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-14 19:07:29,947][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 19:07:29,947][root][INFO] - Score: 69.25 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-14 19:07:29,949][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 19:07:29,950][root][INFO] - 
[3/ 15 Epoch]
[2024-10-14 19:08:18,419][root][INFO] - Step: 270/1350  |  Loss: 0.9414  |  Score: 73.77 [%]  |  Seq Length: 256.0
[2024-10-14 19:08:24,701][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 19:08:24,701][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-14 19:08:30,383][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 19:08:30,383][root][INFO] - Score: 70.45 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 19:08:30,384][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 19:08:30,386][root][INFO] - 
[4/ 15 Epoch]
[2024-10-14 19:09:18,693][root][INFO] - Step: 360/1350  |  Loss: 0.7943  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-14 19:09:25,087][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 19:09:25,088][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 6.39 [s]
[2024-10-14 19:09:30,896][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 19:09:30,896][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 5.81 [s]
[2024-10-14 19:09:30,899][root][INFO] - 
[5/ 15 Epoch]
[2024-10-14 19:10:19,236][root][INFO] - Step: 450/1350  |  Loss: 0.6279  |  Score: 82.66 [%]  |  Seq Length: 256.0
[2024-10-14 19:10:25,661][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 19:10:25,661][root][INFO] - Score: 76.10 [%]  |  Evaluation Time: 6.42 [s]
[2024-10-14 19:10:31,463][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 19:10:31,464][root][INFO] - Score: 69.41 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-14 19:10:31,466][root][INFO] - 
[6/ 15 Epoch]
[2024-10-14 19:11:19,802][root][INFO] - Step: 540/1350  |  Loss: 0.5174  |  Score: 85.44 [%]  |  Seq Length: 256.0
[2024-10-14 19:11:25,201][root][INFO] - Step: 8440/10550  |  Loss: 0.2147  |  Score: 91.18 [%]  |  Seq Length: 256.0
[2024-10-14 19:11:26,104][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 19:11:26,104][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 19:11:31,804][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 19:11:31,805][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:11:31,807][root][INFO] - 
[7/ 15 Epoch]
[2024-10-14 19:12:19,107][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 19:12:19,107][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 53.90 [s]
[2024-10-14 19:12:20,226][root][INFO] - Step: 630/1350  |  Loss: 0.4309  |  Score: 87.86 [%]  |  Seq Length: 256.0
[2024-10-14 19:12:26,674][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 19:12:26,674][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 6.44 [s]
[2024-10-14 19:12:32,510][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 19:12:32,511][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 5.83 [s]
[2024-10-14 19:12:32,512][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 19:12:32,514][root][INFO] - 
[8/ 15 Epoch]
[2024-10-14 19:13:20,923][root][INFO] - Step: 720/1350  |  Loss: 0.3530  |  Score: 89.82 [%]  |  Seq Length: 256.0
[2024-10-14 19:13:27,246][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 19:13:27,247][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-14 19:13:32,925][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 19:13:32,925][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 19:13:32,927][root][INFO] - 
[9/ 15 Epoch]
[2024-10-14 19:14:19,924][root][INFO] - Step: 810/1350  |  Loss: 0.3051  |  Score: 91.04 [%]  |  Seq Length: 256.0
[2024-10-14 19:14:26,232][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 19:14:26,233][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 19:14:31,918][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 19:14:31,918][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-14 19:14:31,920][root][INFO] - 
[10/ 15 Epoch]
[2024-10-14 19:15:14,438][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 19:15:14,438][root][INFO] - Score: 88.63 [%]  |  Evaluation Time: 175.33 [s]
[2024-10-14 19:15:14,440][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 19:15:14,441][root][INFO] - 
[5/ 5 Epoch]
[2024-10-14 19:15:18,759][root][INFO] - Step: 900/1350  |  Loss: 0.2657  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 19:15:25,070][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 19:15:25,070][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-14 19:15:30,768][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 19:15:30,768][root][INFO] - Score: 70.10 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:15:30,770][root][INFO] - 
[11/ 15 Epoch]
[2024-10-14 19:16:18,859][root][INFO] - Step: 990/1350  |  Loss: 0.2278  |  Score: 93.40 [%]  |  Seq Length: 256.0
[2024-10-14 19:16:25,193][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-14 19:16:25,194][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-14 19:16:30,887][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-14 19:16:30,887][root][INFO] - Score: 70.20 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-14 19:16:30,889][root][INFO] - 
[12/ 15 Epoch]
[2024-10-14 19:17:19,237][root][INFO] - Step: 1080/1350  |  Loss: 0.1936  |  Score: 94.11 [%]  |  Seq Length: 256.0
[2024-10-14 19:17:25,491][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-14 19:17:25,491][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-14 19:17:31,197][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-14 19:17:31,197][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:17:31,199][root][INFO] - 
[13/ 15 Epoch]
[2024-10-14 19:18:19,375][root][INFO] - Step: 1170/1350  |  Loss: 0.1861  |  Score: 94.22 [%]  |  Seq Length: 256.0
[2024-10-14 19:18:25,675][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-14 19:18:25,676][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-14 19:18:31,395][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-14 19:18:31,395][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-14 19:18:31,398][root][INFO] - 
[14/ 15 Epoch]
[2024-10-14 19:19:16,929][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.44 [%]  |  Seq Length: 256.0
[2024-10-14 19:19:19,545][root][INFO] - Step: 1260/1350  |  Loss: 0.1743  |  Score: 94.73 [%]  |  Seq Length: 256.0
[2024-10-14 19:19:25,875][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-14 19:19:25,876][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-14 19:19:31,574][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-14 19:19:31,574][root][INFO] - Score: 70.50 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-14 19:19:31,576][root][INFO] - 
[15/ 15 Epoch]
[2024-10-14 19:20:19,598][root][INFO] - Step: 1350/1350  |  Loss: 0.1664  |  Score: 95.00 [%]  |  Seq Length: 256.0
[2024-10-14 19:20:25,924][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-14 19:20:25,924][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-14 19:20:31,581][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-14 19:20:31,581][root][INFO] - Score: 70.95 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-14 19:20:31,582][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-14 19:20:31,582][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 19:20:31,582][root][INFO] - - Epoch: 15
[2024-10-14 19:20:31,582][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 19:20:31,582][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 19:20:31,583][root][INFO] - Fine-tuning is done!
[2024-10-14 19:20:31,584][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 19:20:31,584][root][INFO] - - BEST LR: 0.02
[2024-10-14 19:20:31,584][root][INFO] - - DEV score: 78.72 [%]
[2024-10-14 19:20:31,584][root][INFO] - - TEST score: 70.95 [%]
[2024-10-14 19:28:23,450][root][INFO] - Step: 10000/10550  |  Loss: 0.1926  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 19:33:00,042][root][INFO] - Step: 10550/10550  |  Loss: 0.1885  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-14 19:33:52,677][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 19:33:52,678][root][INFO] - Score: 88.75 [%]  |  Evaluation Time: 52.63 [s]
[2024-10-14 19:36:47,467][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 19:36:47,468][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 174.79 [s]
[2024-10-14 19:36:47,469][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 19:36:47,469][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 19:36:47,469][root][INFO] - - Epoch: 5
[2024-10-14 19:36:47,469][root][INFO] - - DEV score: 88.75 [%]
[2024-10-14 19:36:47,469][root][INFO] - - TEST score: 88.80 [%]
[2024-10-14 19:36:47,470][root][INFO] - Fine-tuning is done!
[2024-10-14 19:36:47,473][root][INFO] - 

[2024-10-14 19:36:47,474][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 19:36:47,474][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 19:36:47,474][root][INFO] - 

[2024-10-14 19:36:47,474][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2046, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.02, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': 10550, 'epochs': 5, 'warmup_steps': 1055, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft', 'slurm_id': 'none', 'working_dir': '/data3/user21/KOMBO_Generation'}

[2024-10-14 19:37:08,122][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,122][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,123][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,123][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,124][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,124][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,125][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,125][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,126][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,126][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,127][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,127][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,127][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,128][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,128][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,129][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,129][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,130][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,130][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,131][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,132][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,132][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,133][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 19:37:08,133][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 19:37:08,135][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 19:37:08,337][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 19:37:08,339][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 19:37:08,340][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 19:37:08,481][root][INFO] - 

[2024-10-14 19:37:08,481][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 19:37:08,481][root][INFO] - Data Preprocessing
[2024-10-14 19:37:08,481][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 19:37:08,481][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 19:37:08,481][root][INFO] - ㄴ data_remove                False

[2024-10-14 19:37:08,481][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 19:37:08,490][root][INFO] - vocab size              : 51200
[2024-10-14 19:37:08,490][root][INFO] - device                  : gpu
[2024-10-14 19:37:08,490][root][INFO] - random seed             : 1
[2024-10-14 19:37:08,490][root][INFO] - train data size         : 135040
[2024-10-14 19:37:08,491][root][INFO] - max epochs              : 5
[2024-10-14 19:37:08,491][root][INFO] - total steps             : 10550
[2024-10-14 19:37:08,491][root][INFO] - warmup steps            : 1055
[2024-10-14 19:37:08,491][root][INFO] - batch size              : 64
[2024-10-14 19:37:08,491][root][INFO] - accumulation steps      : 1
[2024-10-14 19:37:08,491][root][INFO] - optimizer               : adamwscale
[2024-10-14 19:37:08,491][root][INFO] - lr_scheduler            : cosine
[2024-10-14 19:37:08,491][root][INFO] - learning rate           : 0.02
[2024-10-14 19:37:08,491][root][INFO] - max length              : 256

[2024-10-14 19:37:08,491][root][INFO] - LoRA Configuration
[2024-10-14 19:37:08,491][root][INFO] - ㄴ r                    : 32
[2024-10-14 19:37:08,492][root][INFO] - ㄴ alpha                : 128
[2024-10-14 19:37:08,492][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 19:37:08,492][root][INFO] - KOMBO Configuration
[2024-10-14 19:37:08,492][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 19:37:08,492][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 19:37:08,492][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 19:37:08,492][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 19:37:08,492][root][INFO] - ㄴ do_combination       : True
[2024-10-14 19:37:08,492][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 19:37:08,493][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 19:37:08,493][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 19:37:08,493][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 19:37:08,493][root][INFO] - 

[2024-10-14 19:37:08,493][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 19:37:08,493][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 19:37:08,493][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 19:37:08,493][root][INFO] - * tb interval   : 10000

[2024-10-14 19:37:08,493][root][INFO] - 

[2024-10-14 19:37:08,493][root][INFO] - Start the Training !
[2024-10-14 19:37:08,496][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 19:54:53,625][root][INFO] - Step: 2110/10550  |  Loss: 0.3659  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-14 19:55:46,385][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 19:55:46,385][root][INFO] - Score: 85.01 [%]  |  Evaluation Time: 52.76 [s]
[2024-10-14 19:58:41,601][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 19:58:41,601][root][INFO] - Score: 84.99 [%]  |  Evaluation Time: 175.21 [s]
[2024-10-14 19:58:41,603][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 19:58:41,604][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 20:01:08,029][root][INFO] - Step: 14733/73665  |  Loss: 0.6592  |  Score: 72.33 [%]  |  Seq Length: 256.0
[2024-10-14 20:01:17,985][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:01:17,986][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 9.95 [s]
[2024-10-14 20:01:37,625][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:01:37,625][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 19.64 [s]
[2024-10-14 20:01:37,627][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:01:37,628][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 20:08:26,366][root][INFO] - 

[2024-10-14 20:08:26,366][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:08:26,366][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:08:26,366][root][INFO] - 

[2024-10-14 20:08:26,366][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.01, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:08:39,286][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,286][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,287][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,287][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,288][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,288][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,288][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,289][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,289][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,290][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,290][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,291][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,291][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,291][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,292][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,292][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,293][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,293][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,294][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,294][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,294][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,295][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,295][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:08:39,296][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:08:39,297][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:08:39,301][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:08:39,501][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:08:39,504][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:08:39,686][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:08:42,738][root][INFO] - 

[2024-10-14 20:08:42,739][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 20:08:42,739][root][INFO] - Data Preprocessing
[2024-10-14 20:08:42,739][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:08:42,739][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:08:42,739][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:08:42,739][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:08:42,747][root][INFO] - vocab size              : 51200
[2024-10-14 20:08:42,747][root][INFO] - device                  : gpu
[2024-10-14 20:08:42,747][root][INFO] - random seed             : 1
[2024-10-14 20:08:42,747][root][INFO] - train data size         : 49152
[2024-10-14 20:08:42,747][root][INFO] - max epochs              : 10
[2024-10-14 20:08:42,747][root][INFO] - total steps             : 7680
[2024-10-14 20:08:42,747][root][INFO] - warmup steps            : 768
[2024-10-14 20:08:42,747][root][INFO] - batch size              : 64
[2024-10-14 20:08:42,747][root][INFO] - accumulation steps      : 1
[2024-10-14 20:08:42,747][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:08:42,748][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:08:42,748][root][INFO] - learning rate           : 0.01
[2024-10-14 20:08:42,748][root][INFO] - max length              : 256

[2024-10-14 20:08:42,748][root][INFO] - LoRA Configuration
[2024-10-14 20:08:42,748][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:08:42,748][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:08:42,748][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:08:42,748][root][INFO] - KOMBO Configuration
[2024-10-14 20:08:42,748][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:08:42,748][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:08:42,748][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:08:42,749][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:08:42,749][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:08:42,749][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:08:42,749][root][INFO] - 

[2024-10-14 20:08:42,749][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:08:42,749][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:08:42,749][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:08:42,750][root][INFO] - * tb interval   : 10000

[2024-10-14 20:08:42,750][root][INFO] - 

[2024-10-14 20:08:42,750][root][INFO] - Start the Training !
[2024-10-14 20:08:42,753][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 20:16:15,444][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-14 20:16:24,565][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:16:24,565][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-14 20:16:30,194][root][INFO] - Step: 4220/10550  |  Loss: 0.3136  |  Score: 86.57 [%]  |  Seq Length: 256.0
[2024-10-14 20:16:33,678][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:16:33,678][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-14 20:16:33,680][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:16:33,681][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 20:17:23,483][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 20:17:23,483][root][INFO] - Score: 87.31 [%]  |  Evaluation Time: 53.29 [s]
[2024-10-14 20:20:00,308][root][INFO] - 

[2024-10-14 20:20:00,309][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:20:00,309][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:00,309][root][INFO] - 

[2024-10-14 20:20:00,309][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:20:04,406][root][INFO] - 

[2024-10-14 20:20:04,407][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:20:04,407][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:04,407][root][INFO] - 

[2024-10-14 20:20:04,407][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:20:22,774][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,775][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,776][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,776][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,776][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,777][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,777][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,778][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,778][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,779][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,779][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,779][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,780][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,780][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,781][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,781][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,781][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,782][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,782][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,783][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,783][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,784][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,784][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:22,784][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:22,786][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:20:22,792][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:20:22,993][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:20:22,995][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:20:23,202][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:20:26,157][root][INFO] - 

[2024-10-14 20:20:26,157][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 20:20:26,157][root][INFO] - Data Preprocessing
[2024-10-14 20:20:26,157][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:20:26,157][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:20:26,157][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:20:26,157][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:20:26,165][root][INFO] - vocab size              : 51200
[2024-10-14 20:20:26,165][root][INFO] - device                  : gpu
[2024-10-14 20:20:26,165][root][INFO] - random seed             : 1
[2024-10-14 20:20:26,165][root][INFO] - train data size         : 135040
[2024-10-14 20:20:26,165][root][INFO] - max epochs              : 5
[2024-10-14 20:20:26,165][root][INFO] - total steps             : 10550
[2024-10-14 20:20:26,165][root][INFO] - warmup steps            : 1055
[2024-10-14 20:20:26,165][root][INFO] - batch size              : 64
[2024-10-14 20:20:26,165][root][INFO] - accumulation steps      : 1
[2024-10-14 20:20:26,166][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:20:26,166][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:20:26,166][root][INFO] - learning rate           : 0.01
[2024-10-14 20:20:26,166][root][INFO] - max length              : 256

[2024-10-14 20:20:26,166][root][INFO] - LoRA Configuration
[2024-10-14 20:20:26,166][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:20:26,166][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:20:26,166][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:20:26,166][root][INFO] - KOMBO Configuration
[2024-10-14 20:20:26,166][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:20:26,166][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:20:26,167][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:20:26,167][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:20:26,167][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:20:26,167][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:20:26,167][root][INFO] - 

[2024-10-14 20:20:26,168][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:26,168][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:20:26,168][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:20:26,168][root][INFO] - * tb interval   : 10000

[2024-10-14 20:20:26,168][root][INFO] - 

[2024-10-14 20:20:26,168][root][INFO] - Start the Training !
[2024-10-14 20:20:26,171][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:20:26,723][root][INFO] - 

[2024-10-14 20:20:26,723][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:20:26,723][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:26,723][root][INFO] - 

[2024-10-14 20:20:26,723][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:20:39,343][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,344][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,344][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,345][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,345][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,346][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,346][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,347][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,347][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,348][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,349][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,349][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,350][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,350][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,351][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,351][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,352][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,352][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,353][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,353][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,354][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,355][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,355][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:20:39,356][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:20:39,358][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:20:39,362][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:20:39,564][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:20:39,566][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:20:39,757][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:20:42,790][root][INFO] - 

[2024-10-14 20:20:42,790][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 20:20:42,790][root][INFO] - Data Preprocessing
[2024-10-14 20:20:42,790][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:20:42,790][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:20:42,790][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:20:42,790][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:20:42,798][root][INFO] - vocab size              : 51200
[2024-10-14 20:20:42,798][root][INFO] - device                  : gpu
[2024-10-14 20:20:42,798][root][INFO] - random seed             : 1
[2024-10-14 20:20:42,798][root][INFO] - train data size         : 49152
[2024-10-14 20:20:42,798][root][INFO] - max epochs              : 10
[2024-10-14 20:20:42,798][root][INFO] - total steps             : 7680
[2024-10-14 20:20:42,798][root][INFO] - warmup steps            : 768
[2024-10-14 20:20:42,798][root][INFO] - batch size              : 64
[2024-10-14 20:20:42,798][root][INFO] - accumulation steps      : 1
[2024-10-14 20:20:42,799][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:20:42,799][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:20:42,799][root][INFO] - learning rate           : 0.01
[2024-10-14 20:20:42,799][root][INFO] - max length              : 256

[2024-10-14 20:20:42,799][root][INFO] - LoRA Configuration
[2024-10-14 20:20:42,799][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:20:42,799][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:20:42,799][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:20:42,799][root][INFO] - KOMBO Configuration
[2024-10-14 20:20:42,799][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:20:42,799][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:20:42,800][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:20:42,800][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:20:42,800][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:20:42,800][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:20:42,800][root][INFO] - 

[2024-10-14 20:20:42,800][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:20:42,801][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:20:42,801][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:20:42,801][root][INFO] - * tb interval   : 10000

[2024-10-14 20:20:42,801][root][INFO] - 

[2024-10-14 20:20:42,801][root][INFO] - Start the Training !
[2024-10-14 20:20:42,804][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 20:22:06,723][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,723][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,724][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,724][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,725][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,725][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,725][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,726][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,726][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,727][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,727][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,727][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,728][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,728][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,729][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,729][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,730][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,730][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,730][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,731][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,731][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,732][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,732][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:22:06,732][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:22:06,734][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 20:22:06,738][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:22:06,933][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:22:06,935][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 20:22:07,159][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:22:10,237][root][INFO] - 

[2024-10-14 20:22:10,237][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-14 20:22:10,237][root][INFO] - Data Preprocessing
[2024-10-14 20:22:10,237][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:22:10,237][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:22:10,237][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:22:10,237][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:22:10,245][root][INFO] - vocab size              : 51200
[2024-10-14 20:22:10,245][root][INFO] - device                  : gpu
[2024-10-14 20:22:10,245][root][INFO] - random seed             : 1
[2024-10-14 20:22:10,246][root][INFO] - train data size         : 942912
[2024-10-14 20:22:10,246][root][INFO] - max epochs              : 5
[2024-10-14 20:22:10,246][root][INFO] - total steps             : 73665
[2024-10-14 20:22:10,246][root][INFO] - warmup steps            : 7366
[2024-10-14 20:22:10,246][root][INFO] - batch size              : 64
[2024-10-14 20:22:10,246][root][INFO] - accumulation steps      : 1
[2024-10-14 20:22:10,246][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:22:10,246][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:22:10,246][root][INFO] - learning rate           : 0.01
[2024-10-14 20:22:10,246][root][INFO] - max length              : 256

[2024-10-14 20:22:10,246][root][INFO] - LoRA Configuration
[2024-10-14 20:22:10,246][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:22:10,247][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:22:10,247][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:22:10,247][root][INFO] - KOMBO Configuration
[2024-10-14 20:22:10,247][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:22:10,247][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:22:10,247][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:22:10,247][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:22:10,247][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:22:10,247][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:22:10,247][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:22:10,248][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:22:10,248][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:22:10,248][root][INFO] - 

[2024-10-14 20:22:10,248][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:22:10,248][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:22:10,248][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:22:10,248][root][INFO] - * tb interval   : 10000

[2024-10-14 20:22:10,248][root][INFO] - 

[2024-10-14 20:22:10,248][root][INFO] - Start the Training !
[2024-10-14 20:22:10,251][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:23:17,359][root][INFO] - 

[2024-10-14 20:23:17,359][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:23:17,359][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:17,359][root][INFO] - 

[2024-10-14 20:23:17,359][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:23:19,587][root][INFO] - 

[2024-10-14 20:23:19,587][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:23:19,588][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:19,588][root][INFO] - 

[2024-10-14 20:23:19,588][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:23:21,279][root][INFO] - 

[2024-10-14 20:23:21,279][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 20:23:21,280][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:21,280][root][INFO] - 

[2024-10-14 20:23:21,280][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 20:23:34,554][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,554][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,555][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,555][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,556][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,556][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,557][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,557][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,558][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,558][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,559][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,559][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,559][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,560][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,560][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,561][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,561][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,562][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,562][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,563][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,563][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,564][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,564][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:34,565][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:34,566][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:23:34,571][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:23:34,770][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:23:34,772][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:23:34,963][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:23:38,039][root][INFO] - 

[2024-10-14 20:23:38,039][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 20:23:38,039][root][INFO] - Data Preprocessing
[2024-10-14 20:23:38,039][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:23:38,040][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:23:38,040][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:23:38,040][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:23:38,047][root][INFO] - vocab size              : 51200
[2024-10-14 20:23:38,048][root][INFO] - device                  : gpu
[2024-10-14 20:23:38,048][root][INFO] - random seed             : 1
[2024-10-14 20:23:38,048][root][INFO] - train data size         : 49152
[2024-10-14 20:23:38,048][root][INFO] - max epochs              : 10
[2024-10-14 20:23:38,048][root][INFO] - total steps             : 7680
[2024-10-14 20:23:38,048][root][INFO] - warmup steps            : 768
[2024-10-14 20:23:38,048][root][INFO] - batch size              : 64
[2024-10-14 20:23:38,048][root][INFO] - accumulation steps      : 1
[2024-10-14 20:23:38,049][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:23:38,049][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:23:38,049][root][INFO] - learning rate           : 0.01
[2024-10-14 20:23:38,049][root][INFO] - max length              : 256

[2024-10-14 20:23:38,049][root][INFO] - LoRA Configuration
[2024-10-14 20:23:38,049][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:23:38,049][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:23:38,049][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:23:38,049][root][INFO] - KOMBO Configuration
[2024-10-14 20:23:38,049][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:23:38,050][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:23:38,050][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:23:38,050][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:23:38,050][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:23:38,050][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:23:38,051][root][INFO] - 

[2024-10-14 20:23:38,051][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:38,051][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:23:38,051][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:23:38,051][root][INFO] - * tb interval   : 10000

[2024-10-14 20:23:38,051][root][INFO] - 

[2024-10-14 20:23:38,051][root][INFO] - Start the Training !
[2024-10-14 20:23:38,055][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 20:23:42,166][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,167][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,167][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,168][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,168][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,169][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,169][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,169][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,170][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,170][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,171][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,171][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,172][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,172][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,173][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,173][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,173][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,174][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,174][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,175][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,175][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,176][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,176][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:23:42,176][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:23:42,178][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 20:23:42,182][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:23:42,374][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:23:42,376][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 20:23:42,557][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:23:45,540][root][INFO] - 

[2024-10-14 20:23:45,540][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 20:23:45,541][root][INFO] - Data Preprocessing
[2024-10-14 20:23:45,541][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:23:45,541][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:23:45,541][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:23:45,541][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:23:45,548][root][INFO] - vocab size              : 51200
[2024-10-14 20:23:45,548][root][INFO] - device                  : gpu
[2024-10-14 20:23:45,548][root][INFO] - random seed             : 1
[2024-10-14 20:23:45,549][root][INFO] - train data size         : 135040
[2024-10-14 20:23:45,549][root][INFO] - max epochs              : 5
[2024-10-14 20:23:45,549][root][INFO] - total steps             : 10550
[2024-10-14 20:23:45,549][root][INFO] - warmup steps            : 1055
[2024-10-14 20:23:45,549][root][INFO] - batch size              : 64
[2024-10-14 20:23:45,549][root][INFO] - accumulation steps      : 1
[2024-10-14 20:23:45,549][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:23:45,549][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:23:45,549][root][INFO] - learning rate           : 0.01
[2024-10-14 20:23:45,549][root][INFO] - max length              : 256

[2024-10-14 20:23:45,549][root][INFO] - LoRA Configuration
[2024-10-14 20:23:45,550][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:23:45,550][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:23:45,550][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:23:45,550][root][INFO] - KOMBO Configuration
[2024-10-14 20:23:45,550][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:23:45,550][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:23:45,550][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:23:45,550][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:23:45,550][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:23:45,550][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:23:45,551][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:23:45,551][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:23:45,551][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:23:45,551][root][INFO] - 

[2024-10-14 20:23:45,551][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:23:45,551][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:23:45,551][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:23:45,551][root][INFO] - * tb interval   : 10000

[2024-10-14 20:23:45,551][root][INFO] - 

[2024-10-14 20:23:45,551][root][INFO] - Start the Training !
[2024-10-14 20:23:45,554][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:25:18,621][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,622][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,623][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,623][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,624][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,625][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,626][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,626][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,627][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,628][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,629][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,629][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,630][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,631][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,632][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,632][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,633][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,634][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,635][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,635][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,636][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,637][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,638][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 20:25:18,638][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 20:25:18,641][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-14 20:25:18,649][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 20:25:18,887][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 20:25:18,890][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-14 20:25:19,107][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 20:25:22,163][root][INFO] - 

[2024-10-14 20:25:22,163][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-14 20:25:22,163][root][INFO] - Data Preprocessing
[2024-10-14 20:25:22,163][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 20:25:22,163][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 20:25:22,163][root][INFO] - ㄴ data_remove                False

[2024-10-14 20:25:22,163][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 20:25:22,171][root][INFO] - vocab size              : 51200
[2024-10-14 20:25:22,171][root][INFO] - device                  : gpu
[2024-10-14 20:25:22,171][root][INFO] - random seed             : 1
[2024-10-14 20:25:22,171][root][INFO] - train data size         : 942912
[2024-10-14 20:25:22,171][root][INFO] - max epochs              : 5
[2024-10-14 20:25:22,171][root][INFO] - total steps             : 73665
[2024-10-14 20:25:22,172][root][INFO] - warmup steps            : 7366
[2024-10-14 20:25:22,172][root][INFO] - batch size              : 64
[2024-10-14 20:25:22,172][root][INFO] - accumulation steps      : 1
[2024-10-14 20:25:22,172][root][INFO] - optimizer               : adamwscale
[2024-10-14 20:25:22,172][root][INFO] - lr_scheduler            : cosine
[2024-10-14 20:25:22,172][root][INFO] - learning rate           : 0.01
[2024-10-14 20:25:22,172][root][INFO] - max length              : 256

[2024-10-14 20:25:22,172][root][INFO] - LoRA Configuration
[2024-10-14 20:25:22,172][root][INFO] - ㄴ r                    : 32
[2024-10-14 20:25:22,172][root][INFO] - ㄴ alpha                : 128
[2024-10-14 20:25:22,172][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 20:25:22,172][root][INFO] - KOMBO Configuration
[2024-10-14 20:25:22,173][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 20:25:22,173][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 20:25:22,173][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 20:25:22,173][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 20:25:22,173][root][INFO] - ㄴ do_combination       : True
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 20:25:22,173][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 20:25:22,174][root][INFO] - 

[2024-10-14 20:25:22,174][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-14 20:25:22,174][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 20:25:22,174][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 20:25:22,174][root][INFO] - * tb interval   : 10000

[2024-10-14 20:25:22,174][root][INFO] - 

[2024-10-14 20:25:22,174][root][INFO] - Start the Training !
[2024-10-14 20:25:22,177][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 20:31:10,974][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-14 20:31:20,083][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:31:20,084][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-14 20:31:29,137][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:31:29,137][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-14 20:31:29,138][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:31:29,139][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 20:39:01,832][root][INFO] - Step: 1536/7680  |  Loss: 0.5295  |  Score: 73.27 [%]  |  Seq Length: 256.0
[2024-10-14 20:39:11,168][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 20:39:11,168][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 9.33 [s]
[2024-10-14 20:39:20,446][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 20:39:20,446][root][INFO] - Score: 69.51 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-14 20:39:20,447][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 20:39:20,449][root][INFO] - 
[3/ 10 Epoch]
[2024-10-14 20:41:30,485][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-14 20:42:24,568][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 20:42:24,568][root][INFO] - Score: 86.43 [%]  |  Evaluation Time: 54.08 [s]
[2024-10-14 20:45:19,547][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 20:45:19,547][root][INFO] - Score: 86.52 [%]  |  Evaluation Time: 174.98 [s]
[2024-10-14 20:45:19,548][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 20:45:19,549][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 20:46:52,440][root][INFO] - Step: 2304/7680  |  Loss: 0.4638  |  Score: 77.33 [%]  |  Seq Length: 256.0
[2024-10-14 20:47:01,808][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 20:47:01,808][root][INFO] - Score: 72.97 [%]  |  Evaluation Time: 9.36 [s]
[2024-10-14 20:47:10,841][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 20:47:10,841][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-14 20:47:10,842][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 20:47:10,844][root][INFO] - 
[4/ 10 Epoch]
[2024-10-14 20:54:43,174][root][INFO] - Step: 3072/7680  |  Loss: 0.4107  |  Score: 80.68 [%]  |  Seq Length: 256.0
[2024-10-14 20:54:52,414][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 20:54:52,414][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-14 20:55:01,549][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 20:55:01,550][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 20:55:01,551][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 20:55:01,552][root][INFO] - 
[5/ 10 Epoch]
[2024-10-14 21:02:35,819][root][INFO] - Step: 3840/7680  |  Loss: 0.3698  |  Score: 82.74 [%]  |  Seq Length: 256.0
[2024-10-14 21:02:45,164][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 21:02:45,164][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 9.34 [s]
[2024-10-14 21:02:54,424][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 21:02:54,424][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-14 21:02:54,427][root][INFO] - 
[6/ 10 Epoch]
[2024-10-14 21:03:07,999][root][INFO] - Step: 4220/10550  |  Loss: 0.2897  |  Score: 87.70 [%]  |  Seq Length: 256.0
[2024-10-14 21:04:01,821][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 21:04:01,821][root][INFO] - Score: 88.08 [%]  |  Evaluation Time: 53.82 [s]
[2024-10-14 21:07:00,558][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 21:07:00,558][root][INFO] - Score: 88.12 [%]  |  Evaluation Time: 178.73 [s]
[2024-10-14 21:07:00,559][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 21:07:00,560][root][INFO] - 
[3/ 5 Epoch]
[2024-10-14 21:10:29,432][root][INFO] - Step: 4608/7680  |  Loss: 0.3322  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-14 21:10:38,562][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 21:10:38,562][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-14 21:10:47,857][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 21:10:47,858][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.29 [s]
[2024-10-14 21:10:47,859][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 21:10:47,860][root][INFO] - 
[7/ 10 Epoch]
[2024-10-14 21:18:22,718][root][INFO] - Step: 5376/7680  |  Loss: 0.2993  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-14 21:18:31,920][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 21:18:31,920][root][INFO] - Score: 75.63 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-14 21:18:41,080][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 21:18:41,081][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-14 21:18:41,082][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-14 21:18:41,083][root][INFO] - 
[8/ 10 Epoch]
[2024-10-14 21:24:56,190][root][INFO] - Step: 6330/10550  |  Loss: 0.2514  |  Score: 89.56 [%]  |  Seq Length: 256.0
[2024-10-14 21:25:49,763][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 21:25:49,763][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 53.57 [s]
[2024-10-14 21:26:16,429][root][INFO] - Step: 6144/7680  |  Loss: 0.2694  |  Score: 88.03 [%]  |  Seq Length: 256.0
[2024-10-14 21:26:25,649][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 21:26:25,649][root][INFO] - Score: 76.32 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-14 21:26:34,884][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 21:26:34,885][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 21:26:34,886][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-14 21:26:34,888][root][INFO] - 
[9/ 10 Epoch]
[2024-10-14 21:28:48,070][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 21:28:48,070][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 178.31 [s]
[2024-10-14 21:28:48,071][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 21:28:48,073][root][INFO] - 
[4/ 5 Epoch]
[2024-10-14 21:34:10,407][root][INFO] - Step: 6912/7680  |  Loss: 0.2510  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-14 21:34:19,536][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 21:34:19,536][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 21:34:28,660][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 21:34:28,661][root][INFO] - Score: 72.82 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-14 21:34:28,661][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-14 21:34:28,663][root][INFO] - 
[10/ 10 Epoch]
[2024-10-14 21:42:03,822][root][INFO] - Step: 7680/7680  |  Loss: 0.2422  |  Score: 89.34 [%]  |  Seq Length: 256.0
[2024-10-14 21:42:13,049][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 21:42:13,049][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-14 21:42:22,280][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 21:42:22,281][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 21:42:22,282][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 21:42:22,282][root][INFO] - - Epoch: 9
[2024-10-14 21:42:22,282][root][INFO] - - DEV score: 76.67 [%]
[2024-10-14 21:42:22,282][root][INFO] - - TEST score: 72.82 [%]
[2024-10-14 21:42:22,283][root][INFO] - Fine-tuning is done!
[2024-10-14 21:42:34,069][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,070][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,071][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,072][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,072][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,073][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,074][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,075][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,076][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,076][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,077][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,078][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,079][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,080][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,080][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,081][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,082][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,082][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,083][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,083][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,084][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,084][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,084][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 21:42:34,085][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 21:42:34,087][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 21:42:34,320][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 21:42:34,322][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 21:42:34,324][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 21:42:34,497][root][INFO] - 

[2024-10-14 21:42:34,497][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 21:42:34,497][root][INFO] - Data Preprocessing
[2024-10-14 21:42:34,498][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 21:42:34,498][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 21:42:34,498][root][INFO] - ㄴ data_remove                False

[2024-10-14 21:42:34,498][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 21:42:34,507][root][INFO] - vocab size              : 51200
[2024-10-14 21:42:34,507][root][INFO] - device                  : gpu
[2024-10-14 21:42:34,507][root][INFO] - random seed             : 1
[2024-10-14 21:42:34,507][root][INFO] - train data size         : 49152
[2024-10-14 21:42:34,507][root][INFO] - max epochs              : 10
[2024-10-14 21:42:34,507][root][INFO] - total steps             : 7680
[2024-10-14 21:42:34,507][root][INFO] - warmup steps            : 768
[2024-10-14 21:42:34,507][root][INFO] - batch size              : 64
[2024-10-14 21:42:34,508][root][INFO] - accumulation steps      : 1
[2024-10-14 21:42:34,508][root][INFO] - optimizer               : adamwscale
[2024-10-14 21:42:34,508][root][INFO] - lr_scheduler            : cosine
[2024-10-14 21:42:34,508][root][INFO] - learning rate           : 0.02
[2024-10-14 21:42:34,508][root][INFO] - max length              : 256

[2024-10-14 21:42:34,508][root][INFO] - LoRA Configuration
[2024-10-14 21:42:34,508][root][INFO] - ㄴ r                    : 32
[2024-10-14 21:42:34,508][root][INFO] - ㄴ alpha                : 128
[2024-10-14 21:42:34,508][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 21:42:34,508][root][INFO] - KOMBO Configuration
[2024-10-14 21:42:34,508][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 21:42:34,509][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 21:42:34,509][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 21:42:34,509][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 21:42:34,509][root][INFO] - ㄴ do_combination       : True
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 21:42:34,509][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 21:42:34,509][root][INFO] - 

[2024-10-14 21:42:34,510][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-14 21:42:34,510][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 21:42:34,510][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 21:42:34,510][root][INFO] - * tb interval   : 10000

[2024-10-14 21:42:34,510][root][INFO] - 

[2024-10-14 21:42:34,510][root][INFO] - Start the Training !
[2024-10-14 21:42:34,512][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 21:46:40,376][root][INFO] - Step: 8440/10550  |  Loss: 0.2147  |  Score: 91.18 [%]  |  Seq Length: 256.0
[2024-10-14 21:47:33,637][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 21:47:33,637][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 53.26 [s]
[2024-10-14 21:50:11,756][root][INFO] - Step: 768/7680  |  Loss: 0.6396  |  Score: 61.85 [%]  |  Seq Length: 256.0
[2024-10-14 21:50:20,970][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 21:50:20,971][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-14 21:50:30,260][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 21:50:30,260][root][INFO] - Score: 66.86 [%]  |  Evaluation Time: 9.29 [s]
[2024-10-14 21:50:30,262][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 21:50:30,264][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 21:50:30,395][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 21:50:30,395][root][INFO] - Score: 88.63 [%]  |  Evaluation Time: 176.76 [s]
[2024-10-14 21:50:30,396][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 21:50:30,398][root][INFO] - 
[5/ 5 Epoch]
[2024-10-14 21:54:14,521][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.44 [%]  |  Seq Length: 256.0
[2024-10-14 21:58:08,018][root][INFO] - Step: 1536/7680  |  Loss: 0.5290  |  Score: 73.49 [%]  |  Seq Length: 256.0
[2024-10-14 21:58:17,325][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 21:58:17,325][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 9.30 [s]
[2024-10-14 21:58:26,788][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 21:58:26,789][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 9.46 [s]
[2024-10-14 21:58:26,790][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 21:58:26,792][root][INFO] - 
[3/ 10 Epoch]
[2024-10-14 22:03:45,734][root][INFO] - Step: 10000/10550  |  Loss: 0.1926  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-14 22:06:05,777][root][INFO] - Step: 2304/7680  |  Loss: 0.4797  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-14 22:06:15,256][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 22:06:15,257][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.47 [s]
[2024-10-14 22:06:24,730][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 22:06:24,731][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 9.47 [s]
[2024-10-14 22:06:24,732][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 22:06:24,733][root][INFO] - 
[4/ 10 Epoch]
[2024-10-14 22:08:26,067][root][INFO] - Step: 10550/10550  |  Loss: 0.1885  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-14 22:09:19,872][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 22:09:19,873][root][INFO] - Score: 88.75 [%]  |  Evaluation Time: 53.80 [s]
[2024-10-14 22:12:17,049][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 22:12:17,049][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 177.17 [s]
[2024-10-14 22:12:17,051][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 22:12:17,051][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 22:12:17,051][root][INFO] - - Epoch: 5
[2024-10-14 22:12:17,051][root][INFO] - - DEV score: 88.75 [%]
[2024-10-14 22:12:17,051][root][INFO] - - TEST score: 88.80 [%]
[2024-10-14 22:12:17,052][root][INFO] - Fine-tuning is done!
[2024-10-14 22:12:38,767][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,768][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,769][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,770][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,770][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,771][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,772][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,773][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,774][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,774][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,775][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,776][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,777][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,778][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,778][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,779][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,780][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,780][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,781][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,781][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,782][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,782][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,783][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 22:12:38,783][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 22:12:38,785][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 22:12:39,004][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 22:12:39,007][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 22:12:39,008][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 22:12:39,230][root][INFO] - 

[2024-10-14 22:12:39,230][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-14 22:12:39,230][root][INFO] - Data Preprocessing
[2024-10-14 22:12:39,230][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 22:12:39,230][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 22:12:39,230][root][INFO] - ㄴ data_remove                False

[2024-10-14 22:12:39,231][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 22:12:39,240][root][INFO] - vocab size              : 51200
[2024-10-14 22:12:39,241][root][INFO] - device                  : gpu
[2024-10-14 22:12:39,241][root][INFO] - random seed             : 1
[2024-10-14 22:12:39,241][root][INFO] - train data size         : 135040
[2024-10-14 22:12:39,241][root][INFO] - max epochs              : 5
[2024-10-14 22:12:39,241][root][INFO] - total steps             : 10550
[2024-10-14 22:12:39,241][root][INFO] - warmup steps            : 1055
[2024-10-14 22:12:39,241][root][INFO] - batch size              : 64
[2024-10-14 22:12:39,241][root][INFO] - accumulation steps      : 1
[2024-10-14 22:12:39,241][root][INFO] - optimizer               : adamwscale
[2024-10-14 22:12:39,241][root][INFO] - lr_scheduler            : cosine
[2024-10-14 22:12:39,241][root][INFO] - learning rate           : 0.02
[2024-10-14 22:12:39,242][root][INFO] - max length              : 256

[2024-10-14 22:12:39,242][root][INFO] - LoRA Configuration
[2024-10-14 22:12:39,242][root][INFO] - ㄴ r                    : 32
[2024-10-14 22:12:39,242][root][INFO] - ㄴ alpha                : 128
[2024-10-14 22:12:39,242][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 22:12:39,242][root][INFO] - KOMBO Configuration
[2024-10-14 22:12:39,242][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 22:12:39,242][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 22:12:39,242][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 22:12:39,242][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 22:12:39,242][root][INFO] - ㄴ do_combination       : True
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 22:12:39,243][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 22:12:39,243][root][INFO] - 

[2024-10-14 22:12:39,243][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-14 22:12:39,243][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-14 22:12:39,243][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-14 22:12:39,243][root][INFO] - * tb interval   : 10000

[2024-10-14 22:12:39,243][root][INFO] - 

[2024-10-14 22:12:39,243][root][INFO] - Start the Training !
[2024-10-14 22:12:39,246][root][INFO] - 
[1/ 5 Epoch]
[2024-10-14 22:14:03,277][root][INFO] - Step: 3072/7680  |  Loss: 0.4315  |  Score: 79.38 [%]  |  Seq Length: 256.0
[2024-10-14 22:14:12,684][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 22:14:12,684][root][INFO] - Score: 72.79 [%]  |  Evaluation Time: 9.40 [s]
[2024-10-14 22:14:22,055][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 22:14:22,055][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 9.37 [s]
[2024-10-14 22:14:22,057][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 22:14:22,058][root][INFO] - 
[5/ 10 Epoch]
[2024-10-14 22:21:59,172][root][INFO] - Step: 3840/7680  |  Loss: 0.3944  |  Score: 81.60 [%]  |  Seq Length: 256.0
[2024-10-14 22:22:08,512][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 22:22:08,513][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 9.34 [s]
[2024-10-14 22:22:17,743][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 22:22:17,744][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 22:22:17,745][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 22:22:17,746][root][INFO] - 
[6/ 10 Epoch]
[2024-10-14 22:29:54,506][root][INFO] - Step: 4608/7680  |  Loss: 0.3457  |  Score: 84.04 [%]  |  Seq Length: 256.0
[2024-10-14 22:30:03,709][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 22:30:03,709][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-14 22:30:12,924][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 22:30:12,924][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-14 22:30:12,925][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 22:30:12,926][root][INFO] - 
[7/ 10 Epoch]
[2024-10-14 22:30:29,752][root][INFO] - Step: 2110/10550  |  Loss: 0.3659  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-14 22:31:23,772][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 22:31:23,773][root][INFO] - Score: 85.01 [%]  |  Evaluation Time: 54.02 [s]
[2024-10-14 22:34:22,146][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 22:34:22,146][root][INFO] - Score: 84.99 [%]  |  Evaluation Time: 178.37 [s]
[2024-10-14 22:34:22,147][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 22:34:22,149][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 22:36:21,608][root][INFO] - Step: 14733/73665  |  Loss: 0.6592  |  Score: 72.33 [%]  |  Seq Length: 256.0
[2024-10-14 22:36:31,835][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 22:36:31,835][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 10.22 [s]
[2024-10-14 22:36:51,911][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 22:36:51,911][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 20.07 [s]
[2024-10-14 22:36:51,912][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 22:36:51,913][root][INFO] - 
[2/ 5 Epoch]
[2024-10-14 22:37:50,227][root][INFO] - Step: 5376/7680  |  Loss: 0.2974  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-14 22:37:59,536][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 22:37:59,536][root][INFO] - Score: 75.11 [%]  |  Evaluation Time: 9.31 [s]
[2024-10-14 22:38:08,805][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 22:38:08,805][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 9.27 [s]
[2024-10-14 22:38:08,808][root][INFO] - 
[8/ 10 Epoch]
[2024-10-14 22:45:44,502][root][INFO] - Step: 6144/7680  |  Loss: 0.2532  |  Score: 88.87 [%]  |  Seq Length: 256.0
[2024-10-14 22:45:53,651][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-14 22:45:53,651][root][INFO] - Score: 75.03 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-14 22:46:02,880][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-14 22:46:02,880][root][INFO] - Score: 72.98 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-14 22:46:02,882][root][INFO] - 
[9/ 10 Epoch]
[2024-10-14 22:52:12,466][root][INFO] - Step: 4220/10550  |  Loss: 0.3136  |  Score: 86.57 [%]  |  Seq Length: 256.0
[2024-10-14 22:53:07,273][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 22:53:07,273][root][INFO] - Score: 87.31 [%]  |  Evaluation Time: 54.80 [s]
[2024-10-14 22:53:35,074][root][INFO] - Step: 6912/7680  |  Loss: 0.2230  |  Score: 90.33 [%]  |  Seq Length: 256.0
[2024-10-14 22:53:44,226][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-14 22:53:44,226][root][INFO] - Score: 75.21 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-14 22:53:53,368][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-14 22:53:53,369][root][INFO] - Score: 72.91 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-14 22:53:53,371][root][INFO] - 
[10/ 10 Epoch]
[2024-10-14 22:56:03,326][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 22:56:03,326][root][INFO] - Score: 87.45 [%]  |  Evaluation Time: 176.05 [s]
[2024-10-14 22:56:03,328][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 22:56:03,330][root][INFO] - 
[3/ 5 Epoch]
[2024-10-14 23:01:25,438][root][INFO] - Step: 7680/7680  |  Loss: 0.2027  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-14 23:01:34,569][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-14 23:01:34,569][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 23:01:43,709][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-14 23:01:43,709][root][INFO] - Score: 73.03 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-14 23:01:43,710][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-14 23:01:43,710][root][INFO] - - Epoch: 6
[2024-10-14 23:01:43,710][root][INFO] - - DEV score: 74.90 [%]
[2024-10-14 23:01:43,710][root][INFO] - - TEST score: 73.44 [%]
[2024-10-14 23:01:43,711][root][INFO] - Fine-tuning is done!
[2024-10-14 23:01:43,712][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-14 23:01:43,712][root][INFO] - - BEST LR: 0.01
[2024-10-14 23:01:43,712][root][INFO] - - DEV score: 76.67 [%]
[2024-10-14 23:01:43,712][root][INFO] - - TEST score: 72.82 [%]
[2024-10-14 23:01:50,119][root][INFO] - 

[2024-10-14 23:01:50,119][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-14 23:01:50,119][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-14 23:01:50,119][root][INFO] - 

[2024-10-14 23:01:50,119][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-14 23:02:02,942][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,942][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,943][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,943][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,944][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,944][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,945][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,946][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,946][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,947][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,947][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,948][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,948][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,949][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,949][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,950][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,950][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,951][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,952][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,952][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,953][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,953][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,954][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-14 23:02:02,954][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-14 23:02:02,956][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-14 23:02:02,961][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-14 23:02:03,191][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-14 23:02:03,193][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-14 23:02:03,385][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-14 23:02:06,542][root][INFO] - 

[2024-10-14 23:02:06,543][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-14 23:02:06,543][root][INFO] - Data Preprocessing
[2024-10-14 23:02:06,543][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-14 23:02:06,543][root][INFO] - ㄴ do_hangeulize              False
[2024-10-14 23:02:06,543][root][INFO] - ㄴ data_remove                False

[2024-10-14 23:02:06,543][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-14 23:02:06,551][root][INFO] - vocab size              : 51200
[2024-10-14 23:02:06,551][root][INFO] - device                  : gpu
[2024-10-14 23:02:06,551][root][INFO] - random seed             : 2
[2024-10-14 23:02:06,551][root][INFO] - train data size         : 49152
[2024-10-14 23:02:06,551][root][INFO] - max epochs              : 10
[2024-10-14 23:02:06,551][root][INFO] - total steps             : 7680
[2024-10-14 23:02:06,551][root][INFO] - warmup steps            : 768
[2024-10-14 23:02:06,552][root][INFO] - batch size              : 64
[2024-10-14 23:02:06,552][root][INFO] - accumulation steps      : 1
[2024-10-14 23:02:06,552][root][INFO] - optimizer               : adamwscale
[2024-10-14 23:02:06,552][root][INFO] - lr_scheduler            : cosine
[2024-10-14 23:02:06,552][root][INFO] - learning rate           : 0.01
[2024-10-14 23:02:06,552][root][INFO] - max length              : 256

[2024-10-14 23:02:06,552][root][INFO] - LoRA Configuration
[2024-10-14 23:02:06,552][root][INFO] - ㄴ r                    : 32
[2024-10-14 23:02:06,552][root][INFO] - ㄴ alpha                : 128
[2024-10-14 23:02:06,552][root][INFO] - ㄴ dropout              : 0.03

[2024-10-14 23:02:06,552][root][INFO] - KOMBO Configuration
[2024-10-14 23:02:06,552][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-14 23:02:06,553][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-14 23:02:06,553][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-14 23:02:06,553][root][INFO] - ㄴ embedding_norm       : False
[2024-10-14 23:02:06,553][root][INFO] - ㄴ do_combination       : True
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-14 23:02:06,553][root][INFO] -   ㄴ add_lora           : False

[2024-10-14 23:02:06,553][root][INFO] - 

[2024-10-14 23:02:06,553][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-14 23:02:06,554][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-14 23:02:06,554][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb
[2024-10-14 23:02:06,554][root][INFO] - * tb interval   : 10000

[2024-10-14 23:02:06,554][root][INFO] - 

[2024-10-14 23:02:06,554][root][INFO] - Start the Training !
[2024-10-14 23:02:06,557][root][INFO] - 
[1/ 10 Epoch]
[2024-10-14 23:09:40,209][root][INFO] - Step: 768/7680  |  Loss: 0.6386  |  Score: 62.54 [%]  |  Seq Length: 256.0
[2024-10-14 23:09:49,345][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-14 23:09:49,345][root][INFO] - Score: 68.40 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 23:09:58,526][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-14 23:09:58,527][root][INFO] - Score: 66.23 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-14 23:09:58,528][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-14 23:09:58,529][root][INFO] - 
[2/ 10 Epoch]
[2024-10-14 23:13:57,589][root][INFO] - Step: 6330/10550  |  Loss: 0.2831  |  Score: 88.06 [%]  |  Seq Length: 256.0
[2024-10-14 23:14:51,750][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 23:14:51,750][root][INFO] - Score: 88.06 [%]  |  Evaluation Time: 54.16 [s]
[2024-10-14 23:17:33,453][root][INFO] - Step: 1536/7680  |  Loss: 0.5177  |  Score: 74.29 [%]  |  Seq Length: 256.0
[2024-10-14 23:17:42,471][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-14 23:17:42,471][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-14 23:17:48,268][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 23:17:48,268][root][INFO] - Score: 88.11 [%]  |  Evaluation Time: 176.51 [s]
[2024-10-14 23:17:48,270][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 23:17:48,272][root][INFO] - 
[4/ 5 Epoch]
[2024-10-14 23:17:51,529][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-14 23:17:51,530][root][INFO] - Score: 67.61 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-14 23:17:51,530][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-14 23:17:51,532][root][INFO] - 
[3/ 10 Epoch]
[2024-10-14 23:23:41,344][root][INFO] - Step: 20000/73665  |  Loss: 0.6348  |  Score: 73.69 [%]  |  Seq Length: 256.0
[2024-10-14 23:25:25,090][root][INFO] - Step: 2304/7680  |  Loss: 0.4565  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-14 23:25:34,104][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-14 23:25:34,105][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-14 23:25:43,234][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-14 23:25:43,234][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-14 23:25:43,235][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-14 23:25:43,236][root][INFO] - 
[4/ 10 Epoch]
[2024-10-14 23:33:14,205][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-14 23:33:23,255][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 23:33:23,255][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-14 23:33:32,294][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 23:33:32,294][root][INFO] - Score: 72.89 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-14 23:33:32,295][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 23:33:32,297][root][INFO] - 
[5/ 10 Epoch]
[2024-10-14 23:35:39,647][root][INFO] - Step: 8440/10550  |  Loss: 0.2366  |  Score: 90.27 [%]  |  Seq Length: 256.0
[2024-10-14 23:36:33,164][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-14 23:36:33,164][root][INFO] - Score: 88.76 [%]  |  Evaluation Time: 53.51 [s]
[2024-10-14 23:39:29,554][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-14 23:39:29,554][root][INFO] - Score: 88.64 [%]  |  Evaluation Time: 176.39 [s]
[2024-10-14 23:39:29,555][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-14 23:39:29,557][root][INFO] - 
[5/ 5 Epoch]
[2024-10-14 23:41:06,269][root][INFO] - Step: 3840/7680  |  Loss: 0.3670  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-14 23:41:15,350][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 23:41:15,351][root][INFO] - Score: 76.05 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-14 23:41:24,351][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-14 23:41:24,351][root][INFO] - Score: 73.63 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-14 23:41:24,352][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-14 23:41:24,353][root][INFO] - 
[6/ 10 Epoch]
[2024-10-14 23:48:57,595][root][INFO] - Step: 4608/7680  |  Loss: 0.3297  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-14 23:49:06,736][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-14 23:49:06,736][root][INFO] - Score: 75.79 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-14 23:49:15,802][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-14 23:49:15,802][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-14 23:49:15,803][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-14 23:49:15,804][root][INFO] - 
[7/ 10 Epoch]
[2024-10-14 23:52:38,683][root][INFO] - Step: 10000/10550  |  Loss: 0.1977  |  Score: 92.02 [%]  |  Seq Length: 256.0
[2024-10-14 23:56:49,879][root][INFO] - Step: 5376/7680  |  Loss: 0.2950  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-14 23:56:58,926][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-14 23:56:58,926][root][INFO] - Score: 75.40 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-14 23:57:08,006][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-14 23:57:08,007][root][INFO] - Score: 72.84 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-14 23:57:08,009][root][INFO] - 
[8/ 10 Epoch]
[2024-10-14 23:57:17,536][root][INFO] - Step: 10550/10550  |  Loss: 0.1920  |  Score: 92.38 [%]  |  Seq Length: 256.0
[2024-10-14 23:58:10,799][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-14 23:58:10,799][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 53.26 [s]
[2024-10-15 00:01:07,136][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 00:01:07,136][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 176.33 [s]
[2024-10-15 00:01:07,137][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 00:01:07,137][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 00:01:07,137][root][INFO] - - Epoch: 5
[2024-10-15 00:01:07,137][root][INFO] - - DEV score: 88.84 [%]
[2024-10-15 00:01:07,137][root][INFO] - - TEST score: 88.88 [%]
[2024-10-15 00:01:07,139][root][INFO] - Fine-tuning is done!
[2024-10-15 00:01:07,139][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 00:01:07,139][root][INFO] - - BEST LR: 0.02
[2024-10-15 00:01:07,139][root][INFO] - - DEV score: 88.84 [%]
[2024-10-15 00:01:07,139][root][INFO] - - TEST score: 88.88 [%]
[2024-10-15 00:01:13,486][root][INFO] - 

[2024-10-15 00:01:13,487][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 00:01:13,487][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 00:01:13,487][root][INFO] - 

[2024-10-15 00:01:13,487][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 00:01:36,953][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,954][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,954][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,955][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,955][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,956][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,956][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,957][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,957][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,958][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,958][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,959][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,959][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,960][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,960][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,961][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,961][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,962][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,962][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,963][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,963][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,964][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,964][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 00:01:36,965][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 00:01:36,967][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 00:01:36,972][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 00:01:37,175][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 00:01:37,177][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 00:01:37,384][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 00:01:40,452][root][INFO] - 

[2024-10-15 00:01:40,452][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 00:01:40,453][root][INFO] - Data Preprocessing
[2024-10-15 00:01:40,453][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 00:01:40,453][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 00:01:40,453][root][INFO] - ㄴ data_remove                False

[2024-10-15 00:01:40,453][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 00:01:40,461][root][INFO] - vocab size              : 51200
[2024-10-15 00:01:40,461][root][INFO] - device                  : gpu
[2024-10-15 00:01:40,461][root][INFO] - random seed             : 2
[2024-10-15 00:01:40,462][root][INFO] - train data size         : 135040
[2024-10-15 00:01:40,462][root][INFO] - max epochs              : 5
[2024-10-15 00:01:40,462][root][INFO] - total steps             : 10550
[2024-10-15 00:01:40,462][root][INFO] - warmup steps            : 1055
[2024-10-15 00:01:40,462][root][INFO] - batch size              : 64
[2024-10-15 00:01:40,462][root][INFO] - accumulation steps      : 1
[2024-10-15 00:01:40,462][root][INFO] - optimizer               : adamwscale
[2024-10-15 00:01:40,462][root][INFO] - lr_scheduler            : cosine
[2024-10-15 00:01:40,462][root][INFO] - learning rate           : 0.01
[2024-10-15 00:01:40,462][root][INFO] - max length              : 256

[2024-10-15 00:01:40,462][root][INFO] - LoRA Configuration
[2024-10-15 00:01:40,462][root][INFO] - ㄴ r                    : 32
[2024-10-15 00:01:40,463][root][INFO] - ㄴ alpha                : 128
[2024-10-15 00:01:40,463][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 00:01:40,463][root][INFO] - KOMBO Configuration
[2024-10-15 00:01:40,463][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 00:01:40,463][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 00:01:40,463][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 00:01:40,463][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 00:01:40,463][root][INFO] - ㄴ do_combination       : True
[2024-10-15 00:01:40,463][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 00:01:40,463][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 00:01:40,464][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 00:01:40,464][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 00:01:40,464][root][INFO] - 

[2024-10-15 00:01:40,464][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 00:01:40,464][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 00:01:40,464][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 00:01:40,464][root][INFO] - * tb interval   : 10000

[2024-10-15 00:01:40,464][root][INFO] - 

[2024-10-15 00:01:40,464][root][INFO] - Start the Training !
[2024-10-15 00:01:40,467][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 00:04:40,778][root][INFO] - Step: 6144/7680  |  Loss: 0.2654  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-15 00:04:49,864][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 00:04:49,864][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:04:58,919][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 00:04:58,919][root][INFO] - Score: 73.65 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-15 00:04:58,921][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 00:12:32,592][root][INFO] - Step: 6912/7680  |  Loss: 0.2486  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-15 00:12:41,620][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 00:12:41,620][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-15 00:12:50,658][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 00:12:50,658][root][INFO] - Score: 73.59 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-15 00:12:50,660][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 00:19:35,044][root][INFO] - Step: 2110/10550  |  Loss: 0.3658  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-15 00:20:22,509][root][INFO] - Step: 7680/7680  |  Loss: 0.2369  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-15 00:20:28,978][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 00:20:28,978][root][INFO] - Score: 87.16 [%]  |  Evaluation Time: 53.93 [s]
[2024-10-15 00:20:31,520][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 00:20:31,520][root][INFO] - Score: 76.51 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-15 00:20:40,560][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 00:20:40,560][root][INFO] - Score: 73.88 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-15 00:20:40,561][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 00:20:40,561][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 00:20:40,561][root][INFO] - - Epoch: 10
[2024-10-15 00:20:40,561][root][INFO] - - DEV score: 76.51 [%]
[2024-10-15 00:20:40,561][root][INFO] - - TEST score: 73.88 [%]
[2024-10-15 00:20:40,562][root][INFO] - Fine-tuning is done!
[2024-10-15 00:20:52,277][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,277][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,278][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,279][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,279][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,280][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,280][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,281][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,282][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,282][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,283][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,283][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,284][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,284][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,285][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,285][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,286][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,286][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,287][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,287][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,288][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,288][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,289][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 00:20:52,289][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 00:20:52,291][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 00:20:52,499][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 00:20:52,501][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 00:20:52,502][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 00:20:52,668][root][INFO] - 

[2024-10-15 00:20:52,668][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 00:20:52,668][root][INFO] - Data Preprocessing
[2024-10-15 00:20:52,668][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 00:20:52,669][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 00:20:52,669][root][INFO] - ㄴ data_remove                False

[2024-10-15 00:20:52,669][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 00:20:52,676][root][INFO] - vocab size              : 51200
[2024-10-15 00:20:52,677][root][INFO] - device                  : gpu
[2024-10-15 00:20:52,677][root][INFO] - random seed             : 2
[2024-10-15 00:20:52,677][root][INFO] - train data size         : 49152
[2024-10-15 00:20:52,677][root][INFO] - max epochs              : 10
[2024-10-15 00:20:52,677][root][INFO] - total steps             : 7680
[2024-10-15 00:20:52,677][root][INFO] - warmup steps            : 768
[2024-10-15 00:20:52,677][root][INFO] - batch size              : 64
[2024-10-15 00:20:52,677][root][INFO] - accumulation steps      : 1
[2024-10-15 00:20:52,677][root][INFO] - optimizer               : adamwscale
[2024-10-15 00:20:52,677][root][INFO] - lr_scheduler            : cosine
[2024-10-15 00:20:52,678][root][INFO] - learning rate           : 0.02
[2024-10-15 00:20:52,678][root][INFO] - max length              : 256

[2024-10-15 00:20:52,678][root][INFO] - LoRA Configuration
[2024-10-15 00:20:52,678][root][INFO] - ㄴ r                    : 32
[2024-10-15 00:20:52,678][root][INFO] - ㄴ alpha                : 128
[2024-10-15 00:20:52,678][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 00:20:52,678][root][INFO] - KOMBO Configuration
[2024-10-15 00:20:52,678][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 00:20:52,678][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 00:20:52,678][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 00:20:52,678][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 00:20:52,679][root][INFO] - ㄴ do_combination       : True
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 00:20:52,679][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 00:20:52,679][root][INFO] - 

[2024-10-15 00:20:52,679][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-15 00:20:52,679][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 00:20:52,679][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 00:20:52,679][root][INFO] - * tb interval   : 10000

[2024-10-15 00:20:52,679][root][INFO] - 

[2024-10-15 00:20:52,680][root][INFO] - Start the Training !
[2024-10-15 00:20:52,682][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 00:23:24,933][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 00:23:24,933][root][INFO] - Score: 87.02 [%]  |  Evaluation Time: 175.95 [s]
[2024-10-15 00:23:24,934][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 00:23:24,936][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 00:28:23,200][root][INFO] - Step: 768/7680  |  Loss: 0.6222  |  Score: 64.46 [%]  |  Seq Length: 256.0
[2024-10-15 00:28:32,240][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 00:28:32,240][root][INFO] - Score: 67.73 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-15 00:28:41,361][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 00:28:41,362][root][INFO] - Score: 66.79 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 00:28:41,363][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 00:28:41,364][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 00:36:14,746][root][INFO] - Step: 1536/7680  |  Loss: 0.5210  |  Score: 74.06 [%]  |  Seq Length: 256.0
[2024-10-15 00:36:23,854][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 00:36:23,854][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 00:36:32,936][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 00:36:32,936][root][INFO] - Score: 67.05 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:36:32,937][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 00:36:32,939][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 00:41:16,102][root][INFO] - Step: 4220/10550  |  Loss: 0.2907  |  Score: 87.67 [%]  |  Seq Length: 256.0
[2024-10-15 00:42:09,340][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 00:42:09,340][root][INFO] - Score: 88.16 [%]  |  Evaluation Time: 53.24 [s]
[2024-10-15 00:44:08,451][root][INFO] - Step: 2304/7680  |  Loss: 0.4707  |  Score: 77.22 [%]  |  Seq Length: 256.0
[2024-10-15 00:44:17,555][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 00:44:17,556][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 00:44:26,656][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 00:44:26,656][root][INFO] - Score: 70.17 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 00:44:26,657][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 00:44:26,659][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 00:45:05,372][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 00:45:05,372][root][INFO] - Score: 88.11 [%]  |  Evaluation Time: 176.03 [s]
[2024-10-15 00:45:05,374][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 00:45:05,375][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 00:47:55,985][root][INFO] - Step: 29466/73665  |  Loss: 0.6277  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-15 00:48:06,161][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 00:48:06,161][root][INFO] - Score: 73.23 [%]  |  Evaluation Time: 10.17 [s]
[2024-10-15 00:48:26,276][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 00:48:26,276][root][INFO] - Score: 73.97 [%]  |  Evaluation Time: 20.11 [s]
[2024-10-15 00:48:26,277][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 00:48:26,278][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 00:52:01,350][root][INFO] - Step: 3072/7680  |  Loss: 0.4338  |  Score: 79.22 [%]  |  Seq Length: 256.0
[2024-10-15 00:52:10,436][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 00:52:10,436][root][INFO] - Score: 74.96 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:52:19,516][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 00:52:19,516][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 00:52:19,517][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 00:52:19,519][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 00:53:13,737][root][INFO] - Step: 30000/73665  |  Loss: 0.5975  |  Score: 75.59 [%]  |  Seq Length: 256.0
[2024-10-15 00:59:54,995][root][INFO] - Step: 3840/7680  |  Loss: 0.3913  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-15 01:00:04,109][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 01:00:04,109][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-15 01:00:13,253][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 01:00:13,253][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 01:00:13,254][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 01:00:13,255][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 01:02:53,712][root][INFO] - Step: 6330/10550  |  Loss: 0.2512  |  Score: 89.50 [%]  |  Seq Length: 256.0
[2024-10-15 01:03:47,090][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 01:03:47,091][root][INFO] - Score: 88.58 [%]  |  Evaluation Time: 53.37 [s]
[2024-10-15 01:06:43,340][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 01:06:43,341][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 176.25 [s]
[2024-10-15 01:06:43,342][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 01:06:43,344][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 01:07:45,407][root][INFO] - Step: 4608/7680  |  Loss: 0.3479  |  Score: 84.10 [%]  |  Seq Length: 256.0
[2024-10-15 01:07:54,505][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 01:07:54,505][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-15 01:08:03,616][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 01:08:03,616][root][INFO] - Score: 72.64 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-15 01:08:03,617][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 01:08:03,619][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 01:15:38,401][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.63 [%]  |  Seq Length: 256.0
[2024-10-15 01:15:47,484][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 01:15:47,484][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 01:15:56,576][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 01:15:56,576][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-15 01:15:56,578][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 01:23:30,646][root][INFO] - Step: 6144/7680  |  Loss: 0.2514  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-15 01:23:39,683][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 01:23:39,683][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-15 01:23:48,770][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 01:23:48,770][root][INFO] - Score: 74.42 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 01:23:48,771][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 01:23:48,772][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 01:24:31,356][root][INFO] - Step: 8440/10550  |  Loss: 0.2171  |  Score: 91.10 [%]  |  Seq Length: 256.0
[2024-10-15 01:25:24,552][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 01:25:24,553][root][INFO] - Score: 89.05 [%]  |  Evaluation Time: 53.19 [s]
[2024-10-15 01:28:21,617][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 01:28:21,617][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 177.06 [s]
[2024-10-15 01:28:21,618][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 01:28:21,619][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 01:31:20,104][root][INFO] - Step: 6912/7680  |  Loss: 0.2204  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-15 01:31:29,200][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 01:31:29,200][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-15 01:31:38,327][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 01:31:38,327][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 01:31:38,330][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 01:39:11,109][root][INFO] - Step: 7680/7680  |  Loss: 0.1994  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-15 01:39:20,295][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 01:39:20,296][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-15 01:39:29,453][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 01:39:29,453][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 01:39:29,454][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 01:39:29,454][root][INFO] - - Epoch: 8
[2024-10-15 01:39:29,454][root][INFO] - - DEV score: 77.23 [%]
[2024-10-15 01:39:29,454][root][INFO] - - TEST score: 74.42 [%]
[2024-10-15 01:39:29,455][root][INFO] - Fine-tuning is done!
[2024-10-15 01:39:29,456][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 01:39:29,456][root][INFO] - - BEST LR: 0.02
[2024-10-15 01:39:29,456][root][INFO] - - DEV score: 77.23 [%]
[2024-10-15 01:39:29,456][root][INFO] - - TEST score: 74.42 [%]
[2024-10-15 01:39:35,559][root][INFO] - 

[2024-10-15 01:39:35,559][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 01:39:35,560][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 01:39:35,560][root][INFO] - 

[2024-10-15 01:39:35,560][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 01:41:29,422][root][INFO] - Step: 10000/10550  |  Loss: 0.1917  |  Score: 92.31 [%]  |  Seq Length: 256.0
[2024-10-15 01:46:07,685][root][INFO] - Step: 10550/10550  |  Loss: 0.1923  |  Score: 92.27 [%]  |  Seq Length: 256.0
[2024-10-15 01:47:00,134][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 01:47:00,134][root][INFO] - Score: 88.99 [%]  |  Evaluation Time: 52.45 [s]
[2024-10-15 01:49:55,204][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 01:49:55,204][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 175.07 [s]
[2024-10-15 01:49:55,205][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 01:49:55,206][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 01:49:55,206][root][INFO] - - Epoch: 5
[2024-10-15 01:49:55,206][root][INFO] - - DEV score: 88.99 [%]
[2024-10-15 01:49:55,206][root][INFO] - - TEST score: 88.84 [%]
[2024-10-15 01:49:55,206][root][INFO] - Fine-tuning is done!
[2024-10-15 01:51:38,320][root][INFO] - 

[2024-10-15 01:51:38,320][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 01:51:38,320][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 01:51:38,320][root][INFO] - 

[2024-10-15 01:51:38,320][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 02:22:13,398][root][INFO] - Step: 40000/73665  |  Loss: 0.5971  |  Score: 75.45 [%]  |  Seq Length: 256.0
[2024-10-15 02:59:42,781][root][INFO] - Step: 44199/73665  |  Loss: 0.5820  |  Score: 76.20 [%]  |  Seq Length: 256.0
[2024-10-15 02:59:53,124][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 02:59:53,124][root][INFO] - Score: 74.93 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-15 03:00:13,363][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 03:00:13,363][root][INFO] - Score: 75.74 [%]  |  Evaluation Time: 20.24 [s]
[2024-10-15 03:00:13,364][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 03:00:13,366][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 03:51:55,843][root][INFO] - Step: 50000/73665  |  Loss: 0.5498  |  Score: 77.61 [%]  |  Seq Length: 256.0
[2024-10-15 05:11:36,531][root][INFO] - Step: 58932/73665  |  Loss: 0.5401  |  Score: 78.25 [%]  |  Seq Length: 256.0
[2024-10-15 05:11:46,745][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 05:11:46,745][root][INFO] - Score: 74.43 [%]  |  Evaluation Time: 10.21 [s]
[2024-10-15 05:12:06,856][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 05:12:06,856][root][INFO] - Score: 76.33 [%]  |  Evaluation Time: 20.11 [s]
[2024-10-15 05:12:06,857][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 05:12:06,858][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 05:21:39,145][root][INFO] - Step: 60000/73665  |  Loss: 0.5116  |  Score: 79.42 [%]  |  Seq Length: 256.0
[2024-10-15 06:50:52,439][root][INFO] - Step: 70000/73665  |  Loss: 0.5054  |  Score: 79.74 [%]  |  Seq Length: 256.0
[2024-10-15 07:23:29,393][root][INFO] - Step: 73665/73665  |  Loss: 0.5026  |  Score: 79.99 [%]  |  Seq Length: 256.0
[2024-10-15 07:23:39,408][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 07:23:39,408][root][INFO] - Score: 74.99 [%]  |  Evaluation Time: 10.01 [s]
[2024-10-15 07:23:59,218][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 07:23:59,218][root][INFO] - Score: 76.27 [%]  |  Evaluation Time: 19.81 [s]
[2024-10-15 07:23:59,219][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 07:23:59,219][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 07:23:59,219][root][INFO] - - Epoch: 5
[2024-10-15 07:23:59,219][root][INFO] - - DEV score: 74.99 [%]
[2024-10-15 07:23:59,219][root][INFO] - - TEST score: 76.27 [%]
[2024-10-15 07:23:59,220][root][INFO] - Fine-tuning is done!
[2024-10-15 07:25:57,223][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,224][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,225][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,225][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,226][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,226][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,227][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,228][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,228][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,229][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,229][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,230][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,230][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,231][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,231][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,232][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,232][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,233][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,233][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,234][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,235][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,235][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,236][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 07:25:57,236][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 07:25:57,238][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-15 07:25:57,439][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 07:25:57,441][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-15 07:25:57,442][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 07:25:57,625][root][INFO] - 

[2024-10-15 07:25:57,626][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-15 07:25:57,626][root][INFO] - Data Preprocessing
[2024-10-15 07:25:57,626][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 07:25:57,626][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 07:25:57,626][root][INFO] - ㄴ data_remove                False

[2024-10-15 07:25:57,626][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 07:25:57,639][root][INFO] - vocab size              : 51200
[2024-10-15 07:25:57,640][root][INFO] - device                  : gpu
[2024-10-15 07:25:57,640][root][INFO] - random seed             : 1
[2024-10-15 07:25:57,640][root][INFO] - train data size         : 942912
[2024-10-15 07:25:57,640][root][INFO] - max epochs              : 5
[2024-10-15 07:25:57,640][root][INFO] - total steps             : 73665
[2024-10-15 07:25:57,640][root][INFO] - warmup steps            : 7366
[2024-10-15 07:25:57,640][root][INFO] - batch size              : 64
[2024-10-15 07:25:57,640][root][INFO] - accumulation steps      : 1
[2024-10-15 07:25:57,640][root][INFO] - optimizer               : adamwscale
[2024-10-15 07:25:57,640][root][INFO] - lr_scheduler            : cosine
[2024-10-15 07:25:57,641][root][INFO] - learning rate           : 0.02
[2024-10-15 07:25:57,641][root][INFO] - max length              : 256

[2024-10-15 07:25:57,641][root][INFO] - LoRA Configuration
[2024-10-15 07:25:57,641][root][INFO] - ㄴ r                    : 32
[2024-10-15 07:25:57,641][root][INFO] - ㄴ alpha                : 128
[2024-10-15 07:25:57,641][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 07:25:57,641][root][INFO] - KOMBO Configuration
[2024-10-15 07:25:57,641][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 07:25:57,641][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 07:25:57,641][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 07:25:57,641][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 07:25:57,642][root][INFO] - ㄴ do_combination       : True
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 07:25:57,642][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 07:25:57,642][root][INFO] - 

[2024-10-15 07:25:57,642][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-15 07:25:57,642][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 07:25:57,642][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-15 07:25:57,642][root][INFO] - * tb interval   : 10000

[2024-10-15 07:25:57,642][root][INFO] - 

[2024-10-15 07:25:57,642][root][INFO] - Start the Training !
[2024-10-15 07:25:57,645][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 08:54:07,115][root][INFO] - Step: 10000/73665  |  Loss: 0.7559  |  Score: 67.09 [%]  |  Seq Length: 256.0
[2024-10-15 09:35:56,960][root][INFO] - Step: 14733/73665  |  Loss: 0.8257  |  Score: 62.91 [%]  |  Seq Length: 256.0
[2024-10-15 09:36:07,328][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 09:36:07,329][root][INFO] - Score: 56.10 [%]  |  Evaluation Time: 10.37 [s]
[2024-10-15 09:36:27,604][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 09:36:27,604][root][INFO] - Score: 56.93 [%]  |  Evaluation Time: 20.27 [s]
[2024-10-15 09:36:27,605][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 09:36:27,607][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 09:51:12,328][root][INFO] - 

[2024-10-15 09:51:12,328][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 09:51:12,328][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 09:51:12,328][root][INFO] - 

[2024-10-15 09:51:12,328][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 09:51:24,863][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,864][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,865][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,865][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,866][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,866][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,867][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,867][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,868][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,868][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,869][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,869][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,870][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,870][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,871][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,871][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,872][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,872][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,873][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,873][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,874][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,874][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,875][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:24,875][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:24,877][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 09:51:24,881][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 09:51:25,083][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 09:51:25,086][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 09:51:25,277][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 09:51:27,374][root][INFO] - 

[2024-10-15 09:51:27,374][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 09:51:27,374][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 09:51:27,374][root][INFO] - 

[2024-10-15 09:51:27,375][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 09:51:28,541][root][INFO] - 

[2024-10-15 09:51:28,541][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 09:51:28,542][root][INFO] - Data Preprocessing
[2024-10-15 09:51:28,542][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 09:51:28,542][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 09:51:28,542][root][INFO] - ㄴ data_remove                False

[2024-10-15 09:51:28,542][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 09:51:28,550][root][INFO] - vocab size              : 51200
[2024-10-15 09:51:28,550][root][INFO] - device                  : gpu
[2024-10-15 09:51:28,550][root][INFO] - random seed             : 3
[2024-10-15 09:51:28,550][root][INFO] - train data size         : 49152
[2024-10-15 09:51:28,550][root][INFO] - max epochs              : 10
[2024-10-15 09:51:28,550][root][INFO] - total steps             : 7680
[2024-10-15 09:51:28,550][root][INFO] - warmup steps            : 768
[2024-10-15 09:51:28,550][root][INFO] - batch size              : 64
[2024-10-15 09:51:28,550][root][INFO] - accumulation steps      : 1
[2024-10-15 09:51:28,550][root][INFO] - optimizer               : adamwscale
[2024-10-15 09:51:28,550][root][INFO] - lr_scheduler            : cosine
[2024-10-15 09:51:28,551][root][INFO] - learning rate           : 0.01
[2024-10-15 09:51:28,551][root][INFO] - max length              : 256

[2024-10-15 09:51:28,551][root][INFO] - LoRA Configuration
[2024-10-15 09:51:28,551][root][INFO] - ㄴ r                    : 32
[2024-10-15 09:51:28,551][root][INFO] - ㄴ alpha                : 128
[2024-10-15 09:51:28,551][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 09:51:28,551][root][INFO] - KOMBO Configuration
[2024-10-15 09:51:28,551][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 09:51:28,551][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 09:51:28,551][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 09:51:28,551][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 09:51:28,552][root][INFO] - ㄴ do_combination       : True
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 09:51:28,552][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 09:51:28,552][root][INFO] - 

[2024-10-15 09:51:28,552][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 09:51:28,552][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 09:51:28,552][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 09:51:28,552][root][INFO] - * tb interval   : 10000

[2024-10-15 09:51:28,553][root][INFO] - 

[2024-10-15 09:51:28,553][root][INFO] - Start the Training !
[2024-10-15 09:51:28,555][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 09:51:49,586][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,587][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,588][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,588][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,589][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,589][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,590][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,590][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,591][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,591][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,592][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,592][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,592][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,593][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,593][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,594][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,594][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,595][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,595][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,596][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,596][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,597][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,597][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 09:51:49,598][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 09:51:49,599][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 09:51:49,603][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 09:51:49,804][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 09:51:49,807][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 09:51:49,976][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 09:51:53,230][root][INFO] - 

[2024-10-15 09:51:53,231][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 09:51:53,231][root][INFO] - Data Preprocessing
[2024-10-15 09:51:53,231][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 09:51:53,231][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 09:51:53,231][root][INFO] - ㄴ data_remove                False

[2024-10-15 09:51:53,231][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 09:51:53,239][root][INFO] - vocab size              : 51200
[2024-10-15 09:51:53,239][root][INFO] - device                  : gpu
[2024-10-15 09:51:53,239][root][INFO] - random seed             : 2
[2024-10-15 09:51:53,239][root][INFO] - train data size         : 135040
[2024-10-15 09:51:53,239][root][INFO] - max epochs              : 5
[2024-10-15 09:51:53,239][root][INFO] - total steps             : 10550
[2024-10-15 09:51:53,239][root][INFO] - warmup steps            : 1055
[2024-10-15 09:51:53,239][root][INFO] - batch size              : 64
[2024-10-15 09:51:53,239][root][INFO] - accumulation steps      : 1
[2024-10-15 09:51:53,240][root][INFO] - optimizer               : adamwscale
[2024-10-15 09:51:53,240][root][INFO] - lr_scheduler            : cosine
[2024-10-15 09:51:53,240][root][INFO] - learning rate           : 0.01
[2024-10-15 09:51:53,240][root][INFO] - max length              : 256

[2024-10-15 09:51:53,240][root][INFO] - LoRA Configuration
[2024-10-15 09:51:53,240][root][INFO] - ㄴ r                    : 32
[2024-10-15 09:51:53,240][root][INFO] - ㄴ alpha                : 128
[2024-10-15 09:51:53,240][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 09:51:53,240][root][INFO] - KOMBO Configuration
[2024-10-15 09:51:53,240][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 09:51:53,240][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 09:51:53,240][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 09:51:53,241][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 09:51:53,241][root][INFO] - ㄴ do_combination       : True
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 09:51:53,241][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 09:51:53,241][root][INFO] - 

[2024-10-15 09:51:53,241][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 09:51:53,241][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 09:51:53,242][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 09:51:53,242][root][INFO] - * tb interval   : 10000

[2024-10-15 09:51:53,242][root][INFO] - 

[2024-10-15 09:51:53,242][root][INFO] - Start the Training !
[2024-10-15 09:51:53,245][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 09:59:00,664][root][INFO] - Step: 768/7680  |  Loss: 0.6403  |  Score: 62.30 [%]  |  Seq Length: 256.0
[2024-10-15 09:59:09,745][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 09:59:09,746][root][INFO] - Score: 65.99 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 09:59:18,885][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 09:59:18,885][root][INFO] - Score: 65.19 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 09:59:18,886][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 09:59:18,888][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 10:06:53,200][root][INFO] - Step: 1536/7680  |  Loss: 0.5201  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-15 10:07:02,474][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 10:07:02,474][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 9.27 [s]
[2024-10-15 10:07:11,668][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 10:07:11,668][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-15 10:07:11,669][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 10:07:11,671][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 10:09:48,175][root][INFO] - Step: 2110/10550  |  Loss: 0.3658  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-15 10:10:42,149][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 10:10:42,150][root][INFO] - Score: 87.16 [%]  |  Evaluation Time: 53.97 [s]
[2024-10-15 10:13:38,575][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 10:13:38,575][root][INFO] - Score: 87.02 [%]  |  Evaluation Time: 176.42 [s]
[2024-10-15 10:13:38,577][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 10:13:38,578][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 10:14:46,644][root][INFO] - Step: 2304/7680  |  Loss: 0.4547  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-15 10:14:55,731][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 10:14:55,731][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-15 10:15:04,867][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 10:15:04,867][root][INFO] - Score: 70.54 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-15 10:15:04,868][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 10:15:04,870][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 10:22:37,012][root][INFO] - Step: 3072/7680  |  Loss: 0.4076  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-15 10:22:46,181][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 10:22:46,181][root][INFO] - Score: 73.46 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-15 10:22:55,320][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 10:22:55,321][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 10:22:55,322][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 10:22:55,323][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 10:23:23,648][root][INFO] - Step: 20000/73665  |  Loss: 1.0698  |  Score: 41.69 [%]  |  Seq Length: 256.0
[2024-10-15 10:30:24,839][root][INFO] - Step: 3840/7680  |  Loss: 0.3683  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-15 10:30:34,016][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 10:30:34,017][root][INFO] - Score: 75.77 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-15 10:30:42,933][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 10:30:42,933][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-15 10:30:42,935][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 10:30:42,936][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 10:31:24,004][root][INFO] - Step: 4220/10550  |  Loss: 0.2907  |  Score: 87.67 [%]  |  Seq Length: 256.0
[2024-10-15 10:32:17,338][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 10:32:17,338][root][INFO] - Score: 88.16 [%]  |  Evaluation Time: 53.33 [s]
[2024-10-15 10:35:15,488][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 10:35:15,488][root][INFO] - Score: 88.11 [%]  |  Evaluation Time: 178.15 [s]
[2024-10-15 10:35:15,490][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 10:35:15,491][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 10:38:17,501][root][INFO] - Step: 4608/7680  |  Loss: 0.3315  |  Score: 84.98 [%]  |  Seq Length: 256.0
[2024-10-15 10:38:26,620][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 10:38:26,620][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 10:38:35,726][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 10:38:35,726][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-15 10:38:35,727][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 10:38:35,728][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 10:46:08,205][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-15 10:46:17,328][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 10:46:17,328][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 10:46:26,460][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 10:46:26,460][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-15 10:46:26,461][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-15 10:46:26,463][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 10:53:03,252][root][INFO] - Step: 6330/10550  |  Loss: 0.2512  |  Score: 89.50 [%]  |  Seq Length: 256.0
[2024-10-15 10:53:56,571][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 10:53:56,571][root][INFO] - Score: 88.58 [%]  |  Evaluation Time: 53.31 [s]
[2024-10-15 10:54:00,282][root][INFO] - Step: 6144/7680  |  Loss: 0.2681  |  Score: 87.98 [%]  |  Seq Length: 256.0
[2024-10-15 10:54:09,440][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 10:54:09,441][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 10:54:18,566][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 10:54:18,566][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 10:54:18,567][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 10:54:18,568][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 10:56:52,848][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 10:56:52,848][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 176.27 [s]
[2024-10-15 10:56:52,850][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 10:56:52,851][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 11:01:53,992][root][INFO] - Step: 6912/7680  |  Loss: 0.2485  |  Score: 89.16 [%]  |  Seq Length: 256.0
[2024-10-15 11:02:03,147][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 11:02:03,147][root][INFO] - Score: 76.72 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 11:02:12,267][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 11:02:12,267][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-15 11:02:12,268][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-15 11:02:12,269][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 11:09:47,825][root][INFO] - Step: 7680/7680  |  Loss: 0.2410  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-15 11:09:56,937][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 11:09:56,938][root][INFO] - Score: 76.46 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-15 11:10:06,079][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 11:10:06,080][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 11:10:06,081][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 11:10:06,081][root][INFO] - - Epoch: 9
[2024-10-15 11:10:06,081][root][INFO] - - DEV score: 76.72 [%]
[2024-10-15 11:10:06,081][root][INFO] - - TEST score: 72.05 [%]
[2024-10-15 11:10:06,082][root][INFO] - Fine-tuning is done!
[2024-10-15 11:10:18,103][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,103][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,104][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,104][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,105][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,105][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,106][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,106][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,107][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,107][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,108][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,109][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,109][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,110][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,110][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,111][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,111][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,112][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,112][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,113][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,114][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,114][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,115][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 11:10:18,115][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 11:10:18,117][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 11:10:18,326][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 11:10:18,329][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 11:10:18,330][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 11:10:18,502][root][INFO] - 

[2024-10-15 11:10:18,502][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 11:10:18,502][root][INFO] - Data Preprocessing
[2024-10-15 11:10:18,502][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 11:10:18,502][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 11:10:18,502][root][INFO] - ㄴ data_remove                False

[2024-10-15 11:10:18,502][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 11:10:18,510][root][INFO] - vocab size              : 51200
[2024-10-15 11:10:18,511][root][INFO] - device                  : gpu
[2024-10-15 11:10:18,511][root][INFO] - random seed             : 3
[2024-10-15 11:10:18,511][root][INFO] - train data size         : 49152
[2024-10-15 11:10:18,511][root][INFO] - max epochs              : 10
[2024-10-15 11:10:18,511][root][INFO] - total steps             : 7680
[2024-10-15 11:10:18,511][root][INFO] - warmup steps            : 768
[2024-10-15 11:10:18,511][root][INFO] - batch size              : 64
[2024-10-15 11:10:18,511][root][INFO] - accumulation steps      : 1
[2024-10-15 11:10:18,511][root][INFO] - optimizer               : adamwscale
[2024-10-15 11:10:18,511][root][INFO] - lr_scheduler            : cosine
[2024-10-15 11:10:18,511][root][INFO] - learning rate           : 0.02
[2024-10-15 11:10:18,512][root][INFO] - max length              : 256

[2024-10-15 11:10:18,512][root][INFO] - LoRA Configuration
[2024-10-15 11:10:18,512][root][INFO] - ㄴ r                    : 32
[2024-10-15 11:10:18,512][root][INFO] - ㄴ alpha                : 128
[2024-10-15 11:10:18,512][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 11:10:18,512][root][INFO] - KOMBO Configuration
[2024-10-15 11:10:18,512][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 11:10:18,512][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 11:10:18,512][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 11:10:18,512][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 11:10:18,513][root][INFO] - ㄴ do_combination       : True
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 11:10:18,513][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 11:10:18,513][root][INFO] - 

[2024-10-15 11:10:18,513][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-15 11:10:18,513][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 11:10:18,513][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 11:10:18,514][root][INFO] - * tb interval   : 10000

[2024-10-15 11:10:18,514][root][INFO] - 

[2024-10-15 11:10:18,514][root][INFO] - Start the Training !
[2024-10-15 11:10:18,516][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 11:14:36,583][root][INFO] - Step: 8440/10550  |  Loss: 0.2171  |  Score: 91.10 [%]  |  Seq Length: 256.0
[2024-10-15 11:15:29,869][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 11:15:29,869][root][INFO] - Score: 89.05 [%]  |  Evaluation Time: 53.28 [s]
[2024-10-15 11:17:50,043][root][INFO] - Step: 768/7680  |  Loss: 0.6252  |  Score: 64.13 [%]  |  Seq Length: 256.0
[2024-10-15 11:17:59,397][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 11:17:59,397][root][INFO] - Score: 68.57 [%]  |  Evaluation Time: 9.35 [s]
[2024-10-15 11:18:08,654][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 11:18:08,655][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-15 11:18:08,655][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 11:18:08,657][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 11:18:26,817][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 11:18:26,817][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 176.94 [s]
[2024-10-15 11:18:26,818][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 11:18:26,820][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 11:25:43,789][root][INFO] - Step: 1536/7680  |  Loss: 0.5207  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-15 11:25:53,007][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 11:25:53,007][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-15 11:26:02,337][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 11:26:02,337][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 9.33 [s]
[2024-10-15 11:26:02,338][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 11:26:02,340][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 11:31:38,625][root][INFO] - Step: 10000/10550  |  Loss: 0.1917  |  Score: 92.31 [%]  |  Seq Length: 256.0
[2024-10-15 11:33:37,203][root][INFO] - Step: 2304/7680  |  Loss: 0.4711  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-15 11:33:46,355][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 11:33:46,355][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 11:33:55,511][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 11:33:55,511][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-15 11:33:55,512][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 11:33:55,513][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 11:36:16,917][root][INFO] - Step: 10550/10550  |  Loss: 0.1923  |  Score: 92.27 [%]  |  Seq Length: 256.0
[2024-10-15 11:37:10,067][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 11:37:10,067][root][INFO] - Score: 88.99 [%]  |  Evaluation Time: 53.15 [s]
[2024-10-15 11:40:06,147][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 11:40:06,147][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 176.08 [s]
[2024-10-15 11:40:06,148][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 11:40:06,148][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 11:40:06,149][root][INFO] - - Epoch: 5
[2024-10-15 11:40:06,149][root][INFO] - - DEV score: 88.99 [%]
[2024-10-15 11:40:06,149][root][INFO] - - TEST score: 88.84 [%]
[2024-10-15 11:40:06,149][root][INFO] - Fine-tuning is done!
[2024-10-15 11:40:27,563][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,564][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,565][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,566][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,567][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,567][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,568][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,568][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,569][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,570][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,571][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,571][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,573][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,573][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,574][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,574][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,575][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,575][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,576][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,576][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,578][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,578][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,579][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 11:40:27,579][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 11:40:27,581][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 11:40:27,791][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 11:40:27,793][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 11:40:27,795][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 11:40:27,953][root][INFO] - 

[2024-10-15 11:40:27,953][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 11:40:27,953][root][INFO] - Data Preprocessing
[2024-10-15 11:40:27,953][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 11:40:27,953][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 11:40:27,953][root][INFO] - ㄴ data_remove                False

[2024-10-15 11:40:27,953][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 11:40:27,962][root][INFO] - vocab size              : 51200
[2024-10-15 11:40:27,963][root][INFO] - device                  : gpu
[2024-10-15 11:40:27,963][root][INFO] - random seed             : 2
[2024-10-15 11:40:27,963][root][INFO] - train data size         : 135040
[2024-10-15 11:40:27,963][root][INFO] - max epochs              : 5
[2024-10-15 11:40:27,963][root][INFO] - total steps             : 10550
[2024-10-15 11:40:27,963][root][INFO] - warmup steps            : 1055
[2024-10-15 11:40:27,963][root][INFO] - batch size              : 64
[2024-10-15 11:40:27,963][root][INFO] - accumulation steps      : 1
[2024-10-15 11:40:27,963][root][INFO] - optimizer               : adamwscale
[2024-10-15 11:40:27,963][root][INFO] - lr_scheduler            : cosine
[2024-10-15 11:40:27,964][root][INFO] - learning rate           : 0.02
[2024-10-15 11:40:27,964][root][INFO] - max length              : 256

[2024-10-15 11:40:27,964][root][INFO] - LoRA Configuration
[2024-10-15 11:40:27,964][root][INFO] - ㄴ r                    : 32
[2024-10-15 11:40:27,964][root][INFO] - ㄴ alpha                : 128
[2024-10-15 11:40:27,964][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 11:40:27,964][root][INFO] - KOMBO Configuration
[2024-10-15 11:40:27,964][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 11:40:27,964][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 11:40:27,964][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 11:40:27,964][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 11:40:27,965][root][INFO] - ㄴ do_combination       : True
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 11:40:27,965][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 11:40:27,965][root][INFO] - 

[2024-10-15 11:40:27,965][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-15 11:40:27,965][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 11:40:27,965][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 11:40:27,965][root][INFO] - * tb interval   : 10000

[2024-10-15 11:40:27,965][root][INFO] - 

[2024-10-15 11:40:27,966][root][INFO] - Start the Training !
[2024-10-15 11:40:27,968][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 11:41:30,461][root][INFO] - Step: 3072/7680  |  Loss: 0.4328  |  Score: 79.44 [%]  |  Seq Length: 256.0
[2024-10-15 11:41:39,716][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 11:41:39,716][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.25 [s]
[2024-10-15 11:41:48,899][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 11:41:48,900][root][INFO] - Score: 71.79 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-15 11:41:48,901][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 11:41:48,902][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 11:47:01,502][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-15 11:47:11,848][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 11:47:11,848][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-15 11:47:32,074][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 11:47:32,074][root][INFO] - Score: 33.59 [%]  |  Evaluation Time: 20.22 [s]
[2024-10-15 11:47:32,076][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 11:49:23,166][root][INFO] - Step: 3840/7680  |  Loss: 0.3889  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-15 11:49:32,311][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 11:49:32,311][root][INFO] - Score: 74.17 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 11:49:41,537][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 11:49:41,537][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-15 11:49:41,539][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 11:52:16,948][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-15 11:57:15,453][root][INFO] - Step: 4608/7680  |  Loss: 0.3400  |  Score: 84.52 [%]  |  Seq Length: 256.0
[2024-10-15 11:57:24,663][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 11:57:24,663][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-15 11:57:33,892][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 11:57:33,892][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-15 11:57:33,893][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 11:57:33,894][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 11:58:19,057][root][INFO] - Step: 2110/10550  |  Loss: 0.3668  |  Score: 83.72 [%]  |  Seq Length: 256.0
[2024-10-15 11:59:12,379][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 11:59:12,380][root][INFO] - Score: 86.08 [%]  |  Evaluation Time: 53.32 [s]
[2024-10-15 12:02:10,473][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 12:02:10,473][root][INFO] - Score: 86.34 [%]  |  Evaluation Time: 178.09 [s]
[2024-10-15 12:02:10,474][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 12:02:10,476][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 12:05:09,228][root][INFO] - Step: 5376/7680  |  Loss: 0.2948  |  Score: 86.84 [%]  |  Seq Length: 256.0
[2024-10-15 12:05:18,544][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 12:05:18,544][root][INFO] - Score: 75.16 [%]  |  Evaluation Time: 9.31 [s]
[2024-10-15 12:05:27,721][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 12:05:27,722][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-15 12:05:27,724][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 12:13:03,804][root][INFO] - Step: 6144/7680  |  Loss: 0.2517  |  Score: 88.88 [%]  |  Seq Length: 256.0
[2024-10-15 12:13:13,021][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 12:13:13,022][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-15 12:13:22,376][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 12:13:22,377][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 9.35 [s]
[2024-10-15 12:13:22,378][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 12:13:22,379][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 12:20:00,312][root][INFO] - Step: 4220/10550  |  Loss: 0.3154  |  Score: 86.38 [%]  |  Seq Length: 256.0
[2024-10-15 12:20:53,785][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 12:20:53,785][root][INFO] - Score: 86.89 [%]  |  Evaluation Time: 53.47 [s]
[2024-10-15 12:20:58,416][root][INFO] - Step: 6912/7680  |  Loss: 0.2166  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-15 12:21:07,623][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 12:21:07,623][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-15 12:21:16,822][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 12:21:16,822][root][INFO] - Score: 73.41 [%]  |  Evaluation Time: 9.20 [s]
[2024-10-15 12:21:16,823][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-15 12:21:16,824][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 12:23:50,560][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 12:23:50,560][root][INFO] - Score: 87.14 [%]  |  Evaluation Time: 176.77 [s]
[2024-10-15 12:23:50,561][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 12:23:50,563][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 12:28:50,894][root][INFO] - Step: 7680/7680  |  Loss: 0.1979  |  Score: 91.43 [%]  |  Seq Length: 256.0
[2024-10-15 12:29:00,039][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 12:29:00,039][root][INFO] - Score: 76.60 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-15 12:29:09,459][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 12:29:09,460][root][INFO] - Score: 73.52 [%]  |  Evaluation Time: 9.42 [s]
[2024-10-15 12:29:09,461][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 12:29:09,461][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 12:29:09,461][root][INFO] - - Epoch: 10
[2024-10-15 12:29:09,461][root][INFO] - - DEV score: 76.60 [%]
[2024-10-15 12:29:09,461][root][INFO] - - TEST score: 73.52 [%]
[2024-10-15 12:29:09,462][root][INFO] - Fine-tuning is done!
[2024-10-15 12:29:09,463][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 12:29:09,463][root][INFO] - - BEST LR: 0.01
[2024-10-15 12:29:09,463][root][INFO] - - DEV score: 76.72 [%]
[2024-10-15 12:29:09,463][root][INFO] - - TEST score: 72.05 [%]
[2024-10-15 12:41:42,815][root][INFO] - Step: 6330/10550  |  Loss: 0.2803  |  Score: 88.04 [%]  |  Seq Length: 256.0
[2024-10-15 12:42:36,497][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 12:42:36,497][root][INFO] - Score: 87.95 [%]  |  Evaluation Time: 53.68 [s]
[2024-10-15 12:45:32,791][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 12:45:32,791][root][INFO] - Score: 87.96 [%]  |  Evaluation Time: 176.29 [s]
[2024-10-15 12:45:32,792][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 12:45:32,794][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 13:03:23,510][root][INFO] - Step: 8440/10550  |  Loss: 0.2375  |  Score: 90.17 [%]  |  Seq Length: 256.0
[2024-10-15 13:04:17,097][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 13:04:17,097][root][INFO] - Score: 88.71 [%]  |  Evaluation Time: 53.58 [s]
[2024-10-15 13:07:13,744][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 13:07:13,744][root][INFO] - Score: 88.59 [%]  |  Evaluation Time: 176.64 [s]
[2024-10-15 13:07:13,745][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 13:07:13,747][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 13:20:26,192][root][INFO] - Step: 10000/10550  |  Loss: 0.1955  |  Score: 92.11 [%]  |  Seq Length: 256.0
[2024-10-15 13:20:40,589][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-15 13:25:05,086][root][INFO] - Step: 10550/10550  |  Loss: 0.1946  |  Score: 92.04 [%]  |  Seq Length: 256.0
[2024-10-15 13:25:58,572][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 13:25:58,572][root][INFO] - Score: 88.89 [%]  |  Evaluation Time: 53.48 [s]
[2024-10-15 13:28:55,154][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 13:28:55,155][root][INFO] - Score: 88.68 [%]  |  Evaluation Time: 176.58 [s]
[2024-10-15 13:28:55,156][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 13:28:55,156][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 13:28:55,156][root][INFO] - - Epoch: 5
[2024-10-15 13:28:55,157][root][INFO] - - DEV score: 88.89 [%]
[2024-10-15 13:28:55,157][root][INFO] - - TEST score: 88.68 [%]
[2024-10-15 13:28:55,158][root][INFO] - Fine-tuning is done!
[2024-10-15 13:28:55,159][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 13:28:55,159][root][INFO] - - BEST LR: 0.01
[2024-10-15 13:28:55,159][root][INFO] - - DEV score: 88.99 [%]
[2024-10-15 13:28:55,159][root][INFO] - - TEST score: 88.84 [%]
[2024-10-15 13:29:01,931][root][INFO] - 

[2024-10-15 13:29:01,931][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 13:29:01,931][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 13:29:01,931][root][INFO] - 

[2024-10-15 13:29:01,932][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 13:29:25,307][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,308][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,308][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,309][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,309][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,310][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,310][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,310][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,311][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,311][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,312][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,312][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,313][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,313][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,313][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,314][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,314][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,314][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,315][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,315][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,316][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,316][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,317][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 13:29:25,317][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 13:29:25,319][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 13:29:25,323][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 13:29:25,526][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 13:29:25,528][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 13:29:25,705][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 13:29:28,811][root][INFO] - 

[2024-10-15 13:29:28,812][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 13:29:28,812][root][INFO] - Data Preprocessing
[2024-10-15 13:29:28,812][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 13:29:28,812][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 13:29:28,812][root][INFO] - ㄴ data_remove                False

[2024-10-15 13:29:28,812][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 13:29:28,820][root][INFO] - vocab size              : 51200
[2024-10-15 13:29:28,820][root][INFO] - device                  : gpu
[2024-10-15 13:29:28,820][root][INFO] - random seed             : 3
[2024-10-15 13:29:28,820][root][INFO] - train data size         : 135040
[2024-10-15 13:29:28,820][root][INFO] - max epochs              : 5
[2024-10-15 13:29:28,820][root][INFO] - total steps             : 10550
[2024-10-15 13:29:28,820][root][INFO] - warmup steps            : 1055
[2024-10-15 13:29:28,820][root][INFO] - batch size              : 64
[2024-10-15 13:29:28,820][root][INFO] - accumulation steps      : 1
[2024-10-15 13:29:28,820][root][INFO] - optimizer               : adamwscale
[2024-10-15 13:29:28,821][root][INFO] - lr_scheduler            : cosine
[2024-10-15 13:29:28,821][root][INFO] - learning rate           : 0.01
[2024-10-15 13:29:28,821][root][INFO] - max length              : 256

[2024-10-15 13:29:28,821][root][INFO] - LoRA Configuration
[2024-10-15 13:29:28,821][root][INFO] - ㄴ r                    : 32
[2024-10-15 13:29:28,821][root][INFO] - ㄴ alpha                : 128
[2024-10-15 13:29:28,821][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 13:29:28,821][root][INFO] - KOMBO Configuration
[2024-10-15 13:29:28,821][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 13:29:28,821][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 13:29:28,821][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 13:29:28,821][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 13:29:28,822][root][INFO] - ㄴ do_combination       : True
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 13:29:28,822][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 13:29:28,822][root][INFO] - 

[2024-10-15 13:29:28,822][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 13:29:28,822][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 13:29:28,822][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 13:29:28,822][root][INFO] - * tb interval   : 10000

[2024-10-15 13:29:28,823][root][INFO] - 

[2024-10-15 13:29:28,823][root][INFO] - Start the Training !
[2024-10-15 13:29:28,826][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 13:47:18,708][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-15 13:48:11,907][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 13:48:11,908][root][INFO] - Score: 86.73 [%]  |  Evaluation Time: 53.19 [s]
[2024-10-15 13:51:08,454][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 13:51:08,454][root][INFO] - Score: 87.03 [%]  |  Evaluation Time: 176.54 [s]
[2024-10-15 13:51:08,455][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 13:51:08,457][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 13:57:37,192][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-15 13:57:47,723][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 13:57:47,724][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.53 [s]
[2024-10-15 13:58:07,970][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 13:58:07,970][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.24 [s]
[2024-10-15 13:58:07,972][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 13:58:12,590][root][INFO] - 

[2024-10-15 13:58:12,590][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 13:58:12,591][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 13:58:12,591][root][INFO] - 

[2024-10-15 13:58:12,591][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 13:58:20,869][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,870][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,871][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,872][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,872][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,873][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,873][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,874][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,874][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,875][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,875][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,876][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,876][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,877][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,877][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,878][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,878][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,879][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,879][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,880][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,882][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,882][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,883][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 13:58:20,883][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 13:58:20,885][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 13:58:20,890][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 13:58:21,095][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 13:58:21,097][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 13:58:21,289][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 13:58:24,568][root][INFO] - 

[2024-10-15 13:58:24,568][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 13:58:24,568][root][INFO] - Data Preprocessing
[2024-10-15 13:58:24,568][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 13:58:24,568][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 13:58:24,568][root][INFO] - ㄴ data_remove                True

[2024-10-15 13:58:24,568][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 13:58:24,576][root][INFO] - vocab size              : 51200
[2024-10-15 13:58:24,576][root][INFO] - device                  : gpu
[2024-10-15 13:58:24,577][root][INFO] - random seed             : 1
[2024-10-15 13:58:24,577][root][INFO] - train data size         : 24256
[2024-10-15 13:58:24,577][root][INFO] - max epochs              : 10
[2024-10-15 13:58:24,577][root][INFO] - total steps             : 3790
[2024-10-15 13:58:24,577][root][INFO] - warmup steps            : 379
[2024-10-15 13:58:24,577][root][INFO] - batch size              : 64
[2024-10-15 13:58:24,577][root][INFO] - accumulation steps      : 1
[2024-10-15 13:58:24,577][root][INFO] - optimizer               : adamwscale
[2024-10-15 13:58:24,577][root][INFO] - lr_scheduler            : cosine
[2024-10-15 13:58:24,578][root][INFO] - learning rate           : 0.01
[2024-10-15 13:58:24,578][root][INFO] - max length              : 256

[2024-10-15 13:58:24,578][root][INFO] - LoRA Configuration
[2024-10-15 13:58:24,578][root][INFO] - ㄴ r                    : 32
[2024-10-15 13:58:24,578][root][INFO] - ㄴ alpha                : 128
[2024-10-15 13:58:24,578][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 13:58:24,578][root][INFO] - KOMBO Configuration
[2024-10-15 13:58:24,578][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 13:58:24,578][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 13:58:24,579][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 13:58:24,579][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 13:58:24,579][root][INFO] - ㄴ do_combination       : True
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 13:58:24,579][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 13:58:24,579][root][INFO] - 

[2024-10-15 13:58:24,580][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 13:58:24,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 13:58:24,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 13:58:24,580][root][INFO] - * tb interval   : 10000

[2024-10-15 13:58:24,580][root][INFO] - 

[2024-10-15 13:58:24,580][root][INFO] - Start the Training !
[2024-10-15 13:58:24,583][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 14:02:03,140][root][INFO] - Step: 379/3790  |  Loss: 0.6989  |  Score: 54.10 [%]  |  Seq Length: 256.0
[2024-10-15 14:02:07,770][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 14:02:07,771][root][INFO] - Score: 58.98 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:02:12,347][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 14:02:12,347][root][INFO] - Score: 56.52 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 14:02:12,348][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 14:02:12,349][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 14:05:54,132][root][INFO] - Step: 758/3790  |  Loss: 0.5957  |  Score: 68.22 [%]  |  Seq Length: 256.0
[2024-10-15 14:05:58,782][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 14:05:58,782][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 14:06:03,405][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 14:06:03,405][root][INFO] - Score: 60.83 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 14:06:03,406][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 14:06:03,408][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 14:09:00,063][root][INFO] - Step: 4220/10550  |  Loss: 0.2911  |  Score: 87.62 [%]  |  Seq Length: 256.0
[2024-10-15 14:09:46,537][root][INFO] - Step: 1137/3790  |  Loss: 0.5221  |  Score: 73.95 [%]  |  Seq Length: 256.0
[2024-10-15 14:09:51,218][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 14:09:51,219][root][INFO] - Score: 65.33 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 14:09:53,385][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 14:09:53,385][root][INFO] - Score: 87.75 [%]  |  Evaluation Time: 53.32 [s]
[2024-10-15 14:09:55,842][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 14:09:55,843][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 14:09:55,844][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 14:09:55,845][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 14:12:50,262][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 14:12:50,263][root][INFO] - Score: 87.94 [%]  |  Evaluation Time: 176.88 [s]
[2024-10-15 14:12:50,264][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 14:12:50,265][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 14:13:39,469][root][INFO] - Step: 1516/3790  |  Loss: 0.4657  |  Score: 77.93 [%]  |  Seq Length: 256.0
[2024-10-15 14:13:44,142][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 14:13:44,143][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 14:13:48,842][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 14:13:48,842][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:13:48,843][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 14:13:48,845][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 14:17:32,263][root][INFO] - Step: 1895/3790  |  Loss: 0.4148  |  Score: 80.71 [%]  |  Seq Length: 256.0
[2024-10-15 14:17:37,022][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 14:17:37,023][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-15 14:17:41,723][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 14:17:41,724][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:17:41,725][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 14:17:41,726][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 14:21:26,145][root][INFO] - Step: 2274/3790  |  Loss: 0.3753  |  Score: 82.87 [%]  |  Seq Length: 256.0
[2024-10-15 14:21:30,797][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 14:21:30,797][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 14:21:35,398][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 14:21:35,398][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 14:21:35,399][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 14:21:35,400][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 14:25:16,186][root][INFO] - Step: 2653/3790  |  Loss: 0.3384  |  Score: 84.64 [%]  |  Seq Length: 256.0
[2024-10-15 14:25:20,875][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 14:25:20,875][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 14:25:25,460][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 14:25:25,460][root][INFO] - Score: 66.65 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 14:25:25,463][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 14:29:08,024][root][INFO] - Step: 3032/3790  |  Loss: 0.3095  |  Score: 86.36 [%]  |  Seq Length: 256.0
[2024-10-15 14:29:12,694][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 14:29:12,694][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 14:29:17,280][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 14:29:17,280][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 14:29:17,282][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 14:30:37,468][root][INFO] - Step: 6330/10550  |  Loss: 0.2529  |  Score: 89.52 [%]  |  Seq Length: 256.0
[2024-10-15 14:31:31,302][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 14:31:31,302][root][INFO] - Score: 88.52 [%]  |  Evaluation Time: 53.83 [s]
[2024-10-15 14:33:00,351][root][INFO] - Step: 3411/3790  |  Loss: 0.2896  |  Score: 87.03 [%]  |  Seq Length: 256.0
[2024-10-15 14:33:05,090][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 14:33:05,090][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 14:33:09,712][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 14:33:09,712][root][INFO] - Score: 66.61 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 14:33:09,715][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 14:34:28,067][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 14:34:28,067][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 176.76 [s]
[2024-10-15 14:34:28,068][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 14:34:28,070][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 14:36:51,898][root][INFO] - Step: 3790/3790  |  Loss: 0.2791  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-15 14:36:56,553][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 14:36:56,554][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 14:37:01,109][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 14:37:01,109][root][INFO] - Score: 67.19 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 14:37:01,110][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 14:37:01,110][root][INFO] - - Epoch: 6
[2024-10-15 14:37:01,110][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 14:37:01,111][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 14:37:01,111][root][INFO] - Fine-tuning is done!
[2024-10-15 14:37:07,953][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,954][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,955][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,955][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,956][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,956][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,957][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,958][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,958][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,959][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,959][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,960][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,961][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,961][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,962][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,962][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,963][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,963][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,964][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,964][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,965][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,965][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,966][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 14:37:07,966][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 14:37:07,968][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 14:37:08,177][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 14:37:08,179][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 14:37:08,180][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 14:37:08,354][root][INFO] - 

[2024-10-15 14:37:08,355][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 14:37:08,355][root][INFO] - Data Preprocessing
[2024-10-15 14:37:08,355][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 14:37:08,355][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 14:37:08,355][root][INFO] - ㄴ data_remove                True

[2024-10-15 14:37:08,355][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 14:37:08,363][root][INFO] - vocab size              : 51200
[2024-10-15 14:37:08,363][root][INFO] - device                  : gpu
[2024-10-15 14:37:08,363][root][INFO] - random seed             : 1
[2024-10-15 14:37:08,363][root][INFO] - train data size         : 24256
[2024-10-15 14:37:08,363][root][INFO] - max epochs              : 10
[2024-10-15 14:37:08,363][root][INFO] - total steps             : 3790
[2024-10-15 14:37:08,364][root][INFO] - warmup steps            : 379
[2024-10-15 14:37:08,364][root][INFO] - batch size              : 64
[2024-10-15 14:37:08,364][root][INFO] - accumulation steps      : 1
[2024-10-15 14:37:08,364][root][INFO] - optimizer               : adamwscale
[2024-10-15 14:37:08,364][root][INFO] - lr_scheduler            : cosine
[2024-10-15 14:37:08,364][root][INFO] - learning rate           : 0.02
[2024-10-15 14:37:08,364][root][INFO] - max length              : 256

[2024-10-15 14:37:08,364][root][INFO] - LoRA Configuration
[2024-10-15 14:37:08,364][root][INFO] - ㄴ r                    : 32
[2024-10-15 14:37:08,364][root][INFO] - ㄴ alpha                : 128
[2024-10-15 14:37:08,364][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 14:37:08,364][root][INFO] - KOMBO Configuration
[2024-10-15 14:37:08,365][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 14:37:08,365][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 14:37:08,365][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 14:37:08,365][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 14:37:08,365][root][INFO] - ㄴ do_combination       : True
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 14:37:08,365][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 14:37:08,366][root][INFO] - 

[2024-10-15 14:37:08,366][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 14:37:08,366][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 14:37:08,366][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 14:37:08,366][root][INFO] - * tb interval   : 10000

[2024-10-15 14:37:08,366][root][INFO] - 

[2024-10-15 14:37:08,366][root][INFO] - Start the Training !
[2024-10-15 14:37:08,368][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 14:40:46,776][root][INFO] - Step: 379/3790  |  Loss: 0.6780  |  Score: 57.60 [%]  |  Seq Length: 256.0
[2024-10-15 14:40:51,460][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 14:40:51,460][root][INFO] - Score: 64.06 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 14:40:56,046][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 14:40:56,046][root][INFO] - Score: 59.82 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 14:40:56,047][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 14:40:56,048][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 14:44:38,353][root][INFO] - Step: 758/3790  |  Loss: 0.5684  |  Score: 70.11 [%]  |  Seq Length: 256.0
[2024-10-15 14:44:43,061][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 14:44:43,062][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:44:47,811][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 14:44:47,811][root][INFO] - Score: 64.67 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 14:44:47,813][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 14:44:47,814][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 14:48:31,535][root][INFO] - Step: 1137/3790  |  Loss: 0.5130  |  Score: 74.31 [%]  |  Seq Length: 256.0
[2024-10-15 14:48:36,200][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 14:48:36,200][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 14:48:40,833][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 14:48:40,834][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:48:40,835][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 14:48:40,836][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 14:49:24,500][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-15 14:52:17,965][root][INFO] - Step: 8440/10550  |  Loss: 0.2170  |  Score: 91.11 [%]  |  Seq Length: 256.0
[2024-10-15 14:52:23,640][root][INFO] - Step: 1516/3790  |  Loss: 0.4611  |  Score: 77.89 [%]  |  Seq Length: 256.0
[2024-10-15 14:52:28,269][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 14:52:28,270][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:52:32,870][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 14:52:32,870][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 14:52:32,871][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 14:52:32,872][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 14:53:11,355][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 14:53:11,355][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 53.39 [s]
[2024-10-15 14:56:08,996][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 14:56:08,996][root][INFO] - Score: 88.79 [%]  |  Evaluation Time: 177.64 [s]
[2024-10-15 14:56:08,997][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 14:56:08,998][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 14:56:15,418][root][INFO] - Step: 1895/3790  |  Loss: 0.4025  |  Score: 81.25 [%]  |  Seq Length: 256.0
[2024-10-15 14:56:20,122][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 14:56:20,122][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 14:56:24,751][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 14:56:24,751][root][INFO] - Score: 65.55 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 14:56:24,754][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 15:00:07,436][root][INFO] - Step: 2274/3790  |  Loss: 0.3566  |  Score: 83.93 [%]  |  Seq Length: 256.0
[2024-10-15 15:00:12,211][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 15:00:12,211][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-15 15:00:16,832][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 15:00:16,832][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:00:16,835][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 15:04:00,200][root][INFO] - Step: 2653/3790  |  Loss: 0.3011  |  Score: 86.48 [%]  |  Seq Length: 256.0
[2024-10-15 15:04:04,938][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 15:04:04,938][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-15 15:04:09,558][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 15:04:09,558][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:04:09,560][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 15:07:52,105][root][INFO] - Step: 3032/3790  |  Loss: 0.2530  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-15 15:07:56,796][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 15:07:56,797][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 15:08:01,427][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 15:08:01,427][root][INFO] - Score: 67.99 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:08:01,429][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 15:09:17,191][root][INFO] - Step: 10000/10550  |  Loss: 0.1949  |  Score: 92.12 [%]  |  Seq Length: 256.0
[2024-10-15 15:11:44,185][root][INFO] - Step: 3411/3790  |  Loss: 0.2240  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-15 15:11:48,875][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 15:11:48,875][root][INFO] - Score: 68.85 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 15:11:53,494][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 15:11:53,494][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:11:53,497][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 15:13:56,354][root][INFO] - Step: 10550/10550  |  Loss: 0.1925  |  Score: 92.37 [%]  |  Seq Length: 256.0
[2024-10-15 15:14:49,739][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 15:14:49,739][root][INFO] - Score: 88.95 [%]  |  Evaluation Time: 53.38 [s]
[2024-10-15 15:15:36,277][root][INFO] - Step: 3790/3790  |  Loss: 0.2060  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-15 15:15:40,907][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 15:15:40,907][root][INFO] - Score: 70.21 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:15:45,484][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 15:15:45,484][root][INFO] - Score: 67.39 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 15:15:45,485][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 15:15:45,485][root][INFO] - - Epoch: 4
[2024-10-15 15:15:45,485][root][INFO] - - DEV score: 70.02 [%]
[2024-10-15 15:15:45,485][root][INFO] - - TEST score: 67.80 [%]
[2024-10-15 15:15:45,487][root][INFO] - Fine-tuning is done!
[2024-10-15 15:15:45,487][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 15:15:45,487][root][INFO] - - BEST LR: 0.01
[2024-10-15 15:15:45,488][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 15:15:45,488][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 15:15:51,682][root][INFO] - 

[2024-10-15 15:15:51,682][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 15:15:51,682][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 15:15:51,682][root][INFO] - 

[2024-10-15 15:15:51,683][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 15:15:59,889][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,890][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,891][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,891][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,892][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,892][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,893][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,893][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,894][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,895][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,895][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,896][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,896][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,897][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,897][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,898][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,898][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,899][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,899][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,900][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,903][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,904][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,904][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 15:15:59,905][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 15:15:59,907][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 15:15:59,912][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 15:16:00,117][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 15:16:00,119][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 15:16:00,306][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 15:16:03,599][root][INFO] - 

[2024-10-15 15:16:03,599][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 15:16:03,599][root][INFO] - Data Preprocessing
[2024-10-15 15:16:03,599][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 15:16:03,599][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 15:16:03,599][root][INFO] - ㄴ data_remove                True

[2024-10-15 15:16:03,599][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 15:16:03,607][root][INFO] - vocab size              : 51200
[2024-10-15 15:16:03,607][root][INFO] - device                  : gpu
[2024-10-15 15:16:03,608][root][INFO] - random seed             : 2
[2024-10-15 15:16:03,608][root][INFO] - train data size         : 24256
[2024-10-15 15:16:03,608][root][INFO] - max epochs              : 10
[2024-10-15 15:16:03,608][root][INFO] - total steps             : 3790
[2024-10-15 15:16:03,608][root][INFO] - warmup steps            : 379
[2024-10-15 15:16:03,608][root][INFO] - batch size              : 64
[2024-10-15 15:16:03,608][root][INFO] - accumulation steps      : 1
[2024-10-15 15:16:03,608][root][INFO] - optimizer               : adamwscale
[2024-10-15 15:16:03,608][root][INFO] - lr_scheduler            : cosine
[2024-10-15 15:16:03,608][root][INFO] - learning rate           : 0.01
[2024-10-15 15:16:03,609][root][INFO] - max length              : 256

[2024-10-15 15:16:03,609][root][INFO] - LoRA Configuration
[2024-10-15 15:16:03,609][root][INFO] - ㄴ r                    : 32
[2024-10-15 15:16:03,609][root][INFO] - ㄴ alpha                : 128
[2024-10-15 15:16:03,609][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 15:16:03,609][root][INFO] - KOMBO Configuration
[2024-10-15 15:16:03,609][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 15:16:03,609][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 15:16:03,609][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 15:16:03,609][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 15:16:03,609][root][INFO] - ㄴ do_combination       : True
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 15:16:03,610][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 15:16:03,610][root][INFO] - 

[2024-10-15 15:16:03,610][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 15:16:03,610][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 15:16:03,610][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 15:16:03,610][root][INFO] - * tb interval   : 10000

[2024-10-15 15:16:03,610][root][INFO] - 

[2024-10-15 15:16:03,610][root][INFO] - Start the Training !
[2024-10-15 15:16:03,614][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 15:17:47,343][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 15:17:47,344][root][INFO] - Score: 88.85 [%]  |  Evaluation Time: 177.60 [s]
[2024-10-15 15:17:47,345][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 15:17:47,345][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 15:17:47,345][root][INFO] - - Epoch: 5
[2024-10-15 15:17:47,345][root][INFO] - - DEV score: 88.95 [%]
[2024-10-15 15:17:47,345][root][INFO] - - TEST score: 88.85 [%]
[2024-10-15 15:17:47,346][root][INFO] - Fine-tuning is done!
[2024-10-15 15:18:09,775][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,776][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,776][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,777][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,778][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,779][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,779][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,780][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,781][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,781][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,782][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,783][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,784][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,784][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,785][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,786][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,786][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,787][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,787][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,788][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,789][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,789][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,790][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 15:18:09,790][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 15:18:09,792][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 15:18:10,072][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 15:18:10,075][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 15:18:10,076][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 15:18:10,295][root][INFO] - 

[2024-10-15 15:18:10,295][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-15 15:18:10,295][root][INFO] - Data Preprocessing
[2024-10-15 15:18:10,295][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 15:18:10,295][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 15:18:10,295][root][INFO] - ㄴ data_remove                False

[2024-10-15 15:18:10,295][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 15:18:10,304][root][INFO] - vocab size              : 51200
[2024-10-15 15:18:10,305][root][INFO] - device                  : gpu
[2024-10-15 15:18:10,305][root][INFO] - random seed             : 3
[2024-10-15 15:18:10,305][root][INFO] - train data size         : 135040
[2024-10-15 15:18:10,305][root][INFO] - max epochs              : 5
[2024-10-15 15:18:10,305][root][INFO] - total steps             : 10550
[2024-10-15 15:18:10,305][root][INFO] - warmup steps            : 1055
[2024-10-15 15:18:10,305][root][INFO] - batch size              : 64
[2024-10-15 15:18:10,305][root][INFO] - accumulation steps      : 1
[2024-10-15 15:18:10,305][root][INFO] - optimizer               : adamwscale
[2024-10-15 15:18:10,306][root][INFO] - lr_scheduler            : cosine
[2024-10-15 15:18:10,306][root][INFO] - learning rate           : 0.02
[2024-10-15 15:18:10,306][root][INFO] - max length              : 256

[2024-10-15 15:18:10,306][root][INFO] - LoRA Configuration
[2024-10-15 15:18:10,306][root][INFO] - ㄴ r                    : 32
[2024-10-15 15:18:10,306][root][INFO] - ㄴ alpha                : 128
[2024-10-15 15:18:10,306][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 15:18:10,306][root][INFO] - KOMBO Configuration
[2024-10-15 15:18:10,306][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 15:18:10,306][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 15:18:10,306][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 15:18:10,307][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 15:18:10,307][root][INFO] - ㄴ do_combination       : True
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 15:18:10,307][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 15:18:10,307][root][INFO] - 

[2024-10-15 15:18:10,307][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-15 15:18:10,307][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 15:18:10,307][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb
[2024-10-15 15:18:10,307][root][INFO] - * tb interval   : 10000

[2024-10-15 15:18:10,308][root][INFO] - 

[2024-10-15 15:18:10,308][root][INFO] - Start the Training !
[2024-10-15 15:18:10,310][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 15:19:45,939][root][INFO] - Step: 379/3790  |  Loss: 0.6820  |  Score: 57.01 [%]  |  Seq Length: 256.0
[2024-10-15 15:19:50,723][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 15:19:50,723][root][INFO] - Score: 62.79 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 15:19:55,319][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 15:19:55,320][root][INFO] - Score: 59.45 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 15:19:55,321][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 15:19:55,323][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 15:23:37,251][root][INFO] - Step: 758/3790  |  Loss: 0.5809  |  Score: 69.35 [%]  |  Seq Length: 256.0
[2024-10-15 15:23:41,938][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 15:23:41,938][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 15:23:46,555][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 15:23:46,555][root][INFO] - Score: 62.75 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 15:23:46,556][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 15:23:46,558][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 15:27:27,272][root][INFO] - Step: 1137/3790  |  Loss: 0.5210  |  Score: 74.19 [%]  |  Seq Length: 256.0
[2024-10-15 15:27:31,904][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 15:27:31,904][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:27:36,469][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 15:27:36,469][root][INFO] - Score: 64.53 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 15:27:36,470][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 15:27:36,471][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 15:31:18,136][root][INFO] - Step: 1516/3790  |  Loss: 0.4662  |  Score: 77.42 [%]  |  Seq Length: 256.0
[2024-10-15 15:31:22,811][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 15:31:22,811][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 15:31:27,409][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 15:31:27,410][root][INFO] - Score: 65.94 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 15:31:27,412][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 15:35:09,188][root][INFO] - Step: 1895/3790  |  Loss: 0.4199  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-15 15:35:13,855][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 15:35:13,855][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 15:35:18,422][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 15:35:18,423][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 15:35:18,424][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 15:35:18,425][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 15:36:03,811][root][INFO] - Step: 2110/10550  |  Loss: 0.3661  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-15 15:36:57,123][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 15:36:57,123][root][INFO] - Score: 86.43 [%]  |  Evaluation Time: 53.31 [s]
[2024-10-15 15:39:00,427][root][INFO] - Step: 2274/3790  |  Loss: 0.3750  |  Score: 82.67 [%]  |  Seq Length: 256.0
[2024-10-15 15:39:05,227][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 15:39:05,228][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 15:39:09,905][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 15:39:09,905][root][INFO] - Score: 66.42 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 15:39:09,908][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 15:39:54,748][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 15:39:54,748][root][INFO] - Score: 86.50 [%]  |  Evaluation Time: 177.62 [s]
[2024-10-15 15:39:54,750][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 15:39:54,751][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 15:42:51,759][root][INFO] - Step: 2653/3790  |  Loss: 0.3405  |  Score: 84.53 [%]  |  Seq Length: 256.0
[2024-10-15 15:42:56,422][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 15:42:56,423][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 15:43:00,981][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 15:43:00,981][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 15:43:00,983][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 15:46:40,218][root][INFO] - Step: 3032/3790  |  Loss: 0.3098  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-15 15:46:44,808][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 15:46:44,808][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 15:46:49,314][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 15:46:49,314][root][INFO] - Score: 68.67 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-15 15:46:49,315][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 15:46:49,316][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 15:50:33,653][root][INFO] - Step: 3411/3790  |  Loss: 0.2952  |  Score: 86.68 [%]  |  Seq Length: 256.0
[2024-10-15 15:50:38,278][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 15:50:38,278][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 15:50:42,803][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 15:50:42,803][root][INFO] - Score: 67.27 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 15:50:42,805][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 15:54:25,191][root][INFO] - Step: 3790/3790  |  Loss: 0.2806  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-15 15:54:29,828][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 15:54:29,828][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:54:34,398][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 15:54:34,398][root][INFO] - Score: 68.42 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 15:54:34,399][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 15:54:34,400][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 15:54:34,400][root][INFO] - - Epoch: 10
[2024-10-15 15:54:34,400][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 15:54:34,400][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 15:54:34,400][root][INFO] - Fine-tuning is done!
[2024-10-15 15:54:41,173][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,174][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,175][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,175][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,176][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,177][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,177][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,178][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,178][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,179][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,179][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,180][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,181][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,181][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,182][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,182][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,183][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,183][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,184][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,184][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,185][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,185][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,186][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 15:54:41,186][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 15:54:41,188][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 15:54:41,395][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 15:54:41,397][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 15:54:41,398][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 15:54:41,568][root][INFO] - 

[2024-10-15 15:54:41,568][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 15:54:41,568][root][INFO] - Data Preprocessing
[2024-10-15 15:54:41,569][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 15:54:41,569][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 15:54:41,569][root][INFO] - ㄴ data_remove                True

[2024-10-15 15:54:41,569][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 15:54:41,577][root][INFO] - vocab size              : 51200
[2024-10-15 15:54:41,577][root][INFO] - device                  : gpu
[2024-10-15 15:54:41,577][root][INFO] - random seed             : 2
[2024-10-15 15:54:41,577][root][INFO] - train data size         : 24256
[2024-10-15 15:54:41,577][root][INFO] - max epochs              : 10
[2024-10-15 15:54:41,577][root][INFO] - total steps             : 3790
[2024-10-15 15:54:41,577][root][INFO] - warmup steps            : 379
[2024-10-15 15:54:41,577][root][INFO] - batch size              : 64
[2024-10-15 15:54:41,578][root][INFO] - accumulation steps      : 1
[2024-10-15 15:54:41,578][root][INFO] - optimizer               : adamwscale
[2024-10-15 15:54:41,578][root][INFO] - lr_scheduler            : cosine
[2024-10-15 15:54:41,578][root][INFO] - learning rate           : 0.02
[2024-10-15 15:54:41,578][root][INFO] - max length              : 256

[2024-10-15 15:54:41,578][root][INFO] - LoRA Configuration
[2024-10-15 15:54:41,578][root][INFO] - ㄴ r                    : 32
[2024-10-15 15:54:41,578][root][INFO] - ㄴ alpha                : 128
[2024-10-15 15:54:41,578][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 15:54:41,578][root][INFO] - KOMBO Configuration
[2024-10-15 15:54:41,578][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 15:54:41,579][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 15:54:41,579][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 15:54:41,579][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 15:54:41,579][root][INFO] - ㄴ do_combination       : True
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 15:54:41,579][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 15:54:41,579][root][INFO] - 

[2024-10-15 15:54:41,579][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 15:54:41,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 15:54:41,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 15:54:41,580][root][INFO] - * tb interval   : 10000

[2024-10-15 15:54:41,580][root][INFO] - 

[2024-10-15 15:54:41,580][root][INFO] - Start the Training !
[2024-10-15 15:54:41,582][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 15:57:44,068][root][INFO] - Step: 4220/10550  |  Loss: 0.3149  |  Score: 86.50 [%]  |  Seq Length: 256.0
[2024-10-15 15:58:24,547][root][INFO] - Step: 379/3790  |  Loss: 0.6703  |  Score: 59.12 [%]  |  Seq Length: 256.0
[2024-10-15 15:58:29,297][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 15:58:29,297][root][INFO] - Score: 66.41 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 15:58:33,928][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 15:58:33,928][root][INFO] - Score: 59.91 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 15:58:33,930][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 15:58:33,931][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 15:58:37,184][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 15:58:37,184][root][INFO] - Score: 87.29 [%]  |  Evaluation Time: 53.11 [s]
[2024-10-15 16:01:33,146][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 16:01:33,147][root][INFO] - Score: 87.03 [%]  |  Evaluation Time: 175.96 [s]
[2024-10-15 16:01:33,148][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 16:01:33,149][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 16:02:16,818][root][INFO] - Step: 758/3790  |  Loss: 0.5669  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-15 16:02:21,611][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 16:02:21,611][root][INFO] - Score: 67.58 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 16:02:26,248][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 16:02:26,248][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 16:02:26,249][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 16:02:26,250][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 16:06:09,275][root][INFO] - Step: 1137/3790  |  Loss: 0.5082  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-15 16:06:14,015][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 16:06:14,015][root][INFO] - Score: 65.53 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-15 16:06:18,737][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 16:06:18,737][root][INFO] - Score: 67.04 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 16:06:18,739][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 16:08:25,851][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-15 16:08:36,173][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:08:36,173][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.32 [s]
[2024-10-15 16:08:56,360][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:08:56,360][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.18 [s]
[2024-10-15 16:08:56,363][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 16:10:01,824][root][INFO] - Step: 1516/3790  |  Loss: 0.4569  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-15 16:10:06,671][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:10:06,672][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-15 16:10:11,348][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:10:11,348][root][INFO] - Score: 66.84 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 16:10:11,349][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 16:10:11,350][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 16:13:54,775][root][INFO] - Step: 1895/3790  |  Loss: 0.4079  |  Score: 81.11 [%]  |  Seq Length: 256.0
[2024-10-15 16:13:59,495][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 16:13:59,495][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 16:14:04,231][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 16:14:04,232][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 16:14:04,233][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 16:14:04,234][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 16:17:47,048][root][INFO] - Step: 2274/3790  |  Loss: 0.3487  |  Score: 84.15 [%]  |  Seq Length: 256.0
[2024-10-15 16:17:51,877][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 16:17:51,878][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-15 16:17:56,589][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 16:17:56,589][root][INFO] - Score: 68.03 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 16:17:56,591][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 16:17:56,592][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 16:18:22,910][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-15 16:19:25,244][root][INFO] - Step: 6330/10550  |  Loss: 0.2820  |  Score: 88.07 [%]  |  Seq Length: 256.0
[2024-10-15 16:20:18,572][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 16:20:18,572][root][INFO] - Score: 88.03 [%]  |  Evaluation Time: 53.33 [s]
[2024-10-15 16:21:40,276][root][INFO] - Step: 2653/3790  |  Loss: 0.2954  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-15 16:21:45,055][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 16:21:45,055][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 16:21:49,743][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 16:21:49,743][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 16:21:49,745][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-15 16:21:49,746][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 16:23:15,825][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 16:23:15,825][root][INFO] - Score: 87.82 [%]  |  Evaluation Time: 177.25 [s]
[2024-10-15 16:23:15,826][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 16:23:15,827][root][INFO] - 
[4/ 5 Epoch]
[2024-10-15 16:25:34,098][root][INFO] - Step: 3032/3790  |  Loss: 0.2463  |  Score: 89.20 [%]  |  Seq Length: 256.0
[2024-10-15 16:25:38,921][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 16:25:38,922][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-15 16:25:43,707][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 16:25:43,708][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 16:25:43,712][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 16:29:26,372][root][INFO] - Step: 3411/3790  |  Loss: 0.2186  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-15 16:29:31,074][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 16:29:31,074][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 16:29:35,713][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 16:29:35,713][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 16:29:35,715][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 16:33:18,260][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-15 16:33:22,960][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 16:33:22,960][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 16:33:27,712][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 16:33:27,713][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 16:33:27,714][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 16:33:27,714][root][INFO] - - Epoch: 7
[2024-10-15 16:33:27,714][root][INFO] - - DEV score: 71.29 [%]
[2024-10-15 16:33:27,715][root][INFO] - - TEST score: 69.32 [%]
[2024-10-15 16:33:27,716][root][INFO] - Fine-tuning is done!
[2024-10-15 16:33:27,716][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 16:33:27,716][root][INFO] - - BEST LR: 0.01
[2024-10-15 16:33:27,716][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 16:33:27,716][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 16:33:34,156][root][INFO] - 

[2024-10-15 16:33:34,156][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 16:33:34,156][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 16:33:34,156][root][INFO] - 

[2024-10-15 16:33:34,157][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 16:33:42,711][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,712][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,712][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,713][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,713][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,714][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,714][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,715][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,716][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,716][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,717][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,717][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,718][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,718][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,719][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,720][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,720][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,721][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,721][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,722][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,724][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,724][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,725][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 16:33:42,726][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 16:33:42,728][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 16:33:42,733][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 16:33:42,941][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 16:33:42,944][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 16:33:43,130][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 16:33:46,095][root][INFO] - 

[2024-10-15 16:33:46,095][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 16:33:46,095][root][INFO] - Data Preprocessing
[2024-10-15 16:33:46,095][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 16:33:46,095][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 16:33:46,095][root][INFO] - ㄴ data_remove                True

[2024-10-15 16:33:46,095][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 16:33:46,103][root][INFO] - vocab size              : 51200
[2024-10-15 16:33:46,103][root][INFO] - device                  : gpu
[2024-10-15 16:33:46,103][root][INFO] - random seed             : 3
[2024-10-15 16:33:46,103][root][INFO] - train data size         : 24256
[2024-10-15 16:33:46,104][root][INFO] - max epochs              : 10
[2024-10-15 16:33:46,104][root][INFO] - total steps             : 3790
[2024-10-15 16:33:46,104][root][INFO] - warmup steps            : 379
[2024-10-15 16:33:46,104][root][INFO] - batch size              : 64
[2024-10-15 16:33:46,104][root][INFO] - accumulation steps      : 1
[2024-10-15 16:33:46,104][root][INFO] - optimizer               : adamwscale
[2024-10-15 16:33:46,104][root][INFO] - lr_scheduler            : cosine
[2024-10-15 16:33:46,104][root][INFO] - learning rate           : 0.01
[2024-10-15 16:33:46,104][root][INFO] - max length              : 256

[2024-10-15 16:33:46,104][root][INFO] - LoRA Configuration
[2024-10-15 16:33:46,104][root][INFO] - ㄴ r                    : 32
[2024-10-15 16:33:46,104][root][INFO] - ㄴ alpha                : 128
[2024-10-15 16:33:46,105][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 16:33:46,105][root][INFO] - KOMBO Configuration
[2024-10-15 16:33:46,105][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 16:33:46,105][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 16:33:46,105][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 16:33:46,105][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 16:33:46,105][root][INFO] - ㄴ do_combination       : True
[2024-10-15 16:33:46,105][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 16:33:46,105][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 16:33:46,105][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 16:33:46,106][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 16:33:46,106][root][INFO] - 

[2024-10-15 16:33:46,106][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 16:33:46,106][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 16:33:46,106][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 16:33:46,106][root][INFO] - * tb interval   : 10000

[2024-10-15 16:33:46,106][root][INFO] - 

[2024-10-15 16:33:46,106][root][INFO] - Start the Training !
[2024-10-15 16:33:46,109][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 16:37:29,820][root][INFO] - Step: 379/3790  |  Loss: 0.6791  |  Score: 57.91 [%]  |  Seq Length: 256.0
[2024-10-15 16:37:34,480][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 16:37:34,480][root][INFO] - Score: 61.13 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 16:37:39,051][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 16:37:39,051][root][INFO] - Score: 60.72 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 16:37:39,052][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 16:37:39,053][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 16:41:10,836][root][INFO] - Step: 8440/10550  |  Loss: 0.2389  |  Score: 90.16 [%]  |  Seq Length: 256.0
[2024-10-15 16:41:22,603][root][INFO] - Step: 758/3790  |  Loss: 0.5750  |  Score: 69.89 [%]  |  Seq Length: 256.0
[2024-10-15 16:41:27,302][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 16:41:27,302][root][INFO] - Score: 66.02 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 16:41:32,037][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 16:41:32,037][root][INFO] - Score: 64.05 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 16:41:32,039][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 16:41:32,040][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 16:42:05,028][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:42:05,029][root][INFO] - Score: 88.90 [%]  |  Evaluation Time: 54.19 [s]
[2024-10-15 16:45:02,446][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:45:02,447][root][INFO] - Score: 88.55 [%]  |  Evaluation Time: 177.42 [s]
[2024-10-15 16:45:02,448][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 16:45:02,449][root][INFO] - 
[5/ 5 Epoch]
[2024-10-15 16:45:15,031][root][INFO] - Step: 1137/3790  |  Loss: 0.5122  |  Score: 74.67 [%]  |  Seq Length: 256.0
[2024-10-15 16:45:19,677][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 16:45:19,678][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 16:45:24,426][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 16:45:24,426][root][INFO] - Score: 64.39 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 16:45:24,427][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 16:45:24,429][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 16:49:06,695][root][INFO] - Step: 1516/3790  |  Loss: 0.4581  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-15 16:49:11,391][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 16:49:11,391][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 16:49:16,026][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 16:49:16,026][root][INFO] - Score: 63.62 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 16:49:16,029][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 16:52:59,474][root][INFO] - Step: 1895/3790  |  Loss: 0.4133  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-15 16:53:04,192][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 16:53:04,192][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 16:53:08,791][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 16:53:08,791][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 16:53:08,792][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 16:53:08,794][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 16:56:51,971][root][INFO] - Step: 2274/3790  |  Loss: 0.3714  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-15 16:56:56,666][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 16:56:56,667][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 16:57:01,303][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 16:57:01,303][root][INFO] - Score: 65.54 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 16:57:01,305][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 16:58:11,437][root][INFO] - Step: 10000/10550  |  Loss: 0.1991  |  Score: 91.97 [%]  |  Seq Length: 256.0
[2024-10-15 17:00:47,463][root][INFO] - Step: 2653/3790  |  Loss: 0.3333  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-15 17:00:52,179][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 17:00:52,179][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 17:00:56,783][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 17:00:56,783][root][INFO] - Score: 65.60 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 17:00:56,785][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 17:02:51,862][root][INFO] - Step: 10550/10550  |  Loss: 0.1941  |  Score: 92.22 [%]  |  Seq Length: 256.0
[2024-10-15 17:03:45,782][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 17:03:45,782][root][INFO] - Score: 88.90 [%]  |  Evaluation Time: 53.92 [s]
[2024-10-15 17:04:40,659][root][INFO] - Step: 3032/3790  |  Loss: 0.3040  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-15 17:04:45,360][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 17:04:45,360][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 17:04:49,997][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 17:04:49,997][root][INFO] - Score: 66.08 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 17:04:49,998][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 17:04:50,000][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 17:06:43,942][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 17:06:43,942][root][INFO] - Score: 88.72 [%]  |  Evaluation Time: 178.16 [s]
[2024-10-15 17:06:43,944][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 17:06:43,944][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 17:06:43,944][root][INFO] - - Epoch: 5
[2024-10-15 17:06:43,944][root][INFO] - - DEV score: 88.90 [%]
[2024-10-15 17:06:43,944][root][INFO] - - TEST score: 88.72 [%]
[2024-10-15 17:06:43,945][root][INFO] - Fine-tuning is done!
[2024-10-15 17:06:43,945][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 17:06:43,946][root][INFO] - - BEST LR: 0.01
[2024-10-15 17:06:43,946][root][INFO] - - DEV score: 88.95 [%]
[2024-10-15 17:06:43,946][root][INFO] - - TEST score: 88.85 [%]
[2024-10-15 17:08:33,131][root][INFO] - Step: 3411/3790  |  Loss: 0.2838  |  Score: 87.23 [%]  |  Seq Length: 256.0
[2024-10-15 17:08:37,821][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 17:08:37,822][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 17:08:42,402][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 17:08:42,402][root][INFO] - Score: 65.73 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 17:08:42,404][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 17:12:25,809][root][INFO] - Step: 3790/3790  |  Loss: 0.2712  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-15 17:12:30,572][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 17:12:30,572][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-15 17:12:35,152][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 17:12:35,152][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 17:12:35,153][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 17:12:35,153][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 17:12:35,153][root][INFO] - - Epoch: 10
[2024-10-15 17:12:35,154][root][INFO] - - DEV score: 72.85 [%]
[2024-10-15 17:12:35,154][root][INFO] - - TEST score: 65.70 [%]
[2024-10-15 17:12:35,154][root][INFO] - Fine-tuning is done!
[2024-10-15 17:12:42,164][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,164][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,165][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,166][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,167][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,168][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,169][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,170][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,170][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,171][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,172][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,173][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,175][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,176][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,177][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,178][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,179][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,180][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,181][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,183][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,184][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,186][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,187][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 17:12:42,188][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 17:12:42,191][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 17:12:42,420][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 17:12:42,423][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 17:12:42,424][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 17:12:42,540][root][INFO] - 

[2024-10-15 17:12:42,540][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 17:12:42,540][root][INFO] - Data Preprocessing
[2024-10-15 17:12:42,540][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 17:12:42,541][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 17:12:42,541][root][INFO] - ㄴ data_remove                True

[2024-10-15 17:12:42,541][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 17:12:42,549][root][INFO] - vocab size              : 51200
[2024-10-15 17:12:42,550][root][INFO] - device                  : gpu
[2024-10-15 17:12:42,550][root][INFO] - random seed             : 3
[2024-10-15 17:12:42,550][root][INFO] - train data size         : 24256
[2024-10-15 17:12:42,550][root][INFO] - max epochs              : 10
[2024-10-15 17:12:42,550][root][INFO] - total steps             : 3790
[2024-10-15 17:12:42,550][root][INFO] - warmup steps            : 379
[2024-10-15 17:12:42,550][root][INFO] - batch size              : 64
[2024-10-15 17:12:42,550][root][INFO] - accumulation steps      : 1
[2024-10-15 17:12:42,550][root][INFO] - optimizer               : adamwscale
[2024-10-15 17:12:42,550][root][INFO] - lr_scheduler            : cosine
[2024-10-15 17:12:42,551][root][INFO] - learning rate           : 0.02
[2024-10-15 17:12:42,551][root][INFO] - max length              : 256

[2024-10-15 17:12:42,551][root][INFO] - LoRA Configuration
[2024-10-15 17:12:42,551][root][INFO] - ㄴ r                    : 32
[2024-10-15 17:12:42,551][root][INFO] - ㄴ alpha                : 128
[2024-10-15 17:12:42,551][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 17:12:42,551][root][INFO] - KOMBO Configuration
[2024-10-15 17:12:42,551][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 17:12:42,551][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 17:12:42,551][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 17:12:42,551][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 17:12:42,552][root][INFO] - ㄴ do_combination       : True
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 17:12:42,552][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 17:12:42,552][root][INFO] - 

[2024-10-15 17:12:42,552][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 17:12:42,552][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 17:12:42,552][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 17:12:42,552][root][INFO] - * tb interval   : 10000

[2024-10-15 17:12:42,553][root][INFO] - 

[2024-10-15 17:12:42,553][root][INFO] - Start the Training !
[2024-10-15 17:12:42,555][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 17:16:26,251][root][INFO] - Step: 379/3790  |  Loss: 0.6607  |  Score: 60.10 [%]  |  Seq Length: 256.0
[2024-10-15 17:16:31,025][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 17:16:31,025][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-15 17:16:35,704][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 17:16:35,704][root][INFO] - Score: 60.64 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 17:16:35,706][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 17:16:35,707][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 17:20:19,572][root][INFO] - Step: 758/3790  |  Loss: 0.5616  |  Score: 71.12 [%]  |  Seq Length: 256.0
[2024-10-15 17:20:24,455][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 17:20:24,455][root][INFO] - Score: 65.04 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-15 17:20:29,239][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 17:20:29,239][root][INFO] - Score: 62.68 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 17:20:29,242][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 17:24:12,865][root][INFO] - Step: 1137/3790  |  Loss: 0.4997  |  Score: 75.63 [%]  |  Seq Length: 256.0
[2024-10-15 17:24:17,671][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 17:24:17,671][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 17:24:22,362][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 17:24:22,362][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 17:24:22,363][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 17:24:22,365][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 17:28:04,185][root][INFO] - Step: 1516/3790  |  Loss: 0.4472  |  Score: 78.90 [%]  |  Seq Length: 256.0
[2024-10-15 17:28:08,985][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 17:28:08,985][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 17:28:13,721][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 17:28:13,721][root][INFO] - Score: 66.80 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 17:28:13,722][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 17:28:13,723][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 17:31:55,978][root][INFO] - Step: 1895/3790  |  Loss: 0.3977  |  Score: 81.23 [%]  |  Seq Length: 256.0
[2024-10-15 17:32:00,786][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 17:32:00,786][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 17:32:05,496][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 17:32:05,496][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 17:32:05,497][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 17:32:05,498][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 17:35:48,362][root][INFO] - Step: 2274/3790  |  Loss: 0.3445  |  Score: 84.26 [%]  |  Seq Length: 256.0
[2024-10-15 17:35:53,171][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 17:35:53,171][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-15 17:35:57,843][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 17:35:57,843][root][INFO] - Score: 66.36 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 17:35:57,845][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 17:39:40,291][root][INFO] - Step: 2653/3790  |  Loss: 0.2995  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-15 17:39:45,075][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 17:39:45,075][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 17:39:49,796][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 17:39:49,796][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 17:39:49,798][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 17:43:33,180][root][INFO] - Step: 3032/3790  |  Loss: 0.2495  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-15 17:43:37,947][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 17:43:37,947][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-15 17:43:42,676][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 17:43:42,676][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 17:43:42,677][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 17:43:42,679][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 17:46:47,228][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.26 [%]  |  Seq Length: 256.0
[2024-10-15 17:47:25,057][root][INFO] - Step: 3411/3790  |  Loss: 0.2111  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-15 17:47:29,786][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 17:47:29,787][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 17:47:34,536][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 17:47:34,536][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 17:47:34,538][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 17:51:16,233][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.52 [%]  |  Seq Length: 256.0
[2024-10-15 17:51:21,023][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 17:51:21,023][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 17:51:25,715][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 17:51:25,715][root][INFO] - Score: 68.36 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 17:51:25,716][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 17:51:25,716][root][INFO] - - Epoch: 8
[2024-10-15 17:51:25,716][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 17:51:25,716][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 17:51:25,717][root][INFO] - Fine-tuning is done!
[2024-10-15 17:51:25,718][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 17:51:25,718][root][INFO] - - BEST LR: 0.02
[2024-10-15 17:51:25,718][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 17:51:25,718][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 18:19:01,863][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.45 [%]  |  Seq Length: 256.0
[2024-10-15 18:19:12,079][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 18:19:12,080][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.21 [s]
[2024-10-15 18:19:32,065][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 18:19:32,065][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 19.98 [s]
[2024-10-15 18:19:32,066][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 18:19:32,066][root][INFO] - - Epoch: 1
[2024-10-15 18:19:32,066][root][INFO] - - DEV score: 56.10 [%]
[2024-10-15 18:19:32,066][root][INFO] - - TEST score: 56.93 [%]
[2024-10-15 18:19:32,067][root][INFO] - Fine-tuning is done!
[2024-10-15 18:19:32,068][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 18:19:32,068][root][INFO] - - BEST LR: 0.01
[2024-10-15 18:19:32,068][root][INFO] - - DEV score: 74.99 [%]
[2024-10-15 18:19:32,068][root][INFO] - - TEST score: 76.27 [%]
[2024-10-15 18:19:38,593][root][INFO] - 

[2024-10-15 18:19:38,594][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 18:19:38,594][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-15 18:19:38,594][root][INFO] - 

[2024-10-15 18:19:38,594][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 18:21:41,254][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,255][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,255][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,256][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,256][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,257][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,257][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,258][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,258][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,259][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,259][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,260][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,260][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,261][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,261][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,262][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,262][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,263][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,263][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,264][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,264][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,265][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,265][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 18:21:41,266][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 18:21:41,268][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-15 18:21:41,272][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 18:21:41,471][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 18:21:41,473][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-15 18:21:41,746][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 18:21:44,907][root][INFO] - 

[2024-10-15 18:21:44,907][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-15 18:21:44,907][root][INFO] - Data Preprocessing
[2024-10-15 18:21:44,907][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-15 18:21:44,908][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 18:21:44,908][root][INFO] - ㄴ data_remove                False

[2024-10-15 18:21:44,908][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 18:21:44,915][root][INFO] - vocab size              : 51200
[2024-10-15 18:21:44,915][root][INFO] - device                  : gpu
[2024-10-15 18:21:44,916][root][INFO] - random seed             : 2
[2024-10-15 18:21:44,916][root][INFO] - train data size         : 942912
[2024-10-15 18:21:44,916][root][INFO] - max epochs              : 5
[2024-10-15 18:21:44,916][root][INFO] - total steps             : 73665
[2024-10-15 18:21:44,916][root][INFO] - warmup steps            : 7366
[2024-10-15 18:21:44,916][root][INFO] - batch size              : 64
[2024-10-15 18:21:44,916][root][INFO] - accumulation steps      : 1
[2024-10-15 18:21:44,916][root][INFO] - optimizer               : adamwscale
[2024-10-15 18:21:44,916][root][INFO] - lr_scheduler            : cosine
[2024-10-15 18:21:44,916][root][INFO] - learning rate           : 0.01
[2024-10-15 18:21:44,916][root][INFO] - max length              : 256

[2024-10-15 18:21:44,916][root][INFO] - LoRA Configuration
[2024-10-15 18:21:44,917][root][INFO] - ㄴ r                    : 32
[2024-10-15 18:21:44,917][root][INFO] - ㄴ alpha                : 128
[2024-10-15 18:21:44,917][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 18:21:44,917][root][INFO] - KOMBO Configuration
[2024-10-15 18:21:44,917][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 18:21:44,917][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 18:21:44,917][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 18:21:44,917][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 18:21:44,917][root][INFO] - ㄴ do_combination       : True
[2024-10-15 18:21:44,917][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 18:21:44,918][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 18:21:44,918][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 18:21:44,918][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 18:21:44,918][root][INFO] - 

[2024-10-15 18:21:44,918][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-15 18:21:44,918][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 18:21:44,918][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb
[2024-10-15 18:21:44,918][root][INFO] - * tb interval   : 10000

[2024-10-15 18:21:44,918][root][INFO] - 

[2024-10-15 18:21:44,918][root][INFO] - Start the Training !
[2024-10-15 18:21:44,921][root][INFO] - 
[1/ 5 Epoch]
[2024-10-15 19:46:05,733][root][INFO] - 

[2024-10-15 19:46:05,733][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 19:46:05,733][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 19:46:05,733][root][INFO] - 

[2024-10-15 19:46:05,733][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 19:46:13,476][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,477][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,477][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,478][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,479][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,479][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,479][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,480][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,480][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,481][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,481][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,482][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,482][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,483][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,483][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,484][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,484][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,485][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,485][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,485][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,487][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,487][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,488][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 19:46:13,488][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 19:46:13,490][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 19:46:13,494][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 19:46:13,732][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 19:46:13,734][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 19:46:13,912][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 19:46:16,998][root][INFO] - 

[2024-10-15 19:46:16,999][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 19:46:16,999][root][INFO] - Data Preprocessing
[2024-10-15 19:46:16,999][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 19:46:16,999][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 19:46:16,999][root][INFO] - ㄴ data_remove                True

[2024-10-15 19:46:16,999][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 19:46:17,007][root][INFO] - vocab size              : 51200
[2024-10-15 19:46:17,008][root][INFO] - device                  : gpu
[2024-10-15 19:46:17,008][root][INFO] - random seed             : 1
[2024-10-15 19:46:17,008][root][INFO] - train data size         : 24256
[2024-10-15 19:46:17,008][root][INFO] - max epochs              : 10
[2024-10-15 19:46:17,008][root][INFO] - total steps             : 3790
[2024-10-15 19:46:17,008][root][INFO] - warmup steps            : 379
[2024-10-15 19:46:17,008][root][INFO] - batch size              : 64
[2024-10-15 19:46:17,008][root][INFO] - accumulation steps      : 1
[2024-10-15 19:46:17,008][root][INFO] - optimizer               : adamwscale
[2024-10-15 19:46:17,009][root][INFO] - lr_scheduler            : cosine
[2024-10-15 19:46:17,009][root][INFO] - learning rate           : 0.01
[2024-10-15 19:46:17,009][root][INFO] - max length              : 256

[2024-10-15 19:46:17,009][root][INFO] - LoRA Configuration
[2024-10-15 19:46:17,009][root][INFO] - ㄴ r                    : 32
[2024-10-15 19:46:17,009][root][INFO] - ㄴ alpha                : 128
[2024-10-15 19:46:17,009][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 19:46:17,009][root][INFO] - KOMBO Configuration
[2024-10-15 19:46:17,009][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 19:46:17,009][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 19:46:17,009][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 19:46:17,010][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 19:46:17,010][root][INFO] - ㄴ do_combination       : True
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 19:46:17,010][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 19:46:17,010][root][INFO] - 

[2024-10-15 19:46:17,010][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 19:46:17,010][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 19:46:17,011][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 19:46:17,011][root][INFO] - * tb interval   : 10000

[2024-10-15 19:46:17,011][root][INFO] - 

[2024-10-15 19:46:17,011][root][INFO] - Start the Training !
[2024-10-15 19:46:17,014][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 19:49:57,912][root][INFO] - Step: 379/3790  |  Loss: 0.6989  |  Score: 54.10 [%]  |  Seq Length: 256.0
[2024-10-15 19:50:02,526][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 19:50:02,526][root][INFO] - Score: 58.98 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 19:50:07,049][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 19:50:07,049][root][INFO] - Score: 56.52 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 19:50:07,050][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 19:50:07,051][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 19:50:12,524][root][INFO] - Step: 10000/73665  |  Loss: 0.7335  |  Score: 68.28 [%]  |  Seq Length: 256.0
[2024-10-15 19:53:48,351][root][INFO] - Step: 758/3790  |  Loss: 0.5957  |  Score: 68.22 [%]  |  Seq Length: 256.0
[2024-10-15 19:53:52,961][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 19:53:52,961][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 19:53:57,481][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 19:53:57,482][root][INFO] - Score: 60.83 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 19:53:57,483][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 19:53:57,485][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 19:57:38,783][root][INFO] - Step: 1137/3790  |  Loss: 0.5221  |  Score: 73.95 [%]  |  Seq Length: 256.0
[2024-10-15 19:57:43,466][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 19:57:43,466][root][INFO] - Score: 65.33 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 19:57:48,016][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 19:57:48,016][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 19:57:48,017][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 19:57:48,019][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 20:01:29,338][root][INFO] - Step: 1516/3790  |  Loss: 0.4657  |  Score: 77.93 [%]  |  Seq Length: 256.0
[2024-10-15 20:01:34,118][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 20:01:34,118][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 20:01:38,691][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 20:01:38,691][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 20:01:38,692][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 20:01:38,694][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 20:05:20,689][root][INFO] - Step: 1895/3790  |  Loss: 0.4148  |  Score: 80.71 [%]  |  Seq Length: 256.0
[2024-10-15 20:05:25,337][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 20:05:25,337][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 20:05:29,889][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 20:05:29,890][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 20:05:29,891][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 20:05:29,892][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 20:09:11,853][root][INFO] - Step: 2274/3790  |  Loss: 0.3753  |  Score: 82.87 [%]  |  Seq Length: 256.0
[2024-10-15 20:09:16,492][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 20:09:16,492][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 20:09:21,058][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 20:09:21,058][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 20:09:21,059][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 20:09:21,061][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 20:13:02,907][root][INFO] - Step: 2653/3790  |  Loss: 0.3384  |  Score: 84.64 [%]  |  Seq Length: 256.0
[2024-10-15 20:13:07,531][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 20:13:07,532][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 20:13:12,081][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 20:13:12,081][root][INFO] - Score: 66.65 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 20:13:12,083][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 20:16:53,765][root][INFO] - Step: 3032/3790  |  Loss: 0.3095  |  Score: 86.36 [%]  |  Seq Length: 256.0
[2024-10-15 20:16:58,433][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 20:16:58,433][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:17:02,987][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 20:17:02,987][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 20:17:02,990][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 20:20:46,227][root][INFO] - Step: 3411/3790  |  Loss: 0.2896  |  Score: 87.03 [%]  |  Seq Length: 256.0
[2024-10-15 20:20:50,859][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 20:20:50,859][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 20:20:55,394][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 20:20:55,394][root][INFO] - Score: 66.61 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-15 20:20:55,397][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 20:24:37,315][root][INFO] - Step: 3790/3790  |  Loss: 0.2791  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-15 20:24:41,930][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 20:24:41,930][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 20:24:46,490][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 20:24:46,490][root][INFO] - Score: 67.19 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 20:24:46,491][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 20:24:46,491][root][INFO] - - Epoch: 6
[2024-10-15 20:24:46,491][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 20:24:46,491][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 20:24:46,492][root][INFO] - Fine-tuning is done!
[2024-10-15 20:24:53,270][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,271][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,271][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,272][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,272][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,273][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,274][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,274][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,275][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,275][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,276][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,277][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,277][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,278][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,279][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,279][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,279][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,280][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,280][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,281][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,281][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,281][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,282][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 20:24:53,282][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 20:24:53,284][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 20:24:53,509][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 20:24:53,511][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 20:24:53,513][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 20:24:53,682][root][INFO] - 

[2024-10-15 20:24:53,683][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 20:24:53,683][root][INFO] - Data Preprocessing
[2024-10-15 20:24:53,683][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 20:24:53,683][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 20:24:53,683][root][INFO] - ㄴ data_remove                True

[2024-10-15 20:24:53,683][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 20:24:53,692][root][INFO] - vocab size              : 51200
[2024-10-15 20:24:53,692][root][INFO] - device                  : gpu
[2024-10-15 20:24:53,693][root][INFO] - random seed             : 1
[2024-10-15 20:24:53,693][root][INFO] - train data size         : 24256
[2024-10-15 20:24:53,693][root][INFO] - max epochs              : 10
[2024-10-15 20:24:53,693][root][INFO] - total steps             : 3790
[2024-10-15 20:24:53,693][root][INFO] - warmup steps            : 379
[2024-10-15 20:24:53,693][root][INFO] - batch size              : 64
[2024-10-15 20:24:53,693][root][INFO] - accumulation steps      : 1
[2024-10-15 20:24:53,693][root][INFO] - optimizer               : adamwscale
[2024-10-15 20:24:53,693][root][INFO] - lr_scheduler            : cosine
[2024-10-15 20:24:53,693][root][INFO] - learning rate           : 0.02
[2024-10-15 20:24:53,693][root][INFO] - max length              : 256

[2024-10-15 20:24:53,693][root][INFO] - LoRA Configuration
[2024-10-15 20:24:53,694][root][INFO] - ㄴ r                    : 32
[2024-10-15 20:24:53,694][root][INFO] - ㄴ alpha                : 128
[2024-10-15 20:24:53,694][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 20:24:53,694][root][INFO] - KOMBO Configuration
[2024-10-15 20:24:53,694][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 20:24:53,694][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 20:24:53,694][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 20:24:53,694][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 20:24:53,694][root][INFO] - ㄴ do_combination       : True
[2024-10-15 20:24:53,694][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 20:24:53,695][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 20:24:53,695][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 20:24:53,695][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 20:24:53,695][root][INFO] - 

[2024-10-15 20:24:53,695][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 20:24:53,695][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 20:24:53,695][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 20:24:53,695][root][INFO] - * tb interval   : 10000

[2024-10-15 20:24:53,695][root][INFO] - 

[2024-10-15 20:24:53,695][root][INFO] - Start the Training !
[2024-10-15 20:24:53,698][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 20:28:36,469][root][INFO] - Step: 379/3790  |  Loss: 0.6780  |  Score: 57.60 [%]  |  Seq Length: 256.0
[2024-10-15 20:28:41,141][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 20:28:41,142][root][INFO] - Score: 64.06 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 20:28:45,811][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 20:28:45,811][root][INFO] - Score: 59.82 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 20:28:45,812][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 20:28:45,814][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 20:32:20,676][root][INFO] - Step: 14733/73665  |  Loss: 0.6624  |  Score: 72.24 [%]  |  Seq Length: 256.0
[2024-10-15 20:32:28,796][root][INFO] - Step: 758/3790  |  Loss: 0.5684  |  Score: 70.11 [%]  |  Seq Length: 256.0
[2024-10-15 20:32:30,982][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 20:32:30,982][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-15 20:32:33,469][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 20:32:33,469][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 20:32:38,134][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 20:32:38,134][root][INFO] - Score: 64.67 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:32:38,136][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 20:32:38,137][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 20:32:51,038][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 20:32:51,038][root][INFO] - Score: 70.95 [%]  |  Evaluation Time: 20.05 [s]
[2024-10-15 20:32:51,039][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 20:32:51,041][root][INFO] - 
[2/ 5 Epoch]
[2024-10-15 20:36:20,754][root][INFO] - Step: 1137/3790  |  Loss: 0.5130  |  Score: 74.31 [%]  |  Seq Length: 256.0
[2024-10-15 20:36:25,407][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 20:36:25,408][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 20:36:30,044][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 20:36:30,044][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 20:36:30,046][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 20:36:30,047][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 20:40:12,071][root][INFO] - Step: 1516/3790  |  Loss: 0.4611  |  Score: 77.89 [%]  |  Seq Length: 256.0
[2024-10-15 20:40:16,784][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 20:40:16,784][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-15 20:40:21,398][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 20:40:21,398][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 20:40:21,399][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 20:40:21,401][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 20:44:03,125][root][INFO] - Step: 1895/3790  |  Loss: 0.4025  |  Score: 81.25 [%]  |  Seq Length: 256.0
[2024-10-15 20:44:07,785][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 20:44:07,785][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:44:12,361][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 20:44:12,361][root][INFO] - Score: 65.55 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 20:44:12,363][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 20:47:54,308][root][INFO] - Step: 2274/3790  |  Loss: 0.3566  |  Score: 83.93 [%]  |  Seq Length: 256.0
[2024-10-15 20:47:59,112][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 20:47:59,112][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-15 20:48:03,732][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 20:48:03,732][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 20:48:03,734][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 20:51:46,419][root][INFO] - Step: 2653/3790  |  Loss: 0.3011  |  Score: 86.48 [%]  |  Seq Length: 256.0
[2024-10-15 20:51:51,118][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 20:51:51,118][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 20:51:55,727][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 20:51:55,727][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 20:51:55,729][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 20:55:38,104][root][INFO] - Step: 3032/3790  |  Loss: 0.2530  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-15 20:55:42,926][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 20:55:42,926][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-15 20:55:47,619][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 20:55:47,620][root][INFO] - Score: 67.99 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 20:55:47,622][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 20:59:29,705][root][INFO] - Step: 3411/3790  |  Loss: 0.2240  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-15 20:59:34,364][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 20:59:34,364][root][INFO] - Score: 68.85 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 20:59:38,995][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 20:59:38,996][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 20:59:38,998][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 21:03:21,286][root][INFO] - Step: 3790/3790  |  Loss: 0.2060  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-15 21:03:26,036][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 21:03:26,036][root][INFO] - Score: 70.21 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 21:03:30,654][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 21:03:30,654][root][INFO] - Score: 67.39 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:03:30,656][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 21:03:30,656][root][INFO] - - Epoch: 4
[2024-10-15 21:03:30,656][root][INFO] - - DEV score: 70.02 [%]
[2024-10-15 21:03:30,656][root][INFO] - - TEST score: 67.80 [%]
[2024-10-15 21:03:30,657][root][INFO] - Fine-tuning is done!
[2024-10-15 21:03:30,657][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 21:03:30,657][root][INFO] - - BEST LR: 0.01
[2024-10-15 21:03:30,657][root][INFO] - - DEV score: 73.34 [%]
[2024-10-15 21:03:30,658][root][INFO] - - TEST score: 66.74 [%]
[2024-10-15 21:03:36,857][root][INFO] - 

[2024-10-15 21:03:36,857][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 21:03:36,857][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 21:03:36,857][root][INFO] - 

[2024-10-15 21:03:36,858][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 21:03:44,959][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,960][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,961][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,961][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,962][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,962][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,963][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,963][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,963][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,964][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,964][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,965][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,965][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,966][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,966][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,966][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,967][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,967][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,968][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,968][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,972][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,972][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,973][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 21:03:44,973][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 21:03:44,975][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 21:03:44,980][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 21:03:45,181][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 21:03:45,183][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 21:03:45,365][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 21:03:48,595][root][INFO] - 

[2024-10-15 21:03:48,595][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 21:03:48,595][root][INFO] - Data Preprocessing
[2024-10-15 21:03:48,595][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 21:03:48,595][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 21:03:48,595][root][INFO] - ㄴ data_remove                True

[2024-10-15 21:03:48,595][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 21:03:48,603][root][INFO] - vocab size              : 51200
[2024-10-15 21:03:48,603][root][INFO] - device                  : gpu
[2024-10-15 21:03:48,603][root][INFO] - random seed             : 2
[2024-10-15 21:03:48,604][root][INFO] - train data size         : 24256
[2024-10-15 21:03:48,604][root][INFO] - max epochs              : 10
[2024-10-15 21:03:48,604][root][INFO] - total steps             : 3790
[2024-10-15 21:03:48,604][root][INFO] - warmup steps            : 379
[2024-10-15 21:03:48,604][root][INFO] - batch size              : 64
[2024-10-15 21:03:48,604][root][INFO] - accumulation steps      : 1
[2024-10-15 21:03:48,604][root][INFO] - optimizer               : adamwscale
[2024-10-15 21:03:48,604][root][INFO] - lr_scheduler            : cosine
[2024-10-15 21:03:48,604][root][INFO] - learning rate           : 0.01
[2024-10-15 21:03:48,604][root][INFO] - max length              : 256

[2024-10-15 21:03:48,604][root][INFO] - LoRA Configuration
[2024-10-15 21:03:48,605][root][INFO] - ㄴ r                    : 32
[2024-10-15 21:03:48,605][root][INFO] - ㄴ alpha                : 128
[2024-10-15 21:03:48,605][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 21:03:48,605][root][INFO] - KOMBO Configuration
[2024-10-15 21:03:48,605][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 21:03:48,605][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 21:03:48,605][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 21:03:48,605][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 21:03:48,605][root][INFO] - ㄴ do_combination       : True
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 21:03:48,606][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 21:03:48,606][root][INFO] - 

[2024-10-15 21:03:48,606][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 21:03:48,606][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 21:03:48,606][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 21:03:48,606][root][INFO] - * tb interval   : 10000

[2024-10-15 21:03:48,606][root][INFO] - 

[2024-10-15 21:03:48,606][root][INFO] - Start the Training !
[2024-10-15 21:03:48,610][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 21:07:29,087][root][INFO] - Step: 379/3790  |  Loss: 0.6820  |  Score: 57.01 [%]  |  Seq Length: 256.0
[2024-10-15 21:07:33,746][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 21:07:33,746][root][INFO] - Score: 62.79 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 21:07:38,353][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 21:07:38,353][root][INFO] - Score: 59.45 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 21:07:38,355][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 21:07:38,356][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 21:11:19,012][root][INFO] - Step: 758/3790  |  Loss: 0.5809  |  Score: 69.35 [%]  |  Seq Length: 256.0
[2024-10-15 21:11:23,645][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 21:11:23,646][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:11:28,205][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 21:11:28,205][root][INFO] - Score: 62.75 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:11:28,206][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 21:11:28,208][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 21:15:08,824][root][INFO] - Step: 1137/3790  |  Loss: 0.5210  |  Score: 74.19 [%]  |  Seq Length: 256.0
[2024-10-15 21:15:13,452][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 21:15:13,452][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:15:18,044][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 21:15:18,045][root][INFO] - Score: 64.53 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 21:15:18,046][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 21:15:18,047][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 21:18:59,006][root][INFO] - Step: 1516/3790  |  Loss: 0.4662  |  Score: 77.42 [%]  |  Seq Length: 256.0
[2024-10-15 21:19:03,641][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 21:19:03,641][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:19:08,223][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 21:19:08,223][root][INFO] - Score: 65.94 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 21:19:08,225][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 21:19:45,805][root][INFO] - Step: 20000/73665  |  Loss: 0.6373  |  Score: 73.48 [%]  |  Seq Length: 256.0
[2024-10-15 21:22:49,212][root][INFO] - Step: 1895/3790  |  Loss: 0.4199  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-15 21:22:53,872][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 21:22:53,873][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 21:22:58,434][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 21:22:58,434][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:22:58,435][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 21:22:58,436][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 21:26:39,700][root][INFO] - Step: 2274/3790  |  Loss: 0.3750  |  Score: 82.67 [%]  |  Seq Length: 256.0
[2024-10-15 21:26:44,352][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 21:26:44,352][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 21:26:48,989][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 21:26:48,989][root][INFO] - Score: 66.42 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:26:48,992][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 21:30:31,365][root][INFO] - Step: 2653/3790  |  Loss: 0.3405  |  Score: 84.53 [%]  |  Seq Length: 256.0
[2024-10-15 21:30:35,988][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 21:30:35,989][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:30:40,617][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 21:30:40,617][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 21:30:40,620][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 21:34:21,375][root][INFO] - Step: 3032/3790  |  Loss: 0.3098  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-15 21:34:26,108][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 21:34:26,109][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-15 21:34:30,674][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 21:34:30,675][root][INFO] - Score: 68.67 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:34:30,676][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 21:34:30,677][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 21:38:11,286][root][INFO] - Step: 3411/3790  |  Loss: 0.2952  |  Score: 86.68 [%]  |  Seq Length: 256.0
[2024-10-15 21:38:15,910][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 21:38:15,910][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 21:38:20,473][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 21:38:20,473][root][INFO] - Score: 67.27 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 21:38:20,475][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 21:42:00,688][root][INFO] - Step: 3790/3790  |  Loss: 0.2806  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-15 21:42:05,281][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 21:42:05,282][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 21:42:09,882][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 21:42:09,882][root][INFO] - Score: 68.42 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 21:42:09,883][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 21:42:09,883][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 21:42:09,883][root][INFO] - - Epoch: 10
[2024-10-15 21:42:09,883][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 21:42:09,883][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 21:42:09,884][root][INFO] - Fine-tuning is done!
[2024-10-15 21:42:16,872][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,872][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,873][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,873][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,874][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,874][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,875][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,875][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,876][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,876][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,877][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,877][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,877][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,878][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,878][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,879][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,879][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,880][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,880][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,880][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,881][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,881][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,882][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 21:42:16,882][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 21:42:16,884][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 21:42:17,086][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 21:42:17,088][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 21:42:17,089][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 21:42:17,256][root][INFO] - 

[2024-10-15 21:42:17,256][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 21:42:17,256][root][INFO] - Data Preprocessing
[2024-10-15 21:42:17,256][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 21:42:17,256][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 21:42:17,256][root][INFO] - ㄴ data_remove                True

[2024-10-15 21:42:17,256][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 21:42:17,264][root][INFO] - vocab size              : 51200
[2024-10-15 21:42:17,264][root][INFO] - device                  : gpu
[2024-10-15 21:42:17,264][root][INFO] - random seed             : 2
[2024-10-15 21:42:17,265][root][INFO] - train data size         : 24256
[2024-10-15 21:42:17,265][root][INFO] - max epochs              : 10
[2024-10-15 21:42:17,265][root][INFO] - total steps             : 3790
[2024-10-15 21:42:17,265][root][INFO] - warmup steps            : 379
[2024-10-15 21:42:17,265][root][INFO] - batch size              : 64
[2024-10-15 21:42:17,265][root][INFO] - accumulation steps      : 1
[2024-10-15 21:42:17,265][root][INFO] - optimizer               : adamwscale
[2024-10-15 21:42:17,265][root][INFO] - lr_scheduler            : cosine
[2024-10-15 21:42:17,265][root][INFO] - learning rate           : 0.02
[2024-10-15 21:42:17,265][root][INFO] - max length              : 256

[2024-10-15 21:42:17,265][root][INFO] - LoRA Configuration
[2024-10-15 21:42:17,265][root][INFO] - ㄴ r                    : 32
[2024-10-15 21:42:17,266][root][INFO] - ㄴ alpha                : 128
[2024-10-15 21:42:17,266][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 21:42:17,266][root][INFO] - KOMBO Configuration
[2024-10-15 21:42:17,266][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 21:42:17,266][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 21:42:17,266][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 21:42:17,266][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 21:42:17,266][root][INFO] - ㄴ do_combination       : True
[2024-10-15 21:42:17,266][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 21:42:17,266][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 21:42:17,267][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 21:42:17,267][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 21:42:17,267][root][INFO] - 

[2024-10-15 21:42:17,267][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-15 21:42:17,267][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-15 21:42:17,267][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-15 21:42:17,267][root][INFO] - * tb interval   : 10000

[2024-10-15 21:42:17,267][root][INFO] - 

[2024-10-15 21:42:17,267][root][INFO] - Start the Training !
[2024-10-15 21:42:17,269][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 21:45:58,069][root][INFO] - Step: 379/3790  |  Loss: 0.6703  |  Score: 59.12 [%]  |  Seq Length: 256.0
[2024-10-15 21:46:02,776][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 21:46:02,776][root][INFO] - Score: 66.41 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 21:46:07,473][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 21:46:07,473][root][INFO] - Score: 59.91 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 21:46:07,474][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 21:46:07,476][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 21:49:49,207][root][INFO] - Step: 758/3790  |  Loss: 0.5669  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-15 21:49:53,994][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 21:49:53,994][root][INFO] - Score: 67.58 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 21:49:58,606][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 21:49:58,607][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 21:49:58,608][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 21:49:58,609][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 21:53:39,844][root][INFO] - Step: 1137/3790  |  Loss: 0.5082  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-15 21:53:44,527][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 21:53:44,528][root][INFO] - Score: 65.53 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 21:53:49,116][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 21:53:49,116][root][INFO] - Score: 67.04 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 21:53:49,119][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 21:57:30,489][root][INFO] - Step: 1516/3790  |  Loss: 0.4569  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-15 21:57:35,106][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 21:57:35,106][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 21:57:39,752][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 21:57:39,752][root][INFO] - Score: 66.84 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 21:57:39,753][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 21:57:39,755][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 22:01:21,068][root][INFO] - Step: 1895/3790  |  Loss: 0.4079  |  Score: 81.11 [%]  |  Seq Length: 256.0
[2024-10-15 22:01:25,767][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 22:01:25,767][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 22:01:30,362][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 22:01:30,362][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 22:01:30,363][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 22:01:30,364][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 22:05:11,591][root][INFO] - Step: 2274/3790  |  Loss: 0.3487  |  Score: 84.15 [%]  |  Seq Length: 256.0
[2024-10-15 22:05:16,239][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 22:05:16,239][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 22:05:20,785][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 22:05:20,785][root][INFO] - Score: 68.03 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-15 22:05:20,786][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-15 22:05:20,787][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 22:09:02,302][root][INFO] - Step: 2653/3790  |  Loss: 0.2954  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-15 22:09:06,940][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 22:09:06,940][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 22:09:11,513][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 22:09:11,513][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 22:09:11,514][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-15 22:09:11,515][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 22:12:53,185][root][INFO] - Step: 3032/3790  |  Loss: 0.2463  |  Score: 89.20 [%]  |  Seq Length: 256.0
[2024-10-15 22:12:57,785][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 22:12:57,785][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-15 22:13:02,342][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 22:13:02,342][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-15 22:13:02,344][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 22:16:43,650][root][INFO] - Step: 3411/3790  |  Loss: 0.2186  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-15 22:16:48,282][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 22:16:48,282][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 22:16:52,938][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 22:16:52,939][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 22:16:52,941][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 22:20:34,237][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-15 22:20:38,880][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 22:20:38,880][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 22:20:43,382][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 22:20:43,382][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-15 22:20:43,383][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 22:20:43,383][root][INFO] - - Epoch: 7
[2024-10-15 22:20:43,383][root][INFO] - - DEV score: 71.29 [%]
[2024-10-15 22:20:43,383][root][INFO] - - TEST score: 69.32 [%]
[2024-10-15 22:20:43,384][root][INFO] - Fine-tuning is done!
[2024-10-15 22:20:43,384][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 22:20:43,385][root][INFO] - - BEST LR: 0.01
[2024-10-15 22:20:43,385][root][INFO] - - DEV score: 72.75 [%]
[2024-10-15 22:20:43,385][root][INFO] - - TEST score: 68.42 [%]
[2024-10-15 22:20:49,545][root][INFO] - 

[2024-10-15 22:20:49,546][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 22:20:49,546][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 22:20:49,546][root][INFO] - 

[2024-10-15 22:20:49,546][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 22:20:57,844][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,845][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,845][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,846][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,847][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,848][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,848][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,849][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,849][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,850][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,850][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,851][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,852][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,852][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,853][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,853][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,854][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,854][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,855][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,855][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,857][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,857][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,858][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 22:20:57,858][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 22:20:57,860][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 22:20:57,863][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 22:20:58,063][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 22:20:58,065][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 22:20:58,256][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 22:21:01,279][root][INFO] - 

[2024-10-15 22:21:01,279][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 22:21:01,279][root][INFO] - Data Preprocessing
[2024-10-15 22:21:01,279][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 22:21:01,279][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 22:21:01,279][root][INFO] - ㄴ data_remove                True

[2024-10-15 22:21:01,279][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 22:21:01,287][root][INFO] - vocab size              : 51200
[2024-10-15 22:21:01,287][root][INFO] - device                  : gpu
[2024-10-15 22:21:01,287][root][INFO] - random seed             : 3
[2024-10-15 22:21:01,287][root][INFO] - train data size         : 24256
[2024-10-15 22:21:01,287][root][INFO] - max epochs              : 10
[2024-10-15 22:21:01,287][root][INFO] - total steps             : 3790
[2024-10-15 22:21:01,287][root][INFO] - warmup steps            : 379
[2024-10-15 22:21:01,288][root][INFO] - batch size              : 64
[2024-10-15 22:21:01,288][root][INFO] - accumulation steps      : 1
[2024-10-15 22:21:01,288][root][INFO] - optimizer               : adamwscale
[2024-10-15 22:21:01,288][root][INFO] - lr_scheduler            : cosine
[2024-10-15 22:21:01,288][root][INFO] - learning rate           : 0.01
[2024-10-15 22:21:01,288][root][INFO] - max length              : 256

[2024-10-15 22:21:01,288][root][INFO] - LoRA Configuration
[2024-10-15 22:21:01,288][root][INFO] - ㄴ r                    : 32
[2024-10-15 22:21:01,288][root][INFO] - ㄴ alpha                : 128
[2024-10-15 22:21:01,288][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 22:21:01,288][root][INFO] - KOMBO Configuration
[2024-10-15 22:21:01,288][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 22:21:01,289][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 22:21:01,289][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 22:21:01,289][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 22:21:01,289][root][INFO] - ㄴ do_combination       : True
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 22:21:01,289][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 22:21:01,289][root][INFO] - 

[2024-10-15 22:21:01,289][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 22:21:01,290][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 22:21:01,290][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 22:21:01,290][root][INFO] - * tb interval   : 10000

[2024-10-15 22:21:01,290][root][INFO] - 

[2024-10-15 22:21:01,290][root][INFO] - Start the Training !
[2024-10-15 22:21:01,293][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 22:24:42,586][root][INFO] - Step: 379/3790  |  Loss: 0.6791  |  Score: 57.91 [%]  |  Seq Length: 256.0
[2024-10-15 22:24:47,161][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 22:24:47,161][root][INFO] - Score: 61.13 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 22:24:51,640][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 22:24:51,640][root][INFO] - Score: 60.72 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-15 22:24:51,641][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 22:24:51,642][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 22:28:30,992][root][INFO] - Step: 758/3790  |  Loss: 0.5750  |  Score: 69.89 [%]  |  Seq Length: 256.0
[2024-10-15 22:28:35,565][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 22:28:35,566][root][INFO] - Score: 66.02 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 22:28:40,062][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 22:28:40,062][root][INFO] - Score: 64.05 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-15 22:28:40,063][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 22:28:40,065][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 22:32:20,227][root][INFO] - Step: 1137/3790  |  Loss: 0.5122  |  Score: 74.67 [%]  |  Seq Length: 256.0
[2024-10-15 22:32:24,809][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 22:32:24,809][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 22:32:29,351][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 22:32:29,351][root][INFO] - Score: 64.39 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-15 22:32:29,352][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 22:32:29,353][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 22:36:11,443][root][INFO] - Step: 1516/3790  |  Loss: 0.4581  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-15 22:36:16,217][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 22:36:16,217][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-15 22:36:20,908][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 22:36:20,908][root][INFO] - Score: 63.62 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:36:20,911][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 22:40:03,361][root][INFO] - Step: 1895/3790  |  Loss: 0.4133  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-15 22:40:08,058][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 22:40:08,059][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:40:12,666][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 22:40:12,666][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-15 22:40:12,667][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 22:40:12,669][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 22:43:53,283][root][INFO] - Step: 2274/3790  |  Loss: 0.3714  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-15 22:43:57,944][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 22:43:57,944][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 22:44:02,575][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 22:44:02,575][root][INFO] - Score: 65.54 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-15 22:44:02,578][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 22:44:06,162][root][INFO] - Step: 29466/73665  |  Loss: 0.6288  |  Score: 73.89 [%]  |  Seq Length: 256.0
[2024-10-15 22:44:16,365][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 22:44:16,366][root][INFO] - Score: 71.38 [%]  |  Evaluation Time: 10.20 [s]
[2024-10-15 22:44:36,433][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 22:44:36,433][root][INFO] - Score: 73.48 [%]  |  Evaluation Time: 20.07 [s]
[2024-10-15 22:44:36,434][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 22:44:36,435][root][INFO] - 
[3/ 5 Epoch]
[2024-10-15 22:47:43,593][root][INFO] - Step: 2653/3790  |  Loss: 0.3333  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-15 22:47:48,283][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 22:47:48,284][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:47:52,957][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 22:47:52,957][root][INFO] - Score: 65.60 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 22:47:52,960][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 22:49:21,331][root][INFO] - Step: 30000/73665  |  Loss: 0.6015  |  Score: 75.37 [%]  |  Seq Length: 256.0
[2024-10-15 22:51:34,082][root][INFO] - Step: 3032/3790  |  Loss: 0.3040  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-15 22:51:38,773][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 22:51:38,773][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-15 22:51:43,391][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 22:51:43,392][root][INFO] - Score: 66.08 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 22:51:43,393][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 22:51:43,394][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 22:55:24,569][root][INFO] - Step: 3411/3790  |  Loss: 0.2838  |  Score: 87.23 [%]  |  Seq Length: 256.0
[2024-10-15 22:55:29,364][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 22:55:29,365][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 22:55:33,885][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 22:55:33,886][root][INFO] - Score: 65.73 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-15 22:55:33,888][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 22:59:14,900][root][INFO] - Step: 3790/3790  |  Loss: 0.2712  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-15 22:59:19,574][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 22:59:19,575][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 22:59:24,222][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 22:59:24,222][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 22:59:24,223][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-15 22:59:24,223][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 22:59:24,223][root][INFO] - - Epoch: 10
[2024-10-15 22:59:24,223][root][INFO] - - DEV score: 72.85 [%]
[2024-10-15 22:59:24,223][root][INFO] - - TEST score: 65.70 [%]
[2024-10-15 22:59:24,224][root][INFO] - Fine-tuning is done!
[2024-10-15 22:59:30,813][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,814][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,815][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,816][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,817][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,818][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,819][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,820][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,821][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,822][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,823][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,824][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,825][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,826][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,827][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,827][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,828][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,829][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,829][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,830][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,831][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,831][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,832][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 22:59:30,833][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 22:59:30,835][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 22:59:31,084][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 22:59:31,087][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 22:59:31,088][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 22:59:31,254][root][INFO] - 

[2024-10-15 22:59:31,254][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 22:59:31,255][root][INFO] - Data Preprocessing
[2024-10-15 22:59:31,255][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 22:59:31,255][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 22:59:31,255][root][INFO] - ㄴ data_remove                True

[2024-10-15 22:59:31,255][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 22:59:31,263][root][INFO] - vocab size              : 51200
[2024-10-15 22:59:31,263][root][INFO] - device                  : gpu
[2024-10-15 22:59:31,264][root][INFO] - random seed             : 3
[2024-10-15 22:59:31,264][root][INFO] - train data size         : 24256
[2024-10-15 22:59:31,264][root][INFO] - max epochs              : 10
[2024-10-15 22:59:31,264][root][INFO] - total steps             : 3790
[2024-10-15 22:59:31,264][root][INFO] - warmup steps            : 379
[2024-10-15 22:59:31,264][root][INFO] - batch size              : 64
[2024-10-15 22:59:31,264][root][INFO] - accumulation steps      : 1
[2024-10-15 22:59:31,264][root][INFO] - optimizer               : adamwscale
[2024-10-15 22:59:31,264][root][INFO] - lr_scheduler            : cosine
[2024-10-15 22:59:31,264][root][INFO] - learning rate           : 0.02
[2024-10-15 22:59:31,264][root][INFO] - max length              : 256

[2024-10-15 22:59:31,264][root][INFO] - LoRA Configuration
[2024-10-15 22:59:31,265][root][INFO] - ㄴ r                    : 32
[2024-10-15 22:59:31,265][root][INFO] - ㄴ alpha                : 128
[2024-10-15 22:59:31,265][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 22:59:31,265][root][INFO] - KOMBO Configuration
[2024-10-15 22:59:31,265][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 22:59:31,265][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 22:59:31,265][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 22:59:31,265][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 22:59:31,265][root][INFO] - ㄴ do_combination       : True
[2024-10-15 22:59:31,265][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 22:59:31,266][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 22:59:31,266][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 22:59:31,266][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 22:59:31,266][root][INFO] - 

[2024-10-15 22:59:31,266][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-15 22:59:31,266][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-15 22:59:31,266][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-15 22:59:31,266][root][INFO] - * tb interval   : 10000

[2024-10-15 22:59:31,266][root][INFO] - 

[2024-10-15 22:59:31,266][root][INFO] - Start the Training !
[2024-10-15 22:59:31,268][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 23:03:12,843][root][INFO] - Step: 379/3790  |  Loss: 0.6607  |  Score: 60.10 [%]  |  Seq Length: 256.0
[2024-10-15 23:03:17,721][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 23:03:17,721][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 4.87 [s]
[2024-10-15 23:03:22,391][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 23:03:22,391][root][INFO] - Score: 60.64 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-15 23:03:22,392][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 23:03:22,394][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 23:07:03,645][root][INFO] - Step: 758/3790  |  Loss: 0.5616  |  Score: 71.12 [%]  |  Seq Length: 256.0
[2024-10-15 23:07:08,434][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 23:07:08,434][root][INFO] - Score: 65.04 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 23:07:13,085][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 23:07:13,085][root][INFO] - Score: 62.68 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-15 23:07:13,087][root][INFO] - 
[3/ 10 Epoch]
[2024-10-15 23:10:54,621][root][INFO] - Step: 1137/3790  |  Loss: 0.4997  |  Score: 75.63 [%]  |  Seq Length: 256.0
[2024-10-15 23:10:59,325][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-15 23:10:59,325][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 23:11:04,103][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-15 23:11:04,103][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-15 23:11:04,104][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-15 23:11:04,106][root][INFO] - 
[4/ 10 Epoch]
[2024-10-15 23:14:46,034][root][INFO] - Step: 1516/3790  |  Loss: 0.4472  |  Score: 78.90 [%]  |  Seq Length: 256.0
[2024-10-15 23:14:50,757][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-15 23:14:50,757][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-15 23:14:55,350][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-15 23:14:55,350][root][INFO] - Score: 66.80 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-15 23:14:55,351][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-15 23:14:55,353][root][INFO] - 
[5/ 10 Epoch]
[2024-10-15 23:18:36,565][root][INFO] - Step: 1895/3790  |  Loss: 0.3977  |  Score: 81.23 [%]  |  Seq Length: 256.0
[2024-10-15 23:18:41,264][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-15 23:18:41,265][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-15 23:18:45,924][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-15 23:18:45,925][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-15 23:18:45,926][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-15 23:18:45,927][root][INFO] - 
[6/ 10 Epoch]
[2024-10-15 23:22:25,909][root][INFO] - Step: 2274/3790  |  Loss: 0.3445  |  Score: 84.26 [%]  |  Seq Length: 256.0
[2024-10-15 23:22:30,707][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-15 23:22:30,707][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 23:22:35,294][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-15 23:22:35,294][root][INFO] - Score: 66.36 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-15 23:22:35,297][root][INFO] - 
[7/ 10 Epoch]
[2024-10-15 23:26:16,686][root][INFO] - Step: 2653/3790  |  Loss: 0.2995  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-15 23:26:21,437][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-15 23:26:21,438][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-15 23:26:26,227][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-15 23:26:26,227][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-15 23:26:26,229][root][INFO] - 
[8/ 10 Epoch]
[2024-10-15 23:30:07,120][root][INFO] - Step: 3032/3790  |  Loss: 0.2495  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-15 23:30:11,804][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-15 23:30:11,804][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-15 23:30:16,369][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-15 23:30:16,369][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-15 23:30:16,370][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-15 23:30:16,372][root][INFO] - 
[9/ 10 Epoch]
[2024-10-15 23:33:54,801][root][INFO] - Step: 3411/3790  |  Loss: 0.2111  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-15 23:33:59,424][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-15 23:33:59,424][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-15 23:34:04,070][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-15 23:34:04,070][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-15 23:34:04,073][root][INFO] - 
[10/ 10 Epoch]
[2024-10-15 23:37:45,760][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.52 [%]  |  Seq Length: 256.0
[2024-10-15 23:37:50,335][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-15 23:37:50,335][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-15 23:37:54,867][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-15 23:37:54,867][root][INFO] - Score: 68.36 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-15 23:37:54,868][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-15 23:37:54,868][root][INFO] - - Epoch: 8
[2024-10-15 23:37:54,868][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 23:37:54,868][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 23:37:54,869][root][INFO] - Fine-tuning is done!
[2024-10-15 23:37:54,869][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-15 23:37:54,869][root][INFO] - - BEST LR: 0.02
[2024-10-15 23:37:54,870][root][INFO] - - DEV score: 73.83 [%]
[2024-10-15 23:37:54,870][root][INFO] - - TEST score: 68.33 [%]
[2024-10-15 23:38:00,580][root][INFO] - 

[2024-10-15 23:38:00,580][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-15 23:38:00,580][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 23:38:00,580][root][INFO] - 

[2024-10-15 23:38:00,580][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-15 23:38:13,953][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,954][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,954][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,955][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,955][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,956][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,956][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,957][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,957][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,958][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,958][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,959][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,959][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,960][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,960][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,961][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,961][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,962][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,962][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,963][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,963][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,964][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,964][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-15 23:38:13,965][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-15 23:38:13,967][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-15 23:38:13,972][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-15 23:38:14,168][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-15 23:38:14,170][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-15 23:38:14,353][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-15 23:38:17,297][root][INFO] - 

[2024-10-15 23:38:17,298][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-15 23:38:17,298][root][INFO] - Data Preprocessing
[2024-10-15 23:38:17,298][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-15 23:38:17,298][root][INFO] - ㄴ do_hangeulize              False
[2024-10-15 23:38:17,298][root][INFO] - ㄴ data_remove                False

[2024-10-15 23:38:17,298][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-15 23:38:17,305][root][INFO] - vocab size              : 51200
[2024-10-15 23:38:17,306][root][INFO] - device                  : gpu
[2024-10-15 23:38:17,306][root][INFO] - random seed             : 1
[2024-10-15 23:38:17,306][root][INFO] - train data size         : 49152
[2024-10-15 23:38:17,306][root][INFO] - max epochs              : 10
[2024-10-15 23:38:17,306][root][INFO] - total steps             : 7680
[2024-10-15 23:38:17,306][root][INFO] - warmup steps            : 768
[2024-10-15 23:38:17,306][root][INFO] - batch size              : 64
[2024-10-15 23:38:17,306][root][INFO] - accumulation steps      : 1
[2024-10-15 23:38:17,306][root][INFO] - optimizer               : adamwscale
[2024-10-15 23:38:17,306][root][INFO] - lr_scheduler            : cosine
[2024-10-15 23:38:17,306][root][INFO] - learning rate           : 0.01
[2024-10-15 23:38:17,307][root][INFO] - max length              : 256

[2024-10-15 23:38:17,307][root][INFO] - LoRA Configuration
[2024-10-15 23:38:17,307][root][INFO] - ㄴ r                    : 32
[2024-10-15 23:38:17,307][root][INFO] - ㄴ alpha                : 128
[2024-10-15 23:38:17,307][root][INFO] - ㄴ dropout              : 0.03

[2024-10-15 23:38:17,307][root][INFO] - KOMBO Configuration
[2024-10-15 23:38:17,307][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-15 23:38:17,307][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-15 23:38:17,307][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-15 23:38:17,307][root][INFO] - ㄴ embedding_norm       : False
[2024-10-15 23:38:17,307][root][INFO] - ㄴ do_combination       : True
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-15 23:38:17,308][root][INFO] -   ㄴ add_lora           : False

[2024-10-15 23:38:17,308][root][INFO] - 

[2024-10-15 23:38:17,308][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-15 23:38:17,308][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-15 23:38:17,308][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-15 23:38:17,308][root][INFO] - * tb interval   : 10000

[2024-10-15 23:38:17,308][root][INFO] - 

[2024-10-15 23:38:17,308][root][INFO] - Start the Training !
[2024-10-15 23:38:17,311][root][INFO] - 
[1/ 10 Epoch]
[2024-10-15 23:45:47,747][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-15 23:45:56,652][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-15 23:45:56,652][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-15 23:46:05,578][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-15 23:46:05,578][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-15 23:46:05,579][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-15 23:46:05,580][root][INFO] - 
[2/ 10 Epoch]
[2024-10-15 23:53:33,246][root][INFO] - Step: 1536/7680  |  Loss: 0.5295  |  Score: 73.27 [%]  |  Seq Length: 256.0
[2024-10-15 23:53:42,150][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-15 23:53:42,150][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-15 23:53:51,200][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-15 23:53:51,200][root][INFO] - Score: 69.51 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-15 23:53:51,201][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-15 23:53:51,203][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 00:01:20,605][root][INFO] - Step: 2304/7680  |  Loss: 0.4638  |  Score: 77.33 [%]  |  Seq Length: 256.0
[2024-10-16 00:01:29,679][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 00:01:29,679][root][INFO] - Score: 72.97 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 00:01:38,639][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 00:01:38,640][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 00:01:38,640][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 00:01:38,642][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 00:09:07,017][root][INFO] - Step: 3072/7680  |  Loss: 0.4107  |  Score: 80.68 [%]  |  Seq Length: 256.0
[2024-10-16 00:09:15,938][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 00:09:15,938][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 00:09:24,861][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 00:09:24,861][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 00:09:24,862][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 00:09:24,864][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 00:16:51,683][root][INFO] - Step: 3840/7680  |  Loss: 0.3698  |  Score: 82.74 [%]  |  Seq Length: 256.0
[2024-10-16 00:17:00,601][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 00:17:00,601][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 00:17:09,516][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 00:17:09,516][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 00:17:09,518][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 00:18:00,301][root][INFO] - Step: 40000/73665  |  Loss: 0.5978  |  Score: 75.45 [%]  |  Seq Length: 256.0
[2024-10-16 00:24:36,672][root][INFO] - Step: 4608/7680  |  Loss: 0.3322  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-16 00:24:45,618][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 00:24:45,618][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:24:54,568][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 00:24:54,569][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 00:24:54,570][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 00:24:54,574][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 00:32:21,458][root][INFO] - Step: 5376/7680  |  Loss: 0.2993  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-16 00:32:30,364][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 00:32:30,365][root][INFO] - Score: 75.63 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 00:32:39,308][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 00:32:39,308][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:32:39,309][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 00:32:39,311][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 00:40:07,713][root][INFO] - Step: 6144/7680  |  Loss: 0.2694  |  Score: 88.03 [%]  |  Seq Length: 256.0
[2024-10-16 00:40:16,791][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 00:40:16,791][root][INFO] - Score: 76.32 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 00:40:25,798][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 00:40:25,798][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 00:40:25,799][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 00:40:25,801][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 00:47:54,006][root][INFO] - Step: 6912/7680  |  Loss: 0.2510  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-16 00:48:03,110][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 00:48:03,110][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-16 00:48:12,069][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 00:48:12,069][root][INFO] - Score: 72.82 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 00:48:12,070][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 00:48:12,071][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 00:55:12,684][root][INFO] - Step: 44199/73665  |  Loss: 0.5851  |  Score: 76.10 [%]  |  Seq Length: 256.0
[2024-10-16 00:55:22,868][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 00:55:22,868][root][INFO] - Score: 74.12 [%]  |  Evaluation Time: 10.18 [s]
[2024-10-16 00:55:42,054][root][INFO] - Step: 7680/7680  |  Loss: 0.2422  |  Score: 89.34 [%]  |  Seq Length: 256.0
[2024-10-16 00:55:42,790][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 00:55:42,790][root][INFO] - Score: 74.55 [%]  |  Evaluation Time: 19.92 [s]
[2024-10-16 00:55:42,791][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 00:55:42,793][root][INFO] - 
[4/ 5 Epoch]
[2024-10-16 00:55:51,001][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 00:55:51,001][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:55:59,947][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 00:55:59,947][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 00:55:59,948][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 00:55:59,948][root][INFO] - - Epoch: 9
[2024-10-16 00:55:59,949][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 00:55:59,949][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 00:55:59,949][root][INFO] - Fine-tuning is done!
[2024-10-16 00:56:11,061][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,062][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,063][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,063][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,064][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,064][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,065][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,065][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,066][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,066][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,067][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,067][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,068][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,068][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,069][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,069][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,070][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,070][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,071][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,071][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,072][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,072][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,073][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 00:56:11,073][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 00:56:11,075][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 00:56:11,283][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 00:56:11,285][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 00:56:11,286][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 00:56:11,449][root][INFO] - 

[2024-10-16 00:56:11,449][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 00:56:11,450][root][INFO] - Data Preprocessing
[2024-10-16 00:56:11,450][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 00:56:11,450][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 00:56:11,450][root][INFO] - ㄴ data_remove                False

[2024-10-16 00:56:11,450][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 00:56:11,457][root][INFO] - vocab size              : 51200
[2024-10-16 00:56:11,458][root][INFO] - device                  : gpu
[2024-10-16 00:56:11,458][root][INFO] - random seed             : 1
[2024-10-16 00:56:11,458][root][INFO] - train data size         : 49152
[2024-10-16 00:56:11,458][root][INFO] - max epochs              : 10
[2024-10-16 00:56:11,458][root][INFO] - total steps             : 7680
[2024-10-16 00:56:11,458][root][INFO] - warmup steps            : 768
[2024-10-16 00:56:11,458][root][INFO] - batch size              : 64
[2024-10-16 00:56:11,458][root][INFO] - accumulation steps      : 1
[2024-10-16 00:56:11,458][root][INFO] - optimizer               : adamwscale
[2024-10-16 00:56:11,458][root][INFO] - lr_scheduler            : cosine
[2024-10-16 00:56:11,459][root][INFO] - learning rate           : 0.02
[2024-10-16 00:56:11,459][root][INFO] - max length              : 256

[2024-10-16 00:56:11,459][root][INFO] - LoRA Configuration
[2024-10-16 00:56:11,459][root][INFO] - ㄴ r                    : 32
[2024-10-16 00:56:11,459][root][INFO] - ㄴ alpha                : 128
[2024-10-16 00:56:11,459][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 00:56:11,460][root][INFO] - KOMBO Configuration
[2024-10-16 00:56:11,460][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 00:56:11,460][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 00:56:11,460][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 00:56:11,460][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 00:56:11,460][root][INFO] - ㄴ do_combination       : True
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 00:56:11,460][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 00:56:11,461][root][INFO] - 

[2024-10-16 00:56:11,461][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 00:56:11,461][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 00:56:11,461][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 00:56:11,461][root][INFO] - * tb interval   : 10000

[2024-10-16 00:56:11,461][root][INFO] - 

[2024-10-16 00:56:11,461][root][INFO] - Start the Training !
[2024-10-16 00:56:11,463][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 01:03:43,744][root][INFO] - Step: 768/7680  |  Loss: 0.6396  |  Score: 61.85 [%]  |  Seq Length: 256.0
[2024-10-16 01:03:52,713][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 01:03:52,713][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 01:04:01,784][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 01:04:01,785][root][INFO] - Score: 66.86 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 01:04:01,786][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 01:04:01,787][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 01:11:30,341][root][INFO] - Step: 1536/7680  |  Loss: 0.5290  |  Score: 73.49 [%]  |  Seq Length: 256.0
[2024-10-16 01:11:39,323][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 01:11:39,323][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 01:11:48,418][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 01:11:48,418][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 01:11:48,420][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 01:11:48,421][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 01:19:17,791][root][INFO] - Step: 2304/7680  |  Loss: 0.4797  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-16 01:19:26,831][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 01:19:26,831][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 01:19:35,826][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 01:19:35,826][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 01:19:35,827][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 01:19:35,828][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 01:27:04,949][root][INFO] - Step: 3072/7680  |  Loss: 0.4315  |  Score: 79.38 [%]  |  Seq Length: 256.0
[2024-10-16 01:27:13,938][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 01:27:13,938][root][INFO] - Score: 72.79 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 01:27:22,911][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 01:27:22,911][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 01:27:22,912][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 01:27:22,913][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 01:34:51,132][root][INFO] - Step: 3840/7680  |  Loss: 0.3944  |  Score: 81.60 [%]  |  Seq Length: 256.0
[2024-10-16 01:35:00,078][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 01:35:00,079][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 01:35:09,117][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 01:35:09,117][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 01:35:09,118][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 01:35:09,120][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 01:42:37,772][root][INFO] - Step: 4608/7680  |  Loss: 0.3457  |  Score: 84.04 [%]  |  Seq Length: 256.0
[2024-10-16 01:42:46,832][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 01:42:46,832][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 01:42:55,880][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 01:42:55,880][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-16 01:42:55,881][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 01:42:55,882][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 01:47:07,301][root][INFO] - Step: 50000/73665  |  Loss: 0.5508  |  Score: 77.68 [%]  |  Seq Length: 256.0
[2024-10-16 01:50:22,470][root][INFO] - Step: 5376/7680  |  Loss: 0.2974  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-16 01:50:31,441][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 01:50:31,441][root][INFO] - Score: 75.11 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 01:50:40,393][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 01:50:40,393][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 01:50:40,395][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 01:58:10,956][root][INFO] - Step: 6144/7680  |  Loss: 0.2532  |  Score: 88.87 [%]  |  Seq Length: 256.0
[2024-10-16 01:58:20,129][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 01:58:20,129][root][INFO] - Score: 75.03 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-16 01:58:29,317][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 01:58:29,318][root][INFO] - Score: 72.98 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-16 01:58:29,320][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 02:06:04,779][root][INFO] - Step: 6912/7680  |  Loss: 0.2230  |  Score: 90.33 [%]  |  Seq Length: 256.0
[2024-10-16 02:06:13,740][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 02:06:13,740][root][INFO] - Score: 75.21 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 02:06:22,759][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 02:06:22,760][root][INFO] - Score: 72.91 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 02:06:22,762][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 02:13:50,732][root][INFO] - Step: 7680/7680  |  Loss: 0.2027  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-16 02:13:59,725][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 02:13:59,725][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 02:14:08,720][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 02:14:08,720][root][INFO] - Score: 73.03 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 02:14:08,721][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 02:14:08,721][root][INFO] - - Epoch: 6
[2024-10-16 02:14:08,721][root][INFO] - - DEV score: 74.90 [%]
[2024-10-16 02:14:08,721][root][INFO] - - TEST score: 73.44 [%]
[2024-10-16 02:14:08,722][root][INFO] - Fine-tuning is done!
[2024-10-16 02:14:08,723][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 02:14:08,723][root][INFO] - - BEST LR: 0.01
[2024-10-16 02:14:08,723][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 02:14:08,723][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 02:14:14,564][root][INFO] - 

[2024-10-16 02:14:14,564][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 02:14:14,565][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 02:14:14,565][root][INFO] - 

[2024-10-16 02:14:14,565][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 02:14:27,248][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,248][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,249][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,249][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,250][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,250][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,250][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,251][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,251][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,252][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,252][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,253][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,253][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,254][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,254][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,255][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,255][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,256][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,256][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,257][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,257][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,258][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,258][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 02:14:27,259][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 02:14:27,260][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 02:14:27,265][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 02:14:27,461][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 02:14:27,464][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 02:14:27,650][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 02:14:30,663][root][INFO] - 

[2024-10-16 02:14:30,663][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 02:14:30,663][root][INFO] - Data Preprocessing
[2024-10-16 02:14:30,664][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 02:14:30,664][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 02:14:30,664][root][INFO] - ㄴ data_remove                False

[2024-10-16 02:14:30,664][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 02:14:30,671][root][INFO] - vocab size              : 51200
[2024-10-16 02:14:30,672][root][INFO] - device                  : gpu
[2024-10-16 02:14:30,672][root][INFO] - random seed             : 2
[2024-10-16 02:14:30,672][root][INFO] - train data size         : 49152
[2024-10-16 02:14:30,672][root][INFO] - max epochs              : 10
[2024-10-16 02:14:30,672][root][INFO] - total steps             : 7680
[2024-10-16 02:14:30,672][root][INFO] - warmup steps            : 768
[2024-10-16 02:14:30,672][root][INFO] - batch size              : 64
[2024-10-16 02:14:30,672][root][INFO] - accumulation steps      : 1
[2024-10-16 02:14:30,672][root][INFO] - optimizer               : adamwscale
[2024-10-16 02:14:30,672][root][INFO] - lr_scheduler            : cosine
[2024-10-16 02:14:30,672][root][INFO] - learning rate           : 0.01
[2024-10-16 02:14:30,673][root][INFO] - max length              : 256

[2024-10-16 02:14:30,673][root][INFO] - LoRA Configuration
[2024-10-16 02:14:30,673][root][INFO] - ㄴ r                    : 32
[2024-10-16 02:14:30,673][root][INFO] - ㄴ alpha                : 128
[2024-10-16 02:14:30,673][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 02:14:30,673][root][INFO] - KOMBO Configuration
[2024-10-16 02:14:30,673][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 02:14:30,673][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 02:14:30,673][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 02:14:30,673][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 02:14:30,673][root][INFO] - ㄴ do_combination       : True
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 02:14:30,674][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 02:14:30,674][root][INFO] - 

[2024-10-16 02:14:30,674][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 02:14:30,674][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 02:14:30,674][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 02:14:30,674][root][INFO] - * tb interval   : 10000

[2024-10-16 02:14:30,674][root][INFO] - 

[2024-10-16 02:14:30,674][root][INFO] - Start the Training !
[2024-10-16 02:14:30,678][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 02:21:59,456][root][INFO] - Step: 768/7680  |  Loss: 0.6386  |  Score: 62.54 [%]  |  Seq Length: 256.0
[2024-10-16 02:22:08,374][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 02:22:08,374][root][INFO] - Score: 68.40 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 02:22:17,324][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 02:22:17,324][root][INFO] - Score: 66.23 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 02:22:17,325][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 02:22:17,327][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 02:29:45,161][root][INFO] - Step: 1536/7680  |  Loss: 0.5177  |  Score: 74.29 [%]  |  Seq Length: 256.0
[2024-10-16 02:29:54,066][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 02:29:54,067][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 02:30:03,092][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 02:30:03,092][root][INFO] - Score: 67.61 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 02:30:03,093][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 02:30:03,094][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 02:37:31,552][root][INFO] - Step: 2304/7680  |  Loss: 0.4565  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-16 02:37:40,465][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 02:37:40,465][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 02:37:49,437][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 02:37:49,437][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 02:37:49,438][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 02:37:49,439][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 02:45:18,294][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-16 02:45:27,506][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 02:45:27,506][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 02:45:36,482][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 02:45:36,482][root][INFO] - Score: 72.89 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 02:45:36,483][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 02:45:36,484][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 02:53:04,592][root][INFO] - Step: 3840/7680  |  Loss: 0.3670  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-16 02:53:13,564][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 02:53:13,565][root][INFO] - Score: 76.05 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 02:53:22,483][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 02:53:22,484][root][INFO] - Score: 73.63 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 02:53:22,485][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 02:53:22,486][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 03:00:50,088][root][INFO] - Step: 4608/7680  |  Loss: 0.3297  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-16 03:00:58,993][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 03:00:58,993][root][INFO] - Score: 75.79 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 03:01:07,918][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 03:01:07,918][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 03:01:07,919][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 03:01:07,920][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 03:06:13,954][root][INFO] - Step: 58932/73665  |  Loss: 0.5409  |  Score: 78.13 [%]  |  Seq Length: 256.0
[2024-10-16 03:06:24,164][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 03:06:24,164][root][INFO] - Score: 74.50 [%]  |  Evaluation Time: 10.21 [s]
[2024-10-16 03:06:44,150][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 03:06:44,150][root][INFO] - Score: 76.12 [%]  |  Evaluation Time: 19.98 [s]
[2024-10-16 03:06:44,151][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 03:06:44,152][root][INFO] - 
[5/ 5 Epoch]
[2024-10-16 03:08:36,001][root][INFO] - Step: 5376/7680  |  Loss: 0.2950  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-16 03:08:44,880][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 03:08:44,881][root][INFO] - Score: 75.40 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 03:08:53,913][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 03:08:53,913][root][INFO] - Score: 72.84 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-16 03:08:53,915][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 03:16:07,339][root][INFO] - Step: 60000/73665  |  Loss: 0.5080  |  Score: 79.59 [%]  |  Seq Length: 256.0
[2024-10-16 03:16:22,208][root][INFO] - Step: 6144/7680  |  Loss: 0.2654  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-16 03:16:31,110][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 03:16:31,110][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 03:16:40,035][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 03:16:40,035][root][INFO] - Score: 73.65 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 03:16:40,038][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 03:24:09,424][root][INFO] - Step: 6912/7680  |  Loss: 0.2486  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-16 03:24:18,352][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 03:24:18,353][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 8.93 [s]
[2024-10-16 03:24:27,365][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 03:24:27,365][root][INFO] - Score: 73.59 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 03:24:27,367][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 03:31:55,493][root][INFO] - Step: 7680/7680  |  Loss: 0.2369  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-16 03:32:04,379][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 03:32:04,380][root][INFO] - Score: 76.51 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 03:32:13,375][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 03:32:13,376][root][INFO] - Score: 73.88 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 03:32:13,377][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 03:32:13,378][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 03:32:13,378][root][INFO] - - Epoch: 10
[2024-10-16 03:32:13,378][root][INFO] - - DEV score: 76.51 [%]
[2024-10-16 03:32:13,378][root][INFO] - - TEST score: 73.88 [%]
[2024-10-16 03:32:13,380][root][INFO] - Fine-tuning is done!
[2024-10-16 03:32:25,147][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,148][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,149][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,149][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,150][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,150][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,151][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,152][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,152][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,153][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,154][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,155][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,156][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,157][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,158][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,158][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,159][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,159][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,160][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,160][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,161][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,162][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,163][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 03:32:25,163][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 03:32:25,165][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 03:32:25,385][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 03:32:25,387][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 03:32:25,389][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 03:32:25,562][root][INFO] - 

[2024-10-16 03:32:25,562][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 03:32:25,562][root][INFO] - Data Preprocessing
[2024-10-16 03:32:25,562][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 03:32:25,563][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 03:32:25,563][root][INFO] - ㄴ data_remove                False

[2024-10-16 03:32:25,563][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 03:32:25,571][root][INFO] - vocab size              : 51200
[2024-10-16 03:32:25,571][root][INFO] - device                  : gpu
[2024-10-16 03:32:25,571][root][INFO] - random seed             : 2
[2024-10-16 03:32:25,572][root][INFO] - train data size         : 49152
[2024-10-16 03:32:25,572][root][INFO] - max epochs              : 10
[2024-10-16 03:32:25,572][root][INFO] - total steps             : 7680
[2024-10-16 03:32:25,572][root][INFO] - warmup steps            : 768
[2024-10-16 03:32:25,572][root][INFO] - batch size              : 64
[2024-10-16 03:32:25,572][root][INFO] - accumulation steps      : 1
[2024-10-16 03:32:25,572][root][INFO] - optimizer               : adamwscale
[2024-10-16 03:32:25,572][root][INFO] - lr_scheduler            : cosine
[2024-10-16 03:32:25,572][root][INFO] - learning rate           : 0.02
[2024-10-16 03:32:25,572][root][INFO] - max length              : 256

[2024-10-16 03:32:25,572][root][INFO] - LoRA Configuration
[2024-10-16 03:32:25,573][root][INFO] - ㄴ r                    : 32
[2024-10-16 03:32:25,573][root][INFO] - ㄴ alpha                : 128
[2024-10-16 03:32:25,573][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 03:32:25,573][root][INFO] - KOMBO Configuration
[2024-10-16 03:32:25,573][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 03:32:25,573][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 03:32:25,573][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 03:32:25,573][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 03:32:25,573][root][INFO] - ㄴ do_combination       : True
[2024-10-16 03:32:25,573][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 03:32:25,574][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 03:32:25,574][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 03:32:25,574][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 03:32:25,574][root][INFO] - 

[2024-10-16 03:32:25,574][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 03:32:25,574][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 03:32:25,574][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 03:32:25,574][root][INFO] - * tb interval   : 10000

[2024-10-16 03:32:25,574][root][INFO] - 

[2024-10-16 03:32:25,574][root][INFO] - Start the Training !
[2024-10-16 03:32:25,577][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 03:39:55,762][root][INFO] - Step: 768/7680  |  Loss: 0.6222  |  Score: 64.46 [%]  |  Seq Length: 256.0
[2024-10-16 03:40:04,748][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 03:40:04,748][root][INFO] - Score: 67.73 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 03:40:13,841][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 03:40:13,842][root][INFO] - Score: 66.79 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 03:40:13,843][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 03:40:13,844][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 03:47:45,002][root][INFO] - Step: 1536/7680  |  Loss: 0.5210  |  Score: 74.06 [%]  |  Seq Length: 256.0
[2024-10-16 03:47:53,986][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 03:47:53,986][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 03:48:03,006][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 03:48:03,006][root][INFO] - Score: 67.05 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 03:48:03,007][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 03:48:03,009][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 03:55:35,397][root][INFO] - Step: 2304/7680  |  Loss: 0.4707  |  Score: 77.22 [%]  |  Seq Length: 256.0
[2024-10-16 03:55:44,390][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 03:55:44,390][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 03:55:53,620][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 03:55:53,620][root][INFO] - Score: 70.17 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 03:55:53,621][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 03:55:53,623][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 04:03:24,541][root][INFO] - Step: 3072/7680  |  Loss: 0.4338  |  Score: 79.22 [%]  |  Seq Length: 256.0
[2024-10-16 04:03:33,505][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 04:03:33,506][root][INFO] - Score: 74.96 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 04:03:42,509][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 04:03:42,509][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 04:03:42,510][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 04:03:42,512][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 04:11:16,499][root][INFO] - Step: 3840/7680  |  Loss: 0.3913  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-16 04:11:25,618][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 04:11:25,618][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-16 04:11:34,626][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 04:11:34,626][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 04:11:34,627][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 04:11:34,629][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 04:19:07,463][root][INFO] - Step: 4608/7680  |  Loss: 0.3479  |  Score: 84.10 [%]  |  Seq Length: 256.0
[2024-10-16 04:19:16,705][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 04:19:16,706][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 04:19:25,883][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 04:19:25,884][root][INFO] - Score: 72.64 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 04:19:25,885][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 04:19:25,886][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 04:27:00,315][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.63 [%]  |  Seq Length: 256.0
[2024-10-16 04:27:09,341][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 04:27:09,341][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 04:27:18,488][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 04:27:18,488][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 04:27:18,491][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 04:34:48,501][root][INFO] - Step: 6144/7680  |  Loss: 0.2514  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-16 04:34:57,506][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 04:34:57,506][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 04:35:06,571][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 04:35:06,571][root][INFO] - Score: 74.42 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 04:35:06,572][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 04:35:06,573][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 04:42:42,877][root][INFO] - Step: 6912/7680  |  Loss: 0.2204  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-16 04:42:52,120][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 04:42:52,120][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 04:43:01,387][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 04:43:01,387][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-16 04:43:01,389][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 04:44:43,440][root][INFO] - Step: 70000/73665  |  Loss: 0.5059  |  Score: 79.71 [%]  |  Seq Length: 256.0
[2024-10-16 04:50:31,462][root][INFO] - Step: 7680/7680  |  Loss: 0.1994  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-16 04:50:40,492][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 04:50:40,492][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-16 04:50:49,651][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 04:50:49,651][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 04:50:49,652][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 04:50:49,652][root][INFO] - - Epoch: 8
[2024-10-16 04:50:49,652][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 04:50:49,653][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 04:50:49,653][root][INFO] - Fine-tuning is done!
[2024-10-16 04:50:49,654][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 04:50:49,654][root][INFO] - - BEST LR: 0.02
[2024-10-16 04:50:49,654][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 04:50:49,654][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 04:50:55,467][root][INFO] - 

[2024-10-16 04:50:55,467][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 04:50:55,467][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 04:50:55,467][root][INFO] - 

[2024-10-16 04:50:55,467][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 04:51:07,829][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,829][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,830][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,830][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,831][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,831][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,832][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,832][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,832][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,833][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,833][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,834][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,834][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,835][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,835][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,836][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,836][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,837][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,837][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,838][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,838][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,839][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,839][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 04:51:07,840][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 04:51:07,841][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 04:51:07,845][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 04:51:08,038][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 04:51:08,040][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 04:51:08,228][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 04:51:11,204][root][INFO] - 

[2024-10-16 04:51:11,205][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 04:51:11,205][root][INFO] - Data Preprocessing
[2024-10-16 04:51:11,205][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 04:51:11,205][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 04:51:11,205][root][INFO] - ㄴ data_remove                False

[2024-10-16 04:51:11,205][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 04:51:11,213][root][INFO] - vocab size              : 51200
[2024-10-16 04:51:11,213][root][INFO] - device                  : gpu
[2024-10-16 04:51:11,213][root][INFO] - random seed             : 3
[2024-10-16 04:51:11,213][root][INFO] - train data size         : 49152
[2024-10-16 04:51:11,213][root][INFO] - max epochs              : 10
[2024-10-16 04:51:11,213][root][INFO] - total steps             : 7680
[2024-10-16 04:51:11,213][root][INFO] - warmup steps            : 768
[2024-10-16 04:51:11,213][root][INFO] - batch size              : 64
[2024-10-16 04:51:11,214][root][INFO] - accumulation steps      : 1
[2024-10-16 04:51:11,214][root][INFO] - optimizer               : adamwscale
[2024-10-16 04:51:11,214][root][INFO] - lr_scheduler            : cosine
[2024-10-16 04:51:11,214][root][INFO] - learning rate           : 0.01
[2024-10-16 04:51:11,214][root][INFO] - max length              : 256

[2024-10-16 04:51:11,214][root][INFO] - LoRA Configuration
[2024-10-16 04:51:11,214][root][INFO] - ㄴ r                    : 32
[2024-10-16 04:51:11,214][root][INFO] - ㄴ alpha                : 128
[2024-10-16 04:51:11,214][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 04:51:11,214][root][INFO] - KOMBO Configuration
[2024-10-16 04:51:11,214][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 04:51:11,215][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 04:51:11,215][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 04:51:11,215][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 04:51:11,215][root][INFO] - ㄴ do_combination       : True
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 04:51:11,215][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 04:51:11,215][root][INFO] - 

[2024-10-16 04:51:11,215][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 04:51:11,216][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 04:51:11,216][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 04:51:11,216][root][INFO] - * tb interval   : 10000

[2024-10-16 04:51:11,216][root][INFO] - 

[2024-10-16 04:51:11,216][root][INFO] - Start the Training !
[2024-10-16 04:51:11,219][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 04:58:40,231][root][INFO] - Step: 768/7680  |  Loss: 0.6403  |  Score: 62.30 [%]  |  Seq Length: 256.0
[2024-10-16 04:58:49,171][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 04:58:49,172][root][INFO] - Score: 65.99 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 04:58:58,155][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 04:58:58,156][root][INFO] - Score: 65.19 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 04:58:58,157][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 04:58:58,158][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 05:06:26,677][root][INFO] - Step: 1536/7680  |  Loss: 0.5201  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-16 05:06:35,656][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 05:06:35,656][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-16 05:06:44,618][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 05:06:44,619][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:06:44,620][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 05:06:44,621][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 05:14:14,847][root][INFO] - Step: 2304/7680  |  Loss: 0.4547  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-16 05:14:23,978][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 05:14:23,978][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-16 05:14:33,099][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 05:14:33,100][root][INFO] - Score: 70.54 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-16 05:14:33,101][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 05:14:33,102][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 05:17:14,697][root][INFO] - Step: 73665/73665  |  Loss: 0.5080  |  Score: 79.70 [%]  |  Seq Length: 256.0
[2024-10-16 05:17:24,885][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 05:17:24,885][root][INFO] - Score: 74.86 [%]  |  Evaluation Time: 10.18 [s]
[2024-10-16 05:17:45,017][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 05:17:45,017][root][INFO] - Score: 76.17 [%]  |  Evaluation Time: 20.13 [s]
[2024-10-16 05:17:45,018][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 05:17:45,018][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 05:17:45,018][root][INFO] - - Epoch: 5
[2024-10-16 05:17:45,018][root][INFO] - - DEV score: 74.86 [%]
[2024-10-16 05:17:45,018][root][INFO] - - TEST score: 76.17 [%]
[2024-10-16 05:17:45,019][root][INFO] - Fine-tuning is done!
[2024-10-16 05:19:44,938][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,938][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,939][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,939][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,940][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,940][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,941][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,941][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,942][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,942][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,943][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,943][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,944][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,944][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,945][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,945][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,946][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,946][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,947][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,947][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,948][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,948][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,949][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 05:19:44,949][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 05:19:44,951][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-16 05:19:45,157][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 05:19:45,159][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-16 05:19:45,160][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 05:19:45,347][root][INFO] - 

[2024-10-16 05:19:45,347][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-16 05:19:45,347][root][INFO] - Data Preprocessing
[2024-10-16 05:19:45,347][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-16 05:19:45,347][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 05:19:45,347][root][INFO] - ㄴ data_remove                False

[2024-10-16 05:19:45,347][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 05:19:45,359][root][INFO] - vocab size              : 51200
[2024-10-16 05:19:45,360][root][INFO] - device                  : gpu
[2024-10-16 05:19:45,360][root][INFO] - random seed             : 2
[2024-10-16 05:19:45,360][root][INFO] - train data size         : 942912
[2024-10-16 05:19:45,360][root][INFO] - max epochs              : 5
[2024-10-16 05:19:45,360][root][INFO] - total steps             : 73665
[2024-10-16 05:19:45,360][root][INFO] - warmup steps            : 7366
[2024-10-16 05:19:45,360][root][INFO] - batch size              : 64
[2024-10-16 05:19:45,360][root][INFO] - accumulation steps      : 1
[2024-10-16 05:19:45,360][root][INFO] - optimizer               : adamwscale
[2024-10-16 05:19:45,361][root][INFO] - lr_scheduler            : cosine
[2024-10-16 05:19:45,361][root][INFO] - learning rate           : 0.02
[2024-10-16 05:19:45,361][root][INFO] - max length              : 256

[2024-10-16 05:19:45,361][root][INFO] - LoRA Configuration
[2024-10-16 05:19:45,361][root][INFO] - ㄴ r                    : 32
[2024-10-16 05:19:45,361][root][INFO] - ㄴ alpha                : 128
[2024-10-16 05:19:45,361][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 05:19:45,361][root][INFO] - KOMBO Configuration
[2024-10-16 05:19:45,361][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 05:19:45,361][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 05:19:45,361][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 05:19:45,362][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 05:19:45,362][root][INFO] - ㄴ do_combination       : True
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 05:19:45,362][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 05:19:45,362][root][INFO] - 

[2024-10-16 05:19:45,362][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-16 05:19:45,362][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 05:19:45,362][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb
[2024-10-16 05:19:45,362][root][INFO] - * tb interval   : 10000

[2024-10-16 05:19:45,363][root][INFO] - 

[2024-10-16 05:19:45,363][root][INFO] - Start the Training !
[2024-10-16 05:19:45,365][root][INFO] - 
[1/ 5 Epoch]
[2024-10-16 05:22:02,159][root][INFO] - Step: 3072/7680  |  Loss: 0.4076  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-16 05:22:11,119][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 05:22:11,120][root][INFO] - Score: 73.46 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:22:20,132][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 05:22:20,132][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 05:22:20,133][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 05:22:20,134][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 05:29:48,004][root][INFO] - Step: 3840/7680  |  Loss: 0.3683  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-16 05:29:56,969][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 05:29:56,969][root][INFO] - Score: 75.77 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:30:05,932][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 05:30:05,932][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 05:30:05,933][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 05:30:05,934][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 05:37:34,353][root][INFO] - Step: 4608/7680  |  Loss: 0.3315  |  Score: 84.98 [%]  |  Seq Length: 256.0
[2024-10-16 05:37:43,327][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 05:37:43,327][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 05:37:52,326][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 05:37:52,326][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 05:37:52,327][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 05:37:52,328][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 05:45:20,438][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-16 05:45:29,366][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 05:45:29,366][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 05:45:38,436][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 05:45:38,436][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 05:45:38,437][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 05:45:38,438][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 05:53:08,577][root][INFO] - Step: 6144/7680  |  Loss: 0.2681  |  Score: 87.98 [%]  |  Seq Length: 256.0
[2024-10-16 05:53:17,717][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 05:53:17,717][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 05:53:26,805][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 05:53:26,805][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 05:53:26,806][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 05:53:26,807][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 06:00:54,226][root][INFO] - Step: 6912/7680  |  Loss: 0.2485  |  Score: 89.16 [%]  |  Seq Length: 256.0
[2024-10-16 06:01:03,161][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 06:01:03,161][root][INFO] - Score: 76.72 [%]  |  Evaluation Time: 8.93 [s]
[2024-10-16 06:01:12,118][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 06:01:12,119][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 06:01:12,120][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 06:01:12,121][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 06:08:40,221][root][INFO] - Step: 7680/7680  |  Loss: 0.2410  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-16 06:08:49,149][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 06:08:49,149][root][INFO] - Score: 76.46 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 06:08:58,111][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 06:08:58,111][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 06:08:58,112][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 06:08:58,112][root][INFO] - - Epoch: 9
[2024-10-16 06:08:58,112][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 06:08:58,112][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 06:08:58,113][root][INFO] - Fine-tuning is done!
[2024-10-16 06:09:10,131][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,131][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,132][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,133][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,133][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,134][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,135][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,136][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,136][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,137][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,138][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,138][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,139][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,140][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,141][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,142][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,142][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,149][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,150][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,150][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,151][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,151][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,152][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 06:09:10,152][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 06:09:10,154][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 06:09:10,372][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 06:09:10,374][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 06:09:10,375][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 06:09:10,543][root][INFO] - 

[2024-10-16 06:09:10,543][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 06:09:10,543][root][INFO] - Data Preprocessing
[2024-10-16 06:09:10,543][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 06:09:10,543][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 06:09:10,543][root][INFO] - ㄴ data_remove                False

[2024-10-16 06:09:10,543][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 06:09:10,552][root][INFO] - vocab size              : 51200
[2024-10-16 06:09:10,552][root][INFO] - device                  : gpu
[2024-10-16 06:09:10,552][root][INFO] - random seed             : 3
[2024-10-16 06:09:10,552][root][INFO] - train data size         : 49152
[2024-10-16 06:09:10,552][root][INFO] - max epochs              : 10
[2024-10-16 06:09:10,552][root][INFO] - total steps             : 7680
[2024-10-16 06:09:10,552][root][INFO] - warmup steps            : 768
[2024-10-16 06:09:10,552][root][INFO] - batch size              : 64
[2024-10-16 06:09:10,553][root][INFO] - accumulation steps      : 1
[2024-10-16 06:09:10,553][root][INFO] - optimizer               : adamwscale
[2024-10-16 06:09:10,553][root][INFO] - lr_scheduler            : cosine
[2024-10-16 06:09:10,553][root][INFO] - learning rate           : 0.02
[2024-10-16 06:09:10,553][root][INFO] - max length              : 256

[2024-10-16 06:09:10,553][root][INFO] - LoRA Configuration
[2024-10-16 06:09:10,553][root][INFO] - ㄴ r                    : 32
[2024-10-16 06:09:10,553][root][INFO] - ㄴ alpha                : 128
[2024-10-16 06:09:10,553][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 06:09:10,553][root][INFO] - KOMBO Configuration
[2024-10-16 06:09:10,553][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 06:09:10,553][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 06:09:10,554][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 06:09:10,554][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 06:09:10,554][root][INFO] - ㄴ do_combination       : True
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 06:09:10,554][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 06:09:10,554][root][INFO] - 

[2024-10-16 06:09:10,554][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 06:09:10,555][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 06:09:10,555][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 06:09:10,555][root][INFO] - * tb interval   : 10000

[2024-10-16 06:09:10,555][root][INFO] - 

[2024-10-16 06:09:10,555][root][INFO] - Start the Training !
[2024-10-16 06:09:10,557][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 06:16:40,681][root][INFO] - Step: 768/7680  |  Loss: 0.6252  |  Score: 64.13 [%]  |  Seq Length: 256.0
[2024-10-16 06:16:49,702][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 06:16:49,702][root][INFO] - Score: 68.57 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 06:16:58,695][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 06:16:58,696][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 06:16:58,696][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 06:16:58,698][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 06:24:29,143][root][INFO] - Step: 1536/7680  |  Loss: 0.5207  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-16 06:24:38,184][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 06:24:38,185][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 06:24:47,263][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 06:24:47,263][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 06:24:47,264][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 06:24:47,266][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 06:32:14,699][root][INFO] - Step: 2304/7680  |  Loss: 0.4711  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-16 06:32:23,669][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 06:32:23,670][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 06:32:32,711][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 06:32:32,711][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 06:32:32,712][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 06:32:32,714][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 06:40:02,487][root][INFO] - Step: 3072/7680  |  Loss: 0.4328  |  Score: 79.44 [%]  |  Seq Length: 256.0
[2024-10-16 06:40:11,461][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 06:40:11,461][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-16 06:40:20,519][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 06:40:20,519][root][INFO] - Score: 71.79 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 06:40:20,520][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 06:40:20,522][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 06:47:50,585][root][INFO] - Step: 3840/7680  |  Loss: 0.3889  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-16 06:47:59,645][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 06:47:59,645][root][INFO] - Score: 74.17 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 06:48:08,715][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 06:48:08,715][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-16 06:48:08,717][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 06:48:34,562][root][INFO] - Step: 10000/73665  |  Loss: 0.7587  |  Score: 66.92 [%]  |  Seq Length: 256.0
[2024-10-16 06:55:36,491][root][INFO] - Step: 4608/7680  |  Loss: 0.3400  |  Score: 84.52 [%]  |  Seq Length: 256.0
[2024-10-16 06:55:45,510][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 06:55:45,510][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 06:55:54,605][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 06:55:54,605][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 06:55:54,606][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 06:55:54,608][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 07:03:24,834][root][INFO] - Step: 5376/7680  |  Loss: 0.2948  |  Score: 86.84 [%]  |  Seq Length: 256.0
[2024-10-16 07:03:33,915][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 07:03:33,915][root][INFO] - Score: 75.16 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 07:03:42,995][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 07:03:42,995][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 07:03:42,998][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 07:11:10,294][root][INFO] - Step: 6144/7680  |  Loss: 0.2517  |  Score: 88.88 [%]  |  Seq Length: 256.0
[2024-10-16 07:11:19,176][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 07:11:19,176][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 07:11:28,054][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 07:11:28,054][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 07:11:28,055][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 07:11:28,057][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 07:18:56,285][root][INFO] - Step: 6912/7680  |  Loss: 0.2166  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-16 07:19:05,149][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 07:19:05,149][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 8.86 [s]
[2024-10-16 07:19:14,072][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 07:19:14,072][root][INFO] - Score: 73.41 [%]  |  Evaluation Time: 8.92 [s]
[2024-10-16 07:19:14,073][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 07:19:14,074][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 07:26:40,499][root][INFO] - Step: 7680/7680  |  Loss: 0.1979  |  Score: 91.43 [%]  |  Seq Length: 256.0
[2024-10-16 07:26:49,390][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 07:26:49,390][root][INFO] - Score: 76.60 [%]  |  Evaluation Time: 8.89 [s]
[2024-10-16 07:26:58,289][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 07:26:58,289][root][INFO] - Score: 73.52 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 07:26:58,290][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 07:26:58,290][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 07:26:58,290][root][INFO] - - Epoch: 10
[2024-10-16 07:26:58,290][root][INFO] - - DEV score: 76.60 [%]
[2024-10-16 07:26:58,290][root][INFO] - - TEST score: 73.52 [%]
[2024-10-16 07:26:58,291][root][INFO] - Fine-tuning is done!
[2024-10-16 07:26:58,291][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 07:26:58,292][root][INFO] - - BEST LR: 0.01
[2024-10-16 07:26:58,292][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 07:26:58,292][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 07:27:03,909][root][INFO] - 

[2024-10-16 07:27:03,909][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 07:27:03,909][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 07:27:03,909][root][INFO] - 

[2024-10-16 07:27:03,910][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 07:27:11,299][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,300][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,300][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,301][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,302][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,302][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,303][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,303][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,304][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,304][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,305][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,305][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,306][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,307][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,307][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,308][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,308][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,309][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,309][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,310][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,312][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,312][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,313][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 07:27:11,313][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 07:27:11,315][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 07:27:11,320][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 07:27:11,512][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 07:27:11,514][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 07:27:11,698][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 07:27:14,629][root][INFO] - 

[2024-10-16 07:27:14,629][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 07:27:14,629][root][INFO] - Data Preprocessing
[2024-10-16 07:27:14,629][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 07:27:14,629][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 07:27:14,629][root][INFO] - ㄴ data_remove                True

[2024-10-16 07:27:14,629][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 07:27:14,637][root][INFO] - vocab size              : 51200
[2024-10-16 07:27:14,637][root][INFO] - device                  : gpu
[2024-10-16 07:27:14,637][root][INFO] - random seed             : 1
[2024-10-16 07:27:14,637][root][INFO] - train data size         : 24256
[2024-10-16 07:27:14,637][root][INFO] - max epochs              : 10
[2024-10-16 07:27:14,637][root][INFO] - total steps             : 3790
[2024-10-16 07:27:14,637][root][INFO] - warmup steps            : 379
[2024-10-16 07:27:14,637][root][INFO] - batch size              : 64
[2024-10-16 07:27:14,637][root][INFO] - accumulation steps      : 1
[2024-10-16 07:27:14,637][root][INFO] - optimizer               : adamwscale
[2024-10-16 07:27:14,638][root][INFO] - lr_scheduler            : cosine
[2024-10-16 07:27:14,638][root][INFO] - learning rate           : 0.01
[2024-10-16 07:27:14,638][root][INFO] - max length              : 256

[2024-10-16 07:27:14,638][root][INFO] - LoRA Configuration
[2024-10-16 07:27:14,638][root][INFO] - ㄴ r                    : 32
[2024-10-16 07:27:14,638][root][INFO] - ㄴ alpha                : 128
[2024-10-16 07:27:14,638][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 07:27:14,638][root][INFO] - KOMBO Configuration
[2024-10-16 07:27:14,638][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 07:27:14,638][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 07:27:14,638][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 07:27:14,639][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 07:27:14,639][root][INFO] - ㄴ do_combination       : True
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 07:27:14,639][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 07:27:14,639][root][INFO] - 

[2024-10-16 07:27:14,639][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 07:27:14,639][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 07:27:14,639][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 07:27:14,640][root][INFO] - * tb interval   : 10000

[2024-10-16 07:27:14,640][root][INFO] - 

[2024-10-16 07:27:14,640][root][INFO] - Start the Training !
[2024-10-16 07:27:14,642][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 07:30:34,592][root][INFO] - Step: 14733/73665  |  Loss: 0.8354  |  Score: 62.15 [%]  |  Seq Length: 256.0
[2024-10-16 07:30:45,059][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 07:30:45,059][root][INFO] - Score: 58.93 [%]  |  Evaluation Time: 10.46 [s]
[2024-10-16 07:30:53,603][root][INFO] - Step: 379/3790  |  Loss: 0.6989  |  Score: 54.10 [%]  |  Seq Length: 256.0
[2024-10-16 07:30:58,143][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 07:30:58,143][root][INFO] - Score: 58.98 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 07:31:02,615][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 07:31:02,615][root][INFO] - Score: 56.52 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 07:31:02,616][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 07:31:02,617][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 07:31:05,224][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 07:31:05,224][root][INFO] - Score: 58.80 [%]  |  Evaluation Time: 20.16 [s]
[2024-10-16 07:31:05,225][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 07:31:05,226][root][INFO] - 
[2/ 5 Epoch]
[2024-10-16 07:34:41,391][root][INFO] - Step: 758/3790  |  Loss: 0.5957  |  Score: 68.22 [%]  |  Seq Length: 256.0
[2024-10-16 07:34:45,907][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 07:34:45,907][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:34:50,325][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 07:34:50,326][root][INFO] - Score: 60.83 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 07:34:50,326][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 07:34:50,328][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 07:38:29,226][root][INFO] - Step: 1137/3790  |  Loss: 0.5221  |  Score: 73.95 [%]  |  Seq Length: 256.0
[2024-10-16 07:38:33,735][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 07:38:33,735][root][INFO] - Score: 65.33 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:38:38,166][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 07:38:38,167][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 07:38:38,168][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 07:38:38,169][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 07:42:16,662][root][INFO] - Step: 1516/3790  |  Loss: 0.4657  |  Score: 77.93 [%]  |  Seq Length: 256.0
[2024-10-16 07:42:21,181][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 07:42:21,181][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 07:42:25,671][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 07:42:25,671][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 07:42:25,672][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 07:42:25,674][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 07:46:03,629][root][INFO] - Step: 1895/3790  |  Loss: 0.4148  |  Score: 80.71 [%]  |  Seq Length: 256.0
[2024-10-16 07:46:08,156][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 07:46:08,156][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 07:46:12,592][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 07:46:12,592][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 07:46:12,593][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 07:46:12,594][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 07:49:47,230][root][INFO] - Step: 2274/3790  |  Loss: 0.3753  |  Score: 82.87 [%]  |  Seq Length: 256.0
[2024-10-16 07:49:51,751][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 07:49:51,752][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 07:49:56,181][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 07:49:56,181][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 07:49:56,182][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 07:49:56,183][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 07:53:34,664][root][INFO] - Step: 2653/3790  |  Loss: 0.3384  |  Score: 84.64 [%]  |  Seq Length: 256.0
[2024-10-16 07:53:39,174][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 07:53:39,175][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:53:43,612][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 07:53:43,612][root][INFO] - Score: 66.65 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-16 07:53:43,614][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 07:57:22,243][root][INFO] - Step: 3032/3790  |  Loss: 0.3095  |  Score: 86.36 [%]  |  Seq Length: 256.0
[2024-10-16 07:57:26,754][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 07:57:26,754][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 07:57:31,203][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 07:57:31,204][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-16 07:57:31,206][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 08:01:09,344][root][INFO] - Step: 3411/3790  |  Loss: 0.2896  |  Score: 87.03 [%]  |  Seq Length: 256.0
[2024-10-16 08:01:13,867][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 08:01:13,867][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:01:18,324][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 08:01:18,324][root][INFO] - Score: 66.61 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-16 08:01:18,326][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 08:04:56,648][root][INFO] - Step: 3790/3790  |  Loss: 0.2791  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-16 08:05:01,167][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 08:05:01,167][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:05:05,603][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 08:05:05,603][root][INFO] - Score: 67.19 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 08:05:05,604][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 08:05:05,604][root][INFO] - - Epoch: 6
[2024-10-16 08:05:05,604][root][INFO] - - DEV score: 73.34 [%]
[2024-10-16 08:05:05,604][root][INFO] - - TEST score: 66.74 [%]
[2024-10-16 08:05:05,605][root][INFO] - Fine-tuning is done!
[2024-10-16 08:05:12,554][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,555][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,555][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,556][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,557][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,557][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,558][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,559][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,559][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,560][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,561][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,562][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,563][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,563][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,564][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,564][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,565][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,565][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,566][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,566][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,567][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,567][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,568][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 08:05:12,568][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 08:05:12,570][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 08:05:12,770][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 08:05:12,772][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 08:05:12,773][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 08:05:12,935][root][INFO] - 

[2024-10-16 08:05:12,935][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 08:05:12,935][root][INFO] - Data Preprocessing
[2024-10-16 08:05:12,935][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 08:05:12,935][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 08:05:12,935][root][INFO] - ㄴ data_remove                True

[2024-10-16 08:05:12,935][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 08:05:12,943][root][INFO] - vocab size              : 51200
[2024-10-16 08:05:12,944][root][INFO] - device                  : gpu
[2024-10-16 08:05:12,944][root][INFO] - random seed             : 1
[2024-10-16 08:05:12,944][root][INFO] - train data size         : 24256
[2024-10-16 08:05:12,944][root][INFO] - max epochs              : 10
[2024-10-16 08:05:12,944][root][INFO] - total steps             : 3790
[2024-10-16 08:05:12,944][root][INFO] - warmup steps            : 379
[2024-10-16 08:05:12,944][root][INFO] - batch size              : 64
[2024-10-16 08:05:12,944][root][INFO] - accumulation steps      : 1
[2024-10-16 08:05:12,944][root][INFO] - optimizer               : adamwscale
[2024-10-16 08:05:12,944][root][INFO] - lr_scheduler            : cosine
[2024-10-16 08:05:12,944][root][INFO] - learning rate           : 0.02
[2024-10-16 08:05:12,945][root][INFO] - max length              : 256

[2024-10-16 08:05:12,945][root][INFO] - LoRA Configuration
[2024-10-16 08:05:12,945][root][INFO] - ㄴ r                    : 32
[2024-10-16 08:05:12,945][root][INFO] - ㄴ alpha                : 128
[2024-10-16 08:05:12,945][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 08:05:12,945][root][INFO] - KOMBO Configuration
[2024-10-16 08:05:12,945][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 08:05:12,945][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 08:05:12,945][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 08:05:12,945][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 08:05:12,945][root][INFO] - ㄴ do_combination       : True
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 08:05:12,946][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 08:05:12,946][root][INFO] - 

[2024-10-16 08:05:12,946][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 08:05:12,946][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 08:05:12,946][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 08:05:12,946][root][INFO] - * tb interval   : 10000

[2024-10-16 08:05:12,946][root][INFO] - 

[2024-10-16 08:05:12,946][root][INFO] - Start the Training !
[2024-10-16 08:05:12,948][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 08:08:46,119][root][INFO] - Step: 379/3790  |  Loss: 0.6780  |  Score: 57.60 [%]  |  Seq Length: 256.0
[2024-10-16 08:08:50,681][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 08:08:50,681][root][INFO] - Score: 64.06 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 08:08:55,171][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 08:08:55,172][root][INFO] - Score: 59.82 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 08:08:55,173][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 08:08:55,174][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 08:12:28,381][root][INFO] - Step: 758/3790  |  Loss: 0.5684  |  Score: 70.11 [%]  |  Seq Length: 256.0
[2024-10-16 08:12:32,942][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 08:12:32,942][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 08:12:37,421][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 08:12:37,421][root][INFO] - Score: 64.67 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:12:37,422][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 08:12:37,423][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 08:16:12,024][root][INFO] - Step: 1137/3790  |  Loss: 0.5130  |  Score: 74.31 [%]  |  Seq Length: 256.0
[2024-10-16 08:16:16,589][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 08:16:16,589][root][INFO] - Score: 65.23 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 08:16:21,102][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 08:16:21,102][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 08:16:21,103][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 08:16:21,104][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 08:17:53,282][root][INFO] - Step: 20000/73665  |  Loss: 1.0400  |  Score: 44.93 [%]  |  Seq Length: 256.0
[2024-10-16 08:20:00,198][root][INFO] - Step: 1516/3790  |  Loss: 0.4611  |  Score: 77.89 [%]  |  Seq Length: 256.0
[2024-10-16 08:20:04,750][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 08:20:04,750][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 08:20:09,241][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 08:20:09,241][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 08:20:09,242][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 08:20:09,244][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 08:23:47,850][root][INFO] - Step: 1895/3790  |  Loss: 0.4025  |  Score: 81.25 [%]  |  Seq Length: 256.0
[2024-10-16 08:23:52,427][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 08:23:52,427][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 08:23:56,906][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 08:23:56,906][root][INFO] - Score: 65.55 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:23:56,909][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 08:27:35,234][root][INFO] - Step: 2274/3790  |  Loss: 0.3566  |  Score: 83.93 [%]  |  Seq Length: 256.0
[2024-10-16 08:27:39,804][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 08:27:39,804][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 08:27:44,282][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 08:27:44,282][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:27:44,285][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 08:31:23,145][root][INFO] - Step: 2653/3790  |  Loss: 0.3011  |  Score: 86.48 [%]  |  Seq Length: 256.0
[2024-10-16 08:31:27,741][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 08:31:27,741][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 08:31:32,240][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 08:31:32,240][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 08:31:32,242][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 08:35:10,553][root][INFO] - Step: 3032/3790  |  Loss: 0.2530  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-16 08:35:15,084][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 08:35:15,084][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 08:35:19,581][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 08:35:19,581][root][INFO] - Score: 67.99 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 08:35:19,583][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 08:38:58,415][root][INFO] - Step: 3411/3790  |  Loss: 0.2240  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-16 08:39:02,967][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 08:39:02,968][root][INFO] - Score: 68.85 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 08:39:07,493][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 08:39:07,494][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:39:07,495][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 08:42:46,658][root][INFO] - Step: 3790/3790  |  Loss: 0.2060  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-16 08:42:51,260][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 08:42:51,260][root][INFO] - Score: 70.21 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-16 08:42:55,745][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 08:42:55,746][root][INFO] - Score: 67.39 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:42:55,747][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 08:42:55,747][root][INFO] - - Epoch: 4
[2024-10-16 08:42:55,747][root][INFO] - - DEV score: 70.02 [%]
[2024-10-16 08:42:55,747][root][INFO] - - TEST score: 67.80 [%]
[2024-10-16 08:42:55,748][root][INFO] - Fine-tuning is done!
[2024-10-16 08:42:55,748][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 08:42:55,748][root][INFO] - - BEST LR: 0.01
[2024-10-16 08:42:55,748][root][INFO] - - DEV score: 73.34 [%]
[2024-10-16 08:42:55,748][root][INFO] - - TEST score: 66.74 [%]
[2024-10-16 08:43:01,497][root][INFO] - 

[2024-10-16 08:43:01,497][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 08:43:01,497][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 08:43:01,497][root][INFO] - 

[2024-10-16 08:43:01,497][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 08:43:08,960][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,961][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,961][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,962][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,962][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,963][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,963][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,964][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,964][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,965][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,965][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,966][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,966][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,967][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,967][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,968][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,968][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,969][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,969][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,970][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,971][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,972][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,972][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 08:43:08,973][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 08:43:08,975][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 08:43:08,979][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 08:43:09,176][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 08:43:09,179][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 08:43:09,373][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 08:43:12,432][root][INFO] - 

[2024-10-16 08:43:12,432][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 08:43:12,432][root][INFO] - Data Preprocessing
[2024-10-16 08:43:12,432][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 08:43:12,432][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 08:43:12,432][root][INFO] - ㄴ data_remove                True

[2024-10-16 08:43:12,433][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 08:43:12,440][root][INFO] - vocab size              : 51200
[2024-10-16 08:43:12,441][root][INFO] - device                  : gpu
[2024-10-16 08:43:12,441][root][INFO] - random seed             : 2
[2024-10-16 08:43:12,441][root][INFO] - train data size         : 24256
[2024-10-16 08:43:12,441][root][INFO] - max epochs              : 10
[2024-10-16 08:43:12,441][root][INFO] - total steps             : 3790
[2024-10-16 08:43:12,441][root][INFO] - warmup steps            : 379
[2024-10-16 08:43:12,441][root][INFO] - batch size              : 64
[2024-10-16 08:43:12,441][root][INFO] - accumulation steps      : 1
[2024-10-16 08:43:12,441][root][INFO] - optimizer               : adamwscale
[2024-10-16 08:43:12,441][root][INFO] - lr_scheduler            : cosine
[2024-10-16 08:43:12,441][root][INFO] - learning rate           : 0.01
[2024-10-16 08:43:12,441][root][INFO] - max length              : 256

[2024-10-16 08:43:12,442][root][INFO] - LoRA Configuration
[2024-10-16 08:43:12,442][root][INFO] - ㄴ r                    : 32
[2024-10-16 08:43:12,442][root][INFO] - ㄴ alpha                : 128
[2024-10-16 08:43:12,442][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 08:43:12,442][root][INFO] - KOMBO Configuration
[2024-10-16 08:43:12,442][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 08:43:12,442][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 08:43:12,442][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 08:43:12,442][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 08:43:12,442][root][INFO] - ㄴ do_combination       : True
[2024-10-16 08:43:12,442][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 08:43:12,443][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 08:43:12,443][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 08:43:12,443][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 08:43:12,443][root][INFO] - 

[2024-10-16 08:43:12,443][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 08:43:12,443][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 08:43:12,443][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 08:43:12,443][root][INFO] - * tb interval   : 10000

[2024-10-16 08:43:12,443][root][INFO] - 

[2024-10-16 08:43:12,443][root][INFO] - Start the Training !
[2024-10-16 08:43:12,446][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 08:46:51,490][root][INFO] - Step: 379/3790  |  Loss: 0.6820  |  Score: 57.01 [%]  |  Seq Length: 256.0
[2024-10-16 08:46:56,061][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 08:46:56,061][root][INFO] - Score: 62.79 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 08:47:00,539][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 08:47:00,539][root][INFO] - Score: 59.45 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 08:47:00,540][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 08:47:00,542][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 08:50:38,010][root][INFO] - Step: 758/3790  |  Loss: 0.5809  |  Score: 69.35 [%]  |  Seq Length: 256.0
[2024-10-16 08:50:42,536][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 08:50:42,536][root][INFO] - Score: 66.60 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 08:50:46,936][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 08:50:46,937][root][INFO] - Score: 62.75 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-16 08:50:46,937][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 08:50:46,939][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 08:54:24,248][root][INFO] - Step: 1137/3790  |  Loss: 0.5210  |  Score: 74.19 [%]  |  Seq Length: 256.0
[2024-10-16 08:54:28,844][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 08:54:28,844][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 08:54:33,349][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 08:54:33,350][root][INFO] - Score: 64.53 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 08:54:33,351][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 08:54:33,352][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 08:58:11,488][root][INFO] - Step: 1516/3790  |  Loss: 0.4662  |  Score: 77.42 [%]  |  Seq Length: 256.0
[2024-10-16 08:58:15,966][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 08:58:15,966][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 08:58:20,392][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 08:58:20,392][root][INFO] - Score: 65.94 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 08:58:20,394][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 09:01:58,432][root][INFO] - Step: 1895/3790  |  Loss: 0.4199  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-16 09:02:02,960][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 09:02:02,960][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 09:02:07,383][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 09:02:07,383][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 09:02:07,384][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 09:02:07,385][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 09:05:43,701][root][INFO] - Step: 2274/3790  |  Loss: 0.3750  |  Score: 82.67 [%]  |  Seq Length: 256.0
[2024-10-16 09:05:48,226][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 09:05:48,226][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 09:05:52,820][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 09:05:52,820][root][INFO] - Score: 66.42 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:05:52,823][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 09:09:29,401][root][INFO] - Step: 2653/3790  |  Loss: 0.3405  |  Score: 84.53 [%]  |  Seq Length: 256.0
[2024-10-16 09:09:33,990][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 09:09:33,990][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:09:38,439][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 09:09:38,439][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-16 09:09:38,441][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 09:13:16,440][root][INFO] - Step: 3032/3790  |  Loss: 0.3098  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-16 09:13:20,921][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 09:13:20,921][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-16 09:13:25,332][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 09:13:25,333][root][INFO] - Score: 68.67 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-16 09:13:25,334][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 09:13:25,335][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 09:17:03,266][root][INFO] - Step: 3411/3790  |  Loss: 0.2952  |  Score: 86.68 [%]  |  Seq Length: 256.0
[2024-10-16 09:17:07,757][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 09:17:07,757][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 09:17:12,183][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 09:17:12,184][root][INFO] - Score: 67.27 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 09:17:12,186][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 09:20:50,240][root][INFO] - Step: 3790/3790  |  Loss: 0.2806  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-16 09:20:54,825][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 09:20:54,825][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:20:59,366][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 09:20:59,367][root][INFO] - Score: 68.42 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 09:20:59,368][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 09:20:59,368][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 09:20:59,368][root][INFO] - - Epoch: 10
[2024-10-16 09:20:59,368][root][INFO] - - DEV score: 72.75 [%]
[2024-10-16 09:20:59,368][root][INFO] - - TEST score: 68.42 [%]
[2024-10-16 09:20:59,369][root][INFO] - Fine-tuning is done!
[2024-10-16 09:21:06,146][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,147][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,147][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,148][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,148][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,149][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,150][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,150][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,151][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,151][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,152][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,152][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,153][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,153][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,154][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,154][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,155][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,155][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,156][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,156][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,157][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,158][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,158][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 09:21:06,159][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 09:21:06,161][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 09:21:06,355][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 09:21:06,357][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 09:21:06,358][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 09:21:06,523][root][INFO] - 

[2024-10-16 09:21:06,523][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 09:21:06,523][root][INFO] - Data Preprocessing
[2024-10-16 09:21:06,523][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 09:21:06,523][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 09:21:06,524][root][INFO] - ㄴ data_remove                True

[2024-10-16 09:21:06,524][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 09:21:06,531][root][INFO] - vocab size              : 51200
[2024-10-16 09:21:06,531][root][INFO] - device                  : gpu
[2024-10-16 09:21:06,532][root][INFO] - random seed             : 2
[2024-10-16 09:21:06,532][root][INFO] - train data size         : 24256
[2024-10-16 09:21:06,532][root][INFO] - max epochs              : 10
[2024-10-16 09:21:06,532][root][INFO] - total steps             : 3790
[2024-10-16 09:21:06,532][root][INFO] - warmup steps            : 379
[2024-10-16 09:21:06,532][root][INFO] - batch size              : 64
[2024-10-16 09:21:06,532][root][INFO] - accumulation steps      : 1
[2024-10-16 09:21:06,532][root][INFO] - optimizer               : adamwscale
[2024-10-16 09:21:06,532][root][INFO] - lr_scheduler            : cosine
[2024-10-16 09:21:06,532][root][INFO] - learning rate           : 0.02
[2024-10-16 09:21:06,532][root][INFO] - max length              : 256

[2024-10-16 09:21:06,532][root][INFO] - LoRA Configuration
[2024-10-16 09:21:06,533][root][INFO] - ㄴ r                    : 32
[2024-10-16 09:21:06,533][root][INFO] - ㄴ alpha                : 128
[2024-10-16 09:21:06,533][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 09:21:06,533][root][INFO] - KOMBO Configuration
[2024-10-16 09:21:06,533][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 09:21:06,533][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 09:21:06,533][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 09:21:06,533][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 09:21:06,533][root][INFO] - ㄴ do_combination       : True
[2024-10-16 09:21:06,533][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 09:21:06,534][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 09:21:06,534][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 09:21:06,534][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 09:21:06,534][root][INFO] - 

[2024-10-16 09:21:06,534][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 09:21:06,534][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 09:21:06,534][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 09:21:06,534][root][INFO] - * tb interval   : 10000

[2024-10-16 09:21:06,534][root][INFO] - 

[2024-10-16 09:21:06,534][root][INFO] - Start the Training !
[2024-10-16 09:21:06,536][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 09:24:45,719][root][INFO] - Step: 379/3790  |  Loss: 0.6703  |  Score: 59.12 [%]  |  Seq Length: 256.0
[2024-10-16 09:24:50,415][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 09:24:50,415][root][INFO] - Score: 66.41 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-16 09:24:54,891][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 09:24:54,891][root][INFO] - Score: 59.91 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 09:24:54,892][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 09:24:54,893][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 09:28:32,033][root][INFO] - Step: 758/3790  |  Loss: 0.5669  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-16 09:28:36,619][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 09:28:36,619][root][INFO] - Score: 67.58 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:28:41,212][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 09:28:41,212][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:28:41,213][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 09:28:41,214][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 09:32:18,244][root][INFO] - Step: 1137/3790  |  Loss: 0.5082  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-16 09:32:22,773][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 09:32:22,773][root][INFO] - Score: 65.53 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 09:32:27,227][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 09:32:27,227][root][INFO] - Score: 67.04 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-16 09:32:27,229][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 09:36:00,250][root][INFO] - Step: 1516/3790  |  Loss: 0.4569  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-16 09:36:04,809][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 09:36:04,809][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 09:36:09,394][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 09:36:09,394][root][INFO] - Score: 66.84 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:36:09,395][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 09:36:09,396][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 09:39:48,494][root][INFO] - Step: 1895/3790  |  Loss: 0.4079  |  Score: 81.11 [%]  |  Seq Length: 256.0
[2024-10-16 09:39:53,089][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 09:39:53,089][root][INFO] - Score: 69.14 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 09:39:57,663][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 09:39:57,663][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:39:57,664][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 09:39:57,665][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 09:40:54,834][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.35 [%]  |  Seq Length: 256.0
[2024-10-16 09:41:04,927][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 09:41:04,927][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.09 [s]
[2024-10-16 09:41:24,741][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 09:41:24,741][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 19.81 [s]
[2024-10-16 09:41:24,743][root][INFO] - 
[3/ 5 Epoch]
[2024-10-16 09:43:35,952][root][INFO] - Step: 2274/3790  |  Loss: 0.3487  |  Score: 84.15 [%]  |  Seq Length: 256.0
[2024-10-16 09:43:40,525][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 09:43:40,525][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:43:45,053][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 09:43:45,053][root][INFO] - Score: 68.03 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 09:43:45,054][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 09:43:45,055][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 09:46:05,951][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.41 [%]  |  Seq Length: 256.0
[2024-10-16 09:47:24,007][root][INFO] - Step: 2653/3790  |  Loss: 0.2954  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-16 09:47:28,578][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 09:47:28,578][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:47:33,101][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 09:47:33,101][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 09:47:33,102][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 09:47:33,103][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 09:51:11,359][root][INFO] - Step: 3032/3790  |  Loss: 0.2463  |  Score: 89.20 [%]  |  Seq Length: 256.0
[2024-10-16 09:51:15,937][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 09:51:15,938][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-16 09:51:20,370][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 09:51:20,370][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 09:51:20,372][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 09:54:57,506][root][INFO] - Step: 3411/3790  |  Loss: 0.2186  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-16 09:55:02,035][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 09:55:02,035][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 09:55:06,477][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 09:55:06,477][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-16 09:55:06,479][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 09:58:45,016][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-16 09:58:49,591][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 09:58:49,591][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 09:58:54,050][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 09:58:54,050][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-16 09:58:54,051][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 09:58:54,051][root][INFO] - - Epoch: 7
[2024-10-16 09:58:54,051][root][INFO] - - DEV score: 71.29 [%]
[2024-10-16 09:58:54,051][root][INFO] - - TEST score: 69.32 [%]
[2024-10-16 09:58:54,053][root][INFO] - Fine-tuning is done!
[2024-10-16 09:58:54,053][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 09:58:54,053][root][INFO] - - BEST LR: 0.01
[2024-10-16 09:58:54,053][root][INFO] - - DEV score: 72.75 [%]
[2024-10-16 09:58:54,053][root][INFO] - - TEST score: 68.42 [%]
[2024-10-16 09:58:59,645][root][INFO] - 

[2024-10-16 09:58:59,645][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 09:58:59,645][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 09:58:59,645][root][INFO] - 

[2024-10-16 09:58:59,646][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 09:59:07,621][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,622][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,623][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,623][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,624][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,624][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,625][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,625][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,626][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,626][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,627][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,627][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,628][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,628][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,629][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,629][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,630][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,631][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,631][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,632][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,635][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,636][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,636][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 09:59:07,637][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 09:59:07,639][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 09:59:07,643][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 09:59:07,837][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 09:59:07,839][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 09:59:08,041][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 09:59:11,151][root][INFO] - 

[2024-10-16 09:59:11,151][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 09:59:11,151][root][INFO] - Data Preprocessing
[2024-10-16 09:59:11,151][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 09:59:11,151][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 09:59:11,151][root][INFO] - ㄴ data_remove                True

[2024-10-16 09:59:11,151][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 09:59:11,159][root][INFO] - vocab size              : 51200
[2024-10-16 09:59:11,159][root][INFO] - device                  : gpu
[2024-10-16 09:59:11,159][root][INFO] - random seed             : 3
[2024-10-16 09:59:11,159][root][INFO] - train data size         : 24256
[2024-10-16 09:59:11,159][root][INFO] - max epochs              : 10
[2024-10-16 09:59:11,159][root][INFO] - total steps             : 3790
[2024-10-16 09:59:11,160][root][INFO] - warmup steps            : 379
[2024-10-16 09:59:11,160][root][INFO] - batch size              : 64
[2024-10-16 09:59:11,160][root][INFO] - accumulation steps      : 1
[2024-10-16 09:59:11,160][root][INFO] - optimizer               : adamwscale
[2024-10-16 09:59:11,160][root][INFO] - lr_scheduler            : cosine
[2024-10-16 09:59:11,160][root][INFO] - learning rate           : 0.01
[2024-10-16 09:59:11,160][root][INFO] - max length              : 256

[2024-10-16 09:59:11,160][root][INFO] - LoRA Configuration
[2024-10-16 09:59:11,160][root][INFO] - ㄴ r                    : 32
[2024-10-16 09:59:11,160][root][INFO] - ㄴ alpha                : 128
[2024-10-16 09:59:11,160][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 09:59:11,160][root][INFO] - KOMBO Configuration
[2024-10-16 09:59:11,161][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 09:59:11,161][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 09:59:11,161][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 09:59:11,161][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 09:59:11,161][root][INFO] - ㄴ do_combination       : True
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 09:59:11,161][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 09:59:11,162][root][INFO] - 

[2024-10-16 09:59:11,162][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 09:59:11,162][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 09:59:11,162][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 09:59:11,162][root][INFO] - * tb interval   : 10000

[2024-10-16 09:59:11,162][root][INFO] - 

[2024-10-16 09:59:11,162][root][INFO] - Start the Training !
[2024-10-16 09:59:11,165][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 10:02:50,281][root][INFO] - Step: 379/3790  |  Loss: 0.6791  |  Score: 57.91 [%]  |  Seq Length: 256.0
[2024-10-16 10:02:54,789][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 10:02:54,789][root][INFO] - Score: 61.13 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 10:02:59,200][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 10:02:59,200][root][INFO] - Score: 60.72 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-16 10:02:59,201][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 10:02:59,203][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 10:06:37,073][root][INFO] - Step: 758/3790  |  Loss: 0.5750  |  Score: 69.89 [%]  |  Seq Length: 256.0
[2024-10-16 10:06:41,606][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 10:06:41,606][root][INFO] - Score: 66.02 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 10:06:46,046][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 10:06:46,046][root][INFO] - Score: 64.05 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-16 10:06:46,047][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 10:06:46,048][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 10:10:23,930][root][INFO] - Step: 1137/3790  |  Loss: 0.5122  |  Score: 74.67 [%]  |  Seq Length: 256.0
[2024-10-16 10:10:28,439][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 10:10:28,439][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-16 10:10:32,847][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 10:10:32,847][root][INFO] - Score: 64.39 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-16 10:10:32,848][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 10:10:32,849][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 10:14:10,400][root][INFO] - Step: 1516/3790  |  Loss: 0.4581  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-16 10:14:14,967][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 10:14:14,968][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 10:14:19,438][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 10:14:19,438][root][INFO] - Score: 63.62 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 10:14:19,443][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 10:17:57,544][root][INFO] - Step: 1895/3790  |  Loss: 0.4133  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-16 10:18:02,114][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 10:18:02,114][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 10:18:06,657][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 10:18:06,657][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:18:06,658][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 10:18:06,659][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 10:21:45,856][root][INFO] - Step: 2274/3790  |  Loss: 0.3714  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-16 10:21:50,397][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 10:21:50,398][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:21:54,825][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 10:21:54,825][root][INFO] - Score: 65.54 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-16 10:21:54,827][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 10:25:32,799][root][INFO] - Step: 2653/3790  |  Loss: 0.3333  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-16 10:25:37,269][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 10:25:37,269][root][INFO] - Score: 69.24 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 10:25:41,832][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 10:25:41,832][root][INFO] - Score: 65.60 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 10:25:41,834][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 10:29:19,908][root][INFO] - Step: 3032/3790  |  Loss: 0.3040  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-16 10:29:24,466][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 10:29:24,466][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 10:29:28,868][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 10:29:28,868][root][INFO] - Score: 66.08 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-16 10:29:28,869][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 10:29:28,870][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 10:33:05,994][root][INFO] - Step: 3411/3790  |  Loss: 0.2838  |  Score: 87.23 [%]  |  Seq Length: 256.0
[2024-10-16 10:33:10,563][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 10:33:10,563][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-16 10:33:14,989][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 10:33:14,989][root][INFO] - Score: 65.73 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-16 10:33:14,992][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 10:36:53,181][root][INFO] - Step: 3790/3790  |  Loss: 0.2712  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-16 10:36:57,719][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 10:36:57,719][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 10:37:02,435][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 10:37:02,435][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-16 10:37:02,436][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 10:37:02,437][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 10:37:02,437][root][INFO] - - Epoch: 10
[2024-10-16 10:37:02,437][root][INFO] - - DEV score: 72.85 [%]
[2024-10-16 10:37:02,437][root][INFO] - - TEST score: 65.70 [%]
[2024-10-16 10:37:02,437][root][INFO] - Fine-tuning is done!
[2024-10-16 10:37:08,985][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,986][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,986][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,987][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,987][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,988][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,988][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,989][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,989][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,990][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,990][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,990][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,991][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,991][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,992][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,992][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,993][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,993][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,994][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,994][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,995][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,995][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,996][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 10:37:08,996][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 10:37:08,998][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 10:37:09,192][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 10:37:09,194][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 10:37:09,195][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 10:37:09,363][root][INFO] - 

[2024-10-16 10:37:09,363][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 10:37:09,363][root][INFO] - Data Preprocessing
[2024-10-16 10:37:09,363][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 10:37:09,363][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 10:37:09,363][root][INFO] - ㄴ data_remove                True

[2024-10-16 10:37:09,363][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 10:37:09,371][root][INFO] - vocab size              : 51200
[2024-10-16 10:37:09,371][root][INFO] - device                  : gpu
[2024-10-16 10:37:09,371][root][INFO] - random seed             : 3
[2024-10-16 10:37:09,372][root][INFO] - train data size         : 24256
[2024-10-16 10:37:09,372][root][INFO] - max epochs              : 10
[2024-10-16 10:37:09,372][root][INFO] - total steps             : 3790
[2024-10-16 10:37:09,372][root][INFO] - warmup steps            : 379
[2024-10-16 10:37:09,372][root][INFO] - batch size              : 64
[2024-10-16 10:37:09,372][root][INFO] - accumulation steps      : 1
[2024-10-16 10:37:09,372][root][INFO] - optimizer               : adamwscale
[2024-10-16 10:37:09,372][root][INFO] - lr_scheduler            : cosine
[2024-10-16 10:37:09,372][root][INFO] - learning rate           : 0.02
[2024-10-16 10:37:09,372][root][INFO] - max length              : 256

[2024-10-16 10:37:09,372][root][INFO] - LoRA Configuration
[2024-10-16 10:37:09,372][root][INFO] - ㄴ r                    : 32
[2024-10-16 10:37:09,373][root][INFO] - ㄴ alpha                : 128
[2024-10-16 10:37:09,373][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 10:37:09,373][root][INFO] - KOMBO Configuration
[2024-10-16 10:37:09,373][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 10:37:09,373][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 10:37:09,373][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 10:37:09,373][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 10:37:09,373][root][INFO] - ㄴ do_combination       : True
[2024-10-16 10:37:09,373][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 10:37:09,373][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 10:37:09,374][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 10:37:09,374][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 10:37:09,374][root][INFO] - 

[2024-10-16 10:37:09,374][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 10:37:09,374][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 10:37:09,374][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 10:37:09,374][root][INFO] - * tb interval   : 10000

[2024-10-16 10:37:09,374][root][INFO] - 

[2024-10-16 10:37:09,374][root][INFO] - Start the Training !
[2024-10-16 10:37:09,376][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 10:40:48,497][root][INFO] - Step: 379/3790  |  Loss: 0.6607  |  Score: 60.10 [%]  |  Seq Length: 256.0
[2024-10-16 10:40:53,047][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 10:40:53,048][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 10:40:57,543][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 10:40:57,543][root][INFO] - Score: 60.64 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-16 10:40:57,544][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 10:40:57,545][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 10:44:33,194][root][INFO] - Step: 758/3790  |  Loss: 0.5616  |  Score: 71.12 [%]  |  Seq Length: 256.0
[2024-10-16 10:44:37,735][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 10:44:37,735][root][INFO] - Score: 65.04 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:44:42,262][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 10:44:42,263][root][INFO] - Score: 62.68 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-16 10:44:42,265][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 10:48:20,669][root][INFO] - Step: 1137/3790  |  Loss: 0.4997  |  Score: 75.63 [%]  |  Seq Length: 256.0
[2024-10-16 10:48:25,271][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 10:48:25,272][root][INFO] - Score: 69.73 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-16 10:48:29,742][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 10:48:29,742][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 10:48:29,743][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 10:48:29,744][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 10:52:08,422][root][INFO] - Step: 1516/3790  |  Loss: 0.4472  |  Score: 78.90 [%]  |  Seq Length: 256.0
[2024-10-16 10:52:13,014][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 10:52:13,014][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-16 10:52:17,517][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 10:52:17,517][root][INFO] - Score: 66.80 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-16 10:52:17,518][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 10:52:17,519][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 10:55:56,269][root][INFO] - Step: 1895/3790  |  Loss: 0.3977  |  Score: 81.23 [%]  |  Seq Length: 256.0
[2024-10-16 10:56:00,825][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 10:56:00,825][root][INFO] - Score: 71.00 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 10:56:05,364][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 10:56:05,364][root][INFO] - Score: 67.80 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 10:56:05,365][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 10:56:05,366][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 10:59:43,804][root][INFO] - Step: 2274/3790  |  Loss: 0.3445  |  Score: 84.26 [%]  |  Seq Length: 256.0
[2024-10-16 10:59:48,461][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 10:59:48,461][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-16 10:59:53,061][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 10:59:53,062][root][INFO] - Score: 66.36 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-16 10:59:53,064][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 11:03:33,573][root][INFO] - Step: 2653/3790  |  Loss: 0.2995  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-16 11:03:38,136][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 11:03:38,136][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-16 11:03:42,655][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 11:03:42,655][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-16 11:03:42,657][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 11:07:22,964][root][INFO] - Step: 3032/3790  |  Loss: 0.2495  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-16 11:07:27,516][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 11:07:27,517][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-16 11:07:31,991][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 11:07:31,991][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-16 11:07:31,992][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 11:07:31,993][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 11:11:11,234][root][INFO] - Step: 3411/3790  |  Loss: 0.2111  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-16 11:11:15,774][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 11:11:15,774][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-16 11:11:20,240][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 11:11:20,240][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-16 11:11:20,242][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 11:13:34,447][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-16 11:15:00,387][root][INFO] - Step: 3790/3790  |  Loss: 0.1974  |  Score: 91.52 [%]  |  Seq Length: 256.0
[2024-10-16 11:15:05,115][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 11:15:05,115][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-16 11:15:09,870][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 11:15:09,870][root][INFO] - Score: 68.36 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-16 11:15:09,871][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 11:15:09,871][root][INFO] - - Epoch: 8
[2024-10-16 11:15:09,871][root][INFO] - - DEV score: 73.83 [%]
[2024-10-16 11:15:09,871][root][INFO] - - TEST score: 68.33 [%]
[2024-10-16 11:15:09,872][root][INFO] - Fine-tuning is done!
[2024-10-16 11:15:09,873][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 11:15:09,873][root][INFO] - - BEST LR: 0.02
[2024-10-16 11:15:09,873][root][INFO] - - DEV score: 73.83 [%]
[2024-10-16 11:15:09,873][root][INFO] - - TEST score: 68.33 [%]
[2024-10-16 11:15:16,039][root][INFO] - 

[2024-10-16 11:15:16,040][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 11:15:16,040][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 11:15:16,040][root][INFO] - 

[2024-10-16 11:15:16,040][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 11:15:28,974][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,974][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,975][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,975][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,975][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,976][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,976][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,977][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,977][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,978][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,978][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,978][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,979][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,979][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,980][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,980][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,981][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,981][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,982][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,982][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,983][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,983][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,984][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 11:15:28,984][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 11:15:28,986][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 11:15:28,990][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 11:15:29,192][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 11:15:29,195][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 11:15:29,385][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 11:15:32,613][root][INFO] - 

[2024-10-16 11:15:32,613][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 11:15:32,613][root][INFO] - Data Preprocessing
[2024-10-16 11:15:32,613][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 11:15:32,613][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 11:15:32,613][root][INFO] - ㄴ data_remove                False

[2024-10-16 11:15:32,613][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 11:15:32,621][root][INFO] - vocab size              : 51200
[2024-10-16 11:15:32,621][root][INFO] - device                  : gpu
[2024-10-16 11:15:32,621][root][INFO] - random seed             : 1
[2024-10-16 11:15:32,621][root][INFO] - train data size         : 49152
[2024-10-16 11:15:32,621][root][INFO] - max epochs              : 10
[2024-10-16 11:15:32,621][root][INFO] - total steps             : 7680
[2024-10-16 11:15:32,621][root][INFO] - warmup steps            : 768
[2024-10-16 11:15:32,622][root][INFO] - batch size              : 64
[2024-10-16 11:15:32,622][root][INFO] - accumulation steps      : 1
[2024-10-16 11:15:32,622][root][INFO] - optimizer               : adamwscale
[2024-10-16 11:15:32,622][root][INFO] - lr_scheduler            : cosine
[2024-10-16 11:15:32,622][root][INFO] - learning rate           : 0.01
[2024-10-16 11:15:32,622][root][INFO] - max length              : 256

[2024-10-16 11:15:32,622][root][INFO] - LoRA Configuration
[2024-10-16 11:15:32,622][root][INFO] - ㄴ r                    : 32
[2024-10-16 11:15:32,622][root][INFO] - ㄴ alpha                : 128
[2024-10-16 11:15:32,622][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 11:15:32,622][root][INFO] - KOMBO Configuration
[2024-10-16 11:15:32,623][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 11:15:32,623][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 11:15:32,623][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 11:15:32,623][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 11:15:32,623][root][INFO] - ㄴ do_combination       : True
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 11:15:32,623][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 11:15:32,623][root][INFO] - 

[2024-10-16 11:15:32,624][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 11:15:32,624][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 11:15:32,624][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 11:15:32,624][root][INFO] - * tb interval   : 10000

[2024-10-16 11:15:32,624][root][INFO] - 

[2024-10-16 11:15:32,624][root][INFO] - Start the Training !
[2024-10-16 11:15:32,627][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 11:23:01,966][root][INFO] - Step: 768/7680  |  Loss: 0.6592  |  Score: 59.89 [%]  |  Seq Length: 256.0
[2024-10-16 11:23:11,033][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 11:23:11,033][root][INFO] - Score: 65.84 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 11:23:20,051][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 11:23:20,052][root][INFO] - Score: 64.29 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 11:23:20,053][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 11:23:20,054][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 11:30:47,940][root][INFO] - Step: 1536/7680  |  Loss: 0.5295  |  Score: 73.27 [%]  |  Seq Length: 256.0
[2024-10-16 11:30:56,685][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 11:30:56,685][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 11:31:05,430][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 11:31:05,430][root][INFO] - Score: 69.51 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 11:31:05,431][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 11:31:05,432][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 11:38:31,794][root][INFO] - Step: 2304/7680  |  Loss: 0.4638  |  Score: 77.33 [%]  |  Seq Length: 256.0
[2024-10-16 11:38:40,786][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 11:38:40,786][root][INFO] - Score: 72.97 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-16 11:38:49,798][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 11:38:49,798][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-16 11:38:49,800][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 11:38:49,801][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 11:46:16,186][root][INFO] - Step: 3072/7680  |  Loss: 0.4107  |  Score: 80.68 [%]  |  Seq Length: 256.0
[2024-10-16 11:46:24,927][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 11:46:24,927][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 11:46:33,743][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 11:46:33,743][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 11:46:33,744][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 11:46:33,746][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 11:50:33,938][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-16 11:50:44,240][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 11:50:44,240][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-16 11:51:04,369][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 11:51:04,369][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.13 [s]
[2024-10-16 11:51:04,371][root][INFO] - 
[4/ 5 Epoch]
[2024-10-16 11:53:59,611][root][INFO] - Step: 3840/7680  |  Loss: 0.3698  |  Score: 82.74 [%]  |  Seq Length: 256.0
[2024-10-16 11:54:08,389][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 11:54:08,389][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 11:54:17,211][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 11:54:17,211][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 8.82 [s]
[2024-10-16 11:54:17,213][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 12:01:44,288][root][INFO] - Step: 4608/7680  |  Loss: 0.3322  |  Score: 84.90 [%]  |  Seq Length: 256.0
[2024-10-16 12:01:53,056][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 12:01:53,056][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 8.76 [s]
[2024-10-16 12:02:01,862][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 12:02:01,862][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 8.80 [s]
[2024-10-16 12:02:01,863][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 12:02:01,864][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 12:09:17,518][root][INFO] - Step: 5376/7680  |  Loss: 0.2993  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-16 12:09:26,246][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 12:09:26,247][root][INFO] - Score: 75.63 [%]  |  Evaluation Time: 8.73 [s]
[2024-10-16 12:09:35,205][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 12:09:35,205][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 12:09:35,206][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 12:09:35,207][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 12:17:01,753][root][INFO] - Step: 6144/7680  |  Loss: 0.2694  |  Score: 88.03 [%]  |  Seq Length: 256.0
[2024-10-16 12:17:10,478][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 12:17:10,479][root][INFO] - Score: 76.32 [%]  |  Evaluation Time: 8.72 [s]
[2024-10-16 12:17:19,247][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 12:17:19,247][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 12:17:19,248][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 12:17:19,249][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 12:24:44,747][root][INFO] - Step: 6912/7680  |  Loss: 0.2510  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-16 12:24:53,491][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 12:24:53,491][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 8.74 [s]
[2024-10-16 12:25:02,254][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 12:25:02,255][root][INFO] - Score: 72.82 [%]  |  Evaluation Time: 8.76 [s]
[2024-10-16 12:25:02,256][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 12:25:02,257][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 12:32:27,878][root][INFO] - Step: 7680/7680  |  Loss: 0.2422  |  Score: 89.34 [%]  |  Seq Length: 256.0
[2024-10-16 12:32:36,610][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 12:32:36,610][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 8.73 [s]
[2024-10-16 12:32:45,445][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 12:32:45,445][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 8.83 [s]
[2024-10-16 12:32:45,446][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 12:32:45,446][root][INFO] - - Epoch: 9
[2024-10-16 12:32:45,446][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 12:32:45,446][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 12:32:45,447][root][INFO] - Fine-tuning is done!
[2024-10-16 12:32:57,207][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,208][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,209][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,209][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,210][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,210][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,211][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,212][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,212][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,213][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,214][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,214][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,215][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,215][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,216][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,216][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,217][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,217][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,218][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,219][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,220][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,220][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,221][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 12:32:57,222][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 12:32:57,224][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 12:32:57,426][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 12:32:57,428][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 12:32:57,429][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 12:32:57,596][root][INFO] - 

[2024-10-16 12:32:57,597][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 12:32:57,597][root][INFO] - Data Preprocessing
[2024-10-16 12:32:57,597][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 12:32:57,597][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 12:32:57,597][root][INFO] - ㄴ data_remove                False

[2024-10-16 12:32:57,597][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 12:32:57,605][root][INFO] - vocab size              : 51200
[2024-10-16 12:32:57,605][root][INFO] - device                  : gpu
[2024-10-16 12:32:57,605][root][INFO] - random seed             : 1
[2024-10-16 12:32:57,605][root][INFO] - train data size         : 49152
[2024-10-16 12:32:57,605][root][INFO] - max epochs              : 10
[2024-10-16 12:32:57,605][root][INFO] - total steps             : 7680
[2024-10-16 12:32:57,605][root][INFO] - warmup steps            : 768
[2024-10-16 12:32:57,605][root][INFO] - batch size              : 64
[2024-10-16 12:32:57,605][root][INFO] - accumulation steps      : 1
[2024-10-16 12:32:57,605][root][INFO] - optimizer               : adamwscale
[2024-10-16 12:32:57,606][root][INFO] - lr_scheduler            : cosine
[2024-10-16 12:32:57,606][root][INFO] - learning rate           : 0.02
[2024-10-16 12:32:57,606][root][INFO] - max length              : 256

[2024-10-16 12:32:57,606][root][INFO] - LoRA Configuration
[2024-10-16 12:32:57,606][root][INFO] - ㄴ r                    : 32
[2024-10-16 12:32:57,606][root][INFO] - ㄴ alpha                : 128
[2024-10-16 12:32:57,606][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 12:32:57,606][root][INFO] - KOMBO Configuration
[2024-10-16 12:32:57,606][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 12:32:57,606][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 12:32:57,606][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 12:32:57,607][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 12:32:57,607][root][INFO] - ㄴ do_combination       : True
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 12:32:57,607][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 12:32:57,607][root][INFO] - 

[2024-10-16 12:32:57,607][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-16 12:32:57,607][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-16 12:32:57,608][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-16 12:32:57,608][root][INFO] - * tb interval   : 10000

[2024-10-16 12:32:57,608][root][INFO] - 

[2024-10-16 12:32:57,608][root][INFO] - Start the Training !
[2024-10-16 12:32:57,610][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 12:40:24,306][root][INFO] - Step: 768/7680  |  Loss: 0.6396  |  Score: 61.85 [%]  |  Seq Length: 256.0
[2024-10-16 12:40:33,207][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 12:40:33,207][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 8.90 [s]
[2024-10-16 12:40:42,029][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 12:40:42,029][root][INFO] - Score: 66.86 [%]  |  Evaluation Time: 8.82 [s]
[2024-10-16 12:40:42,030][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 12:40:42,032][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 12:42:08,321][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-16 12:47:56,988][root][INFO] - Step: 1536/7680  |  Loss: 0.5290  |  Score: 73.49 [%]  |  Seq Length: 256.0
[2024-10-16 12:48:05,930][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 12:48:05,931][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 12:48:14,711][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 12:48:14,711][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 8.78 [s]
[2024-10-16 12:48:14,712][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 12:48:14,713][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 12:55:36,490][root][INFO] - Step: 2304/7680  |  Loss: 0.4797  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-16 12:55:45,537][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 12:55:45,537][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 12:55:54,452][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 12:55:54,452][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 12:55:54,454][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 12:55:54,455][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 13:03:20,628][root][INFO] - Step: 3072/7680  |  Loss: 0.4315  |  Score: 79.38 [%]  |  Seq Length: 256.0
[2024-10-16 13:03:29,424][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 13:03:29,425][root][INFO] - Score: 72.79 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:03:38,236][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 13:03:38,236][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 13:03:38,237][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 13:03:38,238][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 13:11:05,064][root][INFO] - Step: 3840/7680  |  Loss: 0.3944  |  Score: 81.60 [%]  |  Seq Length: 256.0
[2024-10-16 13:11:13,840][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 13:11:13,840][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 13:11:22,714][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 13:11:22,715][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 8.87 [s]
[2024-10-16 13:11:22,716][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 13:11:22,717][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 13:18:50,205][root][INFO] - Step: 4608/7680  |  Loss: 0.3457  |  Score: 84.04 [%]  |  Seq Length: 256.0
[2024-10-16 13:18:59,067][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 13:18:59,067][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 8.86 [s]
[2024-10-16 13:19:07,905][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 13:19:07,905][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 8.84 [s]
[2024-10-16 13:19:07,906][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 13:19:07,908][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 13:26:34,392][root][INFO] - Step: 5376/7680  |  Loss: 0.2974  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-16 13:26:43,183][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 13:26:43,183][root][INFO] - Score: 75.11 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:26:52,013][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 13:26:52,013][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 8.83 [s]
[2024-10-16 13:26:52,015][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 13:34:12,252][root][INFO] - Step: 6144/7680  |  Loss: 0.2532  |  Score: 88.87 [%]  |  Seq Length: 256.0
[2024-10-16 13:34:21,085][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 13:34:21,085][root][INFO] - Score: 75.03 [%]  |  Evaluation Time: 8.83 [s]
[2024-10-16 13:34:29,882][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 13:34:29,882][root][INFO] - Score: 72.98 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:34:29,884][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 13:41:56,310][root][INFO] - Step: 6912/7680  |  Loss: 0.2230  |  Score: 90.33 [%]  |  Seq Length: 256.0
[2024-10-16 13:42:05,092][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 13:42:05,092][root][INFO] - Score: 75.21 [%]  |  Evaluation Time: 8.78 [s]
[2024-10-16 13:42:13,880][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 13:42:13,880][root][INFO] - Score: 72.91 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 13:42:13,882][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 13:49:39,255][root][INFO] - Step: 7680/7680  |  Loss: 0.2027  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-16 13:49:48,029][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 13:49:48,029][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 8.77 [s]
[2024-10-16 13:49:56,829][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 13:49:56,829][root][INFO] - Score: 73.03 [%]  |  Evaluation Time: 8.80 [s]
[2024-10-16 13:49:56,830][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 13:49:56,830][root][INFO] - - Epoch: 6
[2024-10-16 13:49:56,830][root][INFO] - - DEV score: 74.90 [%]
[2024-10-16 13:49:56,830][root][INFO] - - TEST score: 73.44 [%]
[2024-10-16 13:49:56,831][root][INFO] - Fine-tuning is done!
[2024-10-16 13:49:56,832][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 13:49:56,832][root][INFO] - - BEST LR: 0.01
[2024-10-16 13:49:56,832][root][INFO] - - DEV score: 76.67 [%]
[2024-10-16 13:49:56,832][root][INFO] - - TEST score: 72.82 [%]
[2024-10-16 13:50:02,559][root][INFO] - 

[2024-10-16 13:50:02,559][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 13:50:02,559][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 13:50:02,559][root][INFO] - 

[2024-10-16 13:50:02,559][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 13:50:15,068][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,069][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,069][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,070][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,070][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,071][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,071][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,072][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,072][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,073][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,073][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,074][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,074][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,075][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,075][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,076][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,076][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,077][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,077][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,078][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,078][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,079][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,079][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 13:50:15,080][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 13:50:15,082][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 13:50:15,086][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 13:50:15,280][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 13:50:15,283][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 13:50:15,466][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 13:50:18,339][root][INFO] - 

[2024-10-16 13:50:18,339][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 13:50:18,339][root][INFO] - Data Preprocessing
[2024-10-16 13:50:18,339][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 13:50:18,340][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 13:50:18,340][root][INFO] - ㄴ data_remove                False

[2024-10-16 13:50:18,340][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 13:50:18,347][root][INFO] - vocab size              : 51200
[2024-10-16 13:50:18,347][root][INFO] - device                  : gpu
[2024-10-16 13:50:18,347][root][INFO] - random seed             : 2
[2024-10-16 13:50:18,347][root][INFO] - train data size         : 49152
[2024-10-16 13:50:18,347][root][INFO] - max epochs              : 10
[2024-10-16 13:50:18,347][root][INFO] - total steps             : 7680
[2024-10-16 13:50:18,347][root][INFO] - warmup steps            : 768
[2024-10-16 13:50:18,348][root][INFO] - batch size              : 64
[2024-10-16 13:50:18,348][root][INFO] - accumulation steps      : 1
[2024-10-16 13:50:18,348][root][INFO] - optimizer               : adamwscale
[2024-10-16 13:50:18,348][root][INFO] - lr_scheduler            : cosine
[2024-10-16 13:50:18,348][root][INFO] - learning rate           : 0.01
[2024-10-16 13:50:18,348][root][INFO] - max length              : 256

[2024-10-16 13:50:18,348][root][INFO] - LoRA Configuration
[2024-10-16 13:50:18,348][root][INFO] - ㄴ r                    : 32
[2024-10-16 13:50:18,348][root][INFO] - ㄴ alpha                : 128
[2024-10-16 13:50:18,348][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 13:50:18,348][root][INFO] - KOMBO Configuration
[2024-10-16 13:50:18,348][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 13:50:18,349][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 13:50:18,349][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 13:50:18,349][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 13:50:18,349][root][INFO] - ㄴ do_combination       : True
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 13:50:18,349][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 13:50:18,349][root][INFO] - 

[2024-10-16 13:50:18,349][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 13:50:18,350][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 13:50:18,350][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 13:50:18,350][root][INFO] - * tb interval   : 10000

[2024-10-16 13:50:18,350][root][INFO] - 

[2024-10-16 13:50:18,350][root][INFO] - Start the Training !
[2024-10-16 13:50:18,353][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 13:57:45,261][root][INFO] - Step: 768/7680  |  Loss: 0.6386  |  Score: 62.54 [%]  |  Seq Length: 256.0
[2024-10-16 13:57:54,176][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 13:57:54,176][root][INFO] - Score: 68.40 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 13:58:03,140][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 13:58:03,140][root][INFO] - Score: 66.23 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 13:58:03,141][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 13:58:03,143][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 14:00:48,591][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-16 14:00:58,934][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 14:00:58,934][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-16 14:01:19,024][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 14:01:19,024][root][INFO] - Score: 33.23 [%]  |  Evaluation Time: 20.09 [s]
[2024-10-16 14:01:19,027][root][INFO] - 
[5/ 5 Epoch]
[2024-10-16 14:05:32,701][root][INFO] - Step: 1536/7680  |  Loss: 0.5177  |  Score: 74.29 [%]  |  Seq Length: 256.0
[2024-10-16 14:05:41,583][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 14:05:41,583][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 8.88 [s]
[2024-10-16 14:05:50,542][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 14:05:50,542][root][INFO] - Score: 67.61 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 14:05:50,544][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 14:05:50,547][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 14:10:43,934][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.36 [%]  |  Seq Length: 256.0
[2024-10-16 14:13:20,936][root][INFO] - Step: 2304/7680  |  Loss: 0.4565  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-16 14:13:29,943][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 14:13:29,943][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 14:13:38,944][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 14:13:38,944][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-16 14:13:38,945][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 14:13:38,946][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 14:21:10,305][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-16 14:21:19,115][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 14:21:19,115][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:21:27,928][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 14:21:27,928][root][INFO] - Score: 72.89 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:21:27,929][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 14:21:27,930][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 14:28:55,367][root][INFO] - Step: 3840/7680  |  Loss: 0.3670  |  Score: 82.91 [%]  |  Seq Length: 256.0
[2024-10-16 14:29:04,149][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 14:29:04,149][root][INFO] - Score: 76.05 [%]  |  Evaluation Time: 8.78 [s]
[2024-10-16 14:29:12,948][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 14:29:12,949][root][INFO] - Score: 73.63 [%]  |  Evaluation Time: 8.80 [s]
[2024-10-16 14:29:12,950][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 14:29:12,951][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 14:36:40,376][root][INFO] - Step: 4608/7680  |  Loss: 0.3297  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-16 14:36:49,187][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 14:36:49,187][root][INFO] - Score: 75.79 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:36:57,998][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 14:36:57,999][root][INFO] - Score: 74.44 [%]  |  Evaluation Time: 8.81 [s]
[2024-10-16 14:36:57,999][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 14:36:58,000][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 14:44:25,722][root][INFO] - Step: 5376/7680  |  Loss: 0.2950  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-16 14:44:34,565][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 14:44:34,566][root][INFO] - Score: 75.40 [%]  |  Evaluation Time: 8.84 [s]
[2024-10-16 14:44:43,385][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 14:44:43,386][root][INFO] - Score: 72.84 [%]  |  Evaluation Time: 8.82 [s]
[2024-10-16 14:44:43,387][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 14:52:10,277][root][INFO] - Step: 6144/7680  |  Loss: 0.2654  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-16 14:52:19,135][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 14:52:19,135][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 8.86 [s]
[2024-10-16 14:52:28,077][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 14:52:28,078][root][INFO] - Score: 73.65 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 14:52:28,080][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 14:59:52,900][root][INFO] - Step: 6912/7680  |  Loss: 0.2486  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-16 15:00:01,817][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 15:00:01,817][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 15:00:10,612][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 15:00:10,612][root][INFO] - Score: 73.59 [%]  |  Evaluation Time: 8.79 [s]
[2024-10-16 15:00:10,614][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 15:07:36,635][root][INFO] - Step: 7680/7680  |  Loss: 0.2369  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-16 15:07:45,575][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 15:07:45,575][root][INFO] - Score: 76.51 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-16 15:07:54,535][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 15:07:54,535][root][INFO] - Score: 73.88 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-16 15:07:54,536][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 15:07:54,536][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 15:07:54,536][root][INFO] - - Epoch: 10
[2024-10-16 15:07:54,536][root][INFO] - - DEV score: 76.51 [%]
[2024-10-16 15:07:54,536][root][INFO] - - TEST score: 73.88 [%]
[2024-10-16 15:07:54,537][root][INFO] - Fine-tuning is done!
[2024-10-16 15:08:06,649][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,650][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,650][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,651][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,651][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,652][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,652][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,653][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,654][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,654][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,655][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,655][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,656][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,657][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,657][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,658][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,658][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,659][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,659][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,660][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,660][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,661][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,661][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 15:08:06,662][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 15:08:06,664][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 15:08:06,868][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 15:08:06,871][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 15:08:06,872][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 15:08:07,038][root][INFO] - 

[2024-10-16 15:08:07,038][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 15:08:07,038][root][INFO] - Data Preprocessing
[2024-10-16 15:08:07,038][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 15:08:07,038][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 15:08:07,038][root][INFO] - ㄴ data_remove                False

[2024-10-16 15:08:07,038][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 15:08:07,046][root][INFO] - vocab size              : 51200
[2024-10-16 15:08:07,046][root][INFO] - device                  : gpu
[2024-10-16 15:08:07,046][root][INFO] - random seed             : 2
[2024-10-16 15:08:07,046][root][INFO] - train data size         : 49152
[2024-10-16 15:08:07,046][root][INFO] - max epochs              : 10
[2024-10-16 15:08:07,046][root][INFO] - total steps             : 7680
[2024-10-16 15:08:07,046][root][INFO] - warmup steps            : 768
[2024-10-16 15:08:07,047][root][INFO] - batch size              : 64
[2024-10-16 15:08:07,047][root][INFO] - accumulation steps      : 1
[2024-10-16 15:08:07,047][root][INFO] - optimizer               : adamwscale
[2024-10-16 15:08:07,047][root][INFO] - lr_scheduler            : cosine
[2024-10-16 15:08:07,047][root][INFO] - learning rate           : 0.02
[2024-10-16 15:08:07,047][root][INFO] - max length              : 256

[2024-10-16 15:08:07,047][root][INFO] - LoRA Configuration
[2024-10-16 15:08:07,047][root][INFO] - ㄴ r                    : 32
[2024-10-16 15:08:07,047][root][INFO] - ㄴ alpha                : 128
[2024-10-16 15:08:07,047][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 15:08:07,047][root][INFO] - KOMBO Configuration
[2024-10-16 15:08:07,048][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 15:08:07,048][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 15:08:07,048][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 15:08:07,048][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 15:08:07,048][root][INFO] - ㄴ do_combination       : True
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 15:08:07,048][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 15:08:07,048][root][INFO] - 

[2024-10-16 15:08:07,049][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs
[2024-10-16 15:08:07,049][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-16 15:08:07,049][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-16 15:08:07,049][root][INFO] - * tb interval   : 10000

[2024-10-16 15:08:07,049][root][INFO] - 

[2024-10-16 15:08:07,049][root][INFO] - Start the Training !
[2024-10-16 15:08:07,051][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 15:15:35,186][root][INFO] - Step: 768/7680  |  Loss: 0.6222  |  Score: 64.46 [%]  |  Seq Length: 256.0
[2024-10-16 15:15:44,208][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 15:15:44,209][root][INFO] - Score: 67.73 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 15:15:53,121][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 15:15:53,121][root][INFO] - Score: 66.79 [%]  |  Evaluation Time: 8.91 [s]
[2024-10-16 15:15:53,122][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 15:15:53,123][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 15:23:22,261][root][INFO] - Step: 1536/7680  |  Loss: 0.5210  |  Score: 74.06 [%]  |  Seq Length: 256.0
[2024-10-16 15:23:31,218][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 15:23:31,218][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 8.95 [s]
[2024-10-16 15:23:40,239][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 15:23:40,239][root][INFO] - Score: 67.05 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 15:23:40,241][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 15:23:40,242][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 15:31:16,247][root][INFO] - Step: 2304/7680  |  Loss: 0.4707  |  Score: 77.22 [%]  |  Seq Length: 256.0
[2024-10-16 15:31:25,478][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 15:31:25,478][root][INFO] - Score: 73.31 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 15:31:34,761][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 15:31:34,762][root][INFO] - Score: 70.17 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-16 15:31:34,763][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 15:31:34,764][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 15:38:46,949][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-16 15:39:11,926][root][INFO] - Step: 3072/7680  |  Loss: 0.4338  |  Score: 79.22 [%]  |  Seq Length: 256.0
[2024-10-16 15:39:21,139][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 15:39:21,140][root][INFO] - Score: 74.96 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 15:39:30,301][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 15:39:30,301][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 15:39:30,302][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 15:39:30,304][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 15:47:13,284][root][INFO] - Step: 3840/7680  |  Loss: 0.3913  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-16 15:47:22,662][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 15:47:22,662][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 9.37 [s]
[2024-10-16 15:47:32,016][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 15:47:32,017][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 9.35 [s]
[2024-10-16 15:47:32,018][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 15:47:32,020][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 15:55:06,825][root][INFO] - Step: 4608/7680  |  Loss: 0.3479  |  Score: 84.10 [%]  |  Seq Length: 256.0
[2024-10-16 15:55:15,940][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 15:55:15,941][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 15:55:25,090][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 15:55:25,090][root][INFO] - Score: 72.64 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 15:55:25,091][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 15:55:25,092][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 16:02:58,877][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.63 [%]  |  Seq Length: 256.0
[2024-10-16 16:03:08,112][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 16:03:08,112][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 16:03:17,327][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 16:03:17,327][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 16:03:17,329][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 16:10:53,176][root][INFO] - Step: 6144/7680  |  Loss: 0.2514  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-16 16:11:02,408][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 16:11:02,409][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 16:11:11,693][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 16:11:11,693][root][INFO] - Score: 74.42 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-16 16:11:11,694][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 16:11:11,695][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 16:11:21,502][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.49 [%]  |  Seq Length: 256.0
[2024-10-16 16:11:31,902][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 16:11:31,902][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.40 [s]
[2024-10-16 16:11:52,196][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 16:11:52,196][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.29 [s]
[2024-10-16 16:11:52,197][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 16:11:52,197][root][INFO] - - Epoch: 1
[2024-10-16 16:11:52,197][root][INFO] - - DEV score: 58.93 [%]
[2024-10-16 16:11:52,197][root][INFO] - - TEST score: 58.80 [%]
[2024-10-16 16:11:52,198][root][INFO] - Fine-tuning is done!
[2024-10-16 16:11:52,199][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 16:11:52,199][root][INFO] - - BEST LR: 0.01
[2024-10-16 16:11:52,199][root][INFO] - - DEV score: 74.86 [%]
[2024-10-16 16:11:52,199][root][INFO] - - TEST score: 76.17 [%]
[2024-10-16 16:11:59,103][root][INFO] - 

[2024-10-16 16:11:59,103][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 16:11:59,103][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-16 16:11:59,104][root][INFO] - 

[2024-10-16 16:11:59,104][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 16:14:07,619][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,620][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,620][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,621][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,621][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,622][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,622][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,622][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,623][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,623][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,624][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,624][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,625][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,625][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,625][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,626][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,626][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,627][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,627][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,627][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,628][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,628][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,629][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 16:14:07,629][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 16:14:07,631][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-16 16:14:07,635][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 16:14:07,843][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 16:14:07,845][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-16 16:14:08,085][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 16:14:11,517][root][INFO] - 

[2024-10-16 16:14:11,517][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-16 16:14:11,518][root][INFO] - Data Preprocessing
[2024-10-16 16:14:11,518][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-16 16:14:11,518][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 16:14:11,518][root][INFO] - ㄴ data_remove                False

[2024-10-16 16:14:11,518][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 16:14:11,526][root][INFO] - vocab size              : 51200
[2024-10-16 16:14:11,526][root][INFO] - device                  : gpu
[2024-10-16 16:14:11,527][root][INFO] - random seed             : 3
[2024-10-16 16:14:11,527][root][INFO] - train data size         : 942912
[2024-10-16 16:14:11,527][root][INFO] - max epochs              : 5
[2024-10-16 16:14:11,527][root][INFO] - total steps             : 73665
[2024-10-16 16:14:11,527][root][INFO] - warmup steps            : 7366
[2024-10-16 16:14:11,527][root][INFO] - batch size              : 64
[2024-10-16 16:14:11,527][root][INFO] - accumulation steps      : 1
[2024-10-16 16:14:11,527][root][INFO] - optimizer               : adamwscale
[2024-10-16 16:14:11,527][root][INFO] - lr_scheduler            : cosine
[2024-10-16 16:14:11,527][root][INFO] - learning rate           : 0.01
[2024-10-16 16:14:11,527][root][INFO] - max length              : 256

[2024-10-16 16:14:11,528][root][INFO] - LoRA Configuration
[2024-10-16 16:14:11,528][root][INFO] - ㄴ r                    : 32
[2024-10-16 16:14:11,528][root][INFO] - ㄴ alpha                : 128
[2024-10-16 16:14:11,528][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 16:14:11,528][root][INFO] - KOMBO Configuration
[2024-10-16 16:14:11,528][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 16:14:11,528][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 16:14:11,528][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 16:14:11,528][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 16:14:11,528][root][INFO] - ㄴ do_combination       : True
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 16:14:11,529][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 16:14:11,529][root][INFO] - 

[2024-10-16 16:14:11,529][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-16 16:14:11,529][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 16:14:11,529][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb
[2024-10-16 16:14:11,529][root][INFO] - * tb interval   : 10000

[2024-10-16 16:14:11,529][root][INFO] - 

[2024-10-16 16:14:11,529][root][INFO] - Start the Training !
[2024-10-16 16:14:11,533][root][INFO] - 
[1/ 5 Epoch]
[2024-10-16 16:18:46,441][root][INFO] - Step: 6912/7680  |  Loss: 0.2204  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-16 16:18:55,619][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 16:18:55,619][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-16 16:19:04,793][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 16:19:04,793][root][INFO] - Score: 74.47 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-16 16:19:04,795][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 16:26:37,307][root][INFO] - Step: 7680/7680  |  Loss: 0.1994  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-16 16:26:46,461][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 16:26:46,461][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 16:26:55,683][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 16:26:55,684][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-16 16:26:55,685][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 16:26:55,685][root][INFO] - - Epoch: 8
[2024-10-16 16:26:55,685][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 16:26:55,685][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 16:26:55,686][root][INFO] - Fine-tuning is done!
[2024-10-16 16:26:55,686][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 16:26:55,686][root][INFO] - - BEST LR: 0.02
[2024-10-16 16:26:55,686][root][INFO] - - DEV score: 77.23 [%]
[2024-10-16 16:26:55,686][root][INFO] - - TEST score: 74.42 [%]
[2024-10-16 16:27:02,012][root][INFO] - 

[2024-10-16 16:27:02,012][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-16 16:27:02,012][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 16:27:02,013][root][INFO] - 

[2024-10-16 16:27:02,013][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-16 16:27:16,006][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,007][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,007][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,008][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,008][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,009][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,009][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,009][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,010][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,010][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,011][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,011][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,012][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,012][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,013][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,013][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,014][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,014][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,014][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,015][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,016][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,016][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,017][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 16:27:16,017][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 16:27:16,019][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 16:27:16,025][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-16 16:27:16,231][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 16:27:16,233][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 16:27:16,427][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 16:27:19,842][root][INFO] - 

[2024-10-16 16:27:19,842][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 16:27:19,842][root][INFO] - Data Preprocessing
[2024-10-16 16:27:19,842][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 16:27:19,842][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 16:27:19,842][root][INFO] - ㄴ data_remove                False

[2024-10-16 16:27:19,842][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 16:27:19,850][root][INFO] - vocab size              : 51200
[2024-10-16 16:27:19,850][root][INFO] - device                  : gpu
[2024-10-16 16:27:19,851][root][INFO] - random seed             : 3
[2024-10-16 16:27:19,851][root][INFO] - train data size         : 49152
[2024-10-16 16:27:19,851][root][INFO] - max epochs              : 10
[2024-10-16 16:27:19,851][root][INFO] - total steps             : 7680
[2024-10-16 16:27:19,851][root][INFO] - warmup steps            : 768
[2024-10-16 16:27:19,851][root][INFO] - batch size              : 64
[2024-10-16 16:27:19,851][root][INFO] - accumulation steps      : 1
[2024-10-16 16:27:19,851][root][INFO] - optimizer               : adamwscale
[2024-10-16 16:27:19,851][root][INFO] - lr_scheduler            : cosine
[2024-10-16 16:27:19,851][root][INFO] - learning rate           : 0.01
[2024-10-16 16:27:19,851][root][INFO] - max length              : 256

[2024-10-16 16:27:19,852][root][INFO] - LoRA Configuration
[2024-10-16 16:27:19,852][root][INFO] - ㄴ r                    : 32
[2024-10-16 16:27:19,852][root][INFO] - ㄴ alpha                : 128
[2024-10-16 16:27:19,852][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 16:27:19,852][root][INFO] - KOMBO Configuration
[2024-10-16 16:27:19,852][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 16:27:19,852][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 16:27:19,852][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 16:27:19,852][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 16:27:19,852][root][INFO] - ㄴ do_combination       : True
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 16:27:19,853][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 16:27:19,853][root][INFO] - 

[2024-10-16 16:27:19,853][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 16:27:19,853][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 16:27:19,853][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 16:27:19,853][root][INFO] - * tb interval   : 10000

[2024-10-16 16:27:19,853][root][INFO] - 

[2024-10-16 16:27:19,853][root][INFO] - Start the Training !
[2024-10-16 16:27:19,857][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 16:34:55,728][root][INFO] - Step: 768/7680  |  Loss: 0.6403  |  Score: 62.30 [%]  |  Seq Length: 256.0
[2024-10-16 16:35:04,842][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 16:35:04,842][root][INFO] - Score: 65.99 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 16:35:13,998][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 16:35:13,998][root][INFO] - Score: 65.19 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 16:35:13,999][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 16:35:14,001][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 16:42:48,822][root][INFO] - Step: 1536/7680  |  Loss: 0.5201  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-16 16:42:57,945][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 16:42:57,945][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-16 16:43:07,141][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 16:43:07,141][root][INFO] - Score: 69.05 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-16 16:43:07,142][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 16:43:07,144][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 16:50:41,525][root][INFO] - Step: 2304/7680  |  Loss: 0.4547  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-16 16:50:50,615][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 16:50:50,616][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 16:50:59,703][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 16:50:59,703][root][INFO] - Score: 70.54 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-16 16:50:59,704][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 16:50:59,705][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 16:58:35,788][root][INFO] - Step: 3072/7680  |  Loss: 0.4076  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-16 16:58:44,928][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 16:58:44,928][root][INFO] - Score: 73.46 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 16:58:54,043][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 16:58:54,043][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 16:58:54,044][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 16:58:54,045][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 17:06:22,358][root][INFO] - Step: 3840/7680  |  Loss: 0.3683  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-16 17:06:31,453][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 17:06:31,453][root][INFO] - Score: 75.77 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 17:06:40,639][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 17:06:40,640][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 17:06:40,641][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-16 17:06:40,642][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 17:14:13,217][root][INFO] - Step: 4608/7680  |  Loss: 0.3315  |  Score: 84.98 [%]  |  Seq Length: 256.0
[2024-10-16 17:14:22,464][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 17:14:22,465][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 17:14:31,508][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 17:14:31,508][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-16 17:14:31,509][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 17:14:31,511][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 17:22:05,689][root][INFO] - Step: 5376/7680  |  Loss: 0.2970  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-16 17:22:14,837][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 17:22:14,837][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 17:22:23,972][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 17:22:23,972][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-16 17:22:23,973][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-16 17:22:23,975][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 17:29:58,555][root][INFO] - Step: 6144/7680  |  Loss: 0.2681  |  Score: 87.98 [%]  |  Seq Length: 256.0
[2024-10-16 17:30:07,617][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 17:30:07,617][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-16 17:30:16,796][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 17:30:16,796][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 17:30:16,797][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 17:30:16,798][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 17:37:51,092][root][INFO] - Step: 6912/7680  |  Loss: 0.2485  |  Score: 89.16 [%]  |  Seq Length: 256.0
[2024-10-16 17:38:00,242][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 17:38:00,242][root][INFO] - Score: 76.72 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 17:38:09,263][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 17:38:09,263][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-16 17:38:09,264][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 17:38:09,266][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 17:43:29,009][root][INFO] - Step: 10000/73665  |  Loss: 0.7362  |  Score: 67.99 [%]  |  Seq Length: 256.0
[2024-10-16 17:45:42,729][root][INFO] - Step: 7680/7680  |  Loss: 0.2410  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-16 17:45:51,841][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 17:45:51,841][root][INFO] - Score: 76.46 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 17:46:00,952][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 17:46:00,953][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 17:46:00,954][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 17:46:00,954][root][INFO] - - Epoch: 9
[2024-10-16 17:46:00,954][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 17:46:00,954][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 17:46:00,955][root][INFO] - Fine-tuning is done!
[2024-10-16 17:46:12,751][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,752][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,752][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,753][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,753][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,754][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,754][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,755][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,756][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,756][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,757][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,757][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,758][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,758][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,759][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,760][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,760][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,760][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,761][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,761][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,762][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,763][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,763][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-16 17:46:12,764][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-16 17:46:12,766][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-16 17:46:12,970][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-16 17:46:12,972][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-16 17:46:12,973][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-16 17:46:13,139][root][INFO] - 

[2024-10-16 17:46:13,139][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-16 17:46:13,139][root][INFO] - Data Preprocessing
[2024-10-16 17:46:13,139][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-16 17:46:13,139][root][INFO] - ㄴ do_hangeulize              False
[2024-10-16 17:46:13,139][root][INFO] - ㄴ data_remove                False

[2024-10-16 17:46:13,139][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-16 17:46:13,147][root][INFO] - vocab size              : 51200
[2024-10-16 17:46:13,147][root][INFO] - device                  : gpu
[2024-10-16 17:46:13,147][root][INFO] - random seed             : 3
[2024-10-16 17:46:13,148][root][INFO] - train data size         : 49152
[2024-10-16 17:46:13,148][root][INFO] - max epochs              : 10
[2024-10-16 17:46:13,148][root][INFO] - total steps             : 7680
[2024-10-16 17:46:13,148][root][INFO] - warmup steps            : 768
[2024-10-16 17:46:13,148][root][INFO] - batch size              : 64
[2024-10-16 17:46:13,148][root][INFO] - accumulation steps      : 1
[2024-10-16 17:46:13,148][root][INFO] - optimizer               : adamwscale
[2024-10-16 17:46:13,148][root][INFO] - lr_scheduler            : cosine
[2024-10-16 17:46:13,148][root][INFO] - learning rate           : 0.02
[2024-10-16 17:46:13,148][root][INFO] - max length              : 256

[2024-10-16 17:46:13,148][root][INFO] - LoRA Configuration
[2024-10-16 17:46:13,148][root][INFO] - ㄴ r                    : 32
[2024-10-16 17:46:13,149][root][INFO] - ㄴ alpha                : 128
[2024-10-16 17:46:13,149][root][INFO] - ㄴ dropout              : 0.03

[2024-10-16 17:46:13,149][root][INFO] - KOMBO Configuration
[2024-10-16 17:46:13,149][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-16 17:46:13,149][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-16 17:46:13,149][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-16 17:46:13,149][root][INFO] - ㄴ embedding_norm       : False
[2024-10-16 17:46:13,149][root][INFO] - ㄴ do_combination       : True
[2024-10-16 17:46:13,149][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-16 17:46:13,149][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-16 17:46:13,150][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-16 17:46:13,150][root][INFO] -   ㄴ add_lora           : False

[2024-10-16 17:46:13,150][root][INFO] - 

[2024-10-16 17:46:13,150][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs
[2024-10-16 17:46:13,150][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-16 17:46:13,150][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-16 17:46:13,150][root][INFO] - * tb interval   : 10000

[2024-10-16 17:46:13,150][root][INFO] - 

[2024-10-16 17:46:13,150][root][INFO] - Start the Training !
[2024-10-16 17:46:13,152][root][INFO] - 
[1/ 10 Epoch]
[2024-10-16 17:53:45,487][root][INFO] - Step: 768/7680  |  Loss: 0.6252  |  Score: 64.13 [%]  |  Seq Length: 256.0
[2024-10-16 17:53:54,704][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 17:53:54,704][root][INFO] - Score: 68.57 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-16 17:54:03,849][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 17:54:03,849][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 17:54:03,850][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 17:54:03,852][root][INFO] - 
[2/ 10 Epoch]
[2024-10-16 18:01:38,585][root][INFO] - Step: 1536/7680  |  Loss: 0.5207  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-16 18:01:47,724][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 18:01:47,724][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-16 18:01:56,955][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 18:01:56,955][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 18:01:56,956][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 18:01:56,957][root][INFO] - 
[3/ 10 Epoch]
[2024-10-16 18:09:31,422][root][INFO] - Step: 2304/7680  |  Loss: 0.4711  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-16 18:09:40,532][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 18:09:40,532][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-16 18:09:49,717][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 18:09:49,717][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 18:09:49,718][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 18:09:49,720][root][INFO] - 
[4/ 10 Epoch]
[2024-10-16 18:17:24,846][root][INFO] - Step: 3072/7680  |  Loss: 0.4328  |  Score: 79.44 [%]  |  Seq Length: 256.0
[2024-10-16 18:17:34,037][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-16 18:17:34,037][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.19 [s]
[2024-10-16 18:17:43,264][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-16 18:17:43,265][root][INFO] - Score: 71.79 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-16 18:17:43,266][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-16 18:17:43,267][root][INFO] - 
[5/ 10 Epoch]
[2024-10-16 18:25:18,089][root][INFO] - Step: 3840/7680  |  Loss: 0.3889  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-16 18:25:27,270][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-16 18:25:27,270][root][INFO] - Score: 74.17 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-16 18:25:36,400][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-16 18:25:36,400][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-16 18:25:36,402][root][INFO] - 
[6/ 10 Epoch]
[2024-10-16 18:25:39,020][root][INFO] - Step: 14733/73665  |  Loss: 0.6625  |  Score: 72.18 [%]  |  Seq Length: 256.0
[2024-10-16 18:25:49,326][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-16 18:25:49,327][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-16 18:26:09,628][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-16 18:26:09,628][root][INFO] - Score: 72.65 [%]  |  Evaluation Time: 20.30 [s]
[2024-10-16 18:26:09,629][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-16 18:26:09,631][root][INFO] - 
[2/ 5 Epoch]
[2024-10-16 18:33:10,976][root][INFO] - Step: 4608/7680  |  Loss: 0.3400  |  Score: 84.52 [%]  |  Seq Length: 256.0
[2024-10-16 18:33:20,073][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-16 18:33:20,074][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 18:33:29,173][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-16 18:33:29,173][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-16 18:33:29,174][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-16 18:33:29,175][root][INFO] - 
[7/ 10 Epoch]
[2024-10-16 18:41:02,849][root][INFO] - Step: 5376/7680  |  Loss: 0.2948  |  Score: 86.84 [%]  |  Seq Length: 256.0
[2024-10-16 18:41:12,008][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-16 18:41:12,009][root][INFO] - Score: 75.16 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 18:41:21,160][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-16 18:41:21,160][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 18:41:21,163][root][INFO] - 
[8/ 10 Epoch]
[2024-10-16 18:48:58,220][root][INFO] - Step: 6144/7680  |  Loss: 0.2517  |  Score: 88.88 [%]  |  Seq Length: 256.0
[2024-10-16 18:49:07,318][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-16 18:49:07,318][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-16 18:49:16,468][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-16 18:49:16,468][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-16 18:49:16,469][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-16 18:49:16,470][root][INFO] - 
[9/ 10 Epoch]
[2024-10-16 18:56:50,852][root][INFO] - Step: 6912/7680  |  Loss: 0.2166  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-16 18:57:00,067][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-16 18:57:00,068][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 9.21 [s]
[2024-10-16 18:57:09,305][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-16 18:57:09,305][root][INFO] - Score: 73.41 [%]  |  Evaluation Time: 9.24 [s]
[2024-10-16 18:57:09,306][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-16 18:57:09,307][root][INFO] - 
[10/ 10 Epoch]
[2024-10-16 19:04:42,240][root][INFO] - Step: 7680/7680  |  Loss: 0.1979  |  Score: 91.43 [%]  |  Seq Length: 256.0
[2024-10-16 19:04:51,503][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-16 19:04:51,503][root][INFO] - Score: 76.60 [%]  |  Evaluation Time: 9.26 [s]
[2024-10-16 19:05:00,665][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-16 19:05:00,665][root][INFO] - Score: 73.52 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-16 19:05:00,666][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-16 19:05:00,666][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-16 19:05:00,666][root][INFO] - - Epoch: 10
[2024-10-16 19:05:00,666][root][INFO] - - DEV score: 76.60 [%]
[2024-10-16 19:05:00,666][root][INFO] - - TEST score: 73.52 [%]
[2024-10-16 19:05:00,667][root][INFO] - Fine-tuning is done!
[2024-10-16 19:05:00,667][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-16 19:05:00,667][root][INFO] - - BEST LR: 0.01
[2024-10-16 19:05:00,668][root][INFO] - - DEV score: 76.72 [%]
[2024-10-16 19:05:00,668][root][INFO] - - TEST score: 72.05 [%]
[2024-10-16 19:13:08,210][root][INFO] - Step: 20000/73665  |  Loss: 0.6357  |  Score: 73.67 [%]  |  Seq Length: 256.0
[2024-10-16 20:37:04,106][root][INFO] - Step: 29466/73665  |  Loss: 0.6306  |  Score: 73.81 [%]  |  Seq Length: 256.0
[2024-10-16 20:37:14,262][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-16 20:37:14,262][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 10.15 [s]
[2024-10-16 20:37:34,198][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-16 20:37:34,198][root][INFO] - Score: 72.95 [%]  |  Evaluation Time: 19.93 [s]
[2024-10-16 20:37:34,199][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-16 20:37:34,201][root][INFO] - 
[3/ 5 Epoch]
[2024-10-16 20:42:19,093][root][INFO] - Step: 30000/73665  |  Loss: 0.6061  |  Score: 75.16 [%]  |  Seq Length: 256.0
[2024-10-16 22:11:29,456][root][INFO] - Step: 40000/73665  |  Loss: 0.5994  |  Score: 75.39 [%]  |  Seq Length: 256.0
[2024-10-16 22:48:58,756][root][INFO] - Step: 44199/73665  |  Loss: 0.5837  |  Score: 76.03 [%]  |  Seq Length: 256.0
[2024-10-16 22:49:09,168][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-16 22:49:09,168][root][INFO] - Score: 73.35 [%]  |  Evaluation Time: 10.41 [s]
[2024-10-16 22:49:29,278][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-16 22:49:29,278][root][INFO] - Score: 75.25 [%]  |  Evaluation Time: 20.11 [s]
[2024-10-16 22:49:29,279][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-16 22:49:29,280][root][INFO] - 
[4/ 5 Epoch]
[2024-10-16 23:41:13,237][root][INFO] - Step: 50000/73665  |  Loss: 0.5542  |  Score: 77.51 [%]  |  Seq Length: 256.0
[2024-10-17 01:00:59,902][root][INFO] - Step: 58932/73665  |  Loss: 0.5405  |  Score: 78.15 [%]  |  Seq Length: 256.0
[2024-10-17 01:01:10,206][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 01:01:10,206][root][INFO] - Score: 74.48 [%]  |  Evaluation Time: 10.30 [s]
[2024-10-17 01:01:30,309][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 01:01:30,309][root][INFO] - Score: 75.88 [%]  |  Evaluation Time: 20.10 [s]
[2024-10-17 01:01:30,310][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 01:01:30,311][root][INFO] - 
[5/ 5 Epoch]
[2024-10-17 01:11:00,731][root][INFO] - Step: 60000/73665  |  Loss: 0.5087  |  Score: 79.58 [%]  |  Seq Length: 256.0
[2024-10-17 02:40:02,435][root][INFO] - Step: 70000/73665  |  Loss: 0.5067  |  Score: 79.69 [%]  |  Seq Length: 256.0
[2024-10-17 03:12:44,846][root][INFO] - Step: 73665/73665  |  Loss: 0.5061  |  Score: 79.67 [%]  |  Seq Length: 256.0
[2024-10-17 03:12:55,165][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 03:12:55,166][root][INFO] - Score: 74.55 [%]  |  Evaluation Time: 10.32 [s]
[2024-10-17 03:13:15,343][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 03:13:15,344][root][INFO] - Score: 76.55 [%]  |  Evaluation Time: 20.18 [s]
[2024-10-17 03:13:15,346][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 03:13:15,346][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 03:13:15,346][root][INFO] - - Epoch: 5
[2024-10-17 03:13:15,346][root][INFO] - - DEV score: 74.55 [%]
[2024-10-17 03:13:15,346][root][INFO] - - TEST score: 76.55 [%]
[2024-10-17 03:13:15,347][root][INFO] - Fine-tuning is done!
[2024-10-17 03:15:21,887][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,887][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,888][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,888][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,889][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,889][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,890][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,890][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,891][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,891][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,892][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,892][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,893][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,893][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,894][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,894][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,895][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,895][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,896][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,896][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,897][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,897][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,898][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 03:15:21,898][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 03:15:21,900][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-17 03:15:22,115][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 03:15:22,121][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-17 03:15:22,124][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 03:15:22,314][root][INFO] - 

[2024-10-17 03:15:22,314][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-17 03:15:22,314][root][INFO] - Data Preprocessing
[2024-10-17 03:15:22,314][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-17 03:15:22,314][root][INFO] - ㄴ do_hangeulize              False
[2024-10-17 03:15:22,314][root][INFO] - ㄴ data_remove                False

[2024-10-17 03:15:22,314][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 03:15:22,327][root][INFO] - vocab size              : 51200
[2024-10-17 03:15:22,328][root][INFO] - device                  : gpu
[2024-10-17 03:15:22,328][root][INFO] - random seed             : 3
[2024-10-17 03:15:22,328][root][INFO] - train data size         : 942912
[2024-10-17 03:15:22,328][root][INFO] - max epochs              : 5
[2024-10-17 03:15:22,328][root][INFO] - total steps             : 73665
[2024-10-17 03:15:22,328][root][INFO] - warmup steps            : 7366
[2024-10-17 03:15:22,328][root][INFO] - batch size              : 64
[2024-10-17 03:15:22,328][root][INFO] - accumulation steps      : 1
[2024-10-17 03:15:22,328][root][INFO] - optimizer               : adamwscale
[2024-10-17 03:15:22,329][root][INFO] - lr_scheduler            : cosine
[2024-10-17 03:15:22,329][root][INFO] - learning rate           : 0.02
[2024-10-17 03:15:22,329][root][INFO] - max length              : 256

[2024-10-17 03:15:22,329][root][INFO] - LoRA Configuration
[2024-10-17 03:15:22,329][root][INFO] - ㄴ r                    : 32
[2024-10-17 03:15:22,329][root][INFO] - ㄴ alpha                : 128
[2024-10-17 03:15:22,329][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 03:15:22,329][root][INFO] - KOMBO Configuration
[2024-10-17 03:15:22,329][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 03:15:22,330][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 03:15:22,330][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 03:15:22,330][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 03:15:22,330][root][INFO] - ㄴ do_combination       : True
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 03:15:22,330][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 03:15:22,330][root][INFO] - 

[2024-10-17 03:15:22,331][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-17 03:15:22,331][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-17 03:15:22,331][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb
[2024-10-17 03:15:22,331][root][INFO] - * tb interval   : 10000

[2024-10-17 03:15:22,331][root][INFO] - 

[2024-10-17 03:15:22,331][root][INFO] - Start the Training !
[2024-10-17 03:15:22,333][root][INFO] - 
[1/ 5 Epoch]
[2024-10-17 04:44:01,343][root][INFO] - Step: 10000/73665  |  Loss: 0.7611  |  Score: 66.76 [%]  |  Seq Length: 256.0
[2024-10-17 05:26:11,330][root][INFO] - Step: 14733/73665  |  Loss: 0.8295  |  Score: 62.59 [%]  |  Seq Length: 256.0
[2024-10-17 05:26:21,764][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 05:26:21,764][root][INFO] - Score: 57.00 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-17 05:26:41,983][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 05:26:41,983][root][INFO] - Score: 57.65 [%]  |  Evaluation Time: 20.22 [s]
[2024-10-17 05:26:41,984][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 05:26:41,985][root][INFO] - 
[2/ 5 Epoch]
[2024-10-17 06:13:23,149][root][INFO] - Step: 20000/73665  |  Loss: 1.0191  |  Score: 46.71 [%]  |  Seq Length: 256.0
[2024-10-17 07:36:38,403][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-17 07:36:48,694][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 07:36:48,695][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.29 [s]
[2024-10-17 07:37:08,706][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 07:37:08,706][root][INFO] - Score: 33.38 [%]  |  Evaluation Time: 20.01 [s]
[2024-10-17 07:37:08,708][root][INFO] - 
[3/ 5 Epoch]
[2024-10-17 07:41:50,533][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.52 [%]  |  Seq Length: 256.0
[2024-10-17 09:09:24,976][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-17 09:34:58,321][root][INFO] - 

[2024-10-17 09:34:58,322][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 09:34:58,322][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs
[2024-10-17 09:34:58,322][root][INFO] - 

[2024-10-17 09:34:58,322][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 09:35:06,305][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,306][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,306][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,307][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,309][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,309][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,310][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,310][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,311][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,312][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,312][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,313][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,313][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,314][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,314][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,315][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,316][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,316][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,317][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,317][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,319][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,320][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,320][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 09:35:06,321][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 09:35:06,323][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 09:35:06,327][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 09:35:06,533][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 09:35:06,535][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 09:35:06,716][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 09:41:19,306][root][INFO] - 

[2024-10-17 09:41:19,306][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 09:41:19,306][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:41:19,306][root][INFO] - 

[2024-10-17 09:41:19,306][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 09:41:24,998][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:24,999][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:24,999][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,000][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,000][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,001][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,001][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,002][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,002][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,003][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,004][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,004][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,005][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,005][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,006][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,006][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,007][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,007][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,008][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,008][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,009][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,010][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,010][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 09:41:25,011][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 09:41:25,013][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 09:41:25,017][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 09:41:25,217][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 09:41:25,219][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 09:41:25,400][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 09:41:28,414][root][INFO] - 

[2024-10-17 09:41:28,414][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 09:41:28,414][root][INFO] - Data Preprocessing
[2024-10-17 09:41:28,414][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-17 09:41:28,414][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 09:41:28,414][root][INFO] - ㄴ data_remove                True

[2024-10-17 09:41:28,415][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 09:41:28,422][root][INFO] - vocab size              : 51200
[2024-10-17 09:41:28,422][root][INFO] - device                  : gpu
[2024-10-17 09:41:28,422][root][INFO] - random seed             : 1
[2024-10-17 09:41:28,422][root][INFO] - train data size         : 6464
[2024-10-17 09:41:28,423][root][INFO] - max epochs              : 10
[2024-10-17 09:41:28,423][root][INFO] - total steps             : 1010
[2024-10-17 09:41:28,423][root][INFO] - warmup steps            : 101
[2024-10-17 09:41:28,423][root][INFO] - batch size              : 64
[2024-10-17 09:41:28,423][root][INFO] - accumulation steps      : 1
[2024-10-17 09:41:28,423][root][INFO] - optimizer               : adamwscale
[2024-10-17 09:41:28,423][root][INFO] - lr_scheduler            : cosine
[2024-10-17 09:41:28,423][root][INFO] - learning rate           : 0.01
[2024-10-17 09:41:28,423][root][INFO] - max length              : 256

[2024-10-17 09:41:28,423][root][INFO] - LoRA Configuration
[2024-10-17 09:41:28,423][root][INFO] - ㄴ r                    : 32
[2024-10-17 09:41:28,423][root][INFO] - ㄴ alpha                : 128
[2024-10-17 09:41:28,424][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 09:41:28,424][root][INFO] - KOMBO Configuration
[2024-10-17 09:41:28,424][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 09:41:28,424][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 09:41:28,424][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 09:41:28,424][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 09:41:28,424][root][INFO] - ㄴ do_combination       : True
[2024-10-17 09:41:28,424][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 09:41:28,424][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 09:41:28,425][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 09:41:28,425][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 09:41:28,425][root][INFO] - 

[2024-10-17 09:41:28,425][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:41:28,425][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/ckpt
[2024-10-17 09:41:28,425][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_puncdhdr/256t_64b_1s_1rs/tb
[2024-10-17 09:41:28,425][root][INFO] - * tb interval   : 10000

[2024-10-17 09:41:28,425][root][INFO] - 

[2024-10-17 09:41:28,425][root][INFO] - Start the Training !
[2024-10-17 09:41:28,428][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 09:41:52,265][root][INFO] - 

[2024-10-17 09:41:52,265][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 09:41:52,266][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:41:52,266][root][INFO] - 

[2024-10-17 09:41:52,266][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 09:42:00,060][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,060][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,061][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,061][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,062][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,062][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,062][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,063][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,063][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,064][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,064][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,064][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,065][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,065][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,066][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,066][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,067][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,067][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,067][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,068][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,069][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,070][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,070][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 09:42:00,070][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 09:42:00,072][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 09:42:00,076][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 09:42:00,271][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 09:42:00,274][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 09:42:00,456][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 09:42:03,538][root][INFO] - 

[2024-10-17 09:42:03,538][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 09:42:03,538][root][INFO] - Data Preprocessing
[2024-10-17 09:42:03,538][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 09:42:03,538][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 09:42:03,539][root][INFO] - ㄴ data_remove                True

[2024-10-17 09:42:03,539][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 09:42:03,547][root][INFO] - vocab size              : 51200
[2024-10-17 09:42:03,547][root][INFO] - device                  : gpu
[2024-10-17 09:42:03,547][root][INFO] - random seed             : 1
[2024-10-17 09:42:03,547][root][INFO] - train data size         : 24256
[2024-10-17 09:42:03,547][root][INFO] - max epochs              : 10
[2024-10-17 09:42:03,547][root][INFO] - total steps             : 3790
[2024-10-17 09:42:03,547][root][INFO] - warmup steps            : 379
[2024-10-17 09:42:03,547][root][INFO] - batch size              : 64
[2024-10-17 09:42:03,547][root][INFO] - accumulation steps      : 1
[2024-10-17 09:42:03,547][root][INFO] - optimizer               : adamwscale
[2024-10-17 09:42:03,548][root][INFO] - lr_scheduler            : cosine
[2024-10-17 09:42:03,548][root][INFO] - learning rate           : 0.01
[2024-10-17 09:42:03,548][root][INFO] - max length              : 256

[2024-10-17 09:42:03,548][root][INFO] - LoRA Configuration
[2024-10-17 09:42:03,548][root][INFO] - ㄴ r                    : 32
[2024-10-17 09:42:03,548][root][INFO] - ㄴ alpha                : 128
[2024-10-17 09:42:03,548][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 09:42:03,548][root][INFO] - KOMBO Configuration
[2024-10-17 09:42:03,548][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 09:42:03,548][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 09:42:03,548][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 09:42:03,549][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 09:42:03,549][root][INFO] - ㄴ do_combination       : True
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 09:42:03,549][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 09:42:03,549][root][INFO] - 

[2024-10-17 09:42:03,549][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs
[2024-10-17 09:42:03,549][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/ckpt
[2024-10-17 09:42:03,550][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/tb
[2024-10-17 09:42:03,550][root][INFO] - * tb interval   : 10000

[2024-10-17 09:42:03,550][root][INFO] - 

[2024-10-17 09:42:03,550][root][INFO] - Start the Training !
[2024-10-17 09:42:03,553][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 09:45:44,136][root][INFO] - Step: 379/3790  |  Loss: 0.6939  |  Score: 54.83 [%]  |  Seq Length: 256.0
[2024-10-17 09:45:48,739][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 09:45:48,740][root][INFO] - Score: 60.90 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-17 09:45:53,269][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 09:45:53,270][root][INFO] - Score: 55.12 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-17 09:45:53,271][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 09:45:53,272][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 09:46:12,983][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-17 09:46:23,339][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 09:46:23,339][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.35 [s]
[2024-10-17 09:46:43,341][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 09:46:43,341][root][INFO] - Score: 33.54 [%]  |  Evaluation Time: 20.00 [s]
[2024-10-17 09:46:43,343][root][INFO] - 
[4/ 5 Epoch]
[2024-10-17 09:49:34,167][root][INFO] - Step: 758/3790  |  Loss: 0.5890  |  Score: 68.39 [%]  |  Seq Length: 256.0
[2024-10-17 09:49:38,960][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 09:49:38,961][root][INFO] - Score: 63.61 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 09:49:43,656][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 09:49:43,656][root][INFO] - Score: 63.09 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-17 09:49:43,658][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 09:49:43,659][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 09:53:24,373][root][INFO] - Step: 1137/3790  |  Loss: 0.5120  |  Score: 74.95 [%]  |  Seq Length: 256.0
[2024-10-17 09:53:29,024][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 09:53:29,024][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-17 09:53:33,587][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 09:53:33,587][root][INFO] - Score: 65.92 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-17 09:53:33,588][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 09:53:33,589][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 09:57:13,309][root][INFO] - Step: 1516/3790  |  Loss: 0.4643  |  Score: 78.11 [%]  |  Seq Length: 256.0
[2024-10-17 09:57:17,975][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 09:57:17,976][root][INFO] - Score: 69.79 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 09:57:22,540][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 09:57:22,540][root][INFO] - Score: 66.97 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-17 09:57:22,541][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 09:57:22,542][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 10:01:04,439][root][INFO] - Step: 1895/3790  |  Loss: 0.4223  |  Score: 80.32 [%]  |  Seq Length: 256.0
[2024-10-17 10:01:09,154][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 10:01:09,154][root][INFO] - Score: 72.66 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-17 10:01:13,721][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 10:01:13,721][root][INFO] - Score: 68.90 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-17 10:01:13,722][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 10:01:13,725][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 10:04:56,129][root][INFO] - Step: 2274/3790  |  Loss: 0.3759  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-17 10:05:00,936][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 10:05:00,937][root][INFO] - Score: 75.29 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 10:05:05,630][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 10:05:05,630][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-17 10:05:05,631][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 10:05:05,633][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 10:08:48,288][root][INFO] - Step: 2653/3790  |  Loss: 0.3397  |  Score: 84.68 [%]  |  Seq Length: 256.0
[2024-10-17 10:08:52,996][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 10:08:52,997][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 10:08:57,619][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 10:08:57,619][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 10:08:57,621][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 10:12:40,078][root][INFO] - Step: 3032/3790  |  Loss: 0.3080  |  Score: 86.27 [%]  |  Seq Length: 256.0
[2024-10-17 10:12:44,758][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 10:12:44,758][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 10:12:49,341][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 10:12:49,342][root][INFO] - Score: 70.76 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 10:12:49,342][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-17 10:12:49,344][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 10:16:31,580][root][INFO] - Step: 3411/3790  |  Loss: 0.2905  |  Score: 87.10 [%]  |  Seq Length: 256.0
[2024-10-17 10:16:36,275][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 10:16:36,275][root][INFO] - Score: 72.72 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-17 10:16:40,892][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 10:16:40,893][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 10:16:40,895][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 10:20:21,734][root][INFO] - Step: 3790/3790  |  Loss: 0.2808  |  Score: 87.65 [%]  |  Seq Length: 256.0
[2024-10-17 10:20:26,417][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 10:20:26,417][root][INFO] - Score: 73.11 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 10:20:31,001][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 10:20:31,001][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 10:20:31,002][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 10:20:31,002][root][INFO] - - Epoch: 8
[2024-10-17 10:20:31,002][root][INFO] - - DEV score: 74.90 [%]
[2024-10-17 10:20:31,002][root][INFO] - - TEST score: 70.76 [%]
[2024-10-17 10:20:31,003][root][INFO] - Fine-tuning is done!
[2024-10-17 10:20:37,771][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,772][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,773][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,773][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,774][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,774][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,775][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,775][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,776][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,776][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,777][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,778][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,778][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,779][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,779][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,780][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,780][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,781][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,782][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,782][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,783][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,783][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,784][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 10:20:37,784][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 10:20:37,786][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 10:20:37,996][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 10:20:37,998][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 10:20:37,999][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 10:20:38,167][root][INFO] - 

[2024-10-17 10:20:38,167][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 10:20:38,167][root][INFO] - Data Preprocessing
[2024-10-17 10:20:38,167][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 10:20:38,167][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 10:20:38,167][root][INFO] - ㄴ data_remove                True

[2024-10-17 10:20:38,167][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 10:20:38,175][root][INFO] - vocab size              : 51200
[2024-10-17 10:20:38,176][root][INFO] - device                  : gpu
[2024-10-17 10:20:38,176][root][INFO] - random seed             : 1
[2024-10-17 10:20:38,176][root][INFO] - train data size         : 24256
[2024-10-17 10:20:38,176][root][INFO] - max epochs              : 10
[2024-10-17 10:20:38,176][root][INFO] - total steps             : 3790
[2024-10-17 10:20:38,176][root][INFO] - warmup steps            : 379
[2024-10-17 10:20:38,176][root][INFO] - batch size              : 64
[2024-10-17 10:20:38,176][root][INFO] - accumulation steps      : 1
[2024-10-17 10:20:38,176][root][INFO] - optimizer               : adamwscale
[2024-10-17 10:20:38,176][root][INFO] - lr_scheduler            : cosine
[2024-10-17 10:20:38,177][root][INFO] - learning rate           : 0.02
[2024-10-17 10:20:38,177][root][INFO] - max length              : 256

[2024-10-17 10:20:38,177][root][INFO] - LoRA Configuration
[2024-10-17 10:20:38,177][root][INFO] - ㄴ r                    : 32
[2024-10-17 10:20:38,177][root][INFO] - ㄴ alpha                : 128
[2024-10-17 10:20:38,177][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 10:20:38,177][root][INFO] - KOMBO Configuration
[2024-10-17 10:20:38,177][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 10:20:38,177][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 10:20:38,177][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 10:20:38,177][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 10:20:38,178][root][INFO] - ㄴ do_combination       : True
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 10:20:38,178][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 10:20:38,178][root][INFO] - 

[2024-10-17 10:20:38,178][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs
[2024-10-17 10:20:38,178][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/ckpt
[2024-10-17 10:20:38,178][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_1rs/tb
[2024-10-17 10:20:38,178][root][INFO] - * tb interval   : 10000

[2024-10-17 10:20:38,178][root][INFO] - 

[2024-10-17 10:20:38,179][root][INFO] - Start the Training !
[2024-10-17 10:20:38,181][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 10:24:20,944][root][INFO] - Step: 379/3790  |  Loss: 0.6768  |  Score: 57.28 [%]  |  Seq Length: 256.0
[2024-10-17 10:24:25,686][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 10:24:25,686][root][INFO] - Score: 62.76 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:24:30,389][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 10:24:30,389][root][INFO] - Score: 61.12 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 10:24:30,390][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 10:24:30,392][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 10:28:13,177][root][INFO] - Step: 758/3790  |  Loss: 0.5723  |  Score: 70.23 [%]  |  Seq Length: 256.0
[2024-10-17 10:28:17,927][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 10:28:17,927][root][INFO] - Score: 66.57 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 10:28:22,557][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 10:28:22,557][root][INFO] - Score: 64.41 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 10:28:22,558][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 10:28:22,560][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 10:32:05,600][root][INFO] - Step: 1137/3790  |  Loss: 0.5078  |  Score: 75.27 [%]  |  Seq Length: 256.0
[2024-10-17 10:32:10,313][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 10:32:10,313][root][INFO] - Score: 68.75 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-17 10:32:14,988][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 10:32:14,988][root][INFO] - Score: 66.30 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-17 10:32:14,989][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 10:32:14,991][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 10:35:57,484][root][INFO] - Step: 1516/3790  |  Loss: 0.4583  |  Score: 78.41 [%]  |  Seq Length: 256.0
[2024-10-17 10:36:02,224][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 10:36:02,224][root][INFO] - Score: 70.28 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:36:06,834][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 10:36:06,834][root][INFO] - Score: 65.83 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-17 10:36:06,835][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 10:36:06,836][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 10:37:55,155][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-17 10:39:48,968][root][INFO] - Step: 1895/3790  |  Loss: 0.4172  |  Score: 80.57 [%]  |  Seq Length: 256.0
[2024-10-17 10:39:53,701][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 10:39:53,701][root][INFO] - Score: 72.36 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 10:39:58,342][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 10:39:58,342][root][INFO] - Score: 67.96 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 10:39:58,343][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 10:39:58,344][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 10:43:40,980][root][INFO] - Step: 2274/3790  |  Loss: 0.3611  |  Score: 83.62 [%]  |  Seq Length: 256.0
[2024-10-17 10:43:45,703][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 10:43:45,703][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-17 10:43:50,341][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 10:43:50,341][root][INFO] - Score: 68.43 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 10:43:50,343][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 10:47:32,281][root][INFO] - Step: 2653/3790  |  Loss: 0.3075  |  Score: 86.41 [%]  |  Seq Length: 256.0
[2024-10-17 10:47:37,091][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 10:47:37,091][root][INFO] - Score: 69.01 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-17 10:47:41,835][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 10:47:41,835][root][INFO] - Score: 67.87 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:47:41,838][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 10:51:24,130][root][INFO] - Step: 3032/3790  |  Loss: 0.2640  |  Score: 88.37 [%]  |  Seq Length: 256.0
[2024-10-17 10:51:28,902][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 10:51:28,902][root][INFO] - Score: 70.38 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-17 10:51:33,541][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 10:51:33,541][root][INFO] - Score: 68.64 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 10:51:33,543][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 10:55:15,128][root][INFO] - Step: 3411/3790  |  Loss: 0.2307  |  Score: 90.07 [%]  |  Seq Length: 256.0
[2024-10-17 10:55:19,953][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 10:55:19,953][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 10:55:24,698][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 10:55:24,698][root][INFO] - Score: 67.64 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 10:55:24,699][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 10:55:24,700][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 10:59:07,571][root][INFO] - Step: 3790/3790  |  Loss: 0.2155  |  Score: 90.80 [%]  |  Seq Length: 256.0
[2024-10-17 10:59:12,258][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 10:59:12,258][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 10:59:16,854][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 10:59:16,854][root][INFO] - Score: 68.06 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-17 10:59:16,855][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 10:59:16,855][root][INFO] - - Epoch: 9
[2024-10-17 10:59:16,855][root][INFO] - - DEV score: 72.85 [%]
[2024-10-17 10:59:16,855][root][INFO] - - TEST score: 67.64 [%]
[2024-10-17 10:59:16,856][root][INFO] - Fine-tuning is done!
[2024-10-17 10:59:16,857][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 10:59:16,857][root][INFO] - - BEST LR: 0.01
[2024-10-17 10:59:16,857][root][INFO] - - DEV score: 74.90 [%]
[2024-10-17 10:59:16,857][root][INFO] - - TEST score: 70.76 [%]
[2024-10-17 10:59:23,036][root][INFO] - 

[2024-10-17 10:59:23,036][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 10:59:23,036][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs
[2024-10-17 10:59:23,036][root][INFO] - 

[2024-10-17 10:59:23,036][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 10:59:30,885][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,885][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,886][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,886][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,887][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,887][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,888][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,888][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,889][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,889][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,889][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,890][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,890][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,891][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,891][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,891][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,892][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,892][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,893][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,893][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,895][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,895][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,895][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 10:59:30,896][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 10:59:30,897][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 10:59:30,901][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 10:59:31,107][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 10:59:31,109][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 10:59:31,296][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 10:59:34,388][root][INFO] - 

[2024-10-17 10:59:34,389][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 10:59:34,389][root][INFO] - Data Preprocessing
[2024-10-17 10:59:34,389][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 10:59:34,389][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 10:59:34,389][root][INFO] - ㄴ data_remove                True

[2024-10-17 10:59:34,389][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 10:59:34,396][root][INFO] - vocab size              : 51200
[2024-10-17 10:59:34,397][root][INFO] - device                  : gpu
[2024-10-17 10:59:34,397][root][INFO] - random seed             : 2
[2024-10-17 10:59:34,397][root][INFO] - train data size         : 24256
[2024-10-17 10:59:34,397][root][INFO] - max epochs              : 10
[2024-10-17 10:59:34,397][root][INFO] - total steps             : 3790
[2024-10-17 10:59:34,397][root][INFO] - warmup steps            : 379
[2024-10-17 10:59:34,397][root][INFO] - batch size              : 64
[2024-10-17 10:59:34,397][root][INFO] - accumulation steps      : 1
[2024-10-17 10:59:34,397][root][INFO] - optimizer               : adamwscale
[2024-10-17 10:59:34,397][root][INFO] - lr_scheduler            : cosine
[2024-10-17 10:59:34,397][root][INFO] - learning rate           : 0.01
[2024-10-17 10:59:34,398][root][INFO] - max length              : 256

[2024-10-17 10:59:34,398][root][INFO] - LoRA Configuration
[2024-10-17 10:59:34,398][root][INFO] - ㄴ r                    : 32
[2024-10-17 10:59:34,398][root][INFO] - ㄴ alpha                : 128
[2024-10-17 10:59:34,398][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 10:59:34,398][root][INFO] - KOMBO Configuration
[2024-10-17 10:59:34,398][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 10:59:34,398][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 10:59:34,398][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 10:59:34,398][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 10:59:34,398][root][INFO] - ㄴ do_combination       : True
[2024-10-17 10:59:34,399][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 10:59:34,399][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 10:59:34,399][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 10:59:34,402][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 10:59:34,402][root][INFO] - 

[2024-10-17 10:59:34,403][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs
[2024-10-17 10:59:34,403][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/ckpt
[2024-10-17 10:59:34,403][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/tb
[2024-10-17 10:59:34,403][root][INFO] - * tb interval   : 10000

[2024-10-17 10:59:34,403][root][INFO] - 

[2024-10-17 10:59:34,403][root][INFO] - Start the Training !
[2024-10-17 10:59:34,406][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 11:03:12,069][root][INFO] - Step: 379/3790  |  Loss: 0.6867  |  Score: 56.25 [%]  |  Seq Length: 256.0
[2024-10-17 11:03:16,730][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 11:03:16,730][root][INFO] - Score: 64.36 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 11:03:21,310][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 11:03:21,310][root][INFO] - Score: 59.70 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 11:03:21,311][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 11:03:21,312][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 11:07:02,252][root][INFO] - Step: 758/3790  |  Loss: 0.5783  |  Score: 69.93 [%]  |  Seq Length: 256.0
[2024-10-17 11:07:07,042][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 11:07:07,042][root][INFO] - Score: 65.27 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 11:07:11,619][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 11:07:11,619][root][INFO] - Score: 63.70 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-17 11:07:11,620][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 11:07:11,621][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 11:10:53,236][root][INFO] - Step: 1137/3790  |  Loss: 0.5107  |  Score: 74.97 [%]  |  Seq Length: 256.0
[2024-10-17 11:10:57,900][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 11:10:57,900][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 11:11:02,547][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 11:11:02,547][root][INFO] - Score: 65.26 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 11:11:02,548][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 11:11:02,550][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 11:14:44,027][root][INFO] - Step: 1516/3790  |  Loss: 0.4598  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-17 11:14:48,775][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 11:14:48,776][root][INFO] - Score: 63.96 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 11:14:53,403][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 11:14:53,403][root][INFO] - Score: 67.67 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 11:14:53,405][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 11:18:35,332][root][INFO] - Step: 1895/3790  |  Loss: 0.4140  |  Score: 80.92 [%]  |  Seq Length: 256.0
[2024-10-17 11:18:39,975][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 11:18:39,975][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 11:18:44,547][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 11:18:44,547][root][INFO] - Score: 67.03 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-17 11:18:44,547][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 11:18:44,549][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 11:22:25,856][root][INFO] - Step: 2274/3790  |  Loss: 0.3670  |  Score: 83.35 [%]  |  Seq Length: 256.0
[2024-10-17 11:22:30,697][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 11:22:30,698][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 11:22:35,289][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 11:22:35,289][root][INFO] - Score: 66.72 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-17 11:22:35,290][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 11:22:35,291][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 11:26:17,337][root][INFO] - Step: 2653/3790  |  Loss: 0.3304  |  Score: 85.14 [%]  |  Seq Length: 256.0
[2024-10-17 11:26:22,163][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 11:26:22,163][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 11:26:26,884][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 11:26:26,884][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-17 11:26:26,885][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 11:26:26,887][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 11:30:09,826][root][INFO] - Step: 3032/3790  |  Loss: 0.2999  |  Score: 86.83 [%]  |  Seq Length: 256.0
[2024-10-17 11:30:14,468][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 11:30:14,469][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 11:30:19,071][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 11:30:19,071][root][INFO] - Score: 68.09 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-17 11:30:19,072][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-17 11:30:19,074][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 11:33:59,742][root][INFO] - Step: 3411/3790  |  Loss: 0.2759  |  Score: 87.94 [%]  |  Seq Length: 256.0
[2024-10-17 11:34:04,482][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 11:34:04,483][root][INFO] - Score: 72.66 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 11:34:09,092][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 11:34:09,092][root][INFO] - Score: 68.02 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-17 11:34:09,093][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 11:34:09,096][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 11:37:50,588][root][INFO] - Step: 3790/3790  |  Loss: 0.2722  |  Score: 88.09 [%]  |  Seq Length: 256.0
[2024-10-17 11:37:55,308][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 11:37:55,309][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-17 11:38:00,038][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 11:38:00,039][root][INFO] - Score: 67.48 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 11:38:00,040][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 11:38:00,040][root][INFO] - - Epoch: 9
[2024-10-17 11:38:00,040][root][INFO] - - DEV score: 72.66 [%]
[2024-10-17 11:38:00,040][root][INFO] - - TEST score: 68.02 [%]
[2024-10-17 11:38:00,041][root][INFO] - Fine-tuning is done!
[2024-10-17 11:38:07,057][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,058][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,059][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,059][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,060][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,061][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,062][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,063][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,063][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,064][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,065][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,066][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,066][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,067][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,068][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,068][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,069][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,070][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,070][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,071][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,072][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,072][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,073][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 11:38:07,074][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 11:38:07,076][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 11:38:07,326][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 11:38:07,329][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 11:38:07,330][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 11:38:07,500][root][INFO] - 

[2024-10-17 11:38:07,500][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 11:38:07,500][root][INFO] - Data Preprocessing
[2024-10-17 11:38:07,501][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 11:38:07,501][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 11:38:07,501][root][INFO] - ㄴ data_remove                True

[2024-10-17 11:38:07,501][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 11:38:07,509][root][INFO] - vocab size              : 51200
[2024-10-17 11:38:07,509][root][INFO] - device                  : gpu
[2024-10-17 11:38:07,509][root][INFO] - random seed             : 2
[2024-10-17 11:38:07,509][root][INFO] - train data size         : 24256
[2024-10-17 11:38:07,509][root][INFO] - max epochs              : 10
[2024-10-17 11:38:07,509][root][INFO] - total steps             : 3790
[2024-10-17 11:38:07,509][root][INFO] - warmup steps            : 379
[2024-10-17 11:38:07,509][root][INFO] - batch size              : 64
[2024-10-17 11:38:07,509][root][INFO] - accumulation steps      : 1
[2024-10-17 11:38:07,510][root][INFO] - optimizer               : adamwscale
[2024-10-17 11:38:07,510][root][INFO] - lr_scheduler            : cosine
[2024-10-17 11:38:07,510][root][INFO] - learning rate           : 0.02
[2024-10-17 11:38:07,510][root][INFO] - max length              : 256

[2024-10-17 11:38:07,510][root][INFO] - LoRA Configuration
[2024-10-17 11:38:07,510][root][INFO] - ㄴ r                    : 32
[2024-10-17 11:38:07,510][root][INFO] - ㄴ alpha                : 128
[2024-10-17 11:38:07,510][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 11:38:07,510][root][INFO] - KOMBO Configuration
[2024-10-17 11:38:07,510][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 11:38:07,510][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 11:38:07,511][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 11:38:07,511][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 11:38:07,511][root][INFO] - ㄴ do_combination       : True
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 11:38:07,511][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 11:38:07,511][root][INFO] - 

[2024-10-17 11:38:07,511][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs
[2024-10-17 11:38:07,511][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/ckpt
[2024-10-17 11:38:07,512][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_2rs/tb
[2024-10-17 11:38:07,512][root][INFO] - * tb interval   : 10000

[2024-10-17 11:38:07,512][root][INFO] - 

[2024-10-17 11:38:07,512][root][INFO] - Start the Training !
[2024-10-17 11:38:07,514][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 11:41:49,783][root][INFO] - Step: 379/3790  |  Loss: 0.6785  |  Score: 57.20 [%]  |  Seq Length: 256.0
[2024-10-17 11:41:54,695][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 11:41:54,695][root][INFO] - Score: 64.36 [%]  |  Evaluation Time: 4.91 [s]
[2024-10-17 11:41:59,466][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 11:41:59,466][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-17 11:41:59,467][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 11:41:59,468][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 11:45:42,285][root][INFO] - Step: 758/3790  |  Loss: 0.5734  |  Score: 69.73 [%]  |  Seq Length: 256.0
[2024-10-17 11:45:47,028][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 11:45:47,028][root][INFO] - Score: 67.42 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 11:45:51,663][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 11:45:51,663][root][INFO] - Score: 62.49 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 11:45:51,664][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 11:45:51,665][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 11:49:34,853][root][INFO] - Step: 1137/3790  |  Loss: 0.5098  |  Score: 74.89 [%]  |  Seq Length: 256.0
[2024-10-17 11:49:39,651][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 11:49:39,651][root][INFO] - Score: 69.34 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 11:49:44,441][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 11:49:44,442][root][INFO] - Score: 66.66 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 11:49:44,443][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 11:49:44,444][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 11:53:27,229][root][INFO] - Step: 1516/3790  |  Loss: 0.4597  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-17 11:53:32,068][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 11:53:32,068][root][INFO] - Score: 63.87 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 11:53:36,747][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 11:53:36,748][root][INFO] - Score: 65.92 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 11:53:36,750][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 11:56:56,836][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-17 11:57:07,445][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 11:57:07,445][root][INFO] - Score: 33.31 [%]  |  Evaluation Time: 10.61 [s]
[2024-10-17 11:57:17,040][root][INFO] - Step: 1895/3790  |  Loss: 0.4097  |  Score: 80.88 [%]  |  Seq Length: 256.0
[2024-10-17 11:57:21,794][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 11:57:21,794][root][INFO] - Score: 69.89 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 11:57:26,416][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 11:57:26,416][root][INFO] - Score: 67.64 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 11:57:26,417][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 11:57:26,418][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 11:57:27,740][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 11:57:27,740][root][INFO] - Score: 33.23 [%]  |  Evaluation Time: 20.29 [s]
[2024-10-17 11:57:27,742][root][INFO] - 
[5/ 5 Epoch]
[2024-10-17 12:01:10,013][root][INFO] - Step: 2274/3790  |  Loss: 0.3553  |  Score: 83.82 [%]  |  Seq Length: 256.0
[2024-10-17 12:01:14,832][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 12:01:14,833][root][INFO] - Score: 72.56 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 12:01:19,602][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 12:01:19,602][root][INFO] - Score: 68.86 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-17 12:01:19,603][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 12:01:19,605][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 12:05:03,063][root][INFO] - Step: 2653/3790  |  Loss: 0.2951  |  Score: 86.95 [%]  |  Seq Length: 256.0
[2024-10-17 12:05:07,860][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 12:05:07,860][root][INFO] - Score: 74.22 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 12:05:12,597][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 12:05:12,597][root][INFO] - Score: 68.70 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 12:05:12,599][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 12:05:12,600][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 12:06:52,938][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.46 [%]  |  Seq Length: 256.0
[2024-10-17 12:08:55,978][root][INFO] - Step: 3032/3790  |  Loss: 0.2516  |  Score: 89.30 [%]  |  Seq Length: 256.0
[2024-10-17 12:09:00,769][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 12:09:00,769][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 12:09:05,430][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 12:09:05,430][root][INFO] - Score: 68.19 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 12:09:05,433][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 12:12:48,165][root][INFO] - Step: 3411/3790  |  Loss: 0.2138  |  Score: 90.67 [%]  |  Seq Length: 256.0
[2024-10-17 12:12:52,933][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 12:12:52,933][root][INFO] - Score: 71.06 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-17 12:12:57,687][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 12:12:57,687][root][INFO] - Score: 68.59 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 12:12:57,690][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 12:16:40,484][root][INFO] - Step: 3790/3790  |  Loss: 0.2026  |  Score: 91.35 [%]  |  Seq Length: 256.0
[2024-10-17 12:16:45,265][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 12:16:45,265][root][INFO] - Score: 69.76 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-17 12:16:49,963][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 12:16:49,963][root][INFO] - Score: 68.55 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 12:16:49,964][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 12:16:49,964][root][INFO] - - Epoch: 7
[2024-10-17 12:16:49,964][root][INFO] - - DEV score: 74.22 [%]
[2024-10-17 12:16:49,964][root][INFO] - - TEST score: 68.70 [%]
[2024-10-17 12:16:49,966][root][INFO] - Fine-tuning is done!
[2024-10-17 12:16:49,966][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 12:16:49,966][root][INFO] - - BEST LR: 0.02
[2024-10-17 12:16:49,966][root][INFO] - - DEV score: 74.22 [%]
[2024-10-17 12:16:49,966][root][INFO] - - TEST score: 68.70 [%]
[2024-10-17 12:16:56,182][root][INFO] - 

[2024-10-17 12:16:56,182][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 12:16:56,183][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs
[2024-10-17 12:16:56,183][root][INFO] - 

[2024-10-17 12:16:56,183][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 12:17:04,450][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,451][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,451][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,452][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,452][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,453][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,453][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,454][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,454][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,455][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,455][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,456][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,456][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,457][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,457][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,458][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,458][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,459][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,459][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,460][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,462][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,462][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,463][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 12:17:04,463][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 12:17:04,464][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 12:17:04,469][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 12:17:04,672][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 12:17:04,674][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 12:17:04,868][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 12:17:08,114][root][INFO] - 

[2024-10-17 12:17:08,115][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 12:17:08,115][root][INFO] - Data Preprocessing
[2024-10-17 12:17:08,115][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 12:17:08,115][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 12:17:08,115][root][INFO] - ㄴ data_remove                True

[2024-10-17 12:17:08,115][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 12:17:08,123][root][INFO] - vocab size              : 51200
[2024-10-17 12:17:08,123][root][INFO] - device                  : gpu
[2024-10-17 12:17:08,123][root][INFO] - random seed             : 3
[2024-10-17 12:17:08,123][root][INFO] - train data size         : 24256
[2024-10-17 12:17:08,123][root][INFO] - max epochs              : 10
[2024-10-17 12:17:08,123][root][INFO] - total steps             : 3790
[2024-10-17 12:17:08,124][root][INFO] - warmup steps            : 379
[2024-10-17 12:17:08,124][root][INFO] - batch size              : 64
[2024-10-17 12:17:08,124][root][INFO] - accumulation steps      : 1
[2024-10-17 12:17:08,124][root][INFO] - optimizer               : adamwscale
[2024-10-17 12:17:08,124][root][INFO] - lr_scheduler            : cosine
[2024-10-17 12:17:08,124][root][INFO] - learning rate           : 0.01
[2024-10-17 12:17:08,124][root][INFO] - max length              : 256

[2024-10-17 12:17:08,124][root][INFO] - LoRA Configuration
[2024-10-17 12:17:08,124][root][INFO] - ㄴ r                    : 32
[2024-10-17 12:17:08,124][root][INFO] - ㄴ alpha                : 128
[2024-10-17 12:17:08,124][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 12:17:08,124][root][INFO] - KOMBO Configuration
[2024-10-17 12:17:08,125][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 12:17:08,125][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 12:17:08,125][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 12:17:08,125][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 12:17:08,125][root][INFO] - ㄴ do_combination       : True
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 12:17:08,125][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 12:17:08,125][root][INFO] - 

[2024-10-17 12:17:08,126][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs
[2024-10-17 12:17:08,126][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/ckpt
[2024-10-17 12:17:08,126][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/tb
[2024-10-17 12:17:08,126][root][INFO] - * tb interval   : 10000

[2024-10-17 12:17:08,126][root][INFO] - 

[2024-10-17 12:17:08,126][root][INFO] - Start the Training !
[2024-10-17 12:17:08,129][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 12:20:51,457][root][INFO] - Step: 379/3790  |  Loss: 0.6845  |  Score: 56.77 [%]  |  Seq Length: 256.0
[2024-10-17 12:20:56,194][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 12:20:56,195][root][INFO] - Score: 59.44 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:21:00,840][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 12:21:00,840][root][INFO] - Score: 58.31 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 12:21:00,841][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 12:21:00,842][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 12:24:42,876][root][INFO] - Step: 758/3790  |  Loss: 0.5793  |  Score: 69.78 [%]  |  Seq Length: 256.0
[2024-10-17 12:24:47,680][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 12:24:47,680][root][INFO] - Score: 67.25 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 12:24:52,341][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 12:24:52,341][root][INFO] - Score: 64.57 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 12:24:52,342][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 12:24:52,344][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 12:28:35,950][root][INFO] - Step: 1137/3790  |  Loss: 0.5077  |  Score: 75.23 [%]  |  Seq Length: 256.0
[2024-10-17 12:28:40,755][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 12:28:40,755][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 12:28:45,323][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 12:28:45,323][root][INFO] - Score: 67.45 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-17 12:28:45,324][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 12:28:45,326][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 12:32:27,975][root][INFO] - Step: 1516/3790  |  Loss: 0.4589  |  Score: 78.43 [%]  |  Seq Length: 256.0
[2024-10-17 12:32:32,787][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 12:32:32,787][root][INFO] - Score: 68.72 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-17 12:32:37,485][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 12:32:37,486][root][INFO] - Score: 64.49 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 12:32:37,489][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 12:36:19,845][root][INFO] - Step: 1895/3790  |  Loss: 0.4165  |  Score: 80.56 [%]  |  Seq Length: 256.0
[2024-10-17 12:36:24,691][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 12:36:24,691][root][INFO] - Score: 66.93 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 12:36:29,427][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 12:36:29,427][root][INFO] - Score: 66.74 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:36:29,429][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 12:40:12,109][root][INFO] - Step: 2274/3790  |  Loss: 0.3719  |  Score: 82.93 [%]  |  Seq Length: 256.0
[2024-10-17 12:40:16,946][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 12:40:16,946][root][INFO] - Score: 69.99 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-17 12:40:21,695][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 12:40:21,696][root][INFO] - Score: 68.06 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 12:40:21,698][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 12:44:03,817][root][INFO] - Step: 2653/3790  |  Loss: 0.3372  |  Score: 84.78 [%]  |  Seq Length: 256.0
[2024-10-17 12:44:08,517][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 12:44:08,517][root][INFO] - Score: 69.47 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 12:44:13,422][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 12:44:13,423][root][INFO] - Score: 68.38 [%]  |  Evaluation Time: 4.90 [s]
[2024-10-17 12:44:13,425][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 12:47:55,701][root][INFO] - Step: 3032/3790  |  Loss: 0.3036  |  Score: 86.35 [%]  |  Seq Length: 256.0
[2024-10-17 12:48:00,441][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 12:48:00,441][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 12:48:05,067][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 12:48:05,067][root][INFO] - Score: 67.34 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-17 12:48:05,070][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 12:51:46,404][root][INFO] - Step: 3411/3790  |  Loss: 0.2828  |  Score: 87.34 [%]  |  Seq Length: 256.0
[2024-10-17 12:51:51,216][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 12:51:51,216][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-17 12:51:55,943][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 12:51:55,944][root][INFO] - Score: 68.44 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:51:55,945][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 12:51:55,946][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 12:55:41,228][root][INFO] - Step: 3790/3790  |  Loss: 0.2764  |  Score: 87.84 [%]  |  Seq Length: 256.0
[2024-10-17 12:55:45,960][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 12:55:45,960][root][INFO] - Score: 70.38 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-17 12:55:50,600][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 12:55:50,600][root][INFO] - Score: 67.95 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-17 12:55:50,601][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 12:55:50,601][root][INFO] - - Epoch: 9
[2024-10-17 12:55:50,601][root][INFO] - - DEV score: 70.18 [%]
[2024-10-17 12:55:50,601][root][INFO] - - TEST score: 68.44 [%]
[2024-10-17 12:55:50,602][root][INFO] - Fine-tuning is done!
[2024-10-17 12:55:58,392][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,393][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,394][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,394][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,395][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,395][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,396][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,396][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,397][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,397][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,398][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,398][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,399][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,399][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,400][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,400][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,401][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,401][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,402][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,402][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,403][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,404][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,404][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 12:55:58,405][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 12:55:58,407][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 12:55:58,612][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 12:55:58,615][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 12:55:58,616][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 12:55:58,784][root][INFO] - 

[2024-10-17 12:55:58,784][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 12:55:58,784][root][INFO] - Data Preprocessing
[2024-10-17 12:55:58,784][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 12:55:58,785][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 12:55:58,785][root][INFO] - ㄴ data_remove                True

[2024-10-17 12:55:58,785][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 12:55:58,793][root][INFO] - vocab size              : 51200
[2024-10-17 12:55:58,793][root][INFO] - device                  : gpu
[2024-10-17 12:55:58,793][root][INFO] - random seed             : 3
[2024-10-17 12:55:58,793][root][INFO] - train data size         : 24256
[2024-10-17 12:55:58,793][root][INFO] - max epochs              : 10
[2024-10-17 12:55:58,794][root][INFO] - total steps             : 3790
[2024-10-17 12:55:58,794][root][INFO] - warmup steps            : 379
[2024-10-17 12:55:58,794][root][INFO] - batch size              : 64
[2024-10-17 12:55:58,794][root][INFO] - accumulation steps      : 1
[2024-10-17 12:55:58,794][root][INFO] - optimizer               : adamwscale
[2024-10-17 12:55:58,794][root][INFO] - lr_scheduler            : cosine
[2024-10-17 12:55:58,794][root][INFO] - learning rate           : 0.02
[2024-10-17 12:55:58,794][root][INFO] - max length              : 256

[2024-10-17 12:55:58,794][root][INFO] - LoRA Configuration
[2024-10-17 12:55:58,794][root][INFO] - ㄴ r                    : 32
[2024-10-17 12:55:58,794][root][INFO] - ㄴ alpha                : 128
[2024-10-17 12:55:58,794][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 12:55:58,795][root][INFO] - KOMBO Configuration
[2024-10-17 12:55:58,795][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 12:55:58,795][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 12:55:58,795][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 12:55:58,795][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 12:55:58,795][root][INFO] - ㄴ do_combination       : True
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 12:55:58,795][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 12:55:58,796][root][INFO] - 

[2024-10-17 12:55:58,796][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs
[2024-10-17 12:55:58,796][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/ckpt
[2024-10-17 12:55:58,796][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdhdr/256t_64b_1s_3rs/tb
[2024-10-17 12:55:58,796][root][INFO] - * tb interval   : 10000

[2024-10-17 12:55:58,796][root][INFO] - 

[2024-10-17 12:55:58,796][root][INFO] - Start the Training !
[2024-10-17 12:55:58,798][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 12:59:41,174][root][INFO] - Step: 379/3790  |  Loss: 0.6737  |  Score: 58.41 [%]  |  Seq Length: 256.0
[2024-10-17 12:59:45,975][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 12:59:45,975][root][INFO] - Score: 60.68 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 12:59:50,638][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 12:59:50,638][root][INFO] - Score: 61.57 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-17 12:59:50,639][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 12:59:50,641][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 13:03:32,559][root][INFO] - Step: 758/3790  |  Loss: 0.5624  |  Score: 71.23 [%]  |  Seq Length: 256.0
[2024-10-17 13:03:37,443][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 13:03:37,443][root][INFO] - Score: 66.37 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-17 13:03:42,080][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 13:03:42,080][root][INFO] - Score: 65.00 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-17 13:03:42,081][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 13:03:42,082][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 13:07:25,655][root][INFO] - Step: 1137/3790  |  Loss: 0.5084  |  Score: 74.96 [%]  |  Seq Length: 256.0
[2024-10-17 13:07:30,492][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 13:07:30,492][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-17 13:07:35,167][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 13:07:35,167][root][INFO] - Score: 66.67 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-17 13:07:35,169][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 13:07:35,170][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 13:11:18,725][root][INFO] - Step: 1516/3790  |  Loss: 0.4567  |  Score: 78.53 [%]  |  Seq Length: 256.0
[2024-10-17 13:11:23,527][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 13:11:23,528][root][INFO] - Score: 68.23 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-17 13:11:28,276][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 13:11:28,277][root][INFO] - Score: 65.49 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-17 13:11:28,279][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 13:15:10,481][root][INFO] - Step: 1895/3790  |  Loss: 0.4081  |  Score: 81.07 [%]  |  Seq Length: 256.0
[2024-10-17 13:15:15,271][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 13:15:15,271][root][INFO] - Score: 67.12 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 13:15:19,941][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 13:15:19,941][root][INFO] - Score: 66.59 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-17 13:15:19,943][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 13:19:01,577][root][INFO] - Step: 2274/3790  |  Loss: 0.3490  |  Score: 84.35 [%]  |  Seq Length: 256.0
[2024-10-17 13:19:06,374][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 13:19:06,374][root][INFO] - Score: 70.77 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 13:19:11,055][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 13:19:11,056][root][INFO] - Score: 68.32 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-17 13:19:11,056][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 13:19:11,058][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 13:22:51,239][root][INFO] - Step: 2653/3790  |  Loss: 0.2972  |  Score: 86.89 [%]  |  Seq Length: 256.0
[2024-10-17 13:22:56,081][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 13:22:56,082][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.84 [s]
[2024-10-17 13:23:00,740][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 13:23:00,740][root][INFO] - Score: 68.66 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-17 13:23:00,741][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 13:23:00,742][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 13:26:43,105][root][INFO] - Step: 3032/3790  |  Loss: 0.2483  |  Score: 89.00 [%]  |  Seq Length: 256.0
[2024-10-17 13:26:47,884][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 13:26:47,884][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-17 13:26:52,678][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 13:26:52,678][root][INFO] - Score: 68.81 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-17 13:26:52,680][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 13:30:36,203][root][INFO] - Step: 3411/3790  |  Loss: 0.2160  |  Score: 90.82 [%]  |  Seq Length: 256.0
[2024-10-17 13:30:41,029][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 13:30:41,030][root][INFO] - Score: 69.17 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-17 13:30:45,730][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 13:30:45,730][root][INFO] - Score: 68.69 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-17 13:30:45,733][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 13:34:28,852][root][INFO] - Step: 3790/3790  |  Loss: 0.1951  |  Score: 91.70 [%]  |  Seq Length: 256.0
[2024-10-17 13:34:33,732][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 13:34:33,732][root][INFO] - Score: 69.37 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-17 13:34:38,475][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 13:34:38,476][root][INFO] - Score: 69.13 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-17 13:34:38,477][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 13:34:38,477][root][INFO] - - Epoch: 7
[2024-10-17 13:34:38,477][root][INFO] - - DEV score: 71.65 [%]
[2024-10-17 13:34:38,477][root][INFO] - - TEST score: 68.66 [%]
[2024-10-17 13:34:38,478][root][INFO] - Fine-tuning is done!
[2024-10-17 13:34:38,479][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 13:34:38,479][root][INFO] - - BEST LR: 0.02
[2024-10-17 13:34:38,479][root][INFO] - - DEV score: 71.65 [%]
[2024-10-17 13:34:38,479][root][INFO] - - TEST score: 68.66 [%]
[2024-10-17 13:34:44,886][root][INFO] - 

[2024-10-17 13:34:44,886][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 13:34:44,886][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs
[2024-10-17 13:34:44,886][root][INFO] - 

[2024-10-17 13:34:44,887][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 13:35:06,081][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-17 14:07:24,060][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-17 14:07:34,475][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 14:07:34,476][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.41 [s]
[2024-10-17 14:07:54,685][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 14:07:54,685][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.21 [s]
[2024-10-17 14:07:54,686][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 14:07:54,686][root][INFO] - - Epoch: 1
[2024-10-17 14:07:54,686][root][INFO] - - DEV score: 57.00 [%]
[2024-10-17 14:07:54,686][root][INFO] - - TEST score: 57.65 [%]
[2024-10-17 14:07:54,687][root][INFO] - Fine-tuning is done!
[2024-10-17 14:07:54,688][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 14:07:54,688][root][INFO] - - BEST LR: 0.01
[2024-10-17 14:07:54,688][root][INFO] - - DEV score: 74.55 [%]
[2024-10-17 14:07:54,688][root][INFO] - - TEST score: 76.55 [%]
[2024-10-17 16:22:45,625][root][INFO] - 

[2024-10-17 16:22:45,625][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 16:22:45,625][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:22:45,626][root][INFO] - 

[2024-10-17 16:22:45,626][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 16:22:54,281][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,281][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,282][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,282][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,283][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,283][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,283][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,284][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,284][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,285][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,285][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,285][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,286][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,286][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,287][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,287][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,288][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,288][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,288][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,289][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,292][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,292][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,293][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 16:22:54,293][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 16:22:54,295][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 16:22:54,477][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 16:22:56,603][root][INFO] - 

[2024-10-17 16:22:56,603][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 16:22:56,603][root][INFO] - Data Preprocessing
[2024-10-17 16:22:56,603][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 16:22:56,603][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 16:22:56,603][root][INFO] - ㄴ data_remove                True

[2024-10-17 16:22:56,603][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 16:22:56,613][root][INFO] - vocab size              : 51200
[2024-10-17 16:22:56,614][root][INFO] - device                  : gpu
[2024-10-17 16:22:56,614][root][INFO] - random seed             : 1
[2024-10-17 16:22:56,614][root][INFO] - train data size         : 24256
[2024-10-17 16:22:56,614][root][INFO] - max epochs              : 10
[2024-10-17 16:22:56,614][root][INFO] - total steps             : 3790
[2024-10-17 16:22:56,614][root][INFO] - warmup steps            : 379
[2024-10-17 16:22:56,614][root][INFO] - batch size              : 64
[2024-10-17 16:22:56,614][root][INFO] - accumulation steps      : 1
[2024-10-17 16:22:56,614][root][INFO] - optimizer               : adamwscale
[2024-10-17 16:22:56,614][root][INFO] - lr_scheduler            : cosine
[2024-10-17 16:22:56,614][root][INFO] - learning rate           : 0.01
[2024-10-17 16:22:56,614][root][INFO] - max length              : 256

[2024-10-17 16:22:56,615][root][INFO] - LoRA Configuration
[2024-10-17 16:22:56,615][root][INFO] - ㄴ r                    : 32
[2024-10-17 16:22:56,615][root][INFO] - ㄴ alpha                : 128
[2024-10-17 16:22:56,615][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 16:22:56,615][root][INFO] - 

[2024-10-17 16:22:56,615][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:22:56,615][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 16:22:56,615][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb
[2024-10-17 16:22:56,615][root][INFO] - * tb interval   : 10000

[2024-10-17 16:22:56,615][root][INFO] - 

[2024-10-17 16:22:56,615][root][INFO] - Start the Training !
[2024-10-17 16:22:56,618][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 16:29:10,112][root][INFO] - 

[2024-10-17 16:29:10,112][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 16:29:10,112][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:29:10,113][root][INFO] - 

[2024-10-17 16:29:10,113][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 16:29:18,867][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,868][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,868][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,868][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,869][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,869][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,870][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,870][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,871][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,871][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,871][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,872][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,872][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,873][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,873][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,873][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,874][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,874][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,875][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,875][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,878][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,878][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,879][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 16:29:18,879][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 16:29:18,880][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 16:29:19,057][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 16:29:21,003][root][INFO] - 

[2024-10-17 16:29:21,003][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 16:29:21,003][root][INFO] - Data Preprocessing
[2024-10-17 16:29:21,003][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 16:29:21,003][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 16:29:21,003][root][INFO] - ㄴ data_remove                True

[2024-10-17 16:29:21,003][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 16:29:21,011][root][INFO] - vocab size              : 51200
[2024-10-17 16:29:21,012][root][INFO] - device                  : gpu
[2024-10-17 16:29:21,012][root][INFO] - random seed             : 1
[2024-10-17 16:29:21,012][root][INFO] - train data size         : 24256
[2024-10-17 16:29:21,012][root][INFO] - max epochs              : 10
[2024-10-17 16:29:21,012][root][INFO] - total steps             : 3790
[2024-10-17 16:29:21,012][root][INFO] - warmup steps            : 379
[2024-10-17 16:29:21,012][root][INFO] - batch size              : 64
[2024-10-17 16:29:21,012][root][INFO] - accumulation steps      : 1
[2024-10-17 16:29:21,012][root][INFO] - optimizer               : adamwscale
[2024-10-17 16:29:21,012][root][INFO] - lr_scheduler            : cosine
[2024-10-17 16:29:21,013][root][INFO] - learning rate           : 0.01
[2024-10-17 16:29:21,013][root][INFO] - max length              : 256

[2024-10-17 16:29:21,013][root][INFO] - LoRA Configuration
[2024-10-17 16:29:21,013][root][INFO] - ㄴ r                    : 32
[2024-10-17 16:29:21,013][root][INFO] - ㄴ alpha                : 128
[2024-10-17 16:29:21,013][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 16:29:21,013][root][INFO] - 

[2024-10-17 16:29:21,013][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:29:21,013][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 16:29:21,013][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb
[2024-10-17 16:29:21,013][root][INFO] - * tb interval   : 10000

[2024-10-17 16:29:21,013][root][INFO] - 

[2024-10-17 16:29:21,014][root][INFO] - Start the Training !
[2024-10-17 16:29:21,017][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 16:31:40,514][root][INFO] - Step: 379/3790  |  Loss: 0.7029  |  Score: 53.75 [%]  |  Seq Length: 256.0
[2024-10-17 16:31:43,050][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 16:31:43,050][root][INFO] - Score: 60.16 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 16:31:45,554][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 16:31:45,554][root][INFO] - Score: 57.08 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 16:31:45,555][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 16:31:45,556][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 16:34:04,421][root][INFO] - Step: 758/3790  |  Loss: 0.6006  |  Score: 67.44 [%]  |  Seq Length: 256.0
[2024-10-17 16:34:07,056][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 16:34:07,057][root][INFO] - Score: 68.23 [%]  |  Evaluation Time: 2.63 [s]
[2024-10-17 16:34:09,543][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 16:34:09,543][root][INFO] - Score: 63.58 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 16:34:09,544][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 16:34:09,545][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 16:36:28,423][root][INFO] - Step: 1137/3790  |  Loss: 0.5230  |  Score: 74.08 [%]  |  Seq Length: 256.0
[2024-10-17 16:36:31,003][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 16:36:31,003][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 16:36:33,470][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 16:36:33,471][root][INFO] - Score: 64.03 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 16:36:33,472][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 16:36:33,473][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 16:38:52,364][root][INFO] - Step: 1516/3790  |  Loss: 0.4670  |  Score: 77.70 [%]  |  Seq Length: 256.0
[2024-10-17 16:38:54,887][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 16:38:54,888][root][INFO] - Score: 68.33 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:38:57,361][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 16:38:57,361][root][INFO] - Score: 68.09 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 16:38:57,362][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 16:38:57,363][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 16:41:16,142][root][INFO] - Step: 1895/3790  |  Loss: 0.4237  |  Score: 80.24 [%]  |  Seq Length: 256.0
[2024-10-17 16:41:18,669][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 16:41:18,669][root][INFO] - Score: 69.37 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:41:21,137][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 16:41:21,138][root][INFO] - Score: 66.89 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 16:41:21,140][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 16:43:39,915][root][INFO] - Step: 2274/3790  |  Loss: 0.3759  |  Score: 82.97 [%]  |  Seq Length: 256.0
[2024-10-17 16:43:42,451][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 16:43:42,451][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 16:43:44,947][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 16:43:44,947][root][INFO] - Score: 66.24 [%]  |  Evaluation Time: 2.49 [s]
[2024-10-17 16:43:44,948][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 16:43:44,949][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 16:46:03,828][root][INFO] - Step: 2653/3790  |  Loss: 0.3394  |  Score: 84.74 [%]  |  Seq Length: 256.0
[2024-10-17 16:46:06,355][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 16:46:06,355][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:46:08,821][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 16:46:08,821][root][INFO] - Score: 67.15 [%]  |  Evaluation Time: 2.46 [s]
[2024-10-17 16:46:08,822][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 16:46:08,823][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 16:48:27,450][root][INFO] - Step: 3032/3790  |  Loss: 0.3115  |  Score: 86.27 [%]  |  Seq Length: 256.0
[2024-10-17 16:48:29,993][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 16:48:29,993][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 2.54 [s]
[2024-10-17 16:48:32,477][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 16:48:32,477][root][INFO] - Score: 67.47 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 16:48:32,479][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 16:50:51,269][root][INFO] - Step: 3411/3790  |  Loss: 0.2943  |  Score: 87.07 [%]  |  Seq Length: 256.0
[2024-10-17 16:50:53,829][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 16:50:53,829][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 2.56 [s]
[2024-10-17 16:50:56,355][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 16:50:56,356][root][INFO] - Score: 67.24 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:50:56,358][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 16:53:15,149][root][INFO] - Step: 3790/3790  |  Loss: 0.2820  |  Score: 87.75 [%]  |  Seq Length: 256.0
[2024-10-17 16:53:17,673][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 16:53:17,673][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:53:20,199][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 16:53:20,200][root][INFO] - Score: 67.11 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:53:20,201][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 16:53:20,201][root][INFO] - - Epoch: 7
[2024-10-17 16:53:20,201][root][INFO] - - DEV score: 73.05 [%]
[2024-10-17 16:53:20,201][root][INFO] - - TEST score: 67.15 [%]
[2024-10-17 16:53:20,202][root][INFO] - Fine-tuning is done!
[2024-10-17 16:53:27,024][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,024][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,025][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,025][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,025][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,026][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,026][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,027][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,027][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,028][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,028][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,029][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,029][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,029][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,030][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,030][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,031][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,031][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,032][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,032][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,033][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,033][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,034][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 16:53:27,034][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 16:53:27,036][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 16:53:27,037][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 16:53:27,189][root][INFO] - 

[2024-10-17 16:53:27,189][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 16:53:27,190][root][INFO] - Data Preprocessing
[2024-10-17 16:53:27,190][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 16:53:27,190][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 16:53:27,190][root][INFO] - ㄴ data_remove                True

[2024-10-17 16:53:27,190][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 16:53:27,197][root][INFO] - vocab size              : 51200
[2024-10-17 16:53:27,197][root][INFO] - device                  : gpu
[2024-10-17 16:53:27,197][root][INFO] - random seed             : 1
[2024-10-17 16:53:27,197][root][INFO] - train data size         : 24256
[2024-10-17 16:53:27,197][root][INFO] - max epochs              : 10
[2024-10-17 16:53:27,197][root][INFO] - total steps             : 3790
[2024-10-17 16:53:27,197][root][INFO] - warmup steps            : 379
[2024-10-17 16:53:27,197][root][INFO] - batch size              : 64
[2024-10-17 16:53:27,198][root][INFO] - accumulation steps      : 1
[2024-10-17 16:53:27,198][root][INFO] - optimizer               : adamwscale
[2024-10-17 16:53:27,198][root][INFO] - lr_scheduler            : cosine
[2024-10-17 16:53:27,198][root][INFO] - learning rate           : 0.02
[2024-10-17 16:53:27,198][root][INFO] - max length              : 256

[2024-10-17 16:53:27,198][root][INFO] - LoRA Configuration
[2024-10-17 16:53:27,198][root][INFO] - ㄴ r                    : 32
[2024-10-17 16:53:27,198][root][INFO] - ㄴ alpha                : 128
[2024-10-17 16:53:27,198][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 16:53:27,198][root][INFO] - 

[2024-10-17 16:53:27,198][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs
[2024-10-17 16:53:27,198][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 16:53:27,199][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_1rs/tb
[2024-10-17 16:53:27,199][root][INFO] - * tb interval   : 10000

[2024-10-17 16:53:27,199][root][INFO] - 

[2024-10-17 16:53:27,199][root][INFO] - Start the Training !
[2024-10-17 16:53:27,201][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 16:55:46,075][root][INFO] - Step: 379/3790  |  Loss: 0.6819  |  Score: 57.42 [%]  |  Seq Length: 256.0
[2024-10-17 16:55:48,687][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 16:55:48,687][root][INFO] - Score: 65.43 [%]  |  Evaluation Time: 2.61 [s]
[2024-10-17 16:55:51,247][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 16:55:51,247][root][INFO] - Score: 61.00 [%]  |  Evaluation Time: 2.56 [s]
[2024-10-17 16:55:51,248][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 16:55:51,250][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 16:58:10,129][root][INFO] - Step: 758/3790  |  Loss: 0.5792  |  Score: 69.58 [%]  |  Seq Length: 256.0
[2024-10-17 16:58:12,720][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 16:58:12,720][root][INFO] - Score: 67.15 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 16:58:15,246][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 16:58:15,246][root][INFO] - Score: 63.58 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 16:58:15,246][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 16:58:15,248][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:00:34,246][root][INFO] - Step: 1137/3790  |  Loss: 0.5135  |  Score: 74.62 [%]  |  Seq Length: 256.0
[2024-10-17 17:00:36,857][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:00:36,857][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 2.61 [s]
[2024-10-17 17:00:39,394][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:00:39,394][root][INFO] - Score: 65.34 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 17:00:39,395][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 17:00:39,396][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:02:08,639][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,639][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,640][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,640][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,641][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,641][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,642][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,642][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,643][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,643][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,644][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,644][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,645][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,646][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,646][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,647][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,647][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,648][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,648][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,649][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,650][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,650][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,651][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 17:02:08,651][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 17:02:08,653][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 17:02:08,658][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-17 17:02:08,860][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-17 17:02:08,862][root][INFO] - Trainable params: 17254656 || all params: 142420224 || trainable: 12.12 %
[2024-10-17 17:02:09,053][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 17:02:12,158][root][INFO] - 

[2024-10-17 17:02:12,158][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 17:02:12,158][root][INFO] - Data Preprocessing
[2024-10-17 17:02:12,158][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 17:02:12,158][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 17:02:12,158][root][INFO] - ㄴ data_remove                False

[2024-10-17 17:02:12,158][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 17:02:12,166][root][INFO] - vocab size              : 51200
[2024-10-17 17:02:12,166][root][INFO] - device                  : gpu
[2024-10-17 17:02:12,166][root][INFO] - random seed             : 1
[2024-10-17 17:02:12,166][root][INFO] - train data size         : 49152
[2024-10-17 17:02:12,166][root][INFO] - max epochs              : 10
[2024-10-17 17:02:12,166][root][INFO] - total steps             : 7680
[2024-10-17 17:02:12,166][root][INFO] - warmup steps            : 768
[2024-10-17 17:02:12,167][root][INFO] - batch size              : 64
[2024-10-17 17:02:12,167][root][INFO] - accumulation steps      : 1
[2024-10-17 17:02:12,167][root][INFO] - optimizer               : adamwscale
[2024-10-17 17:02:12,167][root][INFO] - lr_scheduler            : cosine
[2024-10-17 17:02:12,167][root][INFO] - learning rate           : 0.01
[2024-10-17 17:02:12,167][root][INFO] - max length              : 256

[2024-10-17 17:02:12,167][root][INFO] - LoRA Configuration
[2024-10-17 17:02:12,167][root][INFO] - ㄴ r                    : 32
[2024-10-17 17:02:12,167][root][INFO] - ㄴ alpha                : 128
[2024-10-17 17:02:12,167][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 17:02:12,167][root][INFO] - KOMBO Configuration
[2024-10-17 17:02:12,168][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-17 17:02:12,168][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-17 17:02:12,168][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-17 17:02:12,168][root][INFO] - ㄴ embedding_norm       : False
[2024-10-17 17:02:12,168][root][INFO] - ㄴ do_combination       : True
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-17 17:02:12,168][root][INFO] -   ㄴ add_lora           : False

[2024-10-17 17:02:12,168][root][INFO] - 

[2024-10-17 17:02:12,169][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs
[2024-10-17 17:02:12,169][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/ckpt
[2024-10-17 17:02:12,169][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/nlu_tasks_lrs/PAWS_X/ko_en_puncdh/256t_64b_1s_1rs/tb
[2024-10-17 17:02:12,169][root][INFO] - * tb interval   : 10000

[2024-10-17 17:02:12,169][root][INFO] - 

[2024-10-17 17:02:12,169][root][INFO] - Start the Training !
[2024-10-17 17:02:12,172][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 17:02:58,378][root][INFO] - Step: 1516/3790  |  Loss: 0.4617  |  Score: 77.90 [%]  |  Seq Length: 256.0
[2024-10-17 17:03:00,945][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:03:00,946][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:03:03,531][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:03:03,532][root][INFO] - Score: 69.59 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 17:03:03,534][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:03:03,536][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:05:22,603][root][INFO] - Step: 1895/3790  |  Loss: 0.4109  |  Score: 81.01 [%]  |  Seq Length: 256.0
[2024-10-17 17:05:25,199][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:05:25,199][root][INFO] - Score: 73.44 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 17:05:27,755][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:05:27,755][root][INFO] - Score: 69.33 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:05:27,756][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:05:27,757][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:07:46,876][root][INFO] - Step: 2274/3790  |  Loss: 0.3518  |  Score: 83.90 [%]  |  Seq Length: 256.0
[2024-10-17 17:07:49,506][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:07:49,506][root][INFO] - Score: 73.93 [%]  |  Evaluation Time: 2.63 [s]
[2024-10-17 17:07:52,088][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:07:52,089][root][INFO] - Score: 69.44 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 17:07:52,091][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:07:52,093][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:09:42,107][root][INFO] - Step: 768/7680  |  Loss: 0.6529  |  Score: 60.43 [%]  |  Seq Length: 256.0
[2024-10-17 17:09:51,270][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 17:09:51,270][root][INFO] - Score: 68.76 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-17 17:10:00,208][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 17:10:00,208][root][INFO] - Score: 65.64 [%]  |  Evaluation Time: 8.94 [s]
[2024-10-17 17:10:00,209][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 17:10:00,211][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 17:10:11,182][root][INFO] - Step: 2653/3790  |  Loss: 0.3040  |  Score: 86.50 [%]  |  Seq Length: 256.0
[2024-10-17 17:10:13,779][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 17:10:13,780][root][INFO] - Score: 74.02 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 17:10:16,330][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 17:10:16,331][root][INFO] - Score: 68.95 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:10:16,333][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 17:12:35,739][root][INFO] - Step: 3032/3790  |  Loss: 0.2500  |  Score: 88.91 [%]  |  Seq Length: 256.0
[2024-10-17 17:12:38,383][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 17:12:38,384][root][INFO] - Score: 72.72 [%]  |  Evaluation Time: 2.64 [s]
[2024-10-17 17:12:40,955][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 17:12:40,956][root][INFO] - Score: 69.52 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:12:40,958][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 17:15:00,568][root][INFO] - Step: 3411/3790  |  Loss: 0.2193  |  Score: 90.55 [%]  |  Seq Length: 256.0
[2024-10-17 17:15:03,254][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 17:15:03,254][root][INFO] - Score: 75.78 [%]  |  Evaluation Time: 2.68 [s]
[2024-10-17 17:15:05,855][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 17:15:05,856][root][INFO] - Score: 70.43 [%]  |  Evaluation Time: 2.60 [s]
[2024-10-17 17:15:05,858][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 17:15:05,861][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 17:17:25,565][root][INFO] - Step: 3790/3790  |  Loss: 0.2008  |  Score: 91.39 [%]  |  Seq Length: 256.0
[2024-10-17 17:17:26,425][root][INFO] - Step: 1536/7680  |  Loss: 0.5336  |  Score: 73.19 [%]  |  Seq Length: 256.0
[2024-10-17 17:17:28,241][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 17:17:28,241][root][INFO] - Score: 73.70 [%]  |  Evaluation Time: 2.67 [s]
[2024-10-17 17:17:30,841][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 17:17:30,841][root][INFO] - Score: 69.76 [%]  |  Evaluation Time: 2.60 [s]
[2024-10-17 17:17:30,842][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 17:17:30,842][root][INFO] - - Epoch: 9
[2024-10-17 17:17:30,843][root][INFO] - - DEV score: 75.78 [%]
[2024-10-17 17:17:30,843][root][INFO] - - TEST score: 70.43 [%]
[2024-10-17 17:17:30,845][root][INFO] - Fine-tuning is done!
[2024-10-17 17:17:30,845][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-17 17:17:30,845][root][INFO] - - BEST LR: 0.02
[2024-10-17 17:17:30,845][root][INFO] - - DEV score: 75.78 [%]
[2024-10-17 17:17:30,845][root][INFO] - - TEST score: 70.43 [%]
[2024-10-17 17:17:35,462][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 17:17:35,463][root][INFO] - Score: 70.12 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-17 17:17:36,656][root][INFO] - 

[2024-10-17 17:17:36,656][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 17:17:36,656][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs
[2024-10-17 17:17:36,656][root][INFO] - 

[2024-10-17 17:17:36,656][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': True, 'data_remove': True, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 17:17:44,433][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 17:17:44,433][root][INFO] - Score: 67.71 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-17 17:17:44,434][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 17:17:44,435][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:17:45,623][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,624][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,624][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,624][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,625][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,625][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,626][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,626][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,627][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,627][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,627][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,628][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,628][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,629][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,629][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,629][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,630][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,630][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,631][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,631][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,632][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,633][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,633][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 17:17:45,633][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 17:17:45,635][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 17:17:45,807][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 17:17:47,706][root][INFO] - 

[2024-10-17 17:17:47,706][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 17:17:47,706][root][INFO] - Data Preprocessing
[2024-10-17 17:17:47,706][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 17:17:47,707][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 17:17:47,707][root][INFO] - ㄴ data_remove                True

[2024-10-17 17:17:47,707][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 17:17:47,714][root][INFO] - vocab size              : 51200
[2024-10-17 17:17:47,715][root][INFO] - device                  : gpu
[2024-10-17 17:17:47,715][root][INFO] - random seed             : 2
[2024-10-17 17:17:47,715][root][INFO] - train data size         : 24256
[2024-10-17 17:17:47,715][root][INFO] - max epochs              : 10
[2024-10-17 17:17:47,715][root][INFO] - total steps             : 3790
[2024-10-17 17:17:47,715][root][INFO] - warmup steps            : 379
[2024-10-17 17:17:47,715][root][INFO] - batch size              : 64
[2024-10-17 17:17:47,715][root][INFO] - accumulation steps      : 1
[2024-10-17 17:17:47,715][root][INFO] - optimizer               : adamwscale
[2024-10-17 17:17:47,715][root][INFO] - lr_scheduler            : cosine
[2024-10-17 17:17:47,715][root][INFO] - learning rate           : 0.01
[2024-10-17 17:17:47,715][root][INFO] - max length              : 256

[2024-10-17 17:17:47,716][root][INFO] - LoRA Configuration
[2024-10-17 17:17:47,716][root][INFO] - ㄴ r                    : 32
[2024-10-17 17:17:47,716][root][INFO] - ㄴ alpha                : 128
[2024-10-17 17:17:47,716][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 17:17:47,716][root][INFO] - 

[2024-10-17 17:17:47,716][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs
[2024-10-17 17:17:47,716][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/ckpt
[2024-10-17 17:17:47,716][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/tb
[2024-10-17 17:17:47,716][root][INFO] - * tb interval   : 10000

[2024-10-17 17:17:47,716][root][INFO] - 

[2024-10-17 17:17:47,716][root][INFO] - Start the Training !
[2024-10-17 17:17:47,719][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 17:20:07,859][root][INFO] - Step: 379/3790  |  Loss: 0.6762  |  Score: 57.66 [%]  |  Seq Length: 256.0
[2024-10-17 17:20:10,409][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 17:20:10,409][root][INFO] - Score: 61.91 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:20:12,852][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 17:20:12,852][root][INFO] - Score: 58.93 [%]  |  Evaluation Time: 2.44 [s]
[2024-10-17 17:20:12,853][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 17:20:12,854][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 17:22:32,207][root][INFO] - Step: 758/3790  |  Loss: 0.5810  |  Score: 69.58 [%]  |  Seq Length: 256.0
[2024-10-17 17:22:34,726][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 17:22:34,726][root][INFO] - Score: 68.23 [%]  |  Evaluation Time: 2.52 [s]
[2024-10-17 17:22:37,180][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 17:22:37,181][root][INFO] - Score: 64.32 [%]  |  Evaluation Time: 2.45 [s]
[2024-10-17 17:22:37,182][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 17:22:37,183][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:24:56,134][root][INFO] - Step: 1137/3790  |  Loss: 0.5150  |  Score: 74.66 [%]  |  Seq Length: 256.0
[2024-10-17 17:24:58,648][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:24:58,648][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 2.51 [s]
[2024-10-17 17:25:01,084][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:25:01,084][root][INFO] - Score: 64.35 [%]  |  Evaluation Time: 2.43 [s]
[2024-10-17 17:25:01,085][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 17:25:01,086][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:25:12,920][root][INFO] - Step: 2304/7680  |  Loss: 0.4719  |  Score: 77.19 [%]  |  Seq Length: 256.0
[2024-10-17 17:25:21,981][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:25:21,982][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-17 17:25:31,032][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:25:31,032][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-17 17:25:31,033][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 17:25:31,035][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:27:19,771][root][INFO] - Step: 1516/3790  |  Loss: 0.4594  |  Score: 78.18 [%]  |  Seq Length: 256.0
[2024-10-17 17:27:22,277][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:27:22,278][root][INFO] - Score: 69.92 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:27:24,746][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:27:24,746][root][INFO] - Score: 66.44 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 17:27:24,747][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:27:24,748][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:29:43,343][root][INFO] - Step: 1895/3790  |  Loss: 0.4093  |  Score: 80.92 [%]  |  Seq Length: 256.0
[2024-10-17 17:29:45,901][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:29:45,901][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 2.55 [s]
[2024-10-17 17:29:48,377][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:29:48,378][root][INFO] - Score: 66.95 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 17:29:48,379][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:29:48,380][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:32:07,751][root][INFO] - Step: 2274/3790  |  Loss: 0.3701  |  Score: 83.06 [%]  |  Seq Length: 256.0
[2024-10-17 17:32:10,257][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:32:10,257][root][INFO] - Score: 71.97 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:32:12,713][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:32:12,713][root][INFO] - Score: 67.13 [%]  |  Evaluation Time: 2.45 [s]
[2024-10-17 17:32:12,715][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:32:12,716][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:32:58,908][root][INFO] - Step: 3072/7680  |  Loss: 0.4236  |  Score: 79.95 [%]  |  Seq Length: 256.0
[2024-10-17 17:33:07,908][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:33:07,908][root][INFO] - Score: 73.43 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-17 17:33:16,953][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:33:16,953][root][INFO] - Score: 70.65 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-17 17:33:16,954][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:33:16,956][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:34:31,311][root][INFO] - Step: 2653/3790  |  Loss: 0.3335  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-17 17:34:33,848][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 17:34:33,848][root][INFO] - Score: 69.11 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 17:34:36,305][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 17:34:36,305][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 2.45 [s]
[2024-10-17 17:34:36,307][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 17:36:55,130][root][INFO] - Step: 3032/3790  |  Loss: 0.3051  |  Score: 86.55 [%]  |  Seq Length: 256.0
[2024-10-17 17:36:57,617][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-17 17:36:57,617][root][INFO] - Score: 70.28 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 17:37:00,091][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-17 17:37:00,091][root][INFO] - Score: 68.13 [%]  |  Evaluation Time: 2.47 [s]
[2024-10-17 17:37:00,093][root][INFO] - 
[9/ 10 Epoch]
[2024-10-17 17:39:18,852][root][INFO] - Step: 3411/3790  |  Loss: 0.2800  |  Score: 87.68 [%]  |  Seq Length: 256.0
[2024-10-17 17:39:21,337][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-17 17:39:21,337][root][INFO] - Score: 70.57 [%]  |  Evaluation Time: 2.48 [s]
[2024-10-17 17:39:23,781][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-17 17:39:23,781][root][INFO] - Score: 69.27 [%]  |  Evaluation Time: 2.44 [s]
[2024-10-17 17:39:23,782][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-17 17:39:23,783][root][INFO] - 
[10/ 10 Epoch]
[2024-10-17 17:40:45,172][root][INFO] - Step: 3840/7680  |  Loss: 0.3822  |  Score: 82.26 [%]  |  Seq Length: 256.0
[2024-10-17 17:40:54,193][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:40:54,193][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-17 17:41:03,170][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:41:03,171][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-17 17:41:03,171][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:41:03,173][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:41:42,645][root][INFO] - Step: 3790/3790  |  Loss: 0.2717  |  Score: 88.04 [%]  |  Seq Length: 256.0
[2024-10-17 17:41:45,152][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-17 17:41:45,152][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:41:47,592][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-17 17:41:47,592][root][INFO] - Score: 68.90 [%]  |  Evaluation Time: 2.44 [s]
[2024-10-17 17:41:47,593][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-17 17:41:47,593][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-17 17:41:47,593][root][INFO] - - Epoch: 10
[2024-10-17 17:41:47,593][root][INFO] - - DEV score: 72.46 [%]
[2024-10-17 17:41:47,593][root][INFO] - - TEST score: 68.90 [%]
[2024-10-17 17:41:47,594][root][INFO] - Fine-tuning is done!
[2024-10-17 17:41:54,355][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,356][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,356][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,357][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,357][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,358][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,358][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,359][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,359][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,360][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,360][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,361][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,361][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,362][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,362][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,363][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,364][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,364][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,364][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,365][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,366][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,366][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,367][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 17:41:54,367][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 17:41:54,369][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-17 17:41:54,370][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 17:41:54,527][root][INFO] - 

[2024-10-17 17:41:54,527][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-17 17:41:54,528][root][INFO] - Data Preprocessing
[2024-10-17 17:41:54,528][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 17:41:54,528][root][INFO] - ㄴ do_hangeulize              True
[2024-10-17 17:41:54,528][root][INFO] - ㄴ data_remove                True

[2024-10-17 17:41:54,528][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 17:41:54,535][root][INFO] - vocab size              : 51200
[2024-10-17 17:41:54,535][root][INFO] - device                  : gpu
[2024-10-17 17:41:54,535][root][INFO] - random seed             : 2
[2024-10-17 17:41:54,536][root][INFO] - train data size         : 24256
[2024-10-17 17:41:54,536][root][INFO] - max epochs              : 10
[2024-10-17 17:41:54,536][root][INFO] - total steps             : 3790
[2024-10-17 17:41:54,536][root][INFO] - warmup steps            : 379
[2024-10-17 17:41:54,536][root][INFO] - batch size              : 64
[2024-10-17 17:41:54,536][root][INFO] - accumulation steps      : 1
[2024-10-17 17:41:54,536][root][INFO] - optimizer               : adamwscale
[2024-10-17 17:41:54,536][root][INFO] - lr_scheduler            : cosine
[2024-10-17 17:41:54,536][root][INFO] - learning rate           : 0.02
[2024-10-17 17:41:54,536][root][INFO] - max length              : 256

[2024-10-17 17:41:54,536][root][INFO] - LoRA Configuration
[2024-10-17 17:41:54,537][root][INFO] - ㄴ r                    : 32
[2024-10-17 17:41:54,537][root][INFO] - ㄴ alpha                : 128
[2024-10-17 17:41:54,537][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 17:41:54,537][root][INFO] - 

[2024-10-17 17:41:54,537][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs
[2024-10-17 17:41:54,537][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/ckpt
[2024-10-17 17:41:54,537][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/PAWS_X/ko_en_punc_dh_dr/256t_64b_1s_2rs/tb
[2024-10-17 17:41:54,537][root][INFO] - * tb interval   : 10000

[2024-10-17 17:41:54,537][root][INFO] - 

[2024-10-17 17:41:54,537][root][INFO] - Start the Training !
[2024-10-17 17:41:54,539][root][INFO] - 
[1/ 10 Epoch]
[2024-10-17 17:44:13,394][root][INFO] - Step: 379/3790  |  Loss: 0.6682  |  Score: 59.30 [%]  |  Seq Length: 256.0
[2024-10-17 17:44:15,934][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 17:44:15,934][root][INFO] - Score: 60.61 [%]  |  Evaluation Time: 2.54 [s]
[2024-10-17 17:44:18,427][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 17:44:18,427][root][INFO] - Score: 60.66 [%]  |  Evaluation Time: 2.49 [s]
[2024-10-17 17:44:18,428][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 17:44:18,429][root][INFO] - 
[2/ 10 Epoch]
[2024-10-17 17:46:37,838][root][INFO] - Step: 758/3790  |  Loss: 0.5719  |  Score: 70.28 [%]  |  Seq Length: 256.0
[2024-10-17 17:46:40,407][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 17:46:40,408][root][INFO] - Score: 67.94 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:46:42,906][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 17:46:42,906][root][INFO] - Score: 65.30 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:46:42,907][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 17:46:42,908][root][INFO] - 
[3/ 10 Epoch]
[2024-10-17 17:48:30,881][root][INFO] - Step: 4608/7680  |  Loss: 0.3455  |  Score: 84.17 [%]  |  Seq Length: 256.0
[2024-10-17 17:48:39,923][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:48:39,923][root][INFO] - Score: 73.15 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-17 17:48:48,909][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:48:48,909][root][INFO] - Score: 71.54 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-17 17:48:48,910][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:48:48,912][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:49:02,768][root][INFO] - Step: 1137/3790  |  Loss: 0.5114  |  Score: 74.53 [%]  |  Seq Length: 256.0
[2024-10-17 17:49:05,342][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 17:49:05,342][root][INFO] - Score: 66.93 [%]  |  Evaluation Time: 2.57 [s]
[2024-10-17 17:49:07,859][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 17:49:07,859][root][INFO] - Score: 63.97 [%]  |  Evaluation Time: 2.51 [s]
[2024-10-17 17:49:07,861][root][INFO] - 
[4/ 10 Epoch]
[2024-10-17 17:51:26,922][root][INFO] - Step: 1516/3790  |  Loss: 0.4578  |  Score: 78.19 [%]  |  Seq Length: 256.0
[2024-10-17 17:51:29,502][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 17:51:29,502][root][INFO] - Score: 67.81 [%]  |  Evaluation Time: 2.58 [s]
[2024-10-17 17:51:32,038][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 17:51:32,038][root][INFO] - Score: 67.42 [%]  |  Evaluation Time: 2.53 [s]
[2024-10-17 17:51:32,040][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 17:51:32,041][root][INFO] - 
[5/ 10 Epoch]
[2024-10-17 17:53:50,829][root][INFO] - Step: 1895/3790  |  Loss: 0.3992  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-17 17:53:53,429][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-17 17:53:53,429][root][INFO] - Score: 70.38 [%]  |  Evaluation Time: 2.60 [s]
[2024-10-17 17:53:55,933][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-17 17:53:55,933][root][INFO] - Score: 67.94 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:53:55,934][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-17 17:53:55,935][root][INFO] - 
[6/ 10 Epoch]
[2024-10-17 17:56:14,753][root][INFO] - Step: 2274/3790  |  Loss: 0.3456  |  Score: 84.28 [%]  |  Seq Length: 256.0
[2024-10-17 17:56:17,343][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-17 17:56:17,343][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 2.59 [s]
[2024-10-17 17:56:17,746][root][INFO] - Step: 5376/7680  |  Loss: 0.3096  |  Score: 85.98 [%]  |  Seq Length: 256.0
[2024-10-17 17:56:19,845][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-17 17:56:19,845][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 2.50 [s]
[2024-10-17 17:56:19,847][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-17 17:56:19,848][root][INFO] - 
[7/ 10 Epoch]
[2024-10-17 17:56:27,054][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-17 17:56:27,054][root][INFO] - Score: 74.28 [%]  |  Evaluation Time: 9.30 [s]
[2024-10-17 17:56:36,055][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-17 17:56:36,055][root][INFO] - Score: 71.55 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-17 17:56:36,056][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-17 17:56:36,057][root][INFO] - 
[8/ 10 Epoch]
[2024-10-17 18:00:27,601][root][INFO] - 

[2024-10-17 18:00:27,601][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 18:00:27,602][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-17 18:00:27,602][root][INFO] - 

[2024-10-17 18:00:27,602][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 18:00:39,080][root][INFO] - 

[2024-10-17 18:00:39,081][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-17 18:00:39,081][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-17 18:00:39,081][root][INFO] - 

[2024-10-17 18:00:39,082][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-17 18:02:48,671][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,672][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,672][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,672][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,673][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,673][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,674][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,674][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,675][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,675][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,675][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,676][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,676][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,677][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,677][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,678][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,678][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,678][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,679][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,679][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,680][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,680][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,681][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 18:02:48,681][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 18:02:48,683][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-17 18:02:48,911][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 18:02:50,809][root][INFO] - 

[2024-10-17 18:02:50,809][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-17 18:02:50,809][root][INFO] - Data Preprocessing
[2024-10-17 18:02:50,809][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 18:02:50,809][root][INFO] - ㄴ do_hangeulize              False
[2024-10-17 18:02:50,810][root][INFO] - ㄴ data_remove                True

[2024-10-17 18:02:50,810][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 18:02:50,817][root][INFO] - vocab size              : 51200
[2024-10-17 18:02:50,818][root][INFO] - device                  : gpu
[2024-10-17 18:02:50,818][root][INFO] - random seed             : 1
[2024-10-17 18:02:50,818][root][INFO] - train data size         : 845696
[2024-10-17 18:02:50,818][root][INFO] - max epochs              : 5
[2024-10-17 18:02:50,818][root][INFO] - total steps             : 66070
[2024-10-17 18:02:50,818][root][INFO] - warmup steps            : 6607
[2024-10-17 18:02:50,818][root][INFO] - batch size              : 64
[2024-10-17 18:02:50,818][root][INFO] - accumulation steps      : 1
[2024-10-17 18:02:50,818][root][INFO] - optimizer               : adamwscale
[2024-10-17 18:02:50,818][root][INFO] - lr_scheduler            : cosine
[2024-10-17 18:02:50,819][root][INFO] - learning rate           : 0.01
[2024-10-17 18:02:50,819][root][INFO] - max length              : 256

[2024-10-17 18:02:50,819][root][INFO] - LoRA Configuration
[2024-10-17 18:02:50,819][root][INFO] - ㄴ r                    : 32
[2024-10-17 18:02:50,819][root][INFO] - ㄴ alpha                : 128
[2024-10-17 18:02:50,819][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 18:02:50,819][root][INFO] - 

[2024-10-17 18:02:50,819][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-17 18:02:50,819][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-17 18:02:50,819][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-17 18:02:50,819][root][INFO] - * tb interval   : 10000

[2024-10-17 18:02:50,820][root][INFO] - 

[2024-10-17 18:02:50,820][root][INFO] - Start the Training !
[2024-10-17 18:02:50,822][root][INFO] - 
[1/ 5 Epoch]
[2024-10-17 18:03:04,858][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,859][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,859][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,860][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,860][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,861][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,861][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,862][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,863][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,863][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,864][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,864][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,865][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,865][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,866][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,866][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,867][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,868][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,868][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,869][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,869][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,870][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,871][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-17 18:03:04,871][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-17 18:03:04,873][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-17 18:03:05,116][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-17 18:03:07,052][root][INFO] - 

[2024-10-17 18:03:07,053][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-17 18:03:07,053][root][INFO] - Data Preprocessing
[2024-10-17 18:03:07,053][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-17 18:03:07,053][root][INFO] - ㄴ do_hangeulize              False
[2024-10-17 18:03:07,053][root][INFO] - ㄴ data_remove                False

[2024-10-17 18:03:07,053][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-17 18:03:07,061][root][INFO] - vocab size              : 51200
[2024-10-17 18:03:07,061][root][INFO] - device                  : gpu
[2024-10-17 18:03:07,061][root][INFO] - random seed             : 1
[2024-10-17 18:03:07,061][root][INFO] - train data size         : 942912
[2024-10-17 18:03:07,061][root][INFO] - max epochs              : 5
[2024-10-17 18:03:07,061][root][INFO] - total steps             : 73665
[2024-10-17 18:03:07,061][root][INFO] - warmup steps            : 7366
[2024-10-17 18:03:07,061][root][INFO] - batch size              : 64
[2024-10-17 18:03:07,061][root][INFO] - accumulation steps      : 1
[2024-10-17 18:03:07,062][root][INFO] - optimizer               : adamwscale
[2024-10-17 18:03:07,062][root][INFO] - lr_scheduler            : cosine
[2024-10-17 18:03:07,062][root][INFO] - learning rate           : 0.01
[2024-10-17 18:03:07,062][root][INFO] - max length              : 256

[2024-10-17 18:03:07,062][root][INFO] - LoRA Configuration
[2024-10-17 18:03:07,062][root][INFO] - ㄴ r                    : 32
[2024-10-17 18:03:07,062][root][INFO] - ㄴ alpha                : 128
[2024-10-17 18:03:07,062][root][INFO] - ㄴ dropout              : 0.03

[2024-10-17 18:03:07,062][root][INFO] - 

[2024-10-17 18:03:07,062][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-17 18:03:07,062][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-17 18:03:07,062][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-17 18:03:07,063][root][INFO] - * tb interval   : 10000

[2024-10-17 18:03:07,063][root][INFO] - 

[2024-10-17 18:03:07,063][root][INFO] - Start the Training !
[2024-10-17 18:03:07,066][root][INFO] - 
[1/ 5 Epoch]
[2024-10-17 19:04:13,467][root][INFO] - Step: 10000/73665  |  Loss: 0.7315  |  Score: 68.32 [%]  |  Seq Length: 256.0
[2024-10-17 19:04:22,254][root][INFO] - Step: 10000/66070  |  Loss: 0.7213  |  Score: 68.88 [%]  |  Seq Length: 256.0
[2024-10-17 19:24:09,049][root][INFO] - Step: 13214/66070  |  Loss: 0.6525  |  Score: 72.69 [%]  |  Seq Length: 256.0
[2024-10-17 19:24:13,937][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 19:24:13,938][root][INFO] - Score: 70.66 [%]  |  Evaluation Time: 4.89 [s]
[2024-10-17 19:24:22,997][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 19:24:22,997][root][INFO] - Score: 70.93 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-17 19:24:22,998][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 19:24:22,999][root][INFO] - 
[2/ 5 Epoch]
[2024-10-17 19:33:09,056][root][INFO] - Step: 14733/73665  |  Loss: 0.6617  |  Score: 72.26 [%]  |  Seq Length: 256.0
[2024-10-17 19:33:15,161][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-17 19:33:15,161][root][INFO] - Score: 71.49 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-17 19:33:26,938][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-17 19:33:26,939][root][INFO] - Score: 73.01 [%]  |  Evaluation Time: 11.77 [s]
[2024-10-17 19:33:26,940][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-17 19:33:26,941][root][INFO] - 
[2/ 5 Epoch]
[2024-10-17 20:05:39,283][root][INFO] - Step: 20000/73665  |  Loss: 0.6365  |  Score: 73.57 [%]  |  Seq Length: 256.0
[2024-10-17 20:06:10,603][root][INFO] - Step: 20000/66070  |  Loss: 0.6259  |  Score: 74.08 [%]  |  Seq Length: 256.0
[2024-10-17 20:45:45,711][root][INFO] - Step: 26428/66070  |  Loss: 0.6189  |  Score: 74.44 [%]  |  Seq Length: 256.0
[2024-10-17 20:45:50,600][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 20:45:50,601][root][INFO] - Score: 71.96 [%]  |  Evaluation Time: 4.89 [s]
[2024-10-17 20:45:59,774][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 20:45:59,774][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-17 20:45:59,775][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 20:45:59,776][root][INFO] - 
[3/ 5 Epoch]
[2024-10-17 21:03:33,252][root][INFO] - Step: 29466/73665  |  Loss: 0.6283  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-17 21:03:39,358][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-17 21:03:39,359][root][INFO] - Score: 72.30 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-17 21:03:51,075][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-17 21:03:51,075][root][INFO] - Score: 73.57 [%]  |  Evaluation Time: 11.71 [s]
[2024-10-17 21:03:51,076][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-17 21:03:51,077][root][INFO] - 
[3/ 5 Epoch]
[2024-10-17 21:07:07,401][root][INFO] - Step: 30000/73665  |  Loss: 0.5979  |  Score: 75.57 [%]  |  Seq Length: 256.0
[2024-10-17 21:08:00,477][root][INFO] - Step: 30000/66070  |  Loss: 0.5910  |  Score: 75.75 [%]  |  Seq Length: 256.0
[2024-10-17 22:07:15,546][root][INFO] - Step: 39642/66070  |  Loss: 0.5808  |  Score: 76.24 [%]  |  Seq Length: 256.0
[2024-10-17 22:07:20,410][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 22:07:20,411][root][INFO] - Score: 73.16 [%]  |  Evaluation Time: 4.86 [s]
[2024-10-17 22:07:29,458][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 22:07:29,458][root][INFO] - Score: 73.95 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-17 22:07:29,459][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 22:07:29,460][root][INFO] - 
[4/ 5 Epoch]
[2024-10-17 22:08:14,766][root][INFO] - Step: 40000/73665  |  Loss: 0.5976  |  Score: 75.48 [%]  |  Seq Length: 256.0
[2024-10-17 22:09:42,019][root][INFO] - Step: 40000/66070  |  Loss: 0.5465  |  Score: 77.66 [%]  |  Seq Length: 256.0
[2024-10-17 22:33:54,478][root][INFO] - Step: 44199/73665  |  Loss: 0.5852  |  Score: 75.95 [%]  |  Seq Length: 256.0
[2024-10-17 22:34:00,579][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-17 22:34:00,579][root][INFO] - Score: 73.68 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-17 22:34:12,385][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-17 22:34:12,385][root][INFO] - Score: 75.01 [%]  |  Evaluation Time: 11.80 [s]
[2024-10-17 22:34:12,386][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-17 22:34:12,388][root][INFO] - 
[4/ 5 Epoch]
[2024-10-17 23:09:39,607][root][INFO] - Step: 50000/73665  |  Loss: 0.5525  |  Score: 77.53 [%]  |  Seq Length: 256.0
[2024-10-17 23:11:10,287][root][INFO] - Step: 50000/66070  |  Loss: 0.5364  |  Score: 78.40 [%]  |  Seq Length: 256.0
[2024-10-17 23:28:42,970][root][INFO] - Step: 52856/66070  |  Loss: 0.5261  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-17 23:28:47,806][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-17 23:28:47,807][root][INFO] - Score: 74.76 [%]  |  Evaluation Time: 4.83 [s]
[2024-10-17 23:28:56,850][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-17 23:28:56,851][root][INFO] - Score: 75.42 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-17 23:28:56,852][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-17 23:28:56,853][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 00:04:14,695][root][INFO] - Step: 58932/73665  |  Loss: 0.5409  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-18 00:04:20,815][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 00:04:20,815][root][INFO] - Score: 75.52 [%]  |  Evaluation Time: 6.12 [s]
[2024-10-18 00:04:32,581][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 00:04:32,581][root][INFO] - Score: 76.29 [%]  |  Evaluation Time: 11.76 [s]
[2024-10-18 00:04:32,582][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 00:04:32,583][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 00:11:04,845][root][INFO] - Step: 60000/73665  |  Loss: 0.5099  |  Score: 79.35 [%]  |  Seq Length: 256.0
[2024-10-18 00:12:50,865][root][INFO] - Step: 60000/66070  |  Loss: 0.4990  |  Score: 80.08 [%]  |  Seq Length: 256.0
[2024-10-18 00:50:11,419][root][INFO] - Step: 66070/66070  |  Loss: 0.4948  |  Score: 80.21 [%]  |  Seq Length: 256.0
[2024-10-18 00:50:16,269][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 00:50:16,269][root][INFO] - Score: 75.13 [%]  |  Evaluation Time: 4.85 [s]
[2024-10-18 00:50:25,312][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 00:50:25,312][root][INFO] - Score: 75.64 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-18 00:50:25,313][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 00:50:25,313][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 00:50:25,313][root][INFO] - - Epoch: 5
[2024-10-18 00:50:25,314][root][INFO] - - DEV score: 75.13 [%]
[2024-10-18 00:50:25,314][root][INFO] - - TEST score: 75.64 [%]
[2024-10-18 00:50:25,314][root][INFO] - Fine-tuning is done!
[2024-10-18 00:52:05,008][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,008][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,009][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,009][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,010][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,011][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,011][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,012][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,012][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,013][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,013][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,014][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,014][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,015][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,015][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,016][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,016][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,016][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,017][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,017][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,018][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,019][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,019][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 00:52:05,020][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 00:52:05,022][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 00:52:05,023][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 00:52:05,191][root][INFO] - 

[2024-10-18 00:52:05,192][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 00:52:05,192][root][INFO] - Data Preprocessing
[2024-10-18 00:52:05,192][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 00:52:05,192][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 00:52:05,192][root][INFO] - ㄴ data_remove                True

[2024-10-18 00:52:05,192][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 00:52:05,203][root][INFO] - vocab size              : 51200
[2024-10-18 00:52:05,204][root][INFO] - device                  : gpu
[2024-10-18 00:52:05,204][root][INFO] - random seed             : 1
[2024-10-18 00:52:05,205][root][INFO] - train data size         : 845696
[2024-10-18 00:52:05,205][root][INFO] - max epochs              : 5
[2024-10-18 00:52:05,205][root][INFO] - total steps             : 66070
[2024-10-18 00:52:05,205][root][INFO] - warmup steps            : 6607
[2024-10-18 00:52:05,205][root][INFO] - batch size              : 64
[2024-10-18 00:52:05,205][root][INFO] - accumulation steps      : 1
[2024-10-18 00:52:05,205][root][INFO] - optimizer               : adamwscale
[2024-10-18 00:52:05,205][root][INFO] - lr_scheduler            : cosine
[2024-10-18 00:52:05,205][root][INFO] - learning rate           : 0.02
[2024-10-18 00:52:05,205][root][INFO] - max length              : 256

[2024-10-18 00:52:05,205][root][INFO] - LoRA Configuration
[2024-10-18 00:52:05,205][root][INFO] - ㄴ r                    : 32
[2024-10-18 00:52:05,205][root][INFO] - ㄴ alpha                : 128
[2024-10-18 00:52:05,206][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 00:52:05,206][root][INFO] - 

[2024-10-18 00:52:05,206][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 00:52:05,206][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 00:52:05,206][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 00:52:05,206][root][INFO] - * tb interval   : 10000

[2024-10-18 00:52:05,206][root][INFO] - 

[2024-10-18 00:52:05,206][root][INFO] - Start the Training !
[2024-10-18 00:52:05,208][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 01:12:11,841][root][INFO] - Step: 70000/73665  |  Loss: 0.5071  |  Score: 79.69 [%]  |  Seq Length: 256.0
[2024-10-18 01:34:35,373][root][INFO] - Step: 73665/73665  |  Loss: 0.5052  |  Score: 79.80 [%]  |  Seq Length: 256.0
[2024-10-18 01:34:41,534][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 01:34:41,534][root][INFO] - Score: 75.90 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-18 01:34:53,338][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 01:34:53,339][root][INFO] - Score: 76.35 [%]  |  Evaluation Time: 11.80 [s]
[2024-10-18 01:34:53,340][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 01:34:53,340][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 01:34:53,340][root][INFO] - - Epoch: 5
[2024-10-18 01:34:53,340][root][INFO] - - DEV score: 75.90 [%]
[2024-10-18 01:34:53,340][root][INFO] - - TEST score: 76.35 [%]
[2024-10-18 01:34:53,341][root][INFO] - Fine-tuning is done!
[2024-10-18 01:36:52,707][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,708][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,709][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,709][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,710][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,710][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,711][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,712][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,713][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,714][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,714][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,715][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,716][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,716][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,717][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,717][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,718][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,718][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,719][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,719][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,720][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,721][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,721][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 01:36:52,722][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 01:36:52,724][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 01:36:52,726][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 01:36:52,897][root][INFO] - 

[2024-10-18 01:36:52,897][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 01:36:52,897][root][INFO] - Data Preprocessing
[2024-10-18 01:36:52,897][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 01:36:52,897][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 01:36:52,897][root][INFO] - ㄴ data_remove                False

[2024-10-18 01:36:52,897][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 01:36:52,908][root][INFO] - vocab size              : 51200
[2024-10-18 01:36:52,909][root][INFO] - device                  : gpu
[2024-10-18 01:36:52,910][root][INFO] - random seed             : 1
[2024-10-18 01:36:52,910][root][INFO] - train data size         : 942912
[2024-10-18 01:36:52,910][root][INFO] - max epochs              : 5
[2024-10-18 01:36:52,910][root][INFO] - total steps             : 73665
[2024-10-18 01:36:52,910][root][INFO] - warmup steps            : 7366
[2024-10-18 01:36:52,910][root][INFO] - batch size              : 64
[2024-10-18 01:36:52,910][root][INFO] - accumulation steps      : 1
[2024-10-18 01:36:52,910][root][INFO] - optimizer               : adamwscale
[2024-10-18 01:36:52,910][root][INFO] - lr_scheduler            : cosine
[2024-10-18 01:36:52,910][root][INFO] - learning rate           : 0.02
[2024-10-18 01:36:52,910][root][INFO] - max length              : 256

[2024-10-18 01:36:52,910][root][INFO] - LoRA Configuration
[2024-10-18 01:36:52,911][root][INFO] - ㄴ r                    : 32
[2024-10-18 01:36:52,911][root][INFO] - ㄴ alpha                : 128
[2024-10-18 01:36:52,911][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 01:36:52,911][root][INFO] - 

[2024-10-18 01:36:52,911][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 01:36:52,911][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-18 01:36:52,911][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-18 01:36:52,911][root][INFO] - * tb interval   : 10000

[2024-10-18 01:36:52,911][root][INFO] - 

[2024-10-18 01:36:52,911][root][INFO] - Start the Training !
[2024-10-18 01:36:52,913][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 01:53:34,154][root][INFO] - Step: 10000/66070  |  Loss: 0.7531  |  Score: 67.21 [%]  |  Seq Length: 256.0
[2024-10-18 02:13:22,062][root][INFO] - Step: 13214/66070  |  Loss: 0.8103  |  Score: 63.81 [%]  |  Seq Length: 256.0
[2024-10-18 02:13:27,033][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 02:13:27,033][root][INFO] - Score: 59.01 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-18 02:13:36,187][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 02:13:36,187][root][INFO] - Score: 58.16 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-18 02:13:36,188][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 02:13:36,189][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 02:37:53,105][root][INFO] - Step: 10000/73665  |  Loss: 0.7567  |  Score: 67.02 [%]  |  Seq Length: 256.0
[2024-10-18 02:55:21,744][root][INFO] - Step: 20000/66070  |  Loss: 1.0251  |  Score: 45.97 [%]  |  Seq Length: 256.0
[2024-10-18 03:06:47,601][root][INFO] - Step: 14733/73665  |  Loss: 0.8287  |  Score: 62.68 [%]  |  Seq Length: 256.0
[2024-10-18 03:06:53,922][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 03:06:53,922][root][INFO] - Score: 57.14 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-18 03:07:05,959][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 03:07:05,959][root][INFO] - Score: 57.83 [%]  |  Evaluation Time: 12.03 [s]
[2024-10-18 03:07:05,960][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 03:07:05,961][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 03:34:52,191][root][INFO] - Step: 26428/66070  |  Loss: 1.1534  |  Score: 33.74 [%]  |  Seq Length: 256.0
[2024-10-18 03:34:57,168][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 03:34:57,168][root][INFO] - Score: 37.70 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-18 03:35:06,330][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 03:35:06,331][root][INFO] - Score: 37.54 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-18 03:35:06,333][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 03:39:17,049][root][INFO] - Step: 20000/73665  |  Loss: 1.0358  |  Score: 44.59 [%]  |  Seq Length: 256.0
[2024-10-18 03:57:05,134][root][INFO] - Step: 30000/66070  |  Loss: 1.1588  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-18 04:37:06,623][root][INFO] - Step: 29466/73665  |  Loss: 1.1741  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-18 04:37:12,941][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 04:37:12,942][root][INFO] - Score: 32.90 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-18 04:37:24,879][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 04:37:24,879][root][INFO] - Score: 32.44 [%]  |  Evaluation Time: 11.94 [s]
[2024-10-18 04:37:24,881][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 04:40:40,875][root][INFO] - Step: 30000/73665  |  Loss: 1.1753  |  Score: 34.07 [%]  |  Seq Length: 256.0
[2024-10-18 04:56:24,980][root][INFO] - Step: 39642/66070  |  Loss: 1.1630  |  Score: 33.48 [%]  |  Seq Length: 256.0
[2024-10-18 04:56:29,961][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 04:56:29,961][root][INFO] - Score: 33.74 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-18 04:56:39,109][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 04:56:39,109][root][INFO] - Score: 32.80 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-18 04:56:39,111][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 04:58:52,760][root][INFO] - Step: 40000/66070  |  Loss: 1.1563  |  Score: 33.51 [%]  |  Seq Length: 256.0
[2024-10-18 05:41:46,227][root][INFO] - Step: 40000/73665  |  Loss: 1.2144  |  Score: 34.02 [%]  |  Seq Length: 256.0
[2024-10-18 06:00:22,894][root][INFO] - Step: 50000/66070  |  Loss: 1.1575  |  Score: 33.48 [%]  |  Seq Length: 256.0
[2024-10-18 06:07:25,521][root][INFO] - Step: 44199/73665  |  Loss: 1.1946  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-18 06:07:31,827][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 06:07:31,827][root][INFO] - Score: 34.82 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-18 06:07:43,836][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 06:07:43,836][root][INFO] - Score: 34.04 [%]  |  Evaluation Time: 12.01 [s]
[2024-10-18 06:07:43,838][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 06:17:56,678][root][INFO] - Step: 52856/66070  |  Loss: 1.1556  |  Score: 33.63 [%]  |  Seq Length: 256.0
[2024-10-18 06:18:01,645][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 06:18:01,646][root][INFO] - Score: 33.85 [%]  |  Evaluation Time: 4.96 [s]
[2024-10-18 06:18:10,777][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 06:18:10,777][root][INFO] - Score: 34.81 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-18 06:18:10,779][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 06:43:10,505][root][INFO] - Step: 50000/73665  |  Loss: 1.1758  |  Score: 33.17 [%]  |  Seq Length: 256.0
[2024-10-18 07:02:08,556][root][INFO] - Step: 60000/66070  |  Loss: 1.1555  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-18 07:37:44,816][root][INFO] - Step: 58932/73665  |  Loss: 1.1660  |  Score: 33.17 [%]  |  Seq Length: 256.0
[2024-10-18 07:37:51,196][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 07:37:51,197][root][INFO] - Score: 32.95 [%]  |  Evaluation Time: 6.38 [s]
[2024-10-18 07:38:03,093][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 07:38:03,094][root][INFO] - Score: 32.12 [%]  |  Evaluation Time: 11.89 [s]
[2024-10-18 07:38:03,096][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 07:39:33,799][root][INFO] - Step: 66070/66070  |  Loss: 1.1555  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-18 07:39:38,763][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 07:39:38,763][root][INFO] - Score: 36.12 [%]  |  Evaluation Time: 4.96 [s]
[2024-10-18 07:39:47,906][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 07:39:47,906][root][INFO] - Score: 34.03 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-18 07:39:47,907][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 07:39:47,907][root][INFO] - - Epoch: 1
[2024-10-18 07:39:47,907][root][INFO] - - DEV score: 59.01 [%]
[2024-10-18 07:39:47,907][root][INFO] - - TEST score: 58.16 [%]
[2024-10-18 07:39:47,909][root][INFO] - Fine-tuning is done!
[2024-10-18 07:39:47,909][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-18 07:39:47,909][root][INFO] - - BEST LR: 0.01
[2024-10-18 07:39:47,909][root][INFO] - - DEV score: 75.13 [%]
[2024-10-18 07:39:47,909][root][INFO] - - TEST score: 75.64 [%]
[2024-10-18 07:39:53,817][root][INFO] - 

[2024-10-18 07:39:53,817][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-18 07:39:53,817][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 07:39:53,817][root][INFO] - 

[2024-10-18 07:39:53,817][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-18 07:41:38,988][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,988][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,989][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,989][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,990][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,990][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,991][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,992][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,992][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,993][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,993][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,994][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,994][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,995][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,995][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,996][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,996][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,997][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,997][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,998][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,998][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:38,999][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:38,999][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 07:41:39,000][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 07:41:39,002][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 07:41:39,007][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-18 07:41:39,208][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 07:41:39,211][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 07:41:39,463][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 07:41:42,658][root][INFO] - 

[2024-10-18 07:41:42,658][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 07:41:42,658][root][INFO] - Data Preprocessing
[2024-10-18 07:41:42,658][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 07:41:42,658][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 07:41:42,659][root][INFO] - ㄴ data_remove                True

[2024-10-18 07:41:42,659][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 07:41:42,666][root][INFO] - vocab size              : 51200
[2024-10-18 07:41:42,666][root][INFO] - device                  : gpu
[2024-10-18 07:41:42,666][root][INFO] - random seed             : 1
[2024-10-18 07:41:42,667][root][INFO] - train data size         : 845696
[2024-10-18 07:41:42,667][root][INFO] - max epochs              : 5
[2024-10-18 07:41:42,667][root][INFO] - total steps             : 66070
[2024-10-18 07:41:42,667][root][INFO] - warmup steps            : 6607
[2024-10-18 07:41:42,667][root][INFO] - batch size              : 64
[2024-10-18 07:41:42,667][root][INFO] - accumulation steps      : 1
[2024-10-18 07:41:42,667][root][INFO] - optimizer               : adamwscale
[2024-10-18 07:41:42,667][root][INFO] - lr_scheduler            : cosine
[2024-10-18 07:41:42,667][root][INFO] - learning rate           : 0.01
[2024-10-18 07:41:42,667][root][INFO] - max length              : 256

[2024-10-18 07:41:42,667][root][INFO] - LoRA Configuration
[2024-10-18 07:41:42,667][root][INFO] - ㄴ r                    : 32
[2024-10-18 07:41:42,668][root][INFO] - ㄴ alpha                : 128
[2024-10-18 07:41:42,668][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 07:41:42,668][root][INFO] - KOMBO Configuration
[2024-10-18 07:41:42,668][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 07:41:42,668][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 07:41:42,668][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 07:41:42,668][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 07:41:42,668][root][INFO] - ㄴ do_combination       : True
[2024-10-18 07:41:42,668][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 07:41:42,669][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 07:41:42,669][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 07:41:42,669][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 07:41:42,669][root][INFO] - 

[2024-10-18 07:41:42,669][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 07:41:42,669][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 07:41:42,669][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 07:41:42,669][root][INFO] - * tb interval   : 10000

[2024-10-18 07:41:42,669][root][INFO] - 

[2024-10-18 07:41:42,669][root][INFO] - Start the Training !
[2024-10-18 07:41:42,672][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 07:44:35,382][root][INFO] - Step: 60000/73665  |  Loss: 1.3883  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-18 08:45:40,485][root][INFO] - Step: 70000/73665  |  Loss: 1.1804  |  Score: 33.40 [%]  |  Seq Length: 256.0
[2024-10-18 09:07:58,702][root][INFO] - Step: 73665/73665  |  Loss: 1.1627  |  Score: 33.49 [%]  |  Seq Length: 256.0
[2024-10-18 09:08:05,059][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 09:08:05,074][root][INFO] - Score: 31.67 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-18 09:08:17,056][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 09:08:17,056][root][INFO] - Score: 32.66 [%]  |  Evaluation Time: 11.98 [s]
[2024-10-18 09:08:17,058][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 09:08:17,058][root][INFO] - - Epoch: 1
[2024-10-18 09:08:17,058][root][INFO] - - DEV score: 57.14 [%]
[2024-10-18 09:08:17,058][root][INFO] - - TEST score: 57.83 [%]
[2024-10-18 09:08:17,061][root][INFO] - Fine-tuning is done!
[2024-10-18 09:08:17,061][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-18 09:08:17,061][root][INFO] - - BEST LR: 0.01
[2024-10-18 09:08:17,061][root][INFO] - - DEV score: 75.90 [%]
[2024-10-18 09:08:17,061][root][INFO] - - TEST score: 76.35 [%]
[2024-10-18 09:08:23,599][root][INFO] - 

[2024-10-18 09:08:23,599][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-18 09:08:23,599][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 09:08:23,599][root][INFO] - 

[2024-10-18 09:08:23,600][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-18 09:09:18,127][root][INFO] - Step: 10000/66070  |  Loss: 0.7222  |  Score: 68.83 [%]  |  Seq Length: 256.0
[2024-10-18 09:10:22,617][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,618][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,618][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,619][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,619][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,619][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,620][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,620][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,621][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,621][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,621][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,622][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,622][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,623][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,623][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,623][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,624][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,624][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,625][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,625][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,626][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,626][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,626][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 09:10:22,627][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 09:10:22,628][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 09:10:22,633][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-18 09:10:22,828][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 09:10:22,830][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 09:10:23,098][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 09:10:26,171][root][INFO] - 

[2024-10-18 09:10:26,171][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 09:10:26,171][root][INFO] - Data Preprocessing
[2024-10-18 09:10:26,171][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 09:10:26,171][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 09:10:26,171][root][INFO] - ㄴ data_remove                False

[2024-10-18 09:10:26,171][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 09:10:26,179][root][INFO] - vocab size              : 51200
[2024-10-18 09:10:26,179][root][INFO] - device                  : gpu
[2024-10-18 09:10:26,179][root][INFO] - random seed             : 1
[2024-10-18 09:10:26,179][root][INFO] - train data size         : 942912
[2024-10-18 09:10:26,180][root][INFO] - max epochs              : 5
[2024-10-18 09:10:26,180][root][INFO] - total steps             : 73665
[2024-10-18 09:10:26,180][root][INFO] - warmup steps            : 7366
[2024-10-18 09:10:26,180][root][INFO] - batch size              : 64
[2024-10-18 09:10:26,180][root][INFO] - accumulation steps      : 1
[2024-10-18 09:10:26,180][root][INFO] - optimizer               : adamwscale
[2024-10-18 09:10:26,180][root][INFO] - lr_scheduler            : cosine
[2024-10-18 09:10:26,180][root][INFO] - learning rate           : 0.01
[2024-10-18 09:10:26,180][root][INFO] - max length              : 256

[2024-10-18 09:10:26,180][root][INFO] - LoRA Configuration
[2024-10-18 09:10:26,180][root][INFO] - ㄴ r                    : 32
[2024-10-18 09:10:26,180][root][INFO] - ㄴ alpha                : 128
[2024-10-18 09:10:26,181][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 09:10:26,181][root][INFO] - KOMBO Configuration
[2024-10-18 09:10:26,181][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 09:10:26,181][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 09:10:26,181][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 09:10:26,181][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 09:10:26,181][root][INFO] - ㄴ do_combination       : True
[2024-10-18 09:10:26,181][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 09:10:26,181][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 09:10:26,181][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 09:10:26,182][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 09:10:26,182][root][INFO] - 

[2024-10-18 09:10:26,182][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 09:10:26,182][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-18 09:10:26,182][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-18 09:10:26,182][root][INFO] - * tb interval   : 10000

[2024-10-18 09:10:26,182][root][INFO] - 

[2024-10-18 09:10:26,182][root][INFO] - Start the Training !
[2024-10-18 09:10:26,186][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 09:34:24,794][root][INFO] - 

[2024-10-18 09:34:24,795][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-18 09:34:24,795][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-18 09:34:24,796][root][INFO] - 

[2024-10-18 09:34:24,796][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-18 09:36:32,413][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,414][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,414][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,414][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,415][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,415][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,416][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,416][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,417][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,417][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,417][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,418][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,418][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,419][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,421][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,422][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,422][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,422][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,423][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,423][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,424][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,424][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,425][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 09:36:32,425][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 09:36:32,427][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 09:36:32,672][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 09:36:34,732][root][INFO] - 

[2024-10-18 09:36:34,732][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 09:36:34,732][root][INFO] - Data Preprocessing
[2024-10-18 09:36:34,732][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-18 09:36:34,733][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 09:36:34,733][root][INFO] - ㄴ data_remove                True

[2024-10-18 09:36:34,733][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 09:36:34,740][root][INFO] - vocab size              : 51200
[2024-10-18 09:36:34,741][root][INFO] - device                  : gpu
[2024-10-18 09:36:34,741][root][INFO] - random seed             : 1
[2024-10-18 09:36:34,741][root][INFO] - train data size         : 806400
[2024-10-18 09:36:34,741][root][INFO] - max epochs              : 5
[2024-10-18 09:36:34,741][root][INFO] - total steps             : 63000
[2024-10-18 09:36:34,741][root][INFO] - warmup steps            : 6300
[2024-10-18 09:36:34,741][root][INFO] - batch size              : 64
[2024-10-18 09:36:34,741][root][INFO] - accumulation steps      : 1
[2024-10-18 09:36:34,741][root][INFO] - optimizer               : adamwscale
[2024-10-18 09:36:34,742][root][INFO] - lr_scheduler            : cosine
[2024-10-18 09:36:34,742][root][INFO] - learning rate           : 0.01
[2024-10-18 09:36:34,742][root][INFO] - max length              : 256

[2024-10-18 09:36:34,742][root][INFO] - LoRA Configuration
[2024-10-18 09:36:34,742][root][INFO] - ㄴ r                    : 32
[2024-10-18 09:36:34,742][root][INFO] - ㄴ alpha                : 128
[2024-10-18 09:36:34,742][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 09:36:34,742][root][INFO] - 

[2024-10-18 09:36:34,742][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-18 09:36:34,742][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 09:36:34,742][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 09:36:34,743][root][INFO] - * tb interval   : 10000

[2024-10-18 09:36:34,743][root][INFO] - 

[2024-10-18 09:36:34,743][root][INFO] - Start the Training !
[2024-10-18 09:36:34,745][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 09:37:32,570][root][INFO] - Step: 13214/66070  |  Loss: 0.6528  |  Score: 72.75 [%]  |  Seq Length: 256.0
[2024-10-18 09:37:40,736][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 09:37:40,736][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 8.16 [s]
[2024-10-18 09:37:55,996][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 09:37:55,996][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 15.26 [s]
[2024-10-18 09:37:55,997][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 09:37:55,998][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 10:37:33,871][root][INFO] - Step: 10000/63000  |  Loss: 0.7208  |  Score: 68.89 [%]  |  Seq Length: 256.0
[2024-10-18 10:38:14,885][root][INFO] - Step: 20000/66070  |  Loss: 0.6243  |  Score: 74.15 [%]  |  Seq Length: 256.0
[2024-10-18 10:38:55,798][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.44 [%]  |  Seq Length: 256.0
[2024-10-18 10:53:26,454][root][INFO] - Step: 12600/63000  |  Loss: 0.6512  |  Score: 72.77 [%]  |  Seq Length: 256.0
[2024-10-18 10:53:30,806][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 10:53:30,806][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-18 10:53:38,691][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 10:53:38,691][root][INFO] - Score: 72.06 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 10:53:38,692][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 10:53:38,693][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 11:21:21,080][root][INFO] - Step: 14733/73665  |  Loss: 0.6592  |  Score: 72.33 [%]  |  Seq Length: 256.0
[2024-10-18 11:21:31,691][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 11:21:31,692][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 10.61 [s]
[2024-10-18 11:21:52,275][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 11:21:52,276][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 20.58 [s]
[2024-10-18 11:21:52,277][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 11:21:52,278][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 11:35:23,702][root][INFO] - Step: 26428/66070  |  Loss: 0.6170  |  Score: 74.49 [%]  |  Seq Length: 256.0
[2024-10-18 11:35:31,887][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 11:35:31,887][root][INFO] - Score: 71.53 [%]  |  Evaluation Time: 8.18 [s]
[2024-10-18 11:35:47,354][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 11:35:47,354][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 15.46 [s]
[2024-10-18 11:35:47,355][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-18 11:35:47,357][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 11:38:51,898][root][INFO] - Step: 20000/63000  |  Loss: 0.6252  |  Score: 74.09 [%]  |  Seq Length: 256.0
[2024-10-18 12:07:33,896][root][INFO] - Step: 30000/66070  |  Loss: 0.5897  |  Score: 75.76 [%]  |  Seq Length: 256.0
[2024-10-18 12:09:01,044][root][INFO] - Step: 20000/73665  |  Loss: 0.6348  |  Score: 73.69 [%]  |  Seq Length: 256.0
[2024-10-18 12:10:37,971][root][INFO] - Step: 25200/63000  |  Loss: 0.6145  |  Score: 74.78 [%]  |  Seq Length: 256.0
[2024-10-18 12:10:42,302][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 12:10:42,303][root][INFO] - Score: 72.02 [%]  |  Evaluation Time: 4.33 [s]
[2024-10-18 12:10:50,181][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 12:10:50,181][root][INFO] - Score: 72.68 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 12:10:50,182][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-18 12:10:50,183][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 12:40:09,692][root][INFO] - Step: 30000/63000  |  Loss: 0.5870  |  Score: 76.00 [%]  |  Seq Length: 256.0
[2024-10-18 13:27:51,951][root][INFO] - Step: 37800/63000  |  Loss: 0.5768  |  Score: 76.42 [%]  |  Seq Length: 256.0
[2024-10-18 13:27:56,272][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 13:27:56,272][root][INFO] - Score: 73.81 [%]  |  Evaluation Time: 4.32 [s]
[2024-10-18 13:28:04,192][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 13:28:04,192][root][INFO] - Score: 74.15 [%]  |  Evaluation Time: 7.92 [s]
[2024-10-18 13:28:04,193][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-18 13:28:04,194][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 13:33:14,871][root][INFO] - Step: 39642/66070  |  Loss: 0.5793  |  Score: 76.31 [%]  |  Seq Length: 256.0
[2024-10-18 13:33:23,068][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 13:33:23,069][root][INFO] - Score: 73.90 [%]  |  Evaluation Time: 8.19 [s]
[2024-10-18 13:33:29,773][root][INFO] - Step: 29466/73665  |  Loss: 0.6277  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-18 13:33:38,630][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 13:33:38,630][root][INFO] - Score: 73.92 [%]  |  Evaluation Time: 15.56 [s]
[2024-10-18 13:33:38,631][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-18 13:33:38,632][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 13:33:40,162][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 13:33:40,162][root][INFO] - Score: 73.23 [%]  |  Evaluation Time: 10.39 [s]
[2024-10-18 13:34:00,523][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 13:34:00,523][root][INFO] - Score: 73.97 [%]  |  Evaluation Time: 20.36 [s]
[2024-10-18 13:34:00,524][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-18 13:34:00,525][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 13:36:50,265][root][INFO] - Step: 40000/66070  |  Loss: 0.5400  |  Score: 78.06 [%]  |  Seq Length: 256.0
[2024-10-18 13:38:48,551][root][INFO] - Step: 30000/73665  |  Loss: 0.5975  |  Score: 75.59 [%]  |  Seq Length: 256.0
[2024-10-18 13:41:32,436][root][INFO] - Step: 40000/63000  |  Loss: 0.5433  |  Score: 78.04 [%]  |  Seq Length: 256.0
[2024-10-18 14:42:41,339][root][INFO] - Step: 50000/63000  |  Loss: 0.5296  |  Score: 78.65 [%]  |  Seq Length: 256.0
[2024-10-18 14:45:07,718][root][INFO] - Step: 50400/63000  |  Loss: 0.5262  |  Score: 78.71 [%]  |  Seq Length: 256.0
[2024-10-18 14:45:12,001][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 14:45:12,001][root][INFO] - Score: 74.05 [%]  |  Evaluation Time: 4.28 [s]
[2024-10-18 14:45:19,882][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 14:45:19,882][root][INFO] - Score: 75.07 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 14:45:19,883][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 14:45:19,884][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 15:05:25,665][root][INFO] - Step: 50000/66070  |  Loss: 0.5357  |  Score: 78.38 [%]  |  Seq Length: 256.0
[2024-10-18 15:08:00,235][root][INFO] - Step: 40000/73665  |  Loss: 0.5971  |  Score: 75.45 [%]  |  Seq Length: 256.0
[2024-10-18 15:30:42,963][root][INFO] - Step: 52856/66070  |  Loss: 0.5238  |  Score: 78.83 [%]  |  Seq Length: 256.0
[2024-10-18 15:30:51,071][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 15:30:51,072][root][INFO] - Score: 74.36 [%]  |  Evaluation Time: 8.11 [s]
[2024-10-18 15:31:06,369][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 15:31:06,369][root][INFO] - Score: 75.31 [%]  |  Evaluation Time: 15.30 [s]
[2024-10-18 15:31:06,370][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 15:31:06,372][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 15:44:04,609][root][INFO] - Step: 60000/63000  |  Loss: 0.4953  |  Score: 80.27 [%]  |  Seq Length: 256.0
[2024-10-18 15:45:21,356][root][INFO] - Step: 44199/73665  |  Loss: 0.5820  |  Score: 76.20 [%]  |  Seq Length: 256.0
[2024-10-18 15:45:31,790][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 15:45:31,790][root][INFO] - Score: 74.93 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-18 15:45:51,949][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 15:45:51,949][root][INFO] - Score: 75.74 [%]  |  Evaluation Time: 20.16 [s]
[2024-10-18 15:45:51,950][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-18 15:45:51,952][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 16:02:23,902][root][INFO] - Step: 63000/63000  |  Loss: 0.4937  |  Score: 80.29 [%]  |  Seq Length: 256.0
[2024-10-18 16:02:28,203][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 16:02:28,203][root][INFO] - Score: 74.72 [%]  |  Evaluation Time: 4.30 [s]
[2024-10-18 16:02:36,088][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 16:02:36,088][root][INFO] - Score: 75.88 [%]  |  Evaluation Time: 7.88 [s]
[2024-10-18 16:02:36,089][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 16:02:36,089][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 16:02:36,090][root][INFO] - - Epoch: 5
[2024-10-18 16:02:36,090][root][INFO] - - DEV score: 74.72 [%]
[2024-10-18 16:02:36,090][root][INFO] - - TEST score: 75.88 [%]
[2024-10-18 16:02:36,090][root][INFO] - Fine-tuning is done!
[2024-10-18 16:04:12,101][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,102][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,102][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,103][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,103][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,104][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,104][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,105][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,105][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,106][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,107][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,107][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,108][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,108][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,109][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,109][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,110][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,110][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,111][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,112][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,112][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,113][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,113][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 16:04:12,114][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 16:04:12,116][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 16:04:12,117][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 16:04:12,286][root][INFO] - 

[2024-10-18 16:04:12,286][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 16:04:12,286][root][INFO] - Data Preprocessing
[2024-10-18 16:04:12,286][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-18 16:04:12,286][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 16:04:12,286][root][INFO] - ㄴ data_remove                True

[2024-10-18 16:04:12,286][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 16:04:12,297][root][INFO] - vocab size              : 51200
[2024-10-18 16:04:12,298][root][INFO] - device                  : gpu
[2024-10-18 16:04:12,298][root][INFO] - random seed             : 1
[2024-10-18 16:04:12,298][root][INFO] - train data size         : 806400
[2024-10-18 16:04:12,298][root][INFO] - max epochs              : 5
[2024-10-18 16:04:12,298][root][INFO] - total steps             : 63000
[2024-10-18 16:04:12,298][root][INFO] - warmup steps            : 6300
[2024-10-18 16:04:12,299][root][INFO] - batch size              : 64
[2024-10-18 16:04:12,299][root][INFO] - accumulation steps      : 1
[2024-10-18 16:04:12,299][root][INFO] - optimizer               : adamwscale
[2024-10-18 16:04:12,299][root][INFO] - lr_scheduler            : cosine
[2024-10-18 16:04:12,299][root][INFO] - learning rate           : 0.02
[2024-10-18 16:04:12,299][root][INFO] - max length              : 256

[2024-10-18 16:04:12,299][root][INFO] - LoRA Configuration
[2024-10-18 16:04:12,299][root][INFO] - ㄴ r                    : 32
[2024-10-18 16:04:12,299][root][INFO] - ㄴ alpha                : 128
[2024-10-18 16:04:12,299][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 16:04:12,299][root][INFO] - 

[2024-10-18 16:04:12,300][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-18 16:04:12,300][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 16:04:12,300][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 16:04:12,300][root][INFO] - * tb interval   : 10000

[2024-10-18 16:04:12,300][root][INFO] - 

[2024-10-18 16:04:12,300][root][INFO] - Start the Training !
[2024-10-18 16:04:12,302][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 16:34:30,391][root][INFO] - Step: 60000/66070  |  Loss: 0.4965  |  Score: 80.24 [%]  |  Seq Length: 256.0
[2024-10-18 16:37:28,310][root][INFO] - Step: 50000/73665  |  Loss: 0.5498  |  Score: 77.61 [%]  |  Seq Length: 256.0
[2024-10-18 17:05:21,789][root][INFO] - Step: 10000/63000  |  Loss: 0.7534  |  Score: 67.20 [%]  |  Seq Length: 256.0
[2024-10-18 17:21:16,234][root][INFO] - Step: 12600/63000  |  Loss: 0.8022  |  Score: 64.24 [%]  |  Seq Length: 256.0
[2024-10-18 17:21:20,636][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 17:21:20,637][root][INFO] - Score: 61.22 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-18 17:21:28,602][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 17:21:28,602][root][INFO] - Score: 59.99 [%]  |  Evaluation Time: 7.96 [s]
[2024-10-18 17:21:28,603][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 17:21:28,604][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 17:28:12,379][root][INFO] - Step: 66070/66070  |  Loss: 0.4945  |  Score: 80.27 [%]  |  Seq Length: 256.0
[2024-10-18 17:28:20,484][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 17:28:20,484][root][INFO] - Score: 75.53 [%]  |  Evaluation Time: 8.10 [s]
[2024-10-18 17:28:35,792][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 17:28:35,792][root][INFO] - Score: 75.81 [%]  |  Evaluation Time: 15.31 [s]
[2024-10-18 17:28:35,793][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 17:28:35,793][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 17:28:35,793][root][INFO] - - Epoch: 5
[2024-10-18 17:28:35,793][root][INFO] - - DEV score: 75.53 [%]
[2024-10-18 17:28:35,793][root][INFO] - - TEST score: 75.81 [%]
[2024-10-18 17:28:35,794][root][INFO] - Fine-tuning is done!
[2024-10-18 17:30:21,975][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,976][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,977][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,977][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,978][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,978][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,979][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,979][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,980][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,980][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,981][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,981][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,982][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,982][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,982][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,983][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,983][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,984][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,984][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,985][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,986][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,986][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,987][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 17:30:21,987][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 17:30:21,989][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 17:30:22,189][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 17:30:22,191][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 17:30:22,192][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 17:30:22,377][root][INFO] - 

[2024-10-18 17:30:22,378][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 17:30:22,378][root][INFO] - Data Preprocessing
[2024-10-18 17:30:22,378][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 17:30:22,378][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 17:30:22,378][root][INFO] - ㄴ data_remove                True

[2024-10-18 17:30:22,378][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 17:30:22,389][root][INFO] - vocab size              : 51200
[2024-10-18 17:30:22,390][root][INFO] - device                  : gpu
[2024-10-18 17:30:22,390][root][INFO] - random seed             : 1
[2024-10-18 17:30:22,390][root][INFO] - train data size         : 845696
[2024-10-18 17:30:22,390][root][INFO] - max epochs              : 5
[2024-10-18 17:30:22,390][root][INFO] - total steps             : 66070
[2024-10-18 17:30:22,390][root][INFO] - warmup steps            : 6607
[2024-10-18 17:30:22,390][root][INFO] - batch size              : 64
[2024-10-18 17:30:22,390][root][INFO] - accumulation steps      : 1
[2024-10-18 17:30:22,390][root][INFO] - optimizer               : adamwscale
[2024-10-18 17:30:22,391][root][INFO] - lr_scheduler            : cosine
[2024-10-18 17:30:22,391][root][INFO] - learning rate           : 0.02
[2024-10-18 17:30:22,391][root][INFO] - max length              : 256

[2024-10-18 17:30:22,391][root][INFO] - LoRA Configuration
[2024-10-18 17:30:22,391][root][INFO] - ㄴ r                    : 32
[2024-10-18 17:30:22,391][root][INFO] - ㄴ alpha                : 128
[2024-10-18 17:30:22,391][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 17:30:22,391][root][INFO] - KOMBO Configuration
[2024-10-18 17:30:22,391][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 17:30:22,391][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 17:30:22,391][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 17:30:22,392][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 17:30:22,392][root][INFO] - ㄴ do_combination       : True
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 17:30:22,392][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 17:30:22,392][root][INFO] - 

[2024-10-18 17:30:22,392][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-18 17:30:22,392][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-18 17:30:22,392][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-18 17:30:22,392][root][INFO] - * tb interval   : 10000

[2024-10-18 17:30:22,393][root][INFO] - 

[2024-10-18 17:30:22,393][root][INFO] - Start the Training !
[2024-10-18 17:30:22,395][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 17:57:15,410][root][INFO] - Step: 58932/73665  |  Loss: 0.5401  |  Score: 78.25 [%]  |  Seq Length: 256.0
[2024-10-18 17:57:25,812][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 17:57:25,812][root][INFO] - Score: 74.43 [%]  |  Evaluation Time: 10.40 [s]
[2024-10-18 17:57:46,136][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 17:57:46,136][root][INFO] - Score: 76.33 [%]  |  Evaluation Time: 20.32 [s]
[2024-10-18 17:57:46,137][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-18 17:57:46,138][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 18:06:52,816][root][INFO] - Step: 20000/63000  |  Loss: 0.9975  |  Score: 48.04 [%]  |  Seq Length: 256.0
[2024-10-18 18:07:17,563][root][INFO] - Step: 60000/73665  |  Loss: 0.5116  |  Score: 79.42 [%]  |  Seq Length: 256.0
[2024-10-18 18:38:44,573][root][INFO] - Step: 25200/63000  |  Loss: 1.1402  |  Score: 33.54 [%]  |  Seq Length: 256.0
[2024-10-18 18:38:49,088][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 18:38:49,088][root][INFO] - Score: 32.58 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-18 18:38:57,092][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 18:38:57,092][root][INFO] - Score: 31.22 [%]  |  Evaluation Time: 8.00 [s]
[2024-10-18 18:38:57,095][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 18:59:50,105][root][INFO] - Step: 10000/66070  |  Loss: 0.7526  |  Score: 67.26 [%]  |  Seq Length: 256.0
[2024-10-18 19:08:22,209][root][INFO] - Step: 30000/63000  |  Loss: 1.1617  |  Score: 33.20 [%]  |  Seq Length: 256.0
[2024-10-18 19:28:22,968][root][INFO] - Step: 13214/66070  |  Loss: 0.8030  |  Score: 64.31 [%]  |  Seq Length: 256.0
[2024-10-18 19:28:31,444][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 19:28:31,444][root][INFO] - Score: 59.61 [%]  |  Evaluation Time: 8.47 [s]
[2024-10-18 19:28:47,232][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 19:28:47,233][root][INFO] - Score: 59.62 [%]  |  Evaluation Time: 15.79 [s]
[2024-10-18 19:28:47,234][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 19:28:47,235][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 19:36:22,547][root][INFO] - Step: 70000/73665  |  Loss: 0.5054  |  Score: 79.74 [%]  |  Seq Length: 256.0
[2024-10-18 19:56:10,618][root][INFO] - Step: 37800/63000  |  Loss: 1.1919  |  Score: 33.39 [%]  |  Seq Length: 256.0
[2024-10-18 19:56:15,012][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 19:56:15,013][root][INFO] - Score: 34.53 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-18 19:56:23,035][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 19:56:23,035][root][INFO] - Score: 33.24 [%]  |  Evaluation Time: 8.02 [s]
[2024-10-18 19:56:23,037][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 20:09:07,536][root][INFO] - Step: 73665/73665  |  Loss: 0.5026  |  Score: 79.99 [%]  |  Seq Length: 256.0
[2024-10-18 20:09:17,970][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 20:09:17,970][root][INFO] - Score: 74.99 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-18 20:09:38,252][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 20:09:38,252][root][INFO] - Score: 76.27 [%]  |  Evaluation Time: 20.28 [s]
[2024-10-18 20:09:38,253][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-18 20:09:38,253][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 20:09:38,254][root][INFO] - - Epoch: 5
[2024-10-18 20:09:38,254][root][INFO] - - DEV score: 74.99 [%]
[2024-10-18 20:09:38,254][root][INFO] - - TEST score: 76.27 [%]
[2024-10-18 20:09:38,254][root][INFO] - Fine-tuning is done!
[2024-10-18 20:09:52,211][root][INFO] - Step: 40000/63000  |  Loss: 1.3049  |  Score: 33.71 [%]  |  Seq Length: 256.0
[2024-10-18 20:11:42,975][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,976][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,977][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,977][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,978][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,978][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,979][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,979][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,980][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,980][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,981][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,982][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,982][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,983][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,989][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,989][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,990][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,990][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,991][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,991][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,992][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,993][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,993][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-18 20:11:42,994][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-18 20:11:42,996][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-18 20:11:43,204][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-18 20:11:43,207][root][INFO] - Trainable params: 17254656 || all params: 142420992 || trainable: 12.12 %
[2024-10-18 20:11:43,208][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-18 20:11:43,408][root][INFO] - 

[2024-10-18 20:11:43,408][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-18 20:11:43,408][root][INFO] - Data Preprocessing
[2024-10-18 20:11:43,408][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-18 20:11:43,409][root][INFO] - ㄴ do_hangeulize              False
[2024-10-18 20:11:43,409][root][INFO] - ㄴ data_remove                False

[2024-10-18 20:11:43,409][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-18 20:11:43,425][root][INFO] - vocab size              : 51200
[2024-10-18 20:11:43,426][root][INFO] - device                  : gpu
[2024-10-18 20:11:43,426][root][INFO] - random seed             : 1
[2024-10-18 20:11:43,427][root][INFO] - train data size         : 942912
[2024-10-18 20:11:43,427][root][INFO] - max epochs              : 5
[2024-10-18 20:11:43,427][root][INFO] - total steps             : 73665
[2024-10-18 20:11:43,427][root][INFO] - warmup steps            : 7366
[2024-10-18 20:11:43,427][root][INFO] - batch size              : 64
[2024-10-18 20:11:43,427][root][INFO] - accumulation steps      : 1
[2024-10-18 20:11:43,427][root][INFO] - optimizer               : adamwscale
[2024-10-18 20:11:43,427][root][INFO] - lr_scheduler            : cosine
[2024-10-18 20:11:43,427][root][INFO] - learning rate           : 0.02
[2024-10-18 20:11:43,427][root][INFO] - max length              : 256

[2024-10-18 20:11:43,427][root][INFO] - LoRA Configuration
[2024-10-18 20:11:43,427][root][INFO] - ㄴ r                    : 32
[2024-10-18 20:11:43,428][root][INFO] - ㄴ alpha                : 128
[2024-10-18 20:11:43,428][root][INFO] - ㄴ dropout              : 0.03

[2024-10-18 20:11:43,428][root][INFO] - KOMBO Configuration
[2024-10-18 20:11:43,428][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-18 20:11:43,428][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-18 20:11:43,428][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-18 20:11:43,428][root][INFO] - ㄴ embedding_norm       : False
[2024-10-18 20:11:43,428][root][INFO] - ㄴ do_combination       : True
[2024-10-18 20:11:43,428][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-18 20:11:43,428][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-18 20:11:43,429][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-18 20:11:43,429][root][INFO] -   ㄴ add_lora           : False

[2024-10-18 20:11:43,429][root][INFO] - 

[2024-10-18 20:11:43,429][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-18 20:11:43,429][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-18 20:11:43,429][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-18 20:11:43,429][root][INFO] - * tb interval   : 10000

[2024-10-18 20:11:43,429][root][INFO] - 

[2024-10-18 20:11:43,429][root][INFO] - Start the Training !
[2024-10-18 20:11:43,432][root][INFO] - 
[1/ 5 Epoch]
[2024-10-18 20:29:23,128][root][INFO] - Step: 20000/66070  |  Loss: 0.9842  |  Score: 49.33 [%]  |  Seq Length: 256.0
[2024-10-18 21:11:09,152][root][INFO] - Step: 50000/63000  |  Loss: 1.2927  |  Score: 33.24 [%]  |  Seq Length: 256.0
[2024-10-18 21:13:36,203][root][INFO] - Step: 50400/63000  |  Loss: 1.3330  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-18 21:13:40,705][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-18 21:13:40,705][root][INFO] - Score: 30.60 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-18 21:13:48,759][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-18 21:13:48,760][root][INFO] - Score: 31.27 [%]  |  Evaluation Time: 8.05 [s]
[2024-10-18 21:13:48,762][root][INFO] - 
[5/ 5 Epoch]
[2024-10-18 21:26:08,051][root][INFO] - Step: 26428/66070  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-18 21:26:16,447][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-18 21:26:16,448][root][INFO] - Score: 34.57 [%]  |  Evaluation Time: 8.39 [s]
[2024-10-18 21:26:32,435][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-18 21:26:32,435][root][INFO] - Score: 34.86 [%]  |  Evaluation Time: 15.98 [s]
[2024-10-18 21:26:32,437][root][INFO] - 
[3/ 5 Epoch]
[2024-10-18 21:41:02,746][root][INFO] - Step: 10000/73665  |  Loss: 0.7559  |  Score: 67.09 [%]  |  Seq Length: 256.0
[2024-10-18 21:57:55,738][root][INFO] - Step: 30000/66070  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-18 22:12:40,327][root][INFO] - Step: 60000/63000  |  Loss: 1.3151  |  Score: 33.36 [%]  |  Seq Length: 256.0
[2024-10-18 22:23:19,333][root][INFO] - Step: 14733/73665  |  Loss: 0.8257  |  Score: 62.91 [%]  |  Seq Length: 256.0
[2024-10-18 22:23:30,019][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-18 22:23:30,019][root][INFO] - Score: 56.10 [%]  |  Evaluation Time: 10.68 [s]
[2024-10-18 22:23:50,469][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-18 22:23:50,469][root][INFO] - Score: 56.93 [%]  |  Evaluation Time: 20.45 [s]
[2024-10-18 22:23:50,470][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-18 22:23:50,471][root][INFO] - 
[2/ 5 Epoch]
[2024-10-18 22:31:03,620][root][INFO] - Step: 63000/63000  |  Loss: 1.2929  |  Score: 33.21 [%]  |  Seq Length: 256.0
[2024-10-18 22:31:08,067][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-18 22:31:08,067][root][INFO] - Score: 31.57 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-18 22:31:16,092][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-18 22:31:16,092][root][INFO] - Score: 31.13 [%]  |  Evaluation Time: 8.02 [s]
[2024-10-18 22:31:16,093][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-18 22:31:16,094][root][INFO] - - Epoch: 1
[2024-10-18 22:31:16,094][root][INFO] - - DEV score: 61.22 [%]
[2024-10-18 22:31:16,094][root][INFO] - - TEST score: 59.99 [%]
[2024-10-18 22:31:16,095][root][INFO] - Fine-tuning is done!
[2024-10-18 22:31:16,096][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-18 22:31:16,096][root][INFO] - - BEST LR: 0.01
[2024-10-18 22:31:16,096][root][INFO] - - DEV score: 74.72 [%]
[2024-10-18 22:31:16,096][root][INFO] - - TEST score: 75.88 [%]
[2024-10-18 23:10:53,322][root][INFO] - Step: 20000/73665  |  Loss: 1.0698  |  Score: 41.69 [%]  |  Seq Length: 256.0
[2024-10-18 23:22:56,894][root][INFO] - Step: 39642/66070  |  Loss: nan  |  Score: 33.64 [%]  |  Seq Length: 256.0
[2024-10-18 23:23:05,588][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-18 23:23:05,588][root][INFO] - Score: 34.91 [%]  |  Evaluation Time: 8.69 [s]
[2024-10-18 23:23:21,572][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-18 23:23:21,572][root][INFO] - Score: 34.91 [%]  |  Evaluation Time: 15.98 [s]
[2024-10-18 23:23:21,578][root][INFO] - 
[4/ 5 Epoch]
[2024-10-18 23:26:32,827][root][INFO] - Step: 40000/66070  |  Loss: nan  |  Score: 34.24 [%]  |  Seq Length: 256.0
[2024-10-19 00:34:39,137][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.31 [%]  |  Seq Length: 256.0
[2024-10-19 00:34:49,668][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-19 00:34:49,668][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.53 [s]
[2024-10-19 00:35:09,962][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-19 00:35:09,963][root][INFO] - Score: 33.59 [%]  |  Evaluation Time: 20.29 [s]
[2024-10-19 00:35:09,965][root][INFO] - 
[3/ 5 Epoch]
[2024-10-19 00:39:54,012][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-19 00:54:30,349][root][INFO] - Step: 50000/66070  |  Loss: nan  |  Score: 33.59 [%]  |  Seq Length: 256.0
[2024-10-19 01:19:28,653][root][INFO] - Step: 52856/66070  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-19 01:19:36,943][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-19 01:19:36,944][root][INFO] - Score: 34.97 [%]  |  Evaluation Time: 8.29 [s]
[2024-10-19 01:19:52,445][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-19 01:19:52,446][root][INFO] - Score: 34.86 [%]  |  Evaluation Time: 15.50 [s]
[2024-10-19 01:19:52,448][root][INFO] - 
[5/ 5 Epoch]
[2024-10-19 02:08:05,412][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-19 02:22:42,506][root][INFO] - Step: 60000/66070  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-19 02:45:02,898][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-19 02:45:13,333][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-19 02:45:13,333][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-19 02:45:33,782][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-19 02:45:33,782][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.45 [s]
[2024-10-19 02:45:33,784][root][INFO] - 
[4/ 5 Epoch]
[2024-10-19 03:15:49,993][root][INFO] - Step: 66070/66070  |  Loss: nan  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-19 03:15:58,317][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-19 03:15:58,317][root][INFO] - Score: 34.68 [%]  |  Evaluation Time: 8.32 [s]
[2024-10-19 03:16:13,830][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-19 03:16:13,830][root][INFO] - Score: 34.74 [%]  |  Evaluation Time: 15.51 [s]
[2024-10-19 03:16:13,831][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-19 03:16:13,831][root][INFO] - - Epoch: 1
[2024-10-19 03:16:13,831][root][INFO] - - DEV score: 59.61 [%]
[2024-10-19 03:16:13,831][root][INFO] - - TEST score: 59.62 [%]
[2024-10-19 03:16:13,832][root][INFO] - Fine-tuning is done!
[2024-10-19 03:16:13,833][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-19 03:16:13,833][root][INFO] - - BEST LR: 0.01
[2024-10-19 03:16:13,833][root][INFO] - - DEV score: 75.53 [%]
[2024-10-19 03:16:13,833][root][INFO] - - TEST score: 75.81 [%]
[2024-10-19 03:36:47,095][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-19 04:55:31,987][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-19 04:55:42,464][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-19 04:55:42,464][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.47 [s]
[2024-10-19 04:56:02,923][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-19 04:56:02,923][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.46 [s]
[2024-10-19 04:56:02,925][root][INFO] - 
[5/ 5 Epoch]
[2024-10-19 05:05:20,139][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-19 06:33:16,518][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.26 [%]  |  Seq Length: 256.0
[2024-10-19 07:05:19,028][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.45 [%]  |  Seq Length: 256.0
[2024-10-19 07:05:29,351][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-19 07:05:29,351][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.32 [s]
[2024-10-19 07:05:49,359][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-19 07:05:49,359][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 20.01 [s]
[2024-10-19 07:05:49,360][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-19 07:05:49,360][root][INFO] - - Epoch: 1
[2024-10-19 07:05:49,360][root][INFO] - - DEV score: 56.10 [%]
[2024-10-19 07:05:49,360][root][INFO] - - TEST score: 56.93 [%]
[2024-10-19 07:05:49,361][root][INFO] - Fine-tuning is done!
[2024-10-19 07:05:49,362][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-19 07:05:49,362][root][INFO] - - BEST LR: 0.01
[2024-10-19 07:05:49,362][root][INFO] - - DEV score: 74.99 [%]
[2024-10-19 07:05:49,362][root][INFO] - - TEST score: 76.27 [%]
[2024-10-20 06:19:13,631][root][INFO] - 

[2024-10-20 06:19:13,632][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:19:13,632][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:19:13,632][root][INFO] - 

[2024-10-20 06:19:13,632][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:19:16,496][root][INFO] - 

[2024-10-20 06:19:16,496][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:19:16,496][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-20 06:19:16,496][root][INFO] - 

[2024-10-20 06:19:16,496][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:19:31,428][root][INFO] - 

[2024-10-20 06:19:31,428][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:19:31,428][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:19:31,428][root][INFO] - 

[2024-10-20 06:19:31,428][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:20:06,856][root][INFO] - 

[2024-10-20 06:20:06,856][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:20:06,856][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:20:06,856][root][INFO] - 

[2024-10-20 06:20:06,856][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:20:10,920][root][INFO] - 

[2024-10-20 06:20:10,920][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:20:10,920][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 06:20:10,920][root][INFO] - 

[2024-10-20 06:20:10,920][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:20:29,449][root][INFO] - 

[2024-10-20 06:20:29,449][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:20:29,449][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:20:29,449][root][INFO] - 

[2024-10-20 06:20:29,449][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:21:56,378][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,379][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,379][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,379][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,380][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,380][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,381][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,381][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,382][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,382][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,382][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,383][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,383][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,384][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,384][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,384][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,385][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,385][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,386][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,386][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,387][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,387][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,388][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:21:56,388][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:21:56,389][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:21:56,616][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:22:02,681][root][INFO] - 

[2024-10-20 06:22:02,681][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:22:02,681][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:22:02,681][root][INFO] - 

[2024-10-20 06:22:02,681][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:22:11,137][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,138][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,138][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,139][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,139][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,140][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,140][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,141][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,141][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,142][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,142][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,143][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,143][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,144][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,144][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,145][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,145][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,146][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,146][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,147][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,148][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,149][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,149][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:11,150][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:11,152][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:22:11,380][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:22:15,603][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,604][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,605][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,605][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,606][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,606][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,607][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,607][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,608][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,608][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,608][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,609][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,609][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,610][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,610][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,611][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,611][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,612][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,612][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,613][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,613][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,614][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,614][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:22:15,615][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:22:15,616][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:22:15,880][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:22:17,166][root][INFO] - 

[2024-10-20 06:22:17,166][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:22:17,166][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:22:17,166][root][INFO] - 

[2024-10-20 06:22:17,166][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:22:22,096][root][INFO] - 

[2024-10-20 06:22:22,096][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:22:22,096][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 06:22:22,097][root][INFO] - 

[2024-10-20 06:22:22,097][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:23:51,867][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,868][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,869][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,869][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,870][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,871][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,871][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,872][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,873][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,873][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,874][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,875][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,876][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,877][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,878][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,879][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,880][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,881][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,882][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,883][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,885][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,886][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,887][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:23:51,888][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:23:51,891][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:23:51,898][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 06:23:52,103][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 06:23:52,105][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-20 06:23:52,336][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:23:58,508][root][INFO] - 

[2024-10-20 06:23:58,508][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:23:58,508][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-20 06:23:58,508][root][INFO] - 

[2024-10-20 06:23:58,508][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:24:00,332][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,332][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,333][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,333][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,334][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,334][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,335][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,335][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,336][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,336][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,337][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,337][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,337][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,338][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,338][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,339][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,339][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,340][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,340][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,341][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,342][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,343][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,343][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:00,344][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:00,345][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:24:00,349][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 06:24:00,604][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 06:24:00,607][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-20 06:24:00,854][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:24:07,078][root][INFO] - 

[2024-10-20 06:24:07,078][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:24:07,078][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs
[2024-10-20 06:24:07,078][root][INFO] - 

[2024-10-20 06:24:07,078][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:24:31,021][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,022][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,022][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,023][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,023][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,024][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,024][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,025][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,025][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,025][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,026][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,026][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,027][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,027][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,028][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,028][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,029][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,029][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,030][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,030][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,031][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,031][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,032][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:24:31,032][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:24:31,034][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:24:31,038][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 06:24:31,238][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 06:24:31,240][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-20 06:24:31,499][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:24:37,828][root][INFO] - 

[2024-10-20 06:24:37,828][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:24:37,828][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs
[2024-10-20 06:24:37,828][root][INFO] - 

[2024-10-20 06:24:37,828][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:25:49,391][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,392][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,392][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,393][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,393][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,394][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,394][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,394][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,395][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,395][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,396][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,396][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,397][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,397][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,397][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,398][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,398][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,399][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,399][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,400][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,400][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,400][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,401][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:49,401][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:49,403][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:25:49,645][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:25:52,193][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,193][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,194][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,194][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,195][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,195][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,196][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,196][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,197][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,197][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,197][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,198][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,198][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,199][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,199][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,200][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,200][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,201][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,201][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,202][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,203][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,204][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,204][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:25:52,205][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:25:52,206][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:25:52,449][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:25:58,387][root][INFO] - 

[2024-10-20 06:25:58,387][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:25:58,387][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs
[2024-10-20 06:25:58,387][root][INFO] - 

[2024-10-20 06:25:58,387][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:26:42,620][root][INFO] - 

[2024-10-20 06:26:42,621][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:26:42,621][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:26:42,621][root][INFO] - 

[2024-10-20 06:26:42,621][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:26:44,240][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,240][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,241][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,241][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,242][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,242][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,243][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,243][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,243][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,244][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,244][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,245][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,245][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,245][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,246][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,246][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,247][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,247][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,247][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,248][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,248][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,249][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,249][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:26:44,250][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:26:44,251][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:26:44,490][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:26:50,383][root][INFO] - 

[2024-10-20 06:26:50,384][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:26:50,384][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs
[2024-10-20 06:26:50,384][root][INFO] - 

[2024-10-20 06:26:50,384][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:26:57,563][root][INFO] - 

[2024-10-20 06:26:57,563][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:26:57,563][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:26:57,563][root][INFO] - 

[2024-10-20 06:26:57,564][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:27:04,475][root][INFO] - 

[2024-10-20 06:27:04,476][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:27:04,476][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 06:27:04,476][root][INFO] - 

[2024-10-20 06:27:04,476][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:27:14,314][root][INFO] - 

[2024-10-20 06:27:14,314][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:27:14,314][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:27:14,314][root][INFO] - 

[2024-10-20 06:27:14,314][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:28:47,675][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,676][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,676][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,677][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,677][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,678][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,678][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,679][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,679][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,680][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,680][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,681][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,681][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,682][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,682][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,683][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,683][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,684][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,684][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,685][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,685][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,686][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,686][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:47,687][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:47,689][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:28:47,934][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:28:49,843][root][INFO] - 

[2024-10-20 06:28:49,843][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 06:28:49,843][root][INFO] - Data Preprocessing
[2024-10-20 06:28:49,843][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-20 06:28:49,843][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 06:28:49,843][root][INFO] - ㄴ data_remove                True

[2024-10-20 06:28:49,843][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 06:28:49,851][root][INFO] - vocab size              : 51200
[2024-10-20 06:28:49,851][root][INFO] - device                  : gpu
[2024-10-20 06:28:49,851][root][INFO] - random seed             : 1
[2024-10-20 06:28:49,851][root][INFO] - train data size         : 845696
[2024-10-20 06:28:49,851][root][INFO] - max epochs              : 5
[2024-10-20 06:28:49,851][root][INFO] - total steps             : 66070
[2024-10-20 06:28:49,851][root][INFO] - warmup steps            : 6607
[2024-10-20 06:28:49,852][root][INFO] - batch size              : 64
[2024-10-20 06:28:49,852][root][INFO] - accumulation steps      : 1
[2024-10-20 06:28:49,852][root][INFO] - optimizer               : adamwscale
[2024-10-20 06:28:49,852][root][INFO] - lr_scheduler            : cosine
[2024-10-20 06:28:49,852][root][INFO] - learning rate           : 0.01
[2024-10-20 06:28:49,852][root][INFO] - max length              : 256

[2024-10-20 06:28:49,852][root][INFO] - LoRA Configuration
[2024-10-20 06:28:49,852][root][INFO] - ㄴ r                    : 32
[2024-10-20 06:28:49,852][root][INFO] - ㄴ alpha                : 128
[2024-10-20 06:28:49,852][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 06:28:49,852][root][INFO] - 

[2024-10-20 06:28:49,853][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:28:49,853][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 06:28:49,853][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 06:28:49,853][root][INFO] - * tb interval   : 10000

[2024-10-20 06:28:49,853][root][INFO] - 

[2024-10-20 06:28:49,853][root][INFO] - Start the Training !
[2024-10-20 06:28:49,856][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 06:28:56,546][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,546][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,547][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,547][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,548][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,548][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,549][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,549][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,550][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,550][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,551][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,551][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,552][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,552][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,553][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,553][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,554][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,554][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,555][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,555][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,557][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,557][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,558][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:28:56,558][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:28:56,560][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:28:56,789][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:28:58,694][root][INFO] - 

[2024-10-20 06:28:58,695][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 06:28:58,695][root][INFO] - Data Preprocessing
[2024-10-20 06:28:58,695][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 06:28:58,695][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 06:28:58,695][root][INFO] - ㄴ data_remove                True

[2024-10-20 06:28:58,695][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 06:28:58,703][root][INFO] - vocab size              : 51200
[2024-10-20 06:28:58,703][root][INFO] - device                  : gpu
[2024-10-20 06:28:58,703][root][INFO] - random seed             : 1
[2024-10-20 06:28:58,703][root][INFO] - train data size         : 806400
[2024-10-20 06:28:58,703][root][INFO] - max epochs              : 5
[2024-10-20 06:28:58,703][root][INFO] - total steps             : 63000
[2024-10-20 06:28:58,704][root][INFO] - warmup steps            : 6300
[2024-10-20 06:28:58,704][root][INFO] - batch size              : 64
[2024-10-20 06:28:58,704][root][INFO] - accumulation steps      : 1
[2024-10-20 06:28:58,704][root][INFO] - optimizer               : adamwscale
[2024-10-20 06:28:58,704][root][INFO] - lr_scheduler            : cosine
[2024-10-20 06:28:58,704][root][INFO] - learning rate           : 0.01
[2024-10-20 06:28:58,704][root][INFO] - max length              : 256

[2024-10-20 06:28:58,704][root][INFO] - LoRA Configuration
[2024-10-20 06:28:58,704][root][INFO] - ㄴ r                    : 32
[2024-10-20 06:28:58,704][root][INFO] - ㄴ alpha                : 128
[2024-10-20 06:28:58,704][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 06:28:58,705][root][INFO] - 

[2024-10-20 06:28:58,705][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:28:58,705][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 06:28:58,705][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 06:28:58,705][root][INFO] - * tb interval   : 10000

[2024-10-20 06:28:58,705][root][INFO] - 

[2024-10-20 06:28:58,705][root][INFO] - Start the Training !
[2024-10-20 06:28:58,708][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 06:29:14,232][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,232][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,233][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,233][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,234][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,234][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,235][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,235][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,235][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,236][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,236][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,237][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,237][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,237][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,238][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,238][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,239][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,239][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,239][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,240][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,240][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,241][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,241][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:29:14,242][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:29:14,243][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:29:14,496][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:29:16,420][root][INFO] - 

[2024-10-20 06:29:16,420][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 06:29:16,420][root][INFO] - Data Preprocessing
[2024-10-20 06:29:16,420][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-20 06:29:16,420][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 06:29:16,421][root][INFO] - ㄴ data_remove                False

[2024-10-20 06:29:16,421][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 06:29:16,428][root][INFO] - vocab size              : 51200
[2024-10-20 06:29:16,429][root][INFO] - device                  : gpu
[2024-10-20 06:29:16,429][root][INFO] - random seed             : 1
[2024-10-20 06:29:16,429][root][INFO] - train data size         : 942912
[2024-10-20 06:29:16,429][root][INFO] - max epochs              : 5
[2024-10-20 06:29:16,429][root][INFO] - total steps             : 73665
[2024-10-20 06:29:16,429][root][INFO] - warmup steps            : 7366
[2024-10-20 06:29:16,429][root][INFO] - batch size              : 64
[2024-10-20 06:29:16,429][root][INFO] - accumulation steps      : 1
[2024-10-20 06:29:16,429][root][INFO] - optimizer               : adamwscale
[2024-10-20 06:29:16,430][root][INFO] - lr_scheduler            : cosine
[2024-10-20 06:29:16,430][root][INFO] - learning rate           : 0.01
[2024-10-20 06:29:16,430][root][INFO] - max length              : 256

[2024-10-20 06:29:16,430][root][INFO] - LoRA Configuration
[2024-10-20 06:29:16,430][root][INFO] - ㄴ r                    : 32
[2024-10-20 06:29:16,430][root][INFO] - ㄴ alpha                : 128
[2024-10-20 06:29:16,430][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 06:29:16,430][root][INFO] - 

[2024-10-20 06:29:16,430][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 06:29:16,430][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-20 06:29:16,431][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-20 06:29:16,431][root][INFO] - * tb interval   : 10000

[2024-10-20 06:29:16,431][root][INFO] - 

[2024-10-20 06:29:16,431][root][INFO] - Start the Training !
[2024-10-20 06:29:16,434][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 06:32:03,016][root][INFO] - 

[2024-10-20 06:32:03,017][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:32:03,017][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:32:03,017][root][INFO] - 

[2024-10-20 06:32:03,017][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:32:07,584][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,585][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,585][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,586][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,586][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,587][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,587][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,587][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,588][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,588][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,589][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,589][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,590][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,590][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,590][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,591][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,591][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,592][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,592][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,592][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,598][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,599][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,599][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:32:07,599][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:32:07,601][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-20 06:32:07,791][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:32:09,664][root][INFO] - 

[2024-10-20 06:32:09,664][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-20 06:32:09,664][root][INFO] - Data Preprocessing
[2024-10-20 06:32:09,664][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 06:32:09,665][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 06:32:09,665][root][INFO] - ㄴ data_remove                True

[2024-10-20 06:32:09,665][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 06:32:09,675][root][INFO] - vocab size              : 51200
[2024-10-20 06:32:09,675][root][INFO] - device                  : gpu
[2024-10-20 06:32:09,675][root][INFO] - random seed             : 1
[2024-10-20 06:32:09,675][root][INFO] - train data size         : 4096
[2024-10-20 06:32:09,675][root][INFO] - max epochs              : 15
[2024-10-20 06:32:09,675][root][INFO] - total steps             : 960
[2024-10-20 06:32:09,675][root][INFO] - warmup steps            : 96
[2024-10-20 06:32:09,675][root][INFO] - batch size              : 64
[2024-10-20 06:32:09,675][root][INFO] - accumulation steps      : 1
[2024-10-20 06:32:09,676][root][INFO] - optimizer               : adamwscale
[2024-10-20 06:32:09,676][root][INFO] - lr_scheduler            : cosine
[2024-10-20 06:32:09,676][root][INFO] - learning rate           : 0.01
[2024-10-20 06:32:09,676][root][INFO] - max length              : 256

[2024-10-20 06:32:09,676][root][INFO] - LoRA Configuration
[2024-10-20 06:32:09,676][root][INFO] - ㄴ r                    : 32
[2024-10-20 06:32:09,676][root][INFO] - ㄴ alpha                : 128
[2024-10-20 06:32:09,676][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 06:32:09,676][root][INFO] - 

[2024-10-20 06:32:09,676][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:32:09,676][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 06:32:09,677][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 06:32:09,677][root][INFO] - * tb interval   : 10000

[2024-10-20 06:32:09,677][root][INFO] - 

[2024-10-20 06:32:09,677][root][INFO] - Start the Training !
[2024-10-20 06:32:09,680][root][INFO] - 
[1/ 15 Epoch]
[2024-10-20 06:32:34,617][root][INFO] - Step: 64/960  |  Loss: 3.0314  |  Score: 23.98 [%]  |  Seq Length: 256.0
[2024-10-20 06:32:37,524][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 06:32:37,525][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 2.90 [s]
[2024-10-20 06:32:40,362][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 06:32:40,362][root][INFO] - Score: 63.32 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-20 06:32:40,363][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 06:32:40,364][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 06:32:41,329][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 06:32:41,356][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 06:32:41,357][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 06:32:41,357][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 06:32:41,357][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 06:32:41,357][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 06:32:41,358][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 06:32:42,055][root][INFO] - 
[2/ 15 Epoch]
[2024-10-20 06:33:05,823][root][INFO] - Step: 128/960  |  Loss: 1.3288  |  Score: 65.16 [%]  |  Seq Length: 256.0
[2024-10-20 06:33:08,689][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 06:33:08,689][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-20 06:33:11,532][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 06:33:11,532][root][INFO] - Score: 69.33 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-20 06:33:11,533][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 06:33:11,533][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 06:33:13,103][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 06:33:13,451][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 06:33:13,453][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 06:33:13,453][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 06:33:13,453][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 06:33:13,454][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 06:33:13,457][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 06:33:15,100][root][INFO] - 
[3/ 15 Epoch]
[2024-10-20 06:33:38,929][root][INFO] - Step: 192/960  |  Loss: 1.1536  |  Score: 69.98 [%]  |  Seq Length: 256.0
[2024-10-20 06:33:41,789][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 06:33:41,790][root][INFO] - Score: 77.16 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-20 06:33:44,651][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 06:33:44,651][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-20 06:33:44,652][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 06:33:44,652][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 06:33:46,167][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 06:33:46,214][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 06:33:46,215][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 06:33:46,215][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 06:33:46,215][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 06:33:46,215][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 06:33:46,217][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 06:33:47,608][root][INFO] - 
[4/ 15 Epoch]
[2024-10-20 06:34:11,620][root][INFO] - 

[2024-10-20 06:34:11,620][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 06:34:11,621][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:34:11,621][root][INFO] - 

[2024-10-20 06:34:11,621][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 06:35:53,704][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,705][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,706][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,706][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,707][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,707][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,708][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,708][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,709][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,709][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,710][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,710][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,711][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,711][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,712][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,712][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,713][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,713][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,714][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,714][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,716][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,716][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,717][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 06:35:53,717][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 06:35:53,719][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 06:35:53,946][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 06:35:55,975][root][INFO] - 

[2024-10-20 06:35:55,975][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 06:35:55,975][root][INFO] - Data Preprocessing
[2024-10-20 06:35:55,975][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 06:35:55,975][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 06:35:55,975][root][INFO] - ㄴ data_remove                True

[2024-10-20 06:35:55,975][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 06:35:55,983][root][INFO] - vocab size              : 51200
[2024-10-20 06:35:55,983][root][INFO] - device                  : gpu
[2024-10-20 06:35:55,983][root][INFO] - random seed             : 1
[2024-10-20 06:35:55,983][root][INFO] - train data size         : 806400
[2024-10-20 06:35:55,983][root][INFO] - max epochs              : 5
[2024-10-20 06:35:55,984][root][INFO] - total steps             : 63000
[2024-10-20 06:35:55,984][root][INFO] - warmup steps            : 6300
[2024-10-20 06:35:55,984][root][INFO] - batch size              : 64
[2024-10-20 06:35:55,984][root][INFO] - accumulation steps      : 1
[2024-10-20 06:35:55,984][root][INFO] - optimizer               : adamwscale
[2024-10-20 06:35:55,984][root][INFO] - lr_scheduler            : cosine
[2024-10-20 06:35:55,984][root][INFO] - learning rate           : 0.01
[2024-10-20 06:35:55,984][root][INFO] - max length              : 256

[2024-10-20 06:35:55,984][root][INFO] - LoRA Configuration
[2024-10-20 06:35:55,984][root][INFO] - ㄴ r                    : 32
[2024-10-20 06:35:55,984][root][INFO] - ㄴ alpha                : 128
[2024-10-20 06:35:55,984][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 06:35:55,985][root][INFO] - 

[2024-10-20 06:35:55,985][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 06:35:55,985][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 06:35:55,985][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 06:35:55,985][root][INFO] - * tb interval   : 10000

[2024-10-20 06:35:55,985][root][INFO] - 

[2024-10-20 06:35:55,985][root][INFO] - Start the Training !
[2024-10-20 06:35:55,988][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 07:30:18,481][root][INFO] - Step: 10000/73665  |  Loss: 0.7315  |  Score: 68.32 [%]  |  Seq Length: 256.0
[2024-10-20 07:30:30,413][root][INFO] - Step: 10000/66070  |  Loss: 0.7213  |  Score: 68.88 [%]  |  Seq Length: 256.0
[2024-10-20 07:37:07,241][root][INFO] - Step: 10000/63000  |  Loss: 0.7208  |  Score: 68.89 [%]  |  Seq Length: 256.0
[2024-10-20 07:50:19,404][root][INFO] - Step: 13214/66070  |  Loss: 0.6525  |  Score: 72.69 [%]  |  Seq Length: 256.0
[2024-10-20 07:50:24,354][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 07:50:24,354][root][INFO] - Score: 70.66 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-20 07:50:33,463][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 07:50:33,463][root][INFO] - Score: 70.93 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-20 07:50:33,464][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 07:50:33,464][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 07:50:34,307][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 07:50:34,333][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 07:50:34,333][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 07:50:34,333][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 07:50:34,333][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 07:50:34,333][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 07:50:34,334][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 07:50:35,018][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 07:52:59,130][root][INFO] - Step: 12600/63000  |  Loss: 0.6512  |  Score: 72.77 [%]  |  Seq Length: 256.0
[2024-10-20 07:53:03,394][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 07:53:03,394][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 4.26 [s]
[2024-10-20 07:53:11,266][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 07:53:11,266][root][INFO] - Score: 72.06 [%]  |  Evaluation Time: 7.87 [s]
[2024-10-20 07:53:11,267][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 07:53:11,267][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 07:53:12,124][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 07:53:12,150][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 07:53:12,150][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 07:53:12,150][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 07:53:12,150][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 07:53:12,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 07:53:12,152][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 07:53:12,826][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 07:59:12,227][root][INFO] - Step: 14733/73665  |  Loss: 0.6617  |  Score: 72.26 [%]  |  Seq Length: 256.0
[2024-10-20 07:59:18,342][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 07:59:18,342][root][INFO] - Score: 71.49 [%]  |  Evaluation Time: 6.11 [s]
[2024-10-20 07:59:30,079][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 07:59:30,080][root][INFO] - Score: 73.01 [%]  |  Evaluation Time: 11.74 [s]
[2024-10-20 07:59:30,081][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 07:59:30,081][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 07:59:30,915][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 07:59:30,941][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 07:59:30,941][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 07:59:30,941][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 07:59:30,941][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 07:59:30,941][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 07:59:30,942][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 07:59:31,530][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 08:31:43,614][root][INFO] - Step: 20000/73665  |  Loss: 0.6365  |  Score: 73.57 [%]  |  Seq Length: 256.0
[2024-10-20 08:32:29,180][root][INFO] - Step: 20000/66070  |  Loss: 0.6259  |  Score: 74.08 [%]  |  Seq Length: 256.0
[2024-10-20 08:38:27,655][root][INFO] - Step: 20000/63000  |  Loss: 0.6252  |  Score: 74.09 [%]  |  Seq Length: 256.0
[2024-10-20 09:10:16,545][root][INFO] - Step: 25200/63000  |  Loss: 0.6145  |  Score: 74.78 [%]  |  Seq Length: 256.0
[2024-10-20 09:10:20,799][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 09:10:20,799][root][INFO] - Score: 72.02 [%]  |  Evaluation Time: 4.25 [s]
[2024-10-20 09:10:28,652][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 09:10:28,652][root][INFO] - Score: 72.68 [%]  |  Evaluation Time: 7.85 [s]
[2024-10-20 09:10:28,653][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 09:10:28,653][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 09:10:30,236][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 09:10:30,266][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 09:10:30,267][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 09:10:30,267][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 09:10:30,267][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 09:10:30,267][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 09:10:30,268][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 09:10:31,696][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 09:12:10,818][root][INFO] - Step: 26428/66070  |  Loss: 0.6189  |  Score: 74.44 [%]  |  Seq Length: 256.0
[2024-10-20 09:12:15,752][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 09:12:15,752][root][INFO] - Score: 71.96 [%]  |  Evaluation Time: 4.93 [s]
[2024-10-20 09:12:24,914][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 09:12:24,915][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-20 09:12:24,916][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 09:12:24,918][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 09:12:26,469][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 09:12:26,499][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 09:12:26,500][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 09:12:26,500][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 09:12:26,500][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 09:12:26,500][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 09:12:26,501][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 09:12:27,928][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 09:29:36,259][root][INFO] - Step: 29466/73665  |  Loss: 0.6283  |  Score: 73.96 [%]  |  Seq Length: 256.0
[2024-10-20 09:29:42,357][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 09:29:42,357][root][INFO] - Score: 72.30 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-20 09:29:54,167][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 09:29:54,167][root][INFO] - Score: 73.57 [%]  |  Evaluation Time: 11.81 [s]
[2024-10-20 09:29:54,168][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 09:29:54,169][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 09:29:55,749][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 09:29:55,780][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 09:29:55,781][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 09:29:55,781][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 09:29:55,781][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 09:29:55,781][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 09:29:55,782][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 09:29:57,224][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 09:33:13,409][root][INFO] - Step: 30000/73665  |  Loss: 0.5979  |  Score: 75.57 [%]  |  Seq Length: 256.0
[2024-10-20 09:34:31,898][root][INFO] - Step: 30000/66070  |  Loss: 0.5910  |  Score: 75.75 [%]  |  Seq Length: 256.0
[2024-10-20 09:39:53,028][root][INFO] - Step: 30000/63000  |  Loss: 0.5870  |  Score: 76.00 [%]  |  Seq Length: 256.0
[2024-10-20 10:27:33,516][root][INFO] - Step: 37800/63000  |  Loss: 0.5768  |  Score: 76.42 [%]  |  Seq Length: 256.0
[2024-10-20 10:27:37,799][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 10:27:37,799][root][INFO] - Score: 73.81 [%]  |  Evaluation Time: 4.28 [s]
[2024-10-20 10:27:45,786][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 10:27:45,786][root][INFO] - Score: 74.15 [%]  |  Evaluation Time: 7.98 [s]
[2024-10-20 10:27:45,787][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 10:27:45,787][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 10:27:47,345][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 10:27:47,378][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 10:27:47,379][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 10:27:47,379][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 10:27:47,379][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 10:27:47,379][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 10:27:47,380][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 10:27:48,931][root][INFO] - 
[4/ 5 Epoch]
[2024-10-20 10:33:59,822][root][INFO] - Step: 39642/66070  |  Loss: 0.5808  |  Score: 76.24 [%]  |  Seq Length: 256.0
[2024-10-20 10:34:04,735][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 10:34:04,735][root][INFO] - Score: 73.16 [%]  |  Evaluation Time: 4.91 [s]
[2024-10-20 10:34:13,858][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 10:34:13,858][root][INFO] - Score: 73.95 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-20 10:34:13,859][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 10:34:13,859][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 10:34:15,596][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 10:34:15,626][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 10:34:15,626][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 10:34:15,627][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 10:34:15,627][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 10:34:15,627][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 10:34:15,628][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 10:34:17,189][root][INFO] - 
[4/ 5 Epoch]
[2024-10-20 10:34:22,334][root][INFO] - Step: 40000/73665  |  Loss: 0.5976  |  Score: 75.48 [%]  |  Seq Length: 256.0
[2024-10-20 10:36:30,071][root][INFO] - Step: 40000/66070  |  Loss: 0.5465  |  Score: 77.66 [%]  |  Seq Length: 256.0
[2024-10-20 10:41:16,574][root][INFO] - Step: 40000/63000  |  Loss: 0.5433  |  Score: 78.04 [%]  |  Seq Length: 256.0
[2024-10-20 11:00:02,852][root][INFO] - Step: 44199/73665  |  Loss: 0.5852  |  Score: 75.95 [%]  |  Seq Length: 256.0
[2024-10-20 11:00:08,960][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 11:00:08,960][root][INFO] - Score: 73.68 [%]  |  Evaluation Time: 6.10 [s]
[2024-10-20 11:00:20,715][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 11:00:20,715][root][INFO] - Score: 75.01 [%]  |  Evaluation Time: 11.75 [s]
[2024-10-20 11:00:20,716][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 11:00:20,716][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 11:00:22,259][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 11:00:22,308][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 11:00:22,309][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 11:00:22,309][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 11:00:22,309][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 11:00:22,309][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 11:00:22,310][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 11:00:23,724][root][INFO] - 
[4/ 5 Epoch]
[2024-10-20 11:35:49,997][root][INFO] - Step: 50000/73665  |  Loss: 0.5525  |  Score: 77.53 [%]  |  Seq Length: 256.0
[2024-10-20 11:38:10,509][root][INFO] - Step: 50000/66070  |  Loss: 0.5364  |  Score: 78.40 [%]  |  Seq Length: 256.0
[2024-10-20 11:42:23,653][root][INFO] - Step: 50000/63000  |  Loss: 0.5296  |  Score: 78.65 [%]  |  Seq Length: 256.0
[2024-10-20 11:44:50,082][root][INFO] - Step: 50400/63000  |  Loss: 0.5262  |  Score: 78.71 [%]  |  Seq Length: 256.0
[2024-10-20 11:44:54,479][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 11:44:54,479][root][INFO] - Score: 74.05 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-20 11:45:02,316][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 11:45:02,316][root][INFO] - Score: 75.07 [%]  |  Evaluation Time: 7.83 [s]
[2024-10-20 11:45:02,317][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-20 11:45:02,317][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 11:45:03,908][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 11:45:03,937][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 11:45:03,938][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 11:45:03,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 11:45:03,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 11:45:03,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 11:45:03,939][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 11:45:05,495][root][INFO] - 
[5/ 5 Epoch]
[2024-10-20 11:55:50,040][root][INFO] - Step: 52856/66070  |  Loss: 0.5261  |  Score: 78.75 [%]  |  Seq Length: 256.0
[2024-10-20 11:55:54,976][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 11:55:54,976][root][INFO] - Score: 74.76 [%]  |  Evaluation Time: 4.93 [s]
[2024-10-20 11:56:04,208][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 11:56:04,208][root][INFO] - Score: 75.42 [%]  |  Evaluation Time: 9.23 [s]
[2024-10-20 11:56:04,210][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-20 11:56:04,211][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 11:56:05,872][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 11:56:05,907][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 11:56:05,908][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 11:56:05,908][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 11:56:05,908][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 11:56:05,908][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 11:56:05,909][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 11:56:07,485][root][INFO] - 
[5/ 5 Epoch]
[2024-10-20 12:30:21,348][root][INFO] - Step: 58932/73665  |  Loss: 0.5409  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-20 12:30:27,429][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 12:30:27,429][root][INFO] - Score: 75.52 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-20 12:30:39,171][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 12:30:39,171][root][INFO] - Score: 76.29 [%]  |  Evaluation Time: 11.74 [s]
[2024-10-20 12:30:39,172][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-20 12:30:39,172][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 12:30:40,733][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 12:30:40,763][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 12:30:40,764][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 12:30:40,764][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 12:30:40,764][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 12:30:40,764][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 12:30:40,765][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 12:30:42,158][root][INFO] - 
[5/ 5 Epoch]
[2024-10-20 12:37:13,689][root][INFO] - Step: 60000/73665  |  Loss: 0.5099  |  Score: 79.35 [%]  |  Seq Length: 256.0
[2024-10-20 12:40:14,581][root][INFO] - Step: 60000/66070  |  Loss: 0.4990  |  Score: 80.08 [%]  |  Seq Length: 256.0
[2024-10-20 12:43:43,806][root][INFO] - Step: 60000/63000  |  Loss: 0.4953  |  Score: 80.27 [%]  |  Seq Length: 256.0
[2024-10-20 13:02:02,880][root][INFO] - Step: 63000/63000  |  Loss: 0.4937  |  Score: 80.29 [%]  |  Seq Length: 256.0
[2024-10-20 13:02:07,130][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 13:02:07,131][root][INFO] - Score: 74.72 [%]  |  Evaluation Time: 4.25 [s]
[2024-10-20 13:02:14,970][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 13:02:14,970][root][INFO] - Score: 75.88 [%]  |  Evaluation Time: 7.84 [s]
[2024-10-20 13:02:14,971][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-20 13:02:14,971][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 13:02:16,524][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 13:02:16,571][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 13:02:16,572][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 13:02:16,572][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 13:02:16,572][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 13:02:16,572][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 13:02:16,573][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 13:02:18,138][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 13:02:18,138][root][INFO] - - Epoch: 5
[2024-10-20 13:02:18,139][root][INFO] - - DEV score: 74.72 [%]
[2024-10-20 13:02:18,139][root][INFO] - - TEST score: 75.88 [%]
[2024-10-20 13:02:18,140][root][INFO] - Fine-tuning is done!
[2024-10-20 13:03:59,061][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,062][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,062][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,063][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,063][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,064][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,064][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,065][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,065][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,066][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,066][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,067][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,067][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,068][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,068][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,068][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,069][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,069][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,070][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,070][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,071][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,072][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,072][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 13:03:59,073][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 13:03:59,075][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 13:03:59,076][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 13:03:59,247][root][INFO] - 

[2024-10-20 13:03:59,247][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 13:03:59,247][root][INFO] - Data Preprocessing
[2024-10-20 13:03:59,247][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 13:03:59,247][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 13:03:59,247][root][INFO] - ㄴ data_remove                True

[2024-10-20 13:03:59,247][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 13:03:59,258][root][INFO] - vocab size              : 51200
[2024-10-20 13:03:59,259][root][INFO] - device                  : gpu
[2024-10-20 13:03:59,259][root][INFO] - random seed             : 1
[2024-10-20 13:03:59,259][root][INFO] - train data size         : 806400
[2024-10-20 13:03:59,259][root][INFO] - max epochs              : 5
[2024-10-20 13:03:59,259][root][INFO] - total steps             : 63000
[2024-10-20 13:03:59,259][root][INFO] - warmup steps            : 6300
[2024-10-20 13:03:59,260][root][INFO] - batch size              : 64
[2024-10-20 13:03:59,260][root][INFO] - accumulation steps      : 1
[2024-10-20 13:03:59,260][root][INFO] - optimizer               : adamwscale
[2024-10-20 13:03:59,260][root][INFO] - lr_scheduler            : cosine
[2024-10-20 13:03:59,260][root][INFO] - learning rate           : 0.02
[2024-10-20 13:03:59,260][root][INFO] - max length              : 256

[2024-10-20 13:03:59,260][root][INFO] - LoRA Configuration
[2024-10-20 13:03:59,260][root][INFO] - ㄴ r                    : 32
[2024-10-20 13:03:59,260][root][INFO] - ㄴ alpha                : 128
[2024-10-20 13:03:59,260][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 13:03:59,260][root][INFO] - 

[2024-10-20 13:03:59,260][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 13:03:59,261][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 13:03:59,261][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 13:03:59,261][root][INFO] - * tb interval   : 10000

[2024-10-20 13:03:59,261][root][INFO] - 

[2024-10-20 13:03:59,261][root][INFO] - Start the Training !
[2024-10-20 13:03:59,263][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 13:17:44,951][root][INFO] - Step: 66070/66070  |  Loss: 0.4948  |  Score: 80.21 [%]  |  Seq Length: 256.0
[2024-10-20 13:17:49,898][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 13:17:49,898][root][INFO] - Score: 75.13 [%]  |  Evaluation Time: 4.94 [s]
[2024-10-20 13:17:59,063][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 13:17:59,064][root][INFO] - Score: 75.64 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-20 13:17:59,065][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-20 13:17:59,065][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 13:18:00,632][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 13:18:00,677][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 13:18:00,678][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 13:18:00,678][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 13:18:00,678][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 13:18:00,678][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 13:18:00,679][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 13:18:02,248][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 13:18:02,249][root][INFO] - - Epoch: 5
[2024-10-20 13:18:02,249][root][INFO] - - DEV score: 75.13 [%]
[2024-10-20 13:18:02,249][root][INFO] - - TEST score: 75.64 [%]
[2024-10-20 13:18:02,251][root][INFO] - Fine-tuning is done!
[2024-10-20 13:19:49,808][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,809][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,810][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,810][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,811][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,811][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,812][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,812][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,813][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,813][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,814][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,814][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,815][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,815][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,816][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,816][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,817][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,818][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,818][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,819][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,819][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,820][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,820][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 13:19:49,821][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 13:19:49,823][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 13:19:49,825][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 13:19:50,001][root][INFO] - 

[2024-10-20 13:19:50,001][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 13:19:50,001][root][INFO] - Data Preprocessing
[2024-10-20 13:19:50,001][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-20 13:19:50,001][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 13:19:50,001][root][INFO] - ㄴ data_remove                True

[2024-10-20 13:19:50,002][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 13:19:50,014][root][INFO] - vocab size              : 51200
[2024-10-20 13:19:50,015][root][INFO] - device                  : gpu
[2024-10-20 13:19:50,015][root][INFO] - random seed             : 1
[2024-10-20 13:19:50,015][root][INFO] - train data size         : 845696
[2024-10-20 13:19:50,015][root][INFO] - max epochs              : 5
[2024-10-20 13:19:50,015][root][INFO] - total steps             : 66070
[2024-10-20 13:19:50,015][root][INFO] - warmup steps            : 6607
[2024-10-20 13:19:50,015][root][INFO] - batch size              : 64
[2024-10-20 13:19:50,016][root][INFO] - accumulation steps      : 1
[2024-10-20 13:19:50,016][root][INFO] - optimizer               : adamwscale
[2024-10-20 13:19:50,016][root][INFO] - lr_scheduler            : cosine
[2024-10-20 13:19:50,016][root][INFO] - learning rate           : 0.02
[2024-10-20 13:19:50,016][root][INFO] - max length              : 256

[2024-10-20 13:19:50,016][root][INFO] - LoRA Configuration
[2024-10-20 13:19:50,016][root][INFO] - ㄴ r                    : 32
[2024-10-20 13:19:50,016][root][INFO] - ㄴ alpha                : 128
[2024-10-20 13:19:50,016][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 13:19:50,016][root][INFO] - 

[2024-10-20 13:19:50,016][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 13:19:50,017][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 13:19:50,017][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 13:19:50,017][root][INFO] - * tb interval   : 10000

[2024-10-20 13:19:50,017][root][INFO] - 

[2024-10-20 13:19:50,017][root][INFO] - Start the Training !
[2024-10-20 13:19:50,019][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 13:38:14,489][root][INFO] - Step: 70000/73665  |  Loss: 0.5071  |  Score: 79.69 [%]  |  Seq Length: 256.0
[2024-10-20 14:00:37,094][root][INFO] - Step: 73665/73665  |  Loss: 0.5052  |  Score: 79.80 [%]  |  Seq Length: 256.0
[2024-10-20 14:00:43,175][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 14:00:43,175][root][INFO] - Score: 75.90 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-20 14:00:54,900][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 14:00:54,901][root][INFO] - Score: 76.35 [%]  |  Evaluation Time: 11.72 [s]
[2024-10-20 14:00:54,902][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-20 14:00:54,902][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 14:00:56,429][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 14:00:56,476][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 14:00:56,477][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 14:00:56,477][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 14:00:56,477][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 14:00:56,477][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 14:00:56,478][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 14:00:57,872][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 14:00:57,872][root][INFO] - - Epoch: 5
[2024-10-20 14:00:57,872][root][INFO] - - DEV score: 75.90 [%]
[2024-10-20 14:00:57,872][root][INFO] - - TEST score: 76.35 [%]
[2024-10-20 14:00:57,873][root][INFO] - Fine-tuning is done!
[2024-10-20 14:02:58,356][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,356][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,357][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,357][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,358][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,358][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,359][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,359][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,360][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,360][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,361][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,361][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,362][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,362][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,363][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,363][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,364][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,364][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,365][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,365][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,366][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,366][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,367][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 14:02:58,368][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 14:02:58,370][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 14:02:58,371][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 14:02:58,559][root][INFO] - 

[2024-10-20 14:02:58,560][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 14:02:58,560][root][INFO] - Data Preprocessing
[2024-10-20 14:02:58,560][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-20 14:02:58,560][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 14:02:58,560][root][INFO] - ㄴ data_remove                False

[2024-10-20 14:02:58,560][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 14:02:58,573][root][INFO] - vocab size              : 51200
[2024-10-20 14:02:58,574][root][INFO] - device                  : gpu
[2024-10-20 14:02:58,574][root][INFO] - random seed             : 1
[2024-10-20 14:02:58,574][root][INFO] - train data size         : 942912
[2024-10-20 14:02:58,574][root][INFO] - max epochs              : 5
[2024-10-20 14:02:58,574][root][INFO] - total steps             : 73665
[2024-10-20 14:02:58,575][root][INFO] - warmup steps            : 7366
[2024-10-20 14:02:58,575][root][INFO] - batch size              : 64
[2024-10-20 14:02:58,575][root][INFO] - accumulation steps      : 1
[2024-10-20 14:02:58,575][root][INFO] - optimizer               : adamwscale
[2024-10-20 14:02:58,575][root][INFO] - lr_scheduler            : cosine
[2024-10-20 14:02:58,575][root][INFO] - learning rate           : 0.02
[2024-10-20 14:02:58,575][root][INFO] - max length              : 256

[2024-10-20 14:02:58,575][root][INFO] - LoRA Configuration
[2024-10-20 14:02:58,575][root][INFO] - ㄴ r                    : 32
[2024-10-20 14:02:58,575][root][INFO] - ㄴ alpha                : 128
[2024-10-20 14:02:58,575][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 14:02:58,575][root][INFO] - 

[2024-10-20 14:02:58,576][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 14:02:58,576][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-20 14:02:58,576][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-20 14:02:58,576][root][INFO] - * tb interval   : 10000

[2024-10-20 14:02:58,576][root][INFO] - 

[2024-10-20 14:02:58,576][root][INFO] - Start the Training !
[2024-10-20 14:02:58,578][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 14:05:03,674][root][INFO] - Step: 10000/63000  |  Loss: 0.7534  |  Score: 67.20 [%]  |  Seq Length: 256.0
[2024-10-20 14:20:57,672][root][INFO] - Step: 12600/63000  |  Loss: 0.8022  |  Score: 64.24 [%]  |  Seq Length: 256.0
[2024-10-20 14:21:02,048][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 14:21:02,048][root][INFO] - Score: 61.22 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-20 14:21:10,019][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 14:21:10,019][root][INFO] - Score: 59.99 [%]  |  Evaluation Time: 7.97 [s]
[2024-10-20 14:21:10,020][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 14:21:10,020][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 14:21:11,578][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 14:21:11,609][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 14:21:11,609][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 14:21:11,609][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 14:21:11,610][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 14:21:11,610][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 14:21:11,611][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 14:21:13,170][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 14:21:37,293][root][INFO] - Step: 10000/66070  |  Loss: 0.7531  |  Score: 67.21 [%]  |  Seq Length: 256.0
[2024-10-20 14:41:31,287][root][INFO] - Step: 13214/66070  |  Loss: 0.8103  |  Score: 63.81 [%]  |  Seq Length: 256.0
[2024-10-20 14:41:36,430][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 14:41:36,430][root][INFO] - Score: 59.01 [%]  |  Evaluation Time: 5.14 [s]
[2024-10-20 14:41:45,792][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 14:41:45,793][root][INFO] - Score: 58.16 [%]  |  Evaluation Time: 9.36 [s]
[2024-10-20 14:41:45,794][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 14:41:45,794][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 14:41:47,379][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 14:41:47,411][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 14:41:47,412][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 14:41:47,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 14:41:47,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 14:41:47,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 14:41:47,413][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 14:41:48,969][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 15:04:06,905][root][INFO] - Step: 10000/73665  |  Loss: 0.7567  |  Score: 67.02 [%]  |  Seq Length: 256.0
[2024-10-20 15:06:29,700][root][INFO] - Step: 20000/63000  |  Loss: 0.9975  |  Score: 48.04 [%]  |  Seq Length: 256.0
[2024-10-20 15:23:45,888][root][INFO] - Step: 20000/66070  |  Loss: 1.0251  |  Score: 45.97 [%]  |  Seq Length: 256.0
[2024-10-20 15:33:05,478][root][INFO] - Step: 14733/73665  |  Loss: 0.8287  |  Score: 62.68 [%]  |  Seq Length: 256.0
[2024-10-20 15:33:11,679][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 15:33:11,679][root][INFO] - Score: 57.14 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-20 15:33:23,474][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 15:33:23,474][root][INFO] - Score: 57.83 [%]  |  Evaluation Time: 11.79 [s]
[2024-10-20 15:33:23,475][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 15:33:23,475][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 15:33:25,018][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 15:33:25,048][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 15:33:25,048][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 15:33:25,049][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 15:33:25,049][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 15:33:25,049][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 15:33:25,050][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 15:33:26,483][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 15:38:17,894][root][INFO] - Step: 25200/63000  |  Loss: 1.1402  |  Score: 33.54 [%]  |  Seq Length: 256.0
[2024-10-20 15:38:22,300][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 15:38:22,300][root][INFO] - Score: 32.58 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-20 15:38:30,242][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 15:38:30,242][root][INFO] - Score: 31.22 [%]  |  Evaluation Time: 7.94 [s]
[2024-10-20 15:38:30,244][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 16:03:29,113][root][INFO] - Step: 26428/66070  |  Loss: 1.1534  |  Score: 33.74 [%]  |  Seq Length: 256.0
[2024-10-20 16:03:34,250][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 16:03:34,250][root][INFO] - Score: 37.70 [%]  |  Evaluation Time: 5.13 [s]
[2024-10-20 16:03:43,566][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 16:03:43,566][root][INFO] - Score: 37.54 [%]  |  Evaluation Time: 9.31 [s]
[2024-10-20 16:03:43,568][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 16:05:39,511][root][INFO] - Step: 20000/73665  |  Loss: 1.0358  |  Score: 44.59 [%]  |  Seq Length: 256.0
[2024-10-20 16:07:53,320][root][INFO] - Step: 30000/63000  |  Loss: 1.1617  |  Score: 33.20 [%]  |  Seq Length: 256.0
[2024-10-20 16:25:48,542][root][INFO] - Step: 30000/66070  |  Loss: 1.1588  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-20 16:55:36,705][root][INFO] - Step: 37800/63000  |  Loss: 1.1919  |  Score: 33.39 [%]  |  Seq Length: 256.0
[2024-10-20 16:55:41,064][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 16:55:41,064][root][INFO] - Score: 34.53 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-20 16:55:48,981][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 16:55:48,981][root][INFO] - Score: 33.24 [%]  |  Evaluation Time: 7.92 [s]
[2024-10-20 16:55:48,983][root][INFO] - 
[4/ 5 Epoch]
[2024-10-20 17:03:30,558][root][INFO] - Step: 29466/73665  |  Loss: 1.1741  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-20 17:03:36,722][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 17:03:36,722][root][INFO] - Score: 32.90 [%]  |  Evaluation Time: 6.16 [s]
[2024-10-20 17:03:48,496][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 17:03:48,496][root][INFO] - Score: 32.44 [%]  |  Evaluation Time: 11.77 [s]
[2024-10-20 17:03:48,498][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 17:07:04,776][root][INFO] - Step: 30000/73665  |  Loss: 1.1753  |  Score: 34.07 [%]  |  Seq Length: 256.0
[2024-10-20 17:09:16,611][root][INFO] - Step: 40000/63000  |  Loss: 1.3049  |  Score: 33.71 [%]  |  Seq Length: 256.0
[2024-10-20 17:25:23,792][root][INFO] - Step: 39642/66070  |  Loss: 1.1630  |  Score: 33.48 [%]  |  Seq Length: 256.0
[2024-10-20 17:25:28,847][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 17:25:28,847][root][INFO] - Score: 33.74 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-20 17:25:38,130][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 17:25:38,131][root][INFO] - Score: 32.80 [%]  |  Evaluation Time: 9.28 [s]
[2024-10-20 17:25:38,133][root][INFO] - 
[4/ 5 Epoch]
[2024-10-20 17:27:51,322][root][INFO] - Step: 40000/66070  |  Loss: 1.1563  |  Score: 33.51 [%]  |  Seq Length: 256.0
[2024-10-20 18:08:14,387][root][INFO] - Step: 40000/73665  |  Loss: 1.2144  |  Score: 34.02 [%]  |  Seq Length: 256.0
[2024-10-20 18:10:27,755][root][INFO] - Step: 50000/63000  |  Loss: 1.2927  |  Score: 33.24 [%]  |  Seq Length: 256.0
[2024-10-20 18:12:54,514][root][INFO] - Step: 50400/63000  |  Loss: 1.3330  |  Score: 33.27 [%]  |  Seq Length: 256.0
[2024-10-20 18:12:58,958][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 18:12:58,958][root][INFO] - Score: 30.60 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-20 18:13:06,895][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 18:13:06,895][root][INFO] - Score: 31.27 [%]  |  Evaluation Time: 7.93 [s]
[2024-10-20 18:13:06,897][root][INFO] - 
[5/ 5 Epoch]
[2024-10-20 18:29:39,464][root][INFO] - Step: 50000/66070  |  Loss: 1.1575  |  Score: 33.48 [%]  |  Seq Length: 256.0
[2024-10-20 18:33:56,014][root][INFO] - Step: 44199/73665  |  Loss: 1.1946  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-20 18:34:02,196][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 18:34:02,196][root][INFO] - Score: 34.82 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-20 18:34:13,980][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 18:34:13,981][root][INFO] - Score: 34.04 [%]  |  Evaluation Time: 11.78 [s]
[2024-10-20 18:34:13,983][root][INFO] - 
[4/ 5 Epoch]
[2024-10-20 18:47:19,168][root][INFO] - Step: 52856/66070  |  Loss: 1.1556  |  Score: 33.63 [%]  |  Seq Length: 256.0
[2024-10-20 18:47:24,303][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 18:47:24,303][root][INFO] - Score: 33.85 [%]  |  Evaluation Time: 5.13 [s]
[2024-10-20 18:47:33,597][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 18:47:33,597][root][INFO] - Score: 34.81 [%]  |  Evaluation Time: 9.29 [s]
[2024-10-20 18:47:33,599][root][INFO] - 
[5/ 5 Epoch]
[2024-10-20 19:09:44,435][root][INFO] - Step: 50000/73665  |  Loss: 1.1758  |  Score: 33.17 [%]  |  Seq Length: 256.0
[2024-10-20 19:11:54,831][root][INFO] - Step: 60000/63000  |  Loss: 1.3151  |  Score: 33.36 [%]  |  Seq Length: 256.0
[2024-10-20 19:30:16,979][root][INFO] - Step: 63000/63000  |  Loss: 1.2929  |  Score: 33.21 [%]  |  Seq Length: 256.0
[2024-10-20 19:30:21,367][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 19:30:21,367][root][INFO] - Score: 31.57 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-20 19:30:29,295][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 19:30:29,295][root][INFO] - Score: 31.13 [%]  |  Evaluation Time: 7.93 [s]
[2024-10-20 19:30:29,296][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 19:30:29,296][root][INFO] - - Epoch: 1
[2024-10-20 19:30:29,296][root][INFO] - - DEV score: 61.22 [%]
[2024-10-20 19:30:29,296][root][INFO] - - TEST score: 59.99 [%]
[2024-10-20 19:30:29,298][root][INFO] - Fine-tuning is done!
[2024-10-20 19:30:29,299][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-20 19:30:29,299][root][INFO] - - BEST LR: 0.01
[2024-10-20 19:30:29,299][root][INFO] - - DEV score: 74.72 [%]
[2024-10-20 19:30:29,299][root][INFO] - - TEST score: 75.88 [%]
[2024-10-20 19:30:35,837][root][INFO] - 

[2024-10-20 19:30:35,838][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 19:30:35,838][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 19:30:35,838][root][INFO] - 

[2024-10-20 19:30:35,838][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 19:31:46,126][root][INFO] - Step: 60000/66070  |  Loss: 1.1555  |  Score: 33.37 [%]  |  Seq Length: 256.0
[2024-10-20 19:32:20,986][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,987][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,987][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,988][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,988][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,988][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,989][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,989][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,990][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,990][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,990][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,991][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,991][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,992][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,992][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,992][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,993][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,993][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,994][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,994][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,995][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,996][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,996][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 19:32:20,997][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 19:32:20,998][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 19:32:21,002][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 19:32:21,202][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 19:32:21,204][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-20 19:32:21,445][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 19:32:24,661][root][INFO] - 

[2024-10-20 19:32:24,661][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 19:32:24,661][root][INFO] - Data Preprocessing
[2024-10-20 19:32:24,661][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 19:32:24,661][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 19:32:24,662][root][INFO] - ㄴ data_remove                True

[2024-10-20 19:32:24,662][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 19:32:24,669][root][INFO] - vocab size              : 51200
[2024-10-20 19:32:24,669][root][INFO] - device                  : gpu
[2024-10-20 19:32:24,669][root][INFO] - random seed             : 1
[2024-10-20 19:32:24,670][root][INFO] - train data size         : 806400
[2024-10-20 19:32:24,670][root][INFO] - max epochs              : 5
[2024-10-20 19:32:24,670][root][INFO] - total steps             : 63000
[2024-10-20 19:32:24,670][root][INFO] - warmup steps            : 6300
[2024-10-20 19:32:24,670][root][INFO] - batch size              : 64
[2024-10-20 19:32:24,670][root][INFO] - accumulation steps      : 1
[2024-10-20 19:32:24,670][root][INFO] - optimizer               : adamwscale
[2024-10-20 19:32:24,670][root][INFO] - lr_scheduler            : cosine
[2024-10-20 19:32:24,670][root][INFO] - learning rate           : 0.01
[2024-10-20 19:32:24,670][root][INFO] - max length              : 256

[2024-10-20 19:32:24,670][root][INFO] - LoRA Configuration
[2024-10-20 19:32:24,671][root][INFO] - ㄴ r                    : 32
[2024-10-20 19:32:24,671][root][INFO] - ㄴ alpha                : 128
[2024-10-20 19:32:24,671][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 19:32:24,671][root][INFO] - KOMBO Configuration
[2024-10-20 19:32:24,671][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-20 19:32:24,671][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-20 19:32:24,671][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-20 19:32:24,671][root][INFO] - ㄴ embedding_norm       : False
[2024-10-20 19:32:24,671][root][INFO] - ㄴ do_combination       : True
[2024-10-20 19:32:24,671][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-20 19:32:24,672][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-20 19:32:24,672][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-20 19:32:24,672][root][INFO] -   ㄴ add_lora           : False

[2024-10-20 19:32:24,672][root][INFO] - 

[2024-10-20 19:32:24,672][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-20 19:32:24,672][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 19:32:24,672][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 19:32:24,672][root][INFO] - * tb interval   : 10000

[2024-10-20 19:32:24,672][root][INFO] - 

[2024-10-20 19:32:24,672][root][INFO] - Start the Training !
[2024-10-20 19:32:24,675][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 19:44:46,624][root][INFO] - 

[2024-10-20 19:44:46,624][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 19:44:46,624][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-20 19:44:46,624][root][INFO] - 

[2024-10-20 19:44:46,625][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 19:44:51,390][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,390][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,391][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,391][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,391][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,392][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,392][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,393][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,393][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,394][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,394][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,394][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,395][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,395][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,396][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,396][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,396][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,397][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,397][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,398][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,402][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,403][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,403][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 19:44:51,404][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 19:44:51,405][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-20 19:44:51,590][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 19:44:53,635][root][INFO] - 

[2024-10-20 19:44:53,636][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-20 19:44:53,636][root][INFO] - Data Preprocessing
[2024-10-20 19:44:53,636][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 19:44:53,636][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 19:44:53,636][root][INFO] - ㄴ data_remove                False

[2024-10-20 19:44:53,636][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 19:44:53,644][root][INFO] - vocab size              : 51200
[2024-10-20 19:44:53,644][root][INFO] - device                  : gpu
[2024-10-20 19:44:53,644][root][INFO] - random seed             : 1
[2024-10-20 19:44:53,644][root][INFO] - train data size         : 5760
[2024-10-20 19:44:53,645][root][INFO] - max epochs              : 15
[2024-10-20 19:44:53,645][root][INFO] - total steps             : 1350
[2024-10-20 19:44:53,645][root][INFO] - warmup steps            : 135
[2024-10-20 19:44:53,645][root][INFO] - batch size              : 64
[2024-10-20 19:44:53,645][root][INFO] - accumulation steps      : 1
[2024-10-20 19:44:53,645][root][INFO] - optimizer               : adamwscale
[2024-10-20 19:44:53,645][root][INFO] - lr_scheduler            : cosine
[2024-10-20 19:44:53,645][root][INFO] - learning rate           : 0.01
[2024-10-20 19:44:53,645][root][INFO] - max length              : 256

[2024-10-20 19:44:53,645][root][INFO] - LoRA Configuration
[2024-10-20 19:44:53,645][root][INFO] - ㄴ r                    : 32
[2024-10-20 19:44:53,645][root][INFO] - ㄴ alpha                : 128
[2024-10-20 19:44:53,646][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 19:44:53,646][root][INFO] - 

[2024-10-20 19:44:53,646][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-20 19:44:53,646][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-20 19:44:53,646][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-20 19:44:53,646][root][INFO] - * tb interval   : 10000

[2024-10-20 19:44:53,646][root][INFO] - 

[2024-10-20 19:44:53,646][root][INFO] - Start the Training !
[2024-10-20 19:44:53,649][root][INFO] - 
[1/ 15 Epoch]
[2024-10-20 19:45:27,814][root][INFO] - Step: 90/1350  |  Loss: 2.4113  |  Score: 33.10 [%]  |  Seq Length: 256.0
[2024-10-20 19:45:31,582][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 19:45:31,582][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 3.76 [s]
[2024-10-20 19:45:35,052][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 19:45:35,052][root][INFO] - Score: 63.85 [%]  |  Evaluation Time: 3.47 [s]
[2024-10-20 19:45:35,053][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 19:45:35,054][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:45:35,901][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:45:35,942][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:45:35,942][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:45:35,942][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:45:35,942][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:45:35,943][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:45:35,944][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:45:36,610][root][INFO] - 
[2/ 15 Epoch]
[2024-10-20 19:46:09,699][root][INFO] - Step: 180/1350  |  Loss: 1.2280  |  Score: 64.41 [%]  |  Seq Length: 256.0
[2024-10-20 19:46:13,444][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 19:46:13,444][root][INFO] - Score: 76.92 [%]  |  Evaluation Time: 3.74 [s]
[2024-10-20 19:46:16,946][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 19:46:16,947][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 3.50 [s]
[2024-10-20 19:46:16,948][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 19:46:16,948][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:46:18,486][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:46:18,517][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:46:18,517][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:46:18,517][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:46:18,518][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:46:18,518][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:46:18,519][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:46:19,991][root][INFO] - 
[3/ 15 Epoch]
[2024-10-20 19:46:53,150][root][INFO] - Step: 270/1350  |  Loss: 1.0473  |  Score: 70.26 [%]  |  Seq Length: 256.0
[2024-10-20 19:46:56,943][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 19:46:56,944][root][INFO] - Score: 77.97 [%]  |  Evaluation Time: 3.79 [s]
[2024-10-20 19:47:00,435][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 19:47:00,436][root][INFO] - Score: 71.22 [%]  |  Evaluation Time: 3.49 [s]
[2024-10-20 19:47:00,437][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 19:47:00,437][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:47:02,107][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:47:02,155][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:47:02,155][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:47:02,155][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:47:02,156][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:47:02,156][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:47:02,157][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:47:03,568][root][INFO] - 
[4/ 15 Epoch]
[2024-10-20 19:47:36,728][root][INFO] - Step: 360/1350  |  Loss: 0.8776  |  Score: 73.84 [%]  |  Seq Length: 256.0
[2024-10-20 19:47:40,492][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 19:47:40,492][root][INFO] - Score: 78.87 [%]  |  Evaluation Time: 3.76 [s]
[2024-10-20 19:47:44,081][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 19:47:44,082][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-20 19:47:44,083][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-20 19:47:44,083][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:47:45,620][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:47:45,668][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:47:45,668][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:47:45,668][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:47:45,669][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:47:45,669][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:47:45,670][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:47:47,101][root][INFO] - 
[5/ 15 Epoch]
[2024-10-20 19:48:20,394][root][INFO] - Step: 450/1350  |  Loss: 0.7642  |  Score: 78.10 [%]  |  Seq Length: 256.0
[2024-10-20 19:48:24,159][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 19:48:24,160][root][INFO] - Score: 77.14 [%]  |  Evaluation Time: 3.76 [s]
[2024-10-20 19:48:27,661][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 19:48:27,661][root][INFO] - Score: 69.45 [%]  |  Evaluation Time: 3.50 [s]
[2024-10-20 19:48:27,664][root][INFO] - 
[6/ 15 Epoch]
[2024-10-20 19:49:00,976][root][INFO] - Step: 540/1350  |  Loss: 0.7207  |  Score: 79.89 [%]  |  Seq Length: 256.0
[2024-10-20 19:49:04,748][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-20 19:49:04,748][root][INFO] - Score: 77.76 [%]  |  Evaluation Time: 3.77 [s]
[2024-10-20 19:49:08,293][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-20 19:49:08,293][root][INFO] - Score: 72.65 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-20 19:49:08,294][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-20 19:49:08,294][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:49:09,870][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:49:09,900][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:49:09,901][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:49:09,901][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:49:09,901][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:49:09,901][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:49:09,903][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:49:11,329][root][INFO] - 
[7/ 15 Epoch]
[2024-10-20 19:49:44,644][root][INFO] - Step: 630/1350  |  Loss: 0.6084  |  Score: 82.72 [%]  |  Seq Length: 256.0
[2024-10-20 19:49:48,425][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-20 19:49:48,426][root][INFO] - Score: 78.49 [%]  |  Evaluation Time: 3.77 [s]
[2024-10-20 19:49:51,937][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-20 19:49:51,937][root][INFO] - Score: 72.55 [%]  |  Evaluation Time: 3.51 [s]
[2024-10-20 19:49:51,938][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-20 19:49:51,938][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:49:53,594][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:49:53,628][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:49:53,628][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:49:53,628][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:49:53,629][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:49:53,629][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:49:53,630][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:49:55,083][root][INFO] - 
[8/ 15 Epoch]
[2024-10-20 19:50:28,349][root][INFO] - Step: 720/1350  |  Loss: 0.5348  |  Score: 84.41 [%]  |  Seq Length: 256.0
[2024-10-20 19:50:32,208][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-20 19:50:32,209][root][INFO] - Score: 78.69 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-20 19:50:35,711][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-20 19:50:35,711][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 3.50 [s]
[2024-10-20 19:50:35,713][root][INFO] - 
[9/ 15 Epoch]
[2024-10-20 19:51:08,957][root][INFO] - Step: 810/1350  |  Loss: 0.4850  |  Score: 85.78 [%]  |  Seq Length: 256.0
[2024-10-20 19:51:12,769][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-20 19:51:12,769][root][INFO] - Score: 77.98 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-20 19:51:16,285][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-20 19:51:16,285][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 3.51 [s]
[2024-10-20 19:51:16,287][root][INFO] - 
[10/ 15 Epoch]
[2024-10-20 19:51:49,512][root][INFO] - Step: 900/1350  |  Loss: 0.4437  |  Score: 86.97 [%]  |  Seq Length: 256.0
[2024-10-20 19:51:53,256][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-20 19:51:53,256][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 3.74 [s]
[2024-10-20 19:51:56,748][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-20 19:51:56,749][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 3.49 [s]
[2024-10-20 19:51:56,751][root][INFO] - 
[11/ 15 Epoch]
[2024-10-20 19:52:30,107][root][INFO] - Step: 990/1350  |  Loss: 0.3923  |  Score: 88.22 [%]  |  Seq Length: 256.0
[2024-10-20 19:52:33,890][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-20 19:52:33,891][root][INFO] - Score: 78.26 [%]  |  Evaluation Time: 3.78 [s]
[2024-10-20 19:52:37,427][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-20 19:52:37,427][root][INFO] - Score: 71.44 [%]  |  Evaluation Time: 3.53 [s]
[2024-10-20 19:52:37,429][root][INFO] - 
[12/ 15 Epoch]
[2024-10-20 19:53:10,734][root][INFO] - Step: 1080/1350  |  Loss: 0.3720  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-20 19:53:14,505][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-20 19:53:14,505][root][INFO] - Score: 78.88 [%]  |  Evaluation Time: 3.77 [s]
[2024-10-20 19:53:18,042][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-20 19:53:18,042][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-20 19:53:18,044][root][INFO] - 
[13/ 15 Epoch]
[2024-10-20 19:53:51,231][root][INFO] - Step: 1170/1350  |  Loss: 0.3427  |  Score: 89.73 [%]  |  Seq Length: 256.0
[2024-10-20 19:53:54,977][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-20 19:53:54,978][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 3.74 [s]
[2024-10-20 19:53:58,525][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-20 19:53:58,526][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-20 19:53:58,528][root][INFO] - 
[14/ 15 Epoch]
[2024-10-20 19:54:31,746][root][INFO] - Step: 1260/1350  |  Loss: 0.3397  |  Score: 89.75 [%]  |  Seq Length: 256.0
[2024-10-20 19:54:35,544][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-20 19:54:35,544][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 3.79 [s]
[2024-10-20 19:54:39,039][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-20 19:54:39,039][root][INFO] - Score: 71.06 [%]  |  Evaluation Time: 3.49 [s]
[2024-10-20 19:54:39,041][root][INFO] - 
[15/ 15 Epoch]
[2024-10-20 19:55:12,237][root][INFO] - Step: 1350/1350  |  Loss: 0.3280  |  Score: 90.13 [%]  |  Seq Length: 256.0
[2024-10-20 19:55:16,003][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-20 19:55:16,003][root][INFO] - Score: 78.76 [%]  |  Evaluation Time: 3.76 [s]
[2024-10-20 19:55:19,519][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-20 19:55:19,519][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 3.51 [s]
[2024-10-20 19:55:19,520][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 19:55:19,520][root][INFO] - - Epoch: 7
[2024-10-20 19:55:19,520][root][INFO] - - DEV score: 78.49 [%]
[2024-10-20 19:55:19,520][root][INFO] - - TEST score: 72.55 [%]
[2024-10-20 19:55:19,521][root][INFO] - Fine-tuning is done!
[2024-10-20 19:55:22,697][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,698][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,698][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,699][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,699][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,700][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,700][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,701][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,701][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,702][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,702][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,703][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,703][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,704][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,704][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,705][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,705][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,706][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,706][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,707][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,707][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,708][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,708][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 19:55:22,709][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 19:55:22,711][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-20 19:55:22,713][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 19:55:22,868][root][INFO] - 

[2024-10-20 19:55:22,869][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-20 19:55:22,869][root][INFO] - Data Preprocessing
[2024-10-20 19:55:22,869][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 19:55:22,869][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 19:55:22,869][root][INFO] - ㄴ data_remove                False

[2024-10-20 19:55:22,869][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 19:55:22,876][root][INFO] - vocab size              : 51200
[2024-10-20 19:55:22,877][root][INFO] - device                  : gpu
[2024-10-20 19:55:22,877][root][INFO] - random seed             : 1
[2024-10-20 19:55:22,877][root][INFO] - train data size         : 5760
[2024-10-20 19:55:22,877][root][INFO] - max epochs              : 15
[2024-10-20 19:55:22,877][root][INFO] - total steps             : 1350
[2024-10-20 19:55:22,877][root][INFO] - warmup steps            : 135
[2024-10-20 19:55:22,877][root][INFO] - batch size              : 64
[2024-10-20 19:55:22,877][root][INFO] - accumulation steps      : 1
[2024-10-20 19:55:22,877][root][INFO] - optimizer               : adamwscale
[2024-10-20 19:55:22,877][root][INFO] - lr_scheduler            : cosine
[2024-10-20 19:55:22,877][root][INFO] - learning rate           : 0.02
[2024-10-20 19:55:22,878][root][INFO] - max length              : 256

[2024-10-20 19:55:22,878][root][INFO] - LoRA Configuration
[2024-10-20 19:55:22,878][root][INFO] - ㄴ r                    : 32
[2024-10-20 19:55:22,878][root][INFO] - ㄴ alpha                : 128
[2024-10-20 19:55:22,878][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 19:55:22,878][root][INFO] - 

[2024-10-20 19:55:22,878][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-20 19:55:22,878][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-20 19:55:22,878][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-20 19:55:22,878][root][INFO] - * tb interval   : 10000

[2024-10-20 19:55:22,878][root][INFO] - 

[2024-10-20 19:55:22,878][root][INFO] - Start the Training !
[2024-10-20 19:55:22,881][root][INFO] - 
[1/ 15 Epoch]
[2024-10-20 19:55:56,107][root][INFO] - Step: 90/1350  |  Loss: 2.1060  |  Score: 41.54 [%]  |  Seq Length: 256.0
[2024-10-20 19:55:59,925][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 19:55:59,926][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-20 19:56:03,450][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 19:56:03,450][root][INFO] - Score: 64.22 [%]  |  Evaluation Time: 3.52 [s]
[2024-10-20 19:56:03,451][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 19:56:03,451][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:56:05,015][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:56:05,053][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:56:05,054][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:56:05,054][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:56:05,054][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:56:05,054][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:56:05,055][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:56:06,493][root][INFO] - 
[2/ 15 Epoch]
[2024-10-20 19:56:39,802][root][INFO] - Step: 180/1350  |  Loss: 1.1812  |  Score: 66.75 [%]  |  Seq Length: 256.0
[2024-10-20 19:56:43,601][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 19:56:43,601][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 3.80 [s]
[2024-10-20 19:56:47,151][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 19:56:47,151][root][INFO] - Score: 66.63 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-20 19:56:47,152][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 19:56:47,152][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:56:48,726][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:56:48,757][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:56:48,758][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:56:48,758][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:56:48,758][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:56:48,758][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:56:48,759][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:56:50,202][root][INFO] - 
[3/ 15 Epoch]
[2024-10-20 19:57:23,453][root][INFO] - Step: 270/1350  |  Loss: 0.9981  |  Score: 72.86 [%]  |  Seq Length: 256.0
[2024-10-20 19:57:27,287][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 19:57:27,287][root][INFO] - Score: 77.08 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-20 19:57:30,861][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 19:57:30,862][root][INFO] - Score: 70.47 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-20 19:57:30,863][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 19:57:30,863][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:57:32,516][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:57:32,606][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:57:32,607][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:57:32,607][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:57:32,607][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:57:32,607][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:57:32,608][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:57:34,040][root][INFO] - 
[4/ 15 Epoch]
[2024-10-20 19:58:07,362][root][INFO] - Step: 360/1350  |  Loss: 0.7879  |  Score: 77.81 [%]  |  Seq Length: 256.0
[2024-10-20 19:58:11,171][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 19:58:11,171][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-20 19:58:14,723][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 19:58:14,724][root][INFO] - Score: 69.48 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-20 19:58:14,725][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-20 19:58:14,725][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:58:16,349][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:58:16,388][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:58:16,388][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:58:16,388][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:58:16,388][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:58:16,389][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:58:16,390][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:58:17,812][root][INFO] - 
[5/ 15 Epoch]
[2024-10-20 19:58:51,061][root][INFO] - Step: 450/1350  |  Loss: 0.6225  |  Score: 82.20 [%]  |  Seq Length: 256.0
[2024-10-20 19:58:54,872][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 19:58:54,872][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-20 19:58:58,427][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 19:58:58,427][root][INFO] - Score: 69.48 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-20 19:58:58,429][root][INFO] - 
[6/ 15 Epoch]
[2024-10-20 19:59:31,701][root][INFO] - Step: 540/1350  |  Loss: 0.5384  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-20 19:59:35,513][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-20 19:59:35,513][root][INFO] - Score: 77.38 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-20 19:59:39,092][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-20 19:59:39,092][root][INFO] - Score: 71.01 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-20 19:59:39,093][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-20 19:59:39,093][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 19:59:40,659][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 19:59:40,707][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 19:59:40,708][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 19:59:40,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 19:59:40,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 19:59:40,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 19:59:40,710][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 19:59:42,276][root][INFO] - 
[7/ 15 Epoch]
[2024-10-20 20:00:15,532][root][INFO] - Step: 630/1350  |  Loss: 0.4523  |  Score: 87.09 [%]  |  Seq Length: 256.0
[2024-10-20 20:00:19,334][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-20 20:00:19,334][root][INFO] - Score: 78.75 [%]  |  Evaluation Time: 3.80 [s]
[2024-10-20 20:00:22,873][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-20 20:00:22,873][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-20 20:00:22,874][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-20 20:00:22,874][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:00:24,438][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:00:24,470][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:00:24,470][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:00:24,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:00:24,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:00:24,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:00:24,472][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:00:25,933][root][INFO] - 
[8/ 15 Epoch]
[2024-10-20 20:00:59,199][root][INFO] - Step: 720/1350  |  Loss: 0.3620  |  Score: 89.49 [%]  |  Seq Length: 256.0
[2024-10-20 20:01:03,012][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-20 20:01:03,013][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-20 20:01:06,580][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-20 20:01:06,581][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-20 20:01:06,583][root][INFO] - 
[9/ 15 Epoch]
[2024-10-20 20:01:39,897][root][INFO] - Step: 810/1350  |  Loss: 0.3020  |  Score: 91.14 [%]  |  Seq Length: 256.0
[2024-10-20 20:01:43,722][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-20 20:01:43,722][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-20 20:01:47,265][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-20 20:01:47,265][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-20 20:01:47,268][root][INFO] - 
[10/ 15 Epoch]
[2024-10-20 20:02:20,600][root][INFO] - Step: 900/1350  |  Loss: 0.2615  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-20 20:02:24,406][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-20 20:02:24,406][root][INFO] - Score: 78.81 [%]  |  Evaluation Time: 3.80 [s]
[2024-10-20 20:02:28,005][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-20 20:02:28,005][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 3.60 [s]
[2024-10-20 20:02:28,007][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-20 20:02:28,007][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:02:29,572][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:02:29,614][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:02:29,615][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:02:29,615][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:02:29,615][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:02:29,615][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:02:29,616][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:02:31,084][root][INFO] - 
[11/ 15 Epoch]
[2024-10-20 20:03:04,466][root][INFO] - Step: 990/1350  |  Loss: 0.2212  |  Score: 93.51 [%]  |  Seq Length: 256.0
[2024-10-20 20:03:08,289][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-20 20:03:08,289][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-20 20:03:11,831][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-20 20:03:11,831][root][INFO] - Score: 69.68 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-20 20:03:11,833][root][INFO] - 
[12/ 15 Epoch]
[2024-10-20 20:03:45,183][root][INFO] - Step: 1080/1350  |  Loss: 0.2071  |  Score: 93.79 [%]  |  Seq Length: 256.0
[2024-10-20 20:03:49,005][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-20 20:03:49,005][root][INFO] - Score: 79.36 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-20 20:03:52,574][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-20 20:03:52,574][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-20 20:03:52,576][root][INFO] - 
Save new Best Score (Epoch: 12)
[2024-10-20 20:03:52,576][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:03:54,139][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:03:54,179][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:03:54,180][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:03:54,180][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:03:54,180][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:03:54,180][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:03:54,181][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:03:55,617][root][INFO] - 
[13/ 15 Epoch]
[2024-10-20 20:04:23,129][root][INFO] - Step: 58932/73665  |  Loss: 1.1660  |  Score: 33.17 [%]  |  Seq Length: 256.0
[2024-10-20 20:04:28,916][root][INFO] - Step: 1170/1350  |  Loss: 0.1868  |  Score: 94.24 [%]  |  Seq Length: 256.0
[2024-10-20 20:04:29,271][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 20:04:29,271][root][INFO] - Score: 32.95 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-20 20:04:32,749][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-20 20:04:32,749][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-20 20:04:36,321][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-20 20:04:36,321][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-20 20:04:36,324][root][INFO] - 
[14/ 15 Epoch]
[2024-10-20 20:04:41,058][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 20:04:41,058][root][INFO] - Score: 32.12 [%]  |  Evaluation Time: 11.78 [s]
[2024-10-20 20:04:41,060][root][INFO] - 
[5/ 5 Epoch]
[2024-10-20 20:05:09,570][root][INFO] - Step: 1260/1350  |  Loss: 0.1798  |  Score: 94.50 [%]  |  Seq Length: 256.0
[2024-10-20 20:05:13,369][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-20 20:05:13,369][root][INFO] - Score: 78.40 [%]  |  Evaluation Time: 3.80 [s]
[2024-10-20 20:05:16,951][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-20 20:05:16,951][root][INFO] - Score: 69.70 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-20 20:05:16,954][root][INFO] - 
[15/ 15 Epoch]
[2024-10-20 20:05:50,212][root][INFO] - Step: 1350/1350  |  Loss: 0.1723  |  Score: 94.64 [%]  |  Seq Length: 256.0
[2024-10-20 20:05:54,014][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-20 20:05:54,014][root][INFO] - Score: 79.43 [%]  |  Evaluation Time: 3.80 [s]
[2024-10-20 20:05:57,586][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-20 20:05:57,587][root][INFO] - Score: 69.99 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-20 20:05:57,588][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 20:05:57,588][root][INFO] - - Epoch: 12
[2024-10-20 20:05:57,588][root][INFO] - - DEV score: 79.36 [%]
[2024-10-20 20:05:57,588][root][INFO] - - TEST score: 70.60 [%]
[2024-10-20 20:05:57,589][root][INFO] - Fine-tuning is done!
[2024-10-20 20:05:57,590][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-20 20:05:57,590][root][INFO] - - BEST LR: 0.02
[2024-10-20 20:05:57,590][root][INFO] - - DEV score: 79.36 [%]
[2024-10-20 20:05:57,590][root][INFO] - - TEST score: 70.60 [%]
[2024-10-20 20:06:03,860][root][INFO] - 

[2024-10-20 20:06:03,860][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 20:06:03,861][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-20 20:06:03,861][root][INFO] - 

[2024-10-20 20:06:03,861][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 20:06:08,437][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,438][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,438][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,439][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,440][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,440][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,441][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,442][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,443][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,443][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,444][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,445][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,446][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,446][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,447][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,448][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,449][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,449][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,450][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,451][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,457][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,457][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,458][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 20:06:08,459][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 20:06:08,461][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-20 20:06:08,465][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 20:06:08,668][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 20:06:08,670][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-20 20:06:08,859][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 20:06:11,981][root][INFO] - 

[2024-10-20 20:06:11,982][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-20 20:06:11,982][root][INFO] - Data Preprocessing
[2024-10-20 20:06:11,982][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-20 20:06:11,982][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 20:06:11,982][root][INFO] - ㄴ data_remove                False

[2024-10-20 20:06:11,982][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 20:06:11,992][root][INFO] - vocab size              : 51200
[2024-10-20 20:06:11,992][root][INFO] - device                  : gpu
[2024-10-20 20:06:11,992][root][INFO] - random seed             : 1
[2024-10-20 20:06:11,992][root][INFO] - train data size         : 5760
[2024-10-20 20:06:11,992][root][INFO] - max epochs              : 15
[2024-10-20 20:06:11,992][root][INFO] - total steps             : 1350
[2024-10-20 20:06:11,992][root][INFO] - warmup steps            : 135
[2024-10-20 20:06:11,992][root][INFO] - batch size              : 64
[2024-10-20 20:06:11,993][root][INFO] - accumulation steps      : 1
[2024-10-20 20:06:11,993][root][INFO] - optimizer               : adamwscale
[2024-10-20 20:06:11,993][root][INFO] - lr_scheduler            : cosine
[2024-10-20 20:06:11,993][root][INFO] - learning rate           : 0.01
[2024-10-20 20:06:11,993][root][INFO] - max length              : 256

[2024-10-20 20:06:11,993][root][INFO] - LoRA Configuration
[2024-10-20 20:06:11,993][root][INFO] - ㄴ r                    : 32
[2024-10-20 20:06:11,993][root][INFO] - ㄴ alpha                : 128
[2024-10-20 20:06:11,993][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 20:06:11,993][root][INFO] - KOMBO Configuration
[2024-10-20 20:06:11,993][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-20 20:06:11,993][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-20 20:06:11,994][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-20 20:06:11,994][root][INFO] - ㄴ embedding_norm       : False
[2024-10-20 20:06:11,994][root][INFO] - ㄴ do_combination       : True
[2024-10-20 20:06:11,994][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-20 20:06:11,994][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-20 20:06:11,994][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-20 20:06:11,994][root][INFO] -   ㄴ add_lora           : False

[2024-10-20 20:06:11,994][root][INFO] - 

[2024-10-20 20:06:11,994][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-20 20:06:11,995][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-20 20:06:11,995][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-20 20:06:11,995][root][INFO] - * tb interval   : 10000

[2024-10-20 20:06:11,995][root][INFO] - 

[2024-10-20 20:06:11,995][root][INFO] - Start the Training !
[2024-10-20 20:06:11,998][root][INFO] - 
[1/ 15 Epoch]
[2024-10-20 20:06:58,872][root][INFO] - Step: 90/1350  |  Loss: 2.4704  |  Score: 32.46 [%]  |  Seq Length: 256.0
[2024-10-20 20:07:04,905][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 20:07:04,905][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-20 20:07:10,384][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 20:07:10,385][root][INFO] - Score: 63.01 [%]  |  Evaluation Time: 5.48 [s]
[2024-10-20 20:07:10,386][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 20:07:10,386][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:07:10,389][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:07:11,275][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:07:11,382][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:07:11,383][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:07:11,383][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:07:11,383][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:07:11,383][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:07:11,384][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:07:12,134][root][INFO] - 
[2/ 15 Epoch]
[2024-10-20 20:07:58,567][root][INFO] - Step: 180/1350  |  Loss: 1.2200  |  Score: 64.32 [%]  |  Seq Length: 256.0
[2024-10-20 20:08:04,664][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 20:08:04,664][root][INFO] - Score: 76.75 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-20 20:08:10,133][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 20:08:10,134][root][INFO] - Score: 69.52 [%]  |  Evaluation Time: 5.47 [s]
[2024-10-20 20:08:10,134][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 20:08:10,135][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:08:10,137][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:08:11,831][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:08:12,065][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:08:12,067][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:08:12,067][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:08:12,067][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:08:12,068][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:08:12,070][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:08:13,697][root][INFO] - 
[3/ 15 Epoch]
[2024-10-20 20:09:00,092][root][INFO] - Step: 270/1350  |  Loss: 0.9839  |  Score: 71.10 [%]  |  Seq Length: 256.0
[2024-10-20 20:09:06,129][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-20 20:09:06,129][root][INFO] - Score: 77.75 [%]  |  Evaluation Time: 6.03 [s]
[2024-10-20 20:09:11,668][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-20 20:09:11,668][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-20 20:09:11,669][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-20 20:09:11,669][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:09:11,672][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:09:13,352][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:09:13,598][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:09:13,599][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:09:13,600][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:09:13,600][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:09:13,600][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:09:13,603][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:09:15,256][root][INFO] - 
[4/ 15 Epoch]
[2024-10-20 20:09:20,630][root][INFO] - Step: 66070/66070  |  Loss: 1.1555  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-20 20:09:25,805][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 20:09:25,805][root][INFO] - Score: 36.12 [%]  |  Evaluation Time: 5.17 [s]
[2024-10-20 20:09:35,195][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 20:09:35,195][root][INFO] - Score: 34.03 [%]  |  Evaluation Time: 9.39 [s]
[2024-10-20 20:09:35,197][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 20:09:35,197][root][INFO] - - Epoch: 1
[2024-10-20 20:09:35,197][root][INFO] - - DEV score: 59.01 [%]
[2024-10-20 20:09:35,197][root][INFO] - - TEST score: 58.16 [%]
[2024-10-20 20:09:35,200][root][INFO] - Fine-tuning is done!
[2024-10-20 20:09:35,201][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-20 20:09:35,201][root][INFO] - - BEST LR: 0.01
[2024-10-20 20:09:35,201][root][INFO] - - DEV score: 75.13 [%]
[2024-10-20 20:09:35,201][root][INFO] - - TEST score: 75.64 [%]
[2024-10-20 20:09:42,072][root][INFO] - 

[2024-10-20 20:09:42,072][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 20:09:42,072][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 20:09:42,072][root][INFO] - 

[2024-10-20 20:09:42,073][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 20:10:01,909][root][INFO] - Step: 360/1350  |  Loss: 0.8860  |  Score: 74.52 [%]  |  Seq Length: 256.0
[2024-10-20 20:10:07,971][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-20 20:10:07,971][root][INFO] - Score: 77.41 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-20 20:10:13,461][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-20 20:10:13,462][root][INFO] - Score: 71.40 [%]  |  Evaluation Time: 5.49 [s]
[2024-10-20 20:10:13,464][root][INFO] - 
[5/ 15 Epoch]
[2024-10-20 20:11:00,207][root][INFO] - Step: 450/1350  |  Loss: 0.7853  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-20 20:11:06,292][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 20:11:06,292][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-20 20:11:11,818][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 20:11:11,818][root][INFO] - Score: 70.97 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-20 20:11:11,819][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-20 20:11:11,819][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:11:11,822][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:11:13,517][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:11:13,614][root][INFO] - Step: 60000/73665  |  Loss: 1.3883  |  Score: 33.38 [%]  |  Seq Length: 256.0
[2024-10-20 20:11:13,769][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:11:13,770][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:11:13,771][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:11:13,771][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:11:13,771][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:11:13,774][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:11:15,413][root][INFO] - 
[6/ 15 Epoch]
[2024-10-20 20:11:31,145][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,145][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,146][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,146][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,147][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,147][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,148][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,148][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,149][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,149][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,150][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,150][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,151][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,151][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,152][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,152][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,153][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,153][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,154][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,154][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,155][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,156][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,156][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 20:11:31,157][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 20:11:31,159][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 20:11:31,163][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 20:11:31,368][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 20:11:31,370][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-20 20:11:31,619][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 20:11:34,751][root][INFO] - 

[2024-10-20 20:11:34,751][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 20:11:34,751][root][INFO] - Data Preprocessing
[2024-10-20 20:11:34,751][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-20 20:11:34,751][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 20:11:34,751][root][INFO] - ㄴ data_remove                True

[2024-10-20 20:11:34,751][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 20:11:34,759][root][INFO] - vocab size              : 51200
[2024-10-20 20:11:34,759][root][INFO] - device                  : gpu
[2024-10-20 20:11:34,759][root][INFO] - random seed             : 1
[2024-10-20 20:11:34,759][root][INFO] - train data size         : 845696
[2024-10-20 20:11:34,759][root][INFO] - max epochs              : 5
[2024-10-20 20:11:34,759][root][INFO] - total steps             : 66070
[2024-10-20 20:11:34,760][root][INFO] - warmup steps            : 6607
[2024-10-20 20:11:34,760][root][INFO] - batch size              : 64
[2024-10-20 20:11:34,760][root][INFO] - accumulation steps      : 1
[2024-10-20 20:11:34,760][root][INFO] - optimizer               : adamwscale
[2024-10-20 20:11:34,760][root][INFO] - lr_scheduler            : cosine
[2024-10-20 20:11:34,760][root][INFO] - learning rate           : 0.01
[2024-10-20 20:11:34,760][root][INFO] - max length              : 256

[2024-10-20 20:11:34,760][root][INFO] - LoRA Configuration
[2024-10-20 20:11:34,760][root][INFO] - ㄴ r                    : 32
[2024-10-20 20:11:34,760][root][INFO] - ㄴ alpha                : 128
[2024-10-20 20:11:34,760][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 20:11:34,760][root][INFO] - KOMBO Configuration
[2024-10-20 20:11:34,761][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-20 20:11:34,761][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-20 20:11:34,761][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-20 20:11:34,761][root][INFO] - ㄴ embedding_norm       : False
[2024-10-20 20:11:34,761][root][INFO] - ㄴ do_combination       : True
[2024-10-20 20:11:34,761][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-20 20:11:34,761][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-20 20:11:34,761][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-20 20:11:34,761][root][INFO] -   ㄴ add_lora           : False

[2024-10-20 20:11:34,762][root][INFO] - 

[2024-10-20 20:11:34,762][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-20 20:11:34,762][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-20 20:11:34,762][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-20 20:11:34,762][root][INFO] - * tb interval   : 10000

[2024-10-20 20:11:34,762][root][INFO] - 

[2024-10-20 20:11:34,762][root][INFO] - Start the Training !
[2024-10-20 20:11:34,765][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 20:12:01,952][root][INFO] - Step: 540/1350  |  Loss: 0.6758  |  Score: 80.72 [%]  |  Seq Length: 256.0
[2024-10-20 20:12:08,010][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-20 20:12:08,010][root][INFO] - Score: 78.49 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-20 20:12:13,513][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-20 20:12:13,513][root][INFO] - Score: 71.32 [%]  |  Evaluation Time: 5.50 [s]
[2024-10-20 20:12:13,514][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-20 20:12:13,514][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:12:13,516][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:12:15,210][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:12:15,443][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:12:15,444][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:12:15,445][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:12:15,445][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:12:15,445][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:12:15,448][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:12:17,071][root][INFO] - 
[7/ 15 Epoch]
[2024-10-20 20:13:02,317][root][INFO] - Step: 630/1350  |  Loss: 0.6033  |  Score: 83.26 [%]  |  Seq Length: 256.0
[2024-10-20 20:13:08,487][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-20 20:13:08,488][root][INFO] - Score: 79.27 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-20 20:13:13,995][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-20 20:13:13,995][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-20 20:13:13,996][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-20 20:13:13,997][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:13:13,999][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:13:15,704][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:13:15,936][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:13:15,937][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:13:15,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:13:15,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:13:15,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:13:15,941][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:13:17,582][root][INFO] - 
[8/ 15 Epoch]
[2024-10-20 20:14:04,263][root][INFO] - Step: 720/1350  |  Loss: 0.5198  |  Score: 85.21 [%]  |  Seq Length: 256.0
[2024-10-20 20:14:10,434][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-20 20:14:10,435][root][INFO] - Score: 79.29 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-20 20:14:15,971][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-20 20:14:15,971][root][INFO] - Score: 71.44 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-20 20:14:15,972][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-20 20:14:15,972][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:14:15,975][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:14:17,661][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:14:17,914][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:14:17,915][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:14:17,916][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:14:17,916][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:14:17,917][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:14:17,919][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:14:19,570][root][INFO] - 
[9/ 15 Epoch]
[2024-10-20 20:15:05,944][root][INFO] - Step: 810/1350  |  Loss: 0.4630  |  Score: 86.33 [%]  |  Seq Length: 256.0
[2024-10-20 20:15:12,023][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-20 20:15:12,023][root][INFO] - Score: 77.22 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-20 20:15:17,556][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-20 20:15:17,557][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 5.53 [s]
[2024-10-20 20:15:17,559][root][INFO] - 
[10/ 15 Epoch]
[2024-10-20 20:16:04,133][root][INFO] - Step: 900/1350  |  Loss: 0.4112  |  Score: 87.96 [%]  |  Seq Length: 256.0
[2024-10-20 20:16:10,192][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-20 20:16:10,192][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.06 [s]
[2024-10-20 20:16:15,713][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-20 20:16:15,713][root][INFO] - Score: 70.62 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-20 20:16:15,715][root][INFO] - 
[11/ 15 Epoch]
[2024-10-20 20:17:02,377][root][INFO] - Step: 990/1350  |  Loss: 0.3763  |  Score: 88.95 [%]  |  Seq Length: 256.0
[2024-10-20 20:17:08,520][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-20 20:17:08,520][root][INFO] - Score: 78.80 [%]  |  Evaluation Time: 6.14 [s]
[2024-10-20 20:17:14,058][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-20 20:17:14,059][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 5.54 [s]
[2024-10-20 20:17:14,060][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-20 20:17:14,060][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:17:14,062][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:17:15,760][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:17:15,993][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:17:15,994][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:17:15,995][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:17:15,995][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:17:15,995][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:17:15,998][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:17:17,627][root][INFO] - 
[12/ 15 Epoch]
[2024-10-20 20:18:04,220][root][INFO] - Step: 1080/1350  |  Loss: 0.3458  |  Score: 89.55 [%]  |  Seq Length: 256.0
[2024-10-20 20:18:10,317][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-20 20:18:10,317][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-20 20:18:15,837][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-20 20:18:15,838][root][INFO] - Score: 72.61 [%]  |  Evaluation Time: 5.52 [s]
[2024-10-20 20:18:15,840][root][INFO] - 
[13/ 15 Epoch]
[2024-10-20 20:19:02,478][root][INFO] - Step: 1170/1350  |  Loss: 0.3190  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-20 20:19:08,561][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-20 20:19:08,561][root][INFO] - Score: 79.26 [%]  |  Evaluation Time: 6.08 [s]
[2024-10-20 20:19:14,075][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-20 20:19:14,075][root][INFO] - Score: 72.45 [%]  |  Evaluation Time: 5.51 [s]
[2024-10-20 20:19:14,076][root][INFO] - 
Save new Best Score (Epoch: 13)
[2024-10-20 20:19:14,076][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 20:19:14,079][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 20:19:15,839][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 20:19:16,007][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 20:19:16,008][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 20:19:16,009][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 20:19:16,009][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 20:19:16,009][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 20:19:16,012][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 20:19:17,661][root][INFO] - 
[14/ 15 Epoch]
[2024-10-20 20:20:04,305][root][INFO] - Step: 1260/1350  |  Loss: 0.3087  |  Score: 90.72 [%]  |  Seq Length: 256.0
[2024-10-20 20:20:10,404][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-20 20:20:10,404][root][INFO] - Score: 78.81 [%]  |  Evaluation Time: 6.09 [s]
[2024-10-20 20:20:15,977][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-20 20:20:15,978][root][INFO] - Score: 72.28 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-20 20:20:15,980][root][INFO] - 
[15/ 15 Epoch]
[2024-10-20 20:21:41,070][root][INFO] - 

[2024-10-20 20:21:41,070][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 20:21:41,070][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-20 20:21:41,070][root][INFO] - 

[2024-10-20 20:21:41,070][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': 0.01, 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 20:58:46,382][root][INFO] - Step: 10000/63000  |  Loss: 0.7160  |  Score: 69.16 [%]  |  Seq Length: 256.0
[2024-10-20 21:12:22,165][root][INFO] - Step: 70000/73665  |  Loss: 1.1804  |  Score: 33.40 [%]  |  Seq Length: 256.0
[2024-10-20 21:21:08,743][root][INFO] - Step: 12600/63000  |  Loss: 0.6431  |  Score: 73.23 [%]  |  Seq Length: 256.0
[2024-10-20 21:21:15,787][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 21:21:15,787][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 7.04 [s]
[2024-10-20 21:21:29,406][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 21:21:29,406][root][INFO] - Score: 71.48 [%]  |  Evaluation Time: 13.62 [s]
[2024-10-20 21:21:29,407][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 21:21:29,408][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 21:21:29,415][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 21:21:30,317][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 21:21:30,407][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 21:21:30,408][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 21:21:30,408][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 21:21:30,408][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 21:21:30,408][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 21:21:30,409][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 21:21:31,165][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 21:34:46,453][root][INFO] - Step: 73665/73665  |  Loss: 1.1627  |  Score: 33.49 [%]  |  Seq Length: 256.0
[2024-10-20 21:34:52,602][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-20 21:34:52,602][root][INFO] - Score: 31.67 [%]  |  Evaluation Time: 6.15 [s]
[2024-10-20 21:35:04,363][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-20 21:35:04,363][root][INFO] - Score: 32.66 [%]  |  Evaluation Time: 11.76 [s]
[2024-10-20 21:35:04,364][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-20 21:35:04,364][root][INFO] - - Epoch: 1
[2024-10-20 21:35:04,364][root][INFO] - - DEV score: 57.14 [%]
[2024-10-20 21:35:04,364][root][INFO] - - TEST score: 57.83 [%]
[2024-10-20 21:35:04,366][root][INFO] - Fine-tuning is done!
[2024-10-20 21:35:04,367][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-20 21:35:04,367][root][INFO] - - BEST LR: 0.01
[2024-10-20 21:35:04,367][root][INFO] - - DEV score: 75.90 [%]
[2024-10-20 21:35:04,367][root][INFO] - - TEST score: 76.35 [%]
[2024-10-20 21:35:11,116][root][INFO] - 

[2024-10-20 21:35:11,117][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-20 21:35:11,117][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 21:35:11,117][root][INFO] - 

[2024-10-20 21:35:11,117][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-20 21:37:11,275][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,275][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,276][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,276][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,276][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,277][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,277][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,278][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,278][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,278][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,279][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,279][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,280][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,280][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,281][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,281][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,281][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,282][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,282][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,283][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,283][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,283][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,284][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-20 21:37:11,284][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-20 21:37:11,286][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-20 21:37:11,290][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-20 21:37:11,487][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-20 21:37:11,489][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-20 21:37:11,736][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-20 21:37:14,861][root][INFO] - 

[2024-10-20 21:37:14,862][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-20 21:37:14,862][root][INFO] - Data Preprocessing
[2024-10-20 21:37:14,862][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-20 21:37:14,862][root][INFO] - ㄴ do_hangeulize              False
[2024-10-20 21:37:14,862][root][INFO] - ㄴ data_remove                False

[2024-10-20 21:37:14,862][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-20 21:37:14,870][root][INFO] - vocab size              : 51200
[2024-10-20 21:37:14,870][root][INFO] - device                  : gpu
[2024-10-20 21:37:14,870][root][INFO] - random seed             : 1
[2024-10-20 21:37:14,870][root][INFO] - train data size         : 942912
[2024-10-20 21:37:14,870][root][INFO] - max epochs              : 5
[2024-10-20 21:37:14,870][root][INFO] - total steps             : 73665
[2024-10-20 21:37:14,870][root][INFO] - warmup steps            : 7366
[2024-10-20 21:37:14,870][root][INFO] - batch size              : 64
[2024-10-20 21:37:14,870][root][INFO] - accumulation steps      : 1
[2024-10-20 21:37:14,870][root][INFO] - optimizer               : adamwscale
[2024-10-20 21:37:14,870][root][INFO] - lr_scheduler            : cosine
[2024-10-20 21:37:14,871][root][INFO] - learning rate           : 0.01
[2024-10-20 21:37:14,871][root][INFO] - max length              : 256

[2024-10-20 21:37:14,871][root][INFO] - LoRA Configuration
[2024-10-20 21:37:14,871][root][INFO] - ㄴ r                    : 32
[2024-10-20 21:37:14,871][root][INFO] - ㄴ alpha                : 128
[2024-10-20 21:37:14,871][root][INFO] - ㄴ dropout              : 0.03

[2024-10-20 21:37:14,871][root][INFO] - KOMBO Configuration
[2024-10-20 21:37:14,871][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-20 21:37:14,871][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-20 21:37:14,871][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-20 21:37:14,871][root][INFO] - ㄴ embedding_norm       : False
[2024-10-20 21:37:14,872][root][INFO] - ㄴ do_combination       : True
[2024-10-20 21:37:14,872][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-20 21:37:14,872][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-20 21:37:14,872][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-20 21:37:14,872][root][INFO] -   ㄴ add_lora           : False

[2024-10-20 21:37:14,872][root][INFO] - 

[2024-10-20 21:37:14,872][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-20 21:37:14,872][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-20 21:37:14,872][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-20 21:37:14,872][root][INFO] - * tb interval   : 10000

[2024-10-20 21:37:14,873][root][INFO] - 

[2024-10-20 21:37:14,873][root][INFO] - Start the Training !
[2024-10-20 21:37:14,875][root][INFO] - 
[1/ 5 Epoch]
[2024-10-20 21:38:24,405][root][INFO] - Step: 10000/66070  |  Loss: 0.7182  |  Score: 68.99 [%]  |  Seq Length: 256.0
[2024-10-20 22:06:18,575][root][INFO] - Step: 13214/66070  |  Loss: 0.6469  |  Score: 73.07 [%]  |  Seq Length: 256.0
[2024-10-20 22:06:26,528][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 22:06:26,528][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 7.95 [s]
[2024-10-20 22:06:41,574][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 22:06:41,574][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 15.04 [s]
[2024-10-20 22:06:41,575][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 22:06:41,576][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 22:06:41,578][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 22:06:42,485][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 22:06:42,593][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 22:06:42,594][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 22:06:42,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 22:06:42,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 22:06:42,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 22:06:42,595][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 22:06:43,359][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 22:25:02,870][root][INFO] - Step: 20000/63000  |  Loss: 0.6177  |  Score: 74.48 [%]  |  Seq Length: 256.0
[2024-10-20 23:04:15,096][root][INFO] - Step: 10000/73665  |  Loss: 0.7256  |  Score: 68.64 [%]  |  Seq Length: 256.0
[2024-10-20 23:05:38,706][root][INFO] - Step: 20000/66070  |  Loss: 0.6186  |  Score: 74.40 [%]  |  Seq Length: 256.0
[2024-10-20 23:09:53,697][root][INFO] - Step: 25200/63000  |  Loss: 0.6080  |  Score: 75.02 [%]  |  Seq Length: 256.0
[2024-10-20 23:10:00,706][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-20 23:10:00,706][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 7.01 [s]
[2024-10-20 23:10:13,822][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-20 23:10:13,822][root][INFO] - Score: 72.25 [%]  |  Evaluation Time: 13.11 [s]
[2024-10-20 23:10:13,823][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-20 23:10:13,824][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 23:10:13,826][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 23:10:15,566][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 23:10:15,798][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 23:10:15,799][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 23:10:15,799][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 23:10:15,800][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 23:10:15,800][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 23:10:15,803][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 23:10:17,431][root][INFO] - 
[3/ 5 Epoch]
[2024-10-20 23:45:24,668][root][INFO] - Step: 14733/73665  |  Loss: 0.6544  |  Score: 72.60 [%]  |  Seq Length: 256.0
[2024-10-20 23:45:34,853][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-20 23:45:34,853][root][INFO] - Score: 71.97 [%]  |  Evaluation Time: 10.18 [s]
[2024-10-20 23:45:55,056][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-20 23:45:55,057][root][INFO] - Score: 71.38 [%]  |  Evaluation Time: 20.20 [s]
[2024-10-20 23:45:55,058][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-20 23:45:55,058][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-20 23:45:55,061][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-20 23:45:56,001][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-20 23:45:56,103][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-20 23:45:56,103][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-20 23:45:56,103][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-20 23:45:56,104][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-20 23:45:56,104][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-20 23:45:56,105][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-20 23:45:56,914][root][INFO] - 
[2/ 5 Epoch]
[2024-10-20 23:51:45,112][root][INFO] - Step: 30000/63000  |  Loss: 0.5771  |  Score: 76.39 [%]  |  Seq Length: 256.0
[2024-10-21 00:01:40,030][root][INFO] - Step: 26428/66070  |  Loss: 0.6103  |  Score: 74.83 [%]  |  Seq Length: 256.0
[2024-10-21 00:01:48,045][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 00:01:48,045][root][INFO] - Score: 71.89 [%]  |  Evaluation Time: 8.01 [s]
[2024-10-21 00:02:03,410][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 00:02:03,410][root][INFO] - Score: 71.20 [%]  |  Evaluation Time: 15.36 [s]
[2024-10-21 00:02:03,412][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 00:02:03,412][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 00:02:03,415][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 00:02:05,136][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 00:02:05,390][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 00:02:05,391][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 00:02:05,392][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 00:02:05,392][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 00:02:05,392][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 00:02:05,395][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 00:02:07,037][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 00:31:55,894][root][INFO] - Step: 20000/73665  |  Loss: 0.6279  |  Score: 73.92 [%]  |  Seq Length: 256.0
[2024-10-21 00:33:13,839][root][INFO] - Step: 30000/66070  |  Loss: 0.5822  |  Score: 76.19 [%]  |  Seq Length: 256.0
[2024-10-21 00:58:59,492][root][INFO] - Step: 37800/63000  |  Loss: 0.5661  |  Score: 76.97 [%]  |  Seq Length: 256.0
[2024-10-21 00:59:06,505][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 00:59:06,505][root][INFO] - Score: 73.47 [%]  |  Evaluation Time: 7.01 [s]
[2024-10-21 00:59:19,642][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 00:59:19,642][root][INFO] - Score: 75.18 [%]  |  Evaluation Time: 13.13 [s]
[2024-10-21 00:59:19,643][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-21 00:59:19,644][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 00:59:19,647][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 00:59:21,445][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 00:59:21,689][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 00:59:21,691][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 00:59:21,691][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 00:59:21,692][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 00:59:21,692][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 00:59:21,695][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 00:59:23,333][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 01:18:14,170][root][INFO] - Step: 40000/63000  |  Loss: 0.5279  |  Score: 78.73 [%]  |  Seq Length: 256.0
[2024-10-21 01:54:24,227][root][INFO] - Step: 29466/73665  |  Loss: 0.6220  |  Score: 74.30 [%]  |  Seq Length: 256.0
[2024-10-21 01:54:34,433][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 01:54:34,433][root][INFO] - Score: 72.73 [%]  |  Evaluation Time: 10.20 [s]
[2024-10-21 01:54:54,656][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 01:54:54,656][root][INFO] - Score: 73.99 [%]  |  Evaluation Time: 20.22 [s]
[2024-10-21 01:54:54,657][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 01:54:54,658][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 01:54:54,660][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 01:54:56,382][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 01:54:56,591][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 01:54:56,592][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 01:54:56,592][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 01:54:56,593][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 01:54:56,593][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 01:54:56,596][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 01:54:58,253][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 01:57:02,342][root][INFO] - Step: 39642/66070  |  Loss: 0.5699  |  Score: 76.80 [%]  |  Seq Length: 256.0
[2024-10-21 01:57:10,333][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 01:57:10,333][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 7.99 [s]
[2024-10-21 01:57:25,448][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 01:57:25,448][root][INFO] - Score: 73.56 [%]  |  Evaluation Time: 15.11 [s]
[2024-10-21 01:57:25,449][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-21 01:57:25,449][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 01:57:25,452][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 01:57:27,168][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 01:57:27,399][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 01:57:27,400][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 01:57:27,400][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 01:57:27,401][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 01:57:27,401][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 01:57:27,404][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 01:57:29,025][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 01:59:38,234][root][INFO] - Step: 30000/73665  |  Loss: 0.5876  |  Score: 76.23 [%]  |  Seq Length: 256.0
[2024-10-21 02:00:35,870][root][INFO] - Step: 40000/66070  |  Loss: 0.5320  |  Score: 78.53 [%]  |  Seq Length: 256.0
[2024-10-21 02:44:22,040][root][INFO] - Step: 50000/63000  |  Loss: 0.5182  |  Score: 79.24 [%]  |  Seq Length: 256.0
[2024-10-21 02:47:48,258][root][INFO] - Step: 50400/63000  |  Loss: 0.5100  |  Score: 79.72 [%]  |  Seq Length: 256.0
[2024-10-21 02:47:55,182][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 02:47:55,183][root][INFO] - Score: 76.17 [%]  |  Evaluation Time: 6.92 [s]
[2024-10-21 02:48:08,082][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 02:48:08,082][root][INFO] - Score: 75.90 [%]  |  Evaluation Time: 12.90 [s]
[2024-10-21 02:48:08,083][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 02:48:08,084][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 02:48:08,086][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 02:48:09,823][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 02:48:10,047][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 02:48:10,048][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 02:48:10,048][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 02:48:10,049][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 02:48:10,049][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 02:48:10,052][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 02:48:11,800][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 03:26:41,546][root][INFO] - Step: 40000/73665  |  Loss: 0.5883  |  Score: 75.91 [%]  |  Seq Length: 256.0
[2024-10-21 03:27:32,406][root][INFO] - Step: 50000/66070  |  Loss: 0.5258  |  Score: 78.85 [%]  |  Seq Length: 256.0
[2024-10-21 03:52:20,031][root][INFO] - Step: 52856/66070  |  Loss: 0.5122  |  Score: 79.43 [%]  |  Seq Length: 256.0
[2024-10-21 03:52:27,974][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 03:52:27,974][root][INFO] - Score: 74.84 [%]  |  Evaluation Time: 7.94 [s]
[2024-10-21 03:52:43,063][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 03:52:43,063][root][INFO] - Score: 74.90 [%]  |  Evaluation Time: 15.09 [s]
[2024-10-21 03:52:43,064][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 03:52:43,064][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 03:52:43,067][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 03:52:44,767][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 03:52:45,020][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 03:52:45,021][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 03:52:45,022][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 03:52:45,022][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 03:52:45,022][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 03:52:45,025][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 03:52:46,651][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 04:03:07,669][root][INFO] - Step: 44199/73665  |  Loss: 0.5735  |  Score: 76.57 [%]  |  Seq Length: 256.0
[2024-10-21 04:03:17,710][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 04:03:17,710][root][INFO] - Score: 75.50 [%]  |  Evaluation Time: 10.04 [s]
[2024-10-21 04:03:37,408][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 04:03:37,408][root][INFO] - Score: 75.72 [%]  |  Evaluation Time: 19.70 [s]
[2024-10-21 04:03:37,409][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-21 04:03:37,410][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 04:03:37,412][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 04:03:39,136][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 04:03:39,366][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 04:03:39,367][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 04:03:39,367][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 04:03:39,368][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 04:03:39,368][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 04:03:39,371][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 04:03:40,997][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 04:10:47,063][root][INFO] - Step: 60000/63000  |  Loss: 0.4792  |  Score: 81.02 [%]  |  Seq Length: 256.0
[2024-10-21 04:36:32,107][root][INFO] - Step: 63000/63000  |  Loss: 0.4787  |  Score: 81.04 [%]  |  Seq Length: 256.0
[2024-10-21 04:36:39,032][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 04:36:39,033][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 6.92 [s]
[2024-10-21 04:36:52,236][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 04:36:52,236][root][INFO] - Score: 75.19 [%]  |  Evaluation Time: 13.20 [s]
[2024-10-21 04:36:52,238][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 04:36:52,238][root][INFO] - - Epoch: 4
[2024-10-21 04:36:52,238][root][INFO] - - DEV score: 76.17 [%]
[2024-10-21 04:36:52,238][root][INFO] - - TEST score: 75.90 [%]
[2024-10-21 04:36:52,239][root][INFO] - Fine-tuning is done!
[2024-10-21 04:38:30,865][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,865][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,866][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,866][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,867][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,867][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,868][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,868][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,869][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,869][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,870][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,870][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,871][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,871][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,872][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,872][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,873][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,873][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,874][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,874][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,875][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,876][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,876][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 04:38:30,877][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 04:38:30,879][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 04:38:31,086][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 04:38:31,089][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-21 04:38:31,090][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 04:38:31,296][root][INFO] - 

[2024-10-21 04:38:31,297][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 04:38:31,297][root][INFO] - Data Preprocessing
[2024-10-21 04:38:31,297][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 04:38:31,297][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 04:38:31,297][root][INFO] - ㄴ data_remove                True

[2024-10-21 04:38:31,297][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 04:38:31,308][root][INFO] - vocab size              : 51200
[2024-10-21 04:38:31,309][root][INFO] - device                  : gpu
[2024-10-21 04:38:31,309][root][INFO] - random seed             : 1
[2024-10-21 04:38:31,309][root][INFO] - train data size         : 806400
[2024-10-21 04:38:31,309][root][INFO] - max epochs              : 5
[2024-10-21 04:38:31,309][root][INFO] - total steps             : 63000
[2024-10-21 04:38:31,309][root][INFO] - warmup steps            : 6300
[2024-10-21 04:38:31,309][root][INFO] - batch size              : 64
[2024-10-21 04:38:31,309][root][INFO] - accumulation steps      : 1
[2024-10-21 04:38:31,310][root][INFO] - optimizer               : adamwscale
[2024-10-21 04:38:31,310][root][INFO] - lr_scheduler            : cosine
[2024-10-21 04:38:31,310][root][INFO] - learning rate           : 0.02
[2024-10-21 04:38:31,310][root][INFO] - max length              : 256

[2024-10-21 04:38:31,310][root][INFO] - LoRA Configuration
[2024-10-21 04:38:31,310][root][INFO] - ㄴ r                    : 32
[2024-10-21 04:38:31,310][root][INFO] - ㄴ alpha                : 128
[2024-10-21 04:38:31,310][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 04:38:31,310][root][INFO] - KOMBO Configuration
[2024-10-21 04:38:31,310][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 04:38:31,310][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 04:38:31,311][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 04:38:31,311][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 04:38:31,311][root][INFO] - ㄴ do_combination       : True
[2024-10-21 04:38:31,311][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 04:38:31,311][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 04:38:31,311][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 04:38:31,311][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 04:38:31,311][root][INFO] - 

[2024-10-21 04:38:31,311][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs
[2024-10-21 04:38:31,311][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-21 04:38:31,312][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-21 04:38:31,312][root][INFO] - * tb interval   : 10000

[2024-10-21 04:38:31,312][root][INFO] - 

[2024-10-21 04:38:31,312][root][INFO] - Start the Training !
[2024-10-21 04:38:31,314][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 04:53:55,649][root][INFO] - Step: 50000/73665  |  Loss: 0.5382  |  Score: 78.24 [%]  |  Seq Length: 256.0
[2024-10-21 04:54:46,712][root][INFO] - Step: 60000/66070  |  Loss: 0.4833  |  Score: 80.83 [%]  |  Seq Length: 256.0
[2024-10-21 05:47:28,951][root][INFO] - Step: 66070/66070  |  Loss: 0.4807  |  Score: 80.94 [%]  |  Seq Length: 256.0
[2024-10-21 05:47:36,915][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 05:47:36,915][root][INFO] - Score: 75.00 [%]  |  Evaluation Time: 7.96 [s]
[2024-10-21 05:47:51,947][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 05:47:51,947][root][INFO] - Score: 75.05 [%]  |  Evaluation Time: 15.03 [s]
[2024-10-21 05:47:51,948][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-21 05:47:51,948][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 05:47:51,951][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 05:47:53,677][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 05:47:53,910][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 05:47:53,911][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 05:47:53,911][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 05:47:53,911][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 05:47:53,912][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 05:47:53,914][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 05:47:55,558][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 05:47:55,558][root][INFO] - - Epoch: 5
[2024-10-21 05:47:55,558][root][INFO] - - DEV score: 75.00 [%]
[2024-10-21 05:47:55,559][root][INFO] - - TEST score: 75.05 [%]
[2024-10-21 05:47:55,560][root][INFO] - Fine-tuning is done!
[2024-10-21 05:49:39,934][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,935][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,936][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,936][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,937][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,937][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,938][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,938][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,939][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,939][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,940][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,940][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,941][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,941][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,942][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,942][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,943][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,943][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,943][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,944][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,945][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,945][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,946][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 05:49:39,946][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 05:49:39,948][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 05:49:40,153][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 05:49:40,155][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-21 05:49:40,157][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 05:49:40,361][root][INFO] - 

[2024-10-21 05:49:40,361][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 05:49:40,361][root][INFO] - Data Preprocessing
[2024-10-21 05:49:40,361][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-21 05:49:40,361][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 05:49:40,361][root][INFO] - ㄴ data_remove                True

[2024-10-21 05:49:40,361][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 05:49:40,372][root][INFO] - vocab size              : 51200
[2024-10-21 05:49:40,373][root][INFO] - device                  : gpu
[2024-10-21 05:49:40,373][root][INFO] - random seed             : 1
[2024-10-21 05:49:40,374][root][INFO] - train data size         : 845696
[2024-10-21 05:49:40,374][root][INFO] - max epochs              : 5
[2024-10-21 05:49:40,374][root][INFO] - total steps             : 66070
[2024-10-21 05:49:40,374][root][INFO] - warmup steps            : 6607
[2024-10-21 05:49:40,374][root][INFO] - batch size              : 64
[2024-10-21 05:49:40,374][root][INFO] - accumulation steps      : 1
[2024-10-21 05:49:40,374][root][INFO] - optimizer               : adamwscale
[2024-10-21 05:49:40,374][root][INFO] - lr_scheduler            : cosine
[2024-10-21 05:49:40,374][root][INFO] - learning rate           : 0.02
[2024-10-21 05:49:40,374][root][INFO] - max length              : 256

[2024-10-21 05:49:40,374][root][INFO] - LoRA Configuration
[2024-10-21 05:49:40,374][root][INFO] - ㄴ r                    : 32
[2024-10-21 05:49:40,375][root][INFO] - ㄴ alpha                : 128
[2024-10-21 05:49:40,375][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 05:49:40,375][root][INFO] - KOMBO Configuration
[2024-10-21 05:49:40,375][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 05:49:40,375][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 05:49:40,375][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 05:49:40,375][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 05:49:40,375][root][INFO] - ㄴ do_combination       : True
[2024-10-21 05:49:40,375][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 05:49:40,376][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 05:49:40,376][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 05:49:40,376][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 05:49:40,376][root][INFO] - 

[2024-10-21 05:49:40,376][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-21 05:49:40,376][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-21 05:49:40,376][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-21 05:49:40,376][root][INFO] - * tb interval   : 10000

[2024-10-21 05:49:40,376][root][INFO] - 

[2024-10-21 05:49:40,376][root][INFO] - Start the Training !
[2024-10-21 05:49:40,378][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 06:04:38,671][root][INFO] - Step: 10000/63000  |  Loss: 0.7484  |  Score: 67.49 [%]  |  Seq Length: 256.0
[2024-10-21 06:11:23,575][root][INFO] - Step: 58932/73665  |  Loss: 0.5285  |  Score: 78.77 [%]  |  Seq Length: 256.0
[2024-10-21 06:11:33,628][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 06:11:33,628][root][INFO] - Score: 75.36 [%]  |  Evaluation Time: 10.05 [s]
[2024-10-21 06:11:53,341][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 06:11:53,341][root][INFO] - Score: 76.00 [%]  |  Evaluation Time: 19.71 [s]
[2024-10-21 06:11:53,342][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 06:11:53,343][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 06:11:53,345][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 06:11:55,063][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 06:11:55,294][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 06:11:55,295][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 06:11:55,296][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 06:11:55,296][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 06:11:55,296][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 06:11:55,299][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 06:11:56,917][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 06:21:13,669][root][INFO] - Step: 60000/73665  |  Loss: 0.4966  |  Score: 80.09 [%]  |  Seq Length: 256.0
[2024-10-21 06:26:57,982][root][INFO] - Step: 12600/63000  |  Loss: 0.7987  |  Score: 64.67 [%]  |  Seq Length: 256.0
[2024-10-21 06:27:05,209][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 06:27:05,209][root][INFO] - Score: 59.26 [%]  |  Evaluation Time: 7.22 [s]
[2024-10-21 06:27:18,499][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 06:27:18,499][root][INFO] - Score: 60.39 [%]  |  Evaluation Time: 13.29 [s]
[2024-10-21 06:27:18,500][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 06:27:18,501][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 06:27:18,503][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 06:27:20,203][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 06:27:20,474][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 06:27:20,475][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 06:27:20,475][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 06:27:20,475][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 06:27:20,475][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 06:27:20,477][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 06:27:22,271][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 07:16:14,473][root][INFO] - Step: 10000/66070  |  Loss: 0.7487  |  Score: 67.41 [%]  |  Seq Length: 256.0
[2024-10-21 07:31:07,048][root][INFO] - Step: 20000/63000  |  Loss: 1.0102  |  Score: 46.76 [%]  |  Seq Length: 256.0
[2024-10-21 07:44:11,409][root][INFO] - Step: 13214/66070  |  Loss: 0.8040  |  Score: 64.23 [%]  |  Seq Length: 256.0
[2024-10-21 07:44:19,460][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 07:44:19,460][root][INFO] - Score: 59.96 [%]  |  Evaluation Time: 8.05 [s]
[2024-10-21 07:44:34,647][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 07:44:34,647][root][INFO] - Score: 58.60 [%]  |  Evaluation Time: 15.18 [s]
[2024-10-21 07:44:34,648][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 07:44:34,648][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 07:44:34,651][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 07:44:36,377][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 07:44:36,612][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 07:44:36,613][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 07:44:36,613][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 07:44:36,613][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 07:44:36,614][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 07:44:36,617][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 07:44:38,262][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 07:48:06,344][root][INFO] - Step: 70000/73665  |  Loss: 0.4913  |  Score: 80.46 [%]  |  Seq Length: 256.0
[2024-10-21 08:15:34,340][root][INFO] - Step: 25200/63000  |  Loss: nan  |  Score: 33.56 [%]  |  Seq Length: 256.0
[2024-10-21 08:15:41,455][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 08:15:41,456][root][INFO] - Score: 34.63 [%]  |  Evaluation Time: 7.11 [s]
[2024-10-21 08:15:54,700][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 08:15:54,700][root][INFO] - Score: 34.85 [%]  |  Evaluation Time: 13.24 [s]
[2024-10-21 08:15:54,702][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 08:19:49,634][root][INFO] - Step: 73665/73665  |  Loss: 0.4889  |  Score: 80.56 [%]  |  Seq Length: 256.0
[2024-10-21 08:19:59,729][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 08:19:59,729][root][INFO] - Score: 76.00 [%]  |  Evaluation Time: 10.09 [s]
[2024-10-21 08:20:19,817][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 08:20:19,817][root][INFO] - Score: 76.78 [%]  |  Evaluation Time: 20.09 [s]
[2024-10-21 08:20:19,818][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-21 08:20:19,818][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 08:20:19,821][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 08:20:21,562][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 08:20:21,793][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 08:20:21,794][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 08:20:21,794][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 08:20:21,795][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 08:20:21,795][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 08:20:21,798][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 08:20:23,432][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 08:20:23,432][root][INFO] - - Epoch: 5
[2024-10-21 08:20:23,432][root][INFO] - - DEV score: 76.00 [%]
[2024-10-21 08:20:23,433][root][INFO] - - TEST score: 76.78 [%]
[2024-10-21 08:20:23,434][root][INFO] - Fine-tuning is done!
[2024-10-21 08:22:24,653][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,653][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,654][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,655][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,655][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,656][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,656][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,657][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,657][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,658][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,658][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,659][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,659][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,660][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,660][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,661][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,661][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,662][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,662][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,663][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,664][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,664][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,665][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 08:22:24,665][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 08:22:24,667][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 08:22:24,871][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 08:22:24,874][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-21 08:22:24,875][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 08:22:25,059][root][INFO] - 

[2024-10-21 08:22:25,059][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 08:22:25,059][root][INFO] - Data Preprocessing
[2024-10-21 08:22:25,059][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-21 08:22:25,059][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 08:22:25,059][root][INFO] - ㄴ data_remove                False

[2024-10-21 08:22:25,059][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 08:22:25,071][root][INFO] - vocab size              : 51200
[2024-10-21 08:22:25,072][root][INFO] - device                  : gpu
[2024-10-21 08:22:25,072][root][INFO] - random seed             : 1
[2024-10-21 08:22:25,072][root][INFO] - train data size         : 942912
[2024-10-21 08:22:25,073][root][INFO] - max epochs              : 5
[2024-10-21 08:22:25,073][root][INFO] - total steps             : 73665
[2024-10-21 08:22:25,073][root][INFO] - warmup steps            : 7366
[2024-10-21 08:22:25,073][root][INFO] - batch size              : 64
[2024-10-21 08:22:25,073][root][INFO] - accumulation steps      : 1
[2024-10-21 08:22:25,073][root][INFO] - optimizer               : adamwscale
[2024-10-21 08:22:25,073][root][INFO] - lr_scheduler            : cosine
[2024-10-21 08:22:25,073][root][INFO] - learning rate           : 0.02
[2024-10-21 08:22:25,073][root][INFO] - max length              : 256

[2024-10-21 08:22:25,073][root][INFO] - LoRA Configuration
[2024-10-21 08:22:25,073][root][INFO] - ㄴ r                    : 32
[2024-10-21 08:22:25,073][root][INFO] - ㄴ alpha                : 128
[2024-10-21 08:22:25,073][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 08:22:25,074][root][INFO] - KOMBO Configuration
[2024-10-21 08:22:25,074][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 08:22:25,074][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 08:22:25,074][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 08:22:25,074][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 08:22:25,074][root][INFO] - ㄴ do_combination       : True
[2024-10-21 08:22:25,074][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 08:22:25,074][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 08:22:25,074][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 08:22:25,074][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 08:22:25,075][root][INFO] - 

[2024-10-21 08:22:25,075][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs
[2024-10-21 08:22:25,075][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 08:22:25,075][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-21 08:22:25,075][root][INFO] - * tb interval   : 10000

[2024-10-21 08:22:25,075][root][INFO] - 

[2024-10-21 08:22:25,075][root][INFO] - Start the Training !
[2024-10-21 08:22:25,077][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 08:43:40,120][root][INFO] - Step: 20000/66070  |  Loss: 0.9806  |  Score: 50.30 [%]  |  Seq Length: 256.0
[2024-10-21 08:56:26,072][root][INFO] - Step: 30000/63000  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-21 09:38:41,060][root][INFO] - Step: 26428/66070  |  Loss: nan  |  Score: 33.64 [%]  |  Seq Length: 256.0
[2024-10-21 09:38:49,060][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 09:38:49,060][root][INFO] - Score: 34.57 [%]  |  Evaluation Time: 8.00 [s]
[2024-10-21 09:39:04,411][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 09:39:04,411][root][INFO] - Score: 34.86 [%]  |  Evaluation Time: 15.35 [s]
[2024-10-21 09:39:04,414][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 09:49:18,564][root][INFO] - Step: 10000/73665  |  Loss: 0.7541  |  Score: 67.13 [%]  |  Seq Length: 256.0
[2024-10-21 10:02:17,732][root][INFO] - Step: 37800/63000  |  Loss: nan  |  Score: 33.74 [%]  |  Seq Length: 256.0
[2024-10-21 10:02:24,751][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 10:02:24,751][root][INFO] - Score: 34.54 [%]  |  Evaluation Time: 7.02 [s]
[2024-10-21 10:02:37,759][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 10:02:37,759][root][INFO] - Score: 34.89 [%]  |  Evaluation Time: 13.01 [s]
[2024-10-21 10:02:37,761][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 10:09:44,751][root][INFO] - Step: 30000/66070  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-21 10:21:17,405][root][INFO] - Step: 40000/63000  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-21 10:30:05,678][root][INFO] - Step: 14733/73665  |  Loss: 0.8342  |  Score: 62.10 [%]  |  Seq Length: 256.0
[2024-10-21 10:30:15,907][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 10:30:15,907][root][INFO] - Score: 51.71 [%]  |  Evaluation Time: 10.23 [s]
[2024-10-21 10:30:35,786][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 10:30:35,787][root][INFO] - Score: 53.12 [%]  |  Evaluation Time: 19.88 [s]
[2024-10-21 10:30:35,787][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 10:30:35,788][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 10:30:35,790][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 10:30:37,507][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 10:30:37,740][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 10:30:37,741][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 10:30:37,741][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 10:30:37,742][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 10:30:37,742][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 10:30:37,744][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 10:30:39,378][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 11:16:30,749][root][INFO] - Step: 20000/73665  |  Loss: 1.0761  |  Score: 40.34 [%]  |  Seq Length: 256.0
[2024-10-21 11:32:14,186][root][INFO] - Step: 39642/66070  |  Loss: nan  |  Score: 33.64 [%]  |  Seq Length: 256.0
[2024-10-21 11:32:22,283][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 11:32:22,284][root][INFO] - Score: 34.91 [%]  |  Evaluation Time: 8.09 [s]
[2024-10-21 11:32:37,346][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 11:32:37,346][root][INFO] - Score: 34.91 [%]  |  Evaluation Time: 15.06 [s]
[2024-10-21 11:32:37,348][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 11:35:41,919][root][INFO] - Step: 40000/66070  |  Loss: nan  |  Score: 34.24 [%]  |  Seq Length: 256.0
[2024-10-21 11:45:36,666][root][INFO] - Step: 50000/63000  |  Loss: nan  |  Score: 33.75 [%]  |  Seq Length: 256.0
[2024-10-21 11:48:59,402][root][INFO] - Step: 50400/63000  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-21 11:49:06,463][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 11:49:06,463][root][INFO] - Score: 34.72 [%]  |  Evaluation Time: 7.06 [s]
[2024-10-21 11:49:20,268][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 11:49:20,268][root][INFO] - Score: 34.76 [%]  |  Evaluation Time: 13.80 [s]
[2024-10-21 11:49:20,271][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 12:37:48,591][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-21 12:37:58,697][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 12:37:58,697][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.10 [s]
[2024-10-21 12:38:18,436][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 12:38:18,436][root][INFO] - Score: 33.59 [%]  |  Evaluation Time: 19.74 [s]
[2024-10-21 12:38:18,438][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 12:42:55,144][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-21 13:01:23,573][root][INFO] - Step: 50000/66070  |  Loss: nan  |  Score: 33.59 [%]  |  Seq Length: 256.0
[2024-10-21 13:10:36,547][root][INFO] - Step: 60000/63000  |  Loss: nan  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-21 13:25:50,144][root][INFO] - Step: 52856/66070  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-21 13:25:58,154][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 13:25:58,154][root][INFO] - Score: 34.97 [%]  |  Evaluation Time: 8.01 [s]
[2024-10-21 13:26:13,231][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 13:26:13,231][root][INFO] - Score: 34.86 [%]  |  Evaluation Time: 15.07 [s]
[2024-10-21 13:26:13,233][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 13:36:03,106][root][INFO] - Step: 63000/63000  |  Loss: nan  |  Score: 33.86 [%]  |  Seq Length: 256.0
[2024-10-21 13:36:10,161][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 13:36:10,161][root][INFO] - Score: 34.54 [%]  |  Evaluation Time: 7.05 [s]
[2024-10-21 13:36:23,165][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 13:36:23,165][root][INFO] - Score: 35.07 [%]  |  Evaluation Time: 13.00 [s]
[2024-10-21 13:36:23,166][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 13:36:23,166][root][INFO] - - Epoch: 1
[2024-10-21 13:36:23,166][root][INFO] - - DEV score: 59.26 [%]
[2024-10-21 13:36:23,166][root][INFO] - - TEST score: 60.39 [%]
[2024-10-21 13:36:23,167][root][INFO] - Fine-tuning is done!
[2024-10-21 13:36:23,167][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-21 13:36:23,167][root][INFO] - - BEST LR: 0.01
[2024-10-21 13:36:23,168][root][INFO] - - DEV score: 76.17 [%]
[2024-10-21 13:36:23,168][root][INFO] - - TEST score: 75.90 [%]
[2024-10-21 13:36:29,623][root][INFO] - 

[2024-10-21 13:36:29,624][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 13:36:29,624][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs
[2024-10-21 13:36:29,624][root][INFO] - 

[2024-10-21 13:36:29,624][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 13:38:10,108][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,109][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,110][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,110][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,111][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,111][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,112][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,113][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,113][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,114][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,115][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,115][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,116][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,116][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,117][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,117][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,118][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,119][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,119][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,120][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,122][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,122][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,123][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 13:38:10,123][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 13:38:10,126][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 13:38:10,363][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 13:38:12,264][root][INFO] - 

[2024-10-21 13:38:12,264][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 13:38:12,264][root][INFO] - Data Preprocessing
[2024-10-21 13:38:12,264][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 13:38:12,264][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 13:38:12,264][root][INFO] - ㄴ data_remove                True

[2024-10-21 13:38:12,264][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 13:38:12,272][root][INFO] - vocab size              : 51200
[2024-10-21 13:38:12,272][root][INFO] - device                  : gpu
[2024-10-21 13:38:12,272][root][INFO] - random seed             : 2
[2024-10-21 13:38:12,272][root][INFO] - train data size         : 806400
[2024-10-21 13:38:12,272][root][INFO] - max epochs              : 5
[2024-10-21 13:38:12,272][root][INFO] - total steps             : 63000
[2024-10-21 13:38:12,272][root][INFO] - warmup steps            : 6300
[2024-10-21 13:38:12,272][root][INFO] - batch size              : 64
[2024-10-21 13:38:12,272][root][INFO] - accumulation steps      : 1
[2024-10-21 13:38:12,273][root][INFO] - optimizer               : adamwscale
[2024-10-21 13:38:12,273][root][INFO] - lr_scheduler            : cosine
[2024-10-21 13:38:12,273][root][INFO] - learning rate           : 0.01
[2024-10-21 13:38:12,273][root][INFO] - max length              : 256

[2024-10-21 13:38:12,273][root][INFO] - LoRA Configuration
[2024-10-21 13:38:12,273][root][INFO] - ㄴ r                    : 32
[2024-10-21 13:38:12,273][root][INFO] - ㄴ alpha                : 128
[2024-10-21 13:38:12,273][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 13:38:12,273][root][INFO] - 

[2024-10-21 13:38:12,273][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs
[2024-10-21 13:38:12,273][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-21 13:38:12,274][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-21 13:38:12,274][root][INFO] - * tb interval   : 10000

[2024-10-21 13:38:12,274][root][INFO] - 

[2024-10-21 13:38:12,274][root][INFO] - Start the Training !
[2024-10-21 13:38:12,277][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 14:08:54,215][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-21 14:27:27,101][root][INFO] - Step: 60000/66070  |  Loss: nan  |  Score: 33.60 [%]  |  Seq Length: 256.0
[2024-10-21 14:39:13,841][root][INFO] - Step: 10000/63000  |  Loss: 0.7222  |  Score: 68.87 [%]  |  Seq Length: 256.0
[2024-10-21 14:44:58,449][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-21 14:45:08,606][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 14:45:08,606][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.16 [s]
[2024-10-21 14:45:28,433][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 14:45:28,433][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 19.82 [s]
[2024-10-21 14:45:28,435][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 14:55:07,804][root][INFO] - Step: 12600/63000  |  Loss: 0.6509  |  Score: 72.80 [%]  |  Seq Length: 256.0
[2024-10-21 14:55:12,142][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 14:55:12,142][root][INFO] - Score: 70.56 [%]  |  Evaluation Time: 4.34 [s]
[2024-10-21 14:55:20,076][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 14:55:20,076][root][INFO] - Score: 69.72 [%]  |  Evaluation Time: 7.93 [s]
[2024-10-21 14:55:20,077][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 14:55:20,078][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 14:55:20,936][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 14:55:20,970][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 14:55:20,970][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 14:55:20,970][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 14:55:20,971][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 14:55:20,971][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 14:55:20,972][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 14:55:21,655][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 15:19:36,227][root][INFO] - Step: 66070/66070  |  Loss: nan  |  Score: 33.67 [%]  |  Seq Length: 256.0
[2024-10-21 15:19:44,630][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 15:19:44,630][root][INFO] - Score: 34.68 [%]  |  Evaluation Time: 8.40 [s]
[2024-10-21 15:19:59,950][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 15:19:59,950][root][INFO] - Score: 34.74 [%]  |  Evaluation Time: 15.32 [s]
[2024-10-21 15:19:59,951][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 15:19:59,951][root][INFO] - - Epoch: 1
[2024-10-21 15:19:59,951][root][INFO] - - DEV score: 59.96 [%]
[2024-10-21 15:19:59,952][root][INFO] - - TEST score: 58.60 [%]
[2024-10-21 15:19:59,953][root][INFO] - Fine-tuning is done!
[2024-10-21 15:19:59,953][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-21 15:19:59,953][root][INFO] - - BEST LR: 0.01
[2024-10-21 15:19:59,953][root][INFO] - - DEV score: 75.00 [%]
[2024-10-21 15:19:59,953][root][INFO] - - TEST score: 75.05 [%]
[2024-10-21 15:20:06,680][root][INFO] - 

[2024-10-21 15:20:06,680][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 15:20:06,681][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-21 15:20:06,681][root][INFO] - 

[2024-10-21 15:20:06,681][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 15:21:53,854][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,855][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,856][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,856][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,856][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,857][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,857][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,858][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,858][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,859][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,859][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,860][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,860][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,861][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,861][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,862][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,862][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,863][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,863][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,864][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,864][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,865][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,865][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 15:21:53,866][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 15:21:53,867][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 15:21:54,110][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 15:21:56,071][root][INFO] - 

[2024-10-21 15:21:56,071][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 15:21:56,071][root][INFO] - Data Preprocessing
[2024-10-21 15:21:56,071][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-21 15:21:56,071][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 15:21:56,072][root][INFO] - ㄴ data_remove                True

[2024-10-21 15:21:56,072][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 15:21:56,079][root][INFO] - vocab size              : 51200
[2024-10-21 15:21:56,080][root][INFO] - device                  : gpu
[2024-10-21 15:21:56,080][root][INFO] - random seed             : 2
[2024-10-21 15:21:56,080][root][INFO] - train data size         : 845696
[2024-10-21 15:21:56,080][root][INFO] - max epochs              : 5
[2024-10-21 15:21:56,080][root][INFO] - total steps             : 66070
[2024-10-21 15:21:56,080][root][INFO] - warmup steps            : 6607
[2024-10-21 15:21:56,080][root][INFO] - batch size              : 64
[2024-10-21 15:21:56,080][root][INFO] - accumulation steps      : 1
[2024-10-21 15:21:56,080][root][INFO] - optimizer               : adamwscale
[2024-10-21 15:21:56,080][root][INFO] - lr_scheduler            : cosine
[2024-10-21 15:21:56,080][root][INFO] - learning rate           : 0.01
[2024-10-21 15:21:56,081][root][INFO] - max length              : 256

[2024-10-21 15:21:56,081][root][INFO] - LoRA Configuration
[2024-10-21 15:21:56,081][root][INFO] - ㄴ r                    : 32
[2024-10-21 15:21:56,081][root][INFO] - ㄴ alpha                : 128
[2024-10-21 15:21:56,081][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 15:21:56,081][root][INFO] - 

[2024-10-21 15:21:56,081][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-21 15:21:56,081][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-21 15:21:56,081][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/tb
[2024-10-21 15:21:56,081][root][INFO] - * tb interval   : 10000

[2024-10-21 15:21:56,081][root][INFO] - 

[2024-10-21 15:21:56,081][root][INFO] - Start the Training !
[2024-10-21 15:21:56,084][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 15:35:26,333][root][INFO] - Step: 50000/73665  |  Loss: nan  |  Score: 33.34 [%]  |  Seq Length: 256.0
[2024-10-21 15:40:37,571][root][INFO] - Step: 20000/63000  |  Loss: 0.6242  |  Score: 74.15 [%]  |  Seq Length: 256.0
[2024-10-21 16:12:28,106][root][INFO] - Step: 25200/63000  |  Loss: 0.6158  |  Score: 74.59 [%]  |  Seq Length: 256.0
[2024-10-21 16:12:32,452][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 16:12:32,452][root][INFO] - Score: 71.39 [%]  |  Evaluation Time: 4.34 [s]
[2024-10-21 16:12:40,518][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 16:12:40,518][root][INFO] - Score: 73.28 [%]  |  Evaluation Time: 8.06 [s]
[2024-10-21 16:12:40,519][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 16:12:40,520][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 16:12:42,057][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 16:12:42,087][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 16:12:42,087][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 16:12:42,087][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 16:12:42,087][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 16:12:42,088][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 16:12:42,089][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 16:12:43,505][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 16:23:34,624][root][INFO] - Step: 10000/66070  |  Loss: 0.7254  |  Score: 68.60 [%]  |  Seq Length: 256.0
[2024-10-21 16:42:06,107][root][INFO] - Step: 30000/63000  |  Loss: 0.5876  |  Score: 75.97 [%]  |  Seq Length: 256.0
[2024-10-21 16:43:23,113][root][INFO] - Step: 13214/66070  |  Loss: 0.6528  |  Score: 72.60 [%]  |  Seq Length: 256.0
[2024-10-21 16:43:28,072][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 16:43:28,072][root][INFO] - Score: 71.51 [%]  |  Evaluation Time: 4.96 [s]
[2024-10-21 16:43:37,193][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 16:43:37,193][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-21 16:43:37,194][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 16:43:37,195][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 16:43:38,033][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 16:43:38,070][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 16:43:38,070][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 16:43:38,070][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 16:43:38,071][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 16:43:38,071][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 16:43:38,072][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 16:43:38,725][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 16:52:22,082][root][INFO] - Step: 58932/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-21 16:52:32,254][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 16:52:32,254][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.17 [s]
[2024-10-21 16:52:52,047][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 16:52:52,048][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 19.79 [s]
[2024-10-21 16:52:52,050][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 17:02:03,844][root][INFO] - Step: 60000/73665  |  Loss: nan  |  Score: 33.62 [%]  |  Seq Length: 256.0
[2024-10-21 17:25:29,969][root][INFO] - Step: 20000/66070  |  Loss: 0.6257  |  Score: 74.05 [%]  |  Seq Length: 256.0
[2024-10-21 17:29:50,975][root][INFO] - Step: 37800/63000  |  Loss: 0.5759  |  Score: 76.50 [%]  |  Seq Length: 256.0
[2024-10-21 17:29:55,305][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 17:29:55,305][root][INFO] - Score: 73.81 [%]  |  Evaluation Time: 4.33 [s]
[2024-10-21 17:30:03,426][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 17:30:03,426][root][INFO] - Score: 73.85 [%]  |  Evaluation Time: 8.12 [s]
[2024-10-21 17:30:03,427][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-21 17:30:03,428][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 17:30:04,993][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 17:30:05,025][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 17:30:05,025][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 17:30:05,025][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 17:30:05,026][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 17:30:05,026][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 17:30:05,027][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 17:30:06,437][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 17:43:36,976][root][INFO] - Step: 40000/63000  |  Loss: 0.5406  |  Score: 78.20 [%]  |  Seq Length: 256.0
[2024-10-21 18:05:11,460][root][INFO] - Step: 26428/66070  |  Loss: 0.6179  |  Score: 74.42 [%]  |  Seq Length: 256.0
[2024-10-21 18:05:16,406][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 18:05:16,407][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 4.94 [s]
[2024-10-21 18:05:25,592][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 18:05:25,592][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 9.18 [s]
[2024-10-21 18:05:25,594][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 18:05:25,594][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 18:05:27,129][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 18:05:27,159][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 18:05:27,160][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 18:05:27,160][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 18:05:27,160][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 18:05:27,160][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 18:05:27,161][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 18:05:28,563][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 18:27:31,723][root][INFO] - Step: 30000/66070  |  Loss: 0.5881  |  Score: 75.91 [%]  |  Seq Length: 256.0
[2024-10-21 18:28:05,405][root][INFO] - Step: 70000/73665  |  Loss: nan  |  Score: 33.26 [%]  |  Seq Length: 256.0
[2024-10-21 18:44:49,474][root][INFO] - Step: 50000/63000  |  Loss: 0.5304  |  Score: 78.64 [%]  |  Seq Length: 256.0
[2024-10-21 18:47:16,256][root][INFO] - Step: 50400/63000  |  Loss: 0.5218  |  Score: 79.03 [%]  |  Seq Length: 256.0
[2024-10-21 18:47:20,707][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 18:47:20,707][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-21 18:47:28,657][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 18:47:28,657][root][INFO] - Score: 75.26 [%]  |  Evaluation Time: 7.95 [s]
[2024-10-21 18:47:28,658][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 18:47:28,658][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 18:47:30,210][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 18:47:30,245][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 18:47:30,246][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 18:47:30,246][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 18:47:30,246][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 18:47:30,246][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 18:47:30,247][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 18:47:31,776][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 18:59:35,496][root][INFO] - Step: 73665/73665  |  Loss: nan  |  Score: 33.45 [%]  |  Seq Length: 256.0
[2024-10-21 18:59:45,659][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 18:59:45,659][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 10.16 [s]
[2024-10-21 19:00:05,429][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 19:00:05,430][root][INFO] - Score: 33.33 [%]  |  Evaluation Time: 19.77 [s]
[2024-10-21 19:00:05,431][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 19:00:05,431][root][INFO] - - Epoch: 1
[2024-10-21 19:00:05,431][root][INFO] - - DEV score: 51.71 [%]
[2024-10-21 19:00:05,431][root][INFO] - - TEST score: 53.12 [%]
[2024-10-21 19:00:05,432][root][INFO] - Fine-tuning is done!
[2024-10-21 19:00:05,432][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-21 19:00:05,432][root][INFO] - - BEST LR: 0.01
[2024-10-21 19:00:05,432][root][INFO] - - DEV score: 76.00 [%]
[2024-10-21 19:00:05,432][root][INFO] - - TEST score: 76.78 [%]
[2024-10-21 19:00:12,395][root][INFO] - 

[2024-10-21 19:00:12,395][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 19:00:12,396][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs
[2024-10-21 19:00:12,396][root][INFO] - 

[2024-10-21 19:00:12,396][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 19:02:20,639][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,640][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,640][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,641][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,641][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,642][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,642][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,643][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,643][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,643][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,644][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,644][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,645][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,645][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,646][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,646][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,647][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,647][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,647][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,648][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,648][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,649][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,649][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 19:02:20,650][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 19:02:20,651][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 19:02:20,915][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 19:02:22,841][root][INFO] - 

[2024-10-21 19:02:22,841][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 19:02:22,841][root][INFO] - Data Preprocessing
[2024-10-21 19:02:22,841][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-21 19:02:22,841][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 19:02:22,841][root][INFO] - ㄴ data_remove                False

[2024-10-21 19:02:22,841][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 19:02:22,851][root][INFO] - vocab size              : 51200
[2024-10-21 19:02:22,851][root][INFO] - device                  : gpu
[2024-10-21 19:02:22,851][root][INFO] - random seed             : 2
[2024-10-21 19:02:22,851][root][INFO] - train data size         : 942912
[2024-10-21 19:02:22,851][root][INFO] - max epochs              : 5
[2024-10-21 19:02:22,851][root][INFO] - total steps             : 73665
[2024-10-21 19:02:22,851][root][INFO] - warmup steps            : 7366
[2024-10-21 19:02:22,852][root][INFO] - batch size              : 64
[2024-10-21 19:02:22,852][root][INFO] - accumulation steps      : 1
[2024-10-21 19:02:22,852][root][INFO] - optimizer               : adamwscale
[2024-10-21 19:02:22,852][root][INFO] - lr_scheduler            : cosine
[2024-10-21 19:02:22,852][root][INFO] - learning rate           : 0.01
[2024-10-21 19:02:22,852][root][INFO] - max length              : 256

[2024-10-21 19:02:22,852][root][INFO] - LoRA Configuration
[2024-10-21 19:02:22,852][root][INFO] - ㄴ r                    : 32
[2024-10-21 19:02:22,852][root][INFO] - ㄴ alpha                : 128
[2024-10-21 19:02:22,852][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 19:02:22,852][root][INFO] - 

[2024-10-21 19:02:22,853][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs
[2024-10-21 19:02:22,853][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-21 19:02:22,853][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-21 19:02:22,853][root][INFO] - * tb interval   : 10000

[2024-10-21 19:02:22,853][root][INFO] - 

[2024-10-21 19:02:22,853][root][INFO] - Start the Training !
[2024-10-21 19:02:22,856][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 19:27:00,948][root][INFO] - Step: 39642/66070  |  Loss: 0.5816  |  Score: 76.19 [%]  |  Seq Length: 256.0
[2024-10-21 19:27:05,886][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 19:27:05,886][root][INFO] - Score: 73.66 [%]  |  Evaluation Time: 4.93 [s]
[2024-10-21 19:27:15,014][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 19:27:15,015][root][INFO] - Score: 73.81 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-21 19:27:15,016][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-21 19:27:15,016][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 19:27:16,584][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 19:27:16,617][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 19:27:16,618][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 19:27:16,618][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 19:27:16,618][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 19:27:16,618][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 19:27:16,619][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 19:27:18,042][root][INFO] - 
[4/ 5 Epoch]
[2024-10-21 19:29:30,874][root][INFO] - Step: 40000/66070  |  Loss: 0.5435  |  Score: 77.88 [%]  |  Seq Length: 256.0
[2024-10-21 19:46:21,065][root][INFO] - Step: 60000/63000  |  Loss: 0.4961  |  Score: 80.22 [%]  |  Seq Length: 256.0
[2024-10-21 20:03:30,297][root][INFO] - Step: 10000/73665  |  Loss: 0.7326  |  Score: 68.27 [%]  |  Seq Length: 256.0
[2024-10-21 20:04:43,907][root][INFO] - Step: 63000/63000  |  Loss: 0.4910  |  Score: 80.27 [%]  |  Seq Length: 256.0
[2024-10-21 20:04:48,318][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 20:04:48,318][root][INFO] - Score: 74.81 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-21 20:04:56,328][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 20:04:56,328][root][INFO] - Score: 75.24 [%]  |  Evaluation Time: 8.01 [s]
[2024-10-21 20:04:56,329][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-21 20:04:56,330][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 20:04:57,921][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 20:04:57,952][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 20:04:57,952][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 20:04:57,952][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 20:04:57,952][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 20:04:57,953][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 20:04:57,954][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 20:04:59,524][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 20:04:59,524][root][INFO] - - Epoch: 5
[2024-10-21 20:04:59,525][root][INFO] - - DEV score: 74.81 [%]
[2024-10-21 20:04:59,525][root][INFO] - - TEST score: 75.24 [%]
[2024-10-21 20:04:59,526][root][INFO] - Fine-tuning is done!
[2024-10-21 20:06:41,681][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,682][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,682][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,683][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,683][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,684][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,684][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,684][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,685][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,685][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,686][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,686][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,687][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,687][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,687][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,688][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,688][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,689][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,689][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,689][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,690][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,690][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,691][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 20:06:41,691][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 20:06:41,693][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 20:06:41,694][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 20:06:41,831][root][INFO] - 

[2024-10-21 20:06:41,831][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 20:06:41,831][root][INFO] - Data Preprocessing
[2024-10-21 20:06:41,831][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 20:06:41,832][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 20:06:41,832][root][INFO] - ㄴ data_remove                True

[2024-10-21 20:06:41,832][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 20:06:41,847][root][INFO] - vocab size              : 51200
[2024-10-21 20:06:41,848][root][INFO] - device                  : gpu
[2024-10-21 20:06:41,848][root][INFO] - random seed             : 2
[2024-10-21 20:06:41,849][root][INFO] - train data size         : 806400
[2024-10-21 20:06:41,849][root][INFO] - max epochs              : 5
[2024-10-21 20:06:41,849][root][INFO] - total steps             : 63000
[2024-10-21 20:06:41,849][root][INFO] - warmup steps            : 6300
[2024-10-21 20:06:41,849][root][INFO] - batch size              : 64
[2024-10-21 20:06:41,849][root][INFO] - accumulation steps      : 1
[2024-10-21 20:06:41,849][root][INFO] - optimizer               : adamwscale
[2024-10-21 20:06:41,849][root][INFO] - lr_scheduler            : cosine
[2024-10-21 20:06:41,849][root][INFO] - learning rate           : 0.02
[2024-10-21 20:06:41,849][root][INFO] - max length              : 256

[2024-10-21 20:06:41,849][root][INFO] - LoRA Configuration
[2024-10-21 20:06:41,849][root][INFO] - ㄴ r                    : 32
[2024-10-21 20:06:41,850][root][INFO] - ㄴ alpha                : 128
[2024-10-21 20:06:41,850][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 20:06:41,850][root][INFO] - 

[2024-10-21 20:06:41,850][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs
[2024-10-21 20:06:41,850][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-21 20:06:41,850][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-21 20:06:41,850][root][INFO] - * tb interval   : 10000

[2024-10-21 20:06:41,850][root][INFO] - 

[2024-10-21 20:06:41,850][root][INFO] - Start the Training !
[2024-10-21 20:06:41,852][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 20:31:07,630][root][INFO] - Step: 50000/66070  |  Loss: 0.5370  |  Score: 78.34 [%]  |  Seq Length: 256.0
[2024-10-21 20:32:23,727][root][INFO] - Step: 14733/73665  |  Loss: 0.6635  |  Score: 72.16 [%]  |  Seq Length: 256.0
[2024-10-21 20:32:29,950][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 20:32:29,950][root][INFO] - Score: 71.04 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-21 20:32:41,801][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 20:32:41,801][root][INFO] - Score: 71.54 [%]  |  Evaluation Time: 11.85 [s]
[2024-10-21 20:32:41,803][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 20:32:41,804][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 20:32:42,683][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 20:32:42,709][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 20:32:42,710][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 20:32:42,710][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 20:32:42,710][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 20:32:42,710][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 20:32:42,712][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 20:32:43,381][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 20:48:45,971][root][INFO] - Step: 52856/66070  |  Loss: 0.5221  |  Score: 78.98 [%]  |  Seq Length: 256.0
[2024-10-21 20:48:50,916][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 20:48:50,916][root][INFO] - Score: 75.05 [%]  |  Evaluation Time: 4.94 [s]
[2024-10-21 20:49:00,079][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 20:49:00,079][root][INFO] - Score: 75.06 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-21 20:49:00,080][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 20:49:00,080][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 20:49:01,612][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 20:49:01,657][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 20:49:01,658][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 20:49:01,658][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 20:49:01,658][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 20:49:01,658][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 20:49:01,659][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 20:49:03,125][root][INFO] - 
[5/ 5 Epoch]
[2024-10-21 21:04:56,167][root][INFO] - Step: 20000/73665  |  Loss: 0.6367  |  Score: 73.53 [%]  |  Seq Length: 256.0
[2024-10-21 21:07:50,506][root][INFO] - Step: 10000/63000  |  Loss: 0.7544  |  Score: 67.13 [%]  |  Seq Length: 256.0
[2024-10-21 21:23:46,881][root][INFO] - Step: 12600/63000  |  Loss: 0.8060  |  Score: 63.98 [%]  |  Seq Length: 256.0
[2024-10-21 21:23:51,525][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 21:23:51,525][root][INFO] - Score: 53.58 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-21 21:23:59,668][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 21:23:59,669][root][INFO] - Score: 54.01 [%]  |  Evaluation Time: 8.14 [s]
[2024-10-21 21:23:59,670][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 21:23:59,670][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 21:24:01,232][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 21:24:01,272][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 21:24:01,273][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 21:24:01,273][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 21:24:01,273][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 21:24:01,273][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 21:24:01,275][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 21:24:02,838][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 21:33:08,366][root][INFO] - Step: 60000/66070  |  Loss: 0.4980  |  Score: 80.13 [%]  |  Seq Length: 256.0
[2024-10-21 22:02:56,299][root][INFO] - Step: 29466/73665  |  Loss: 0.6291  |  Score: 73.91 [%]  |  Seq Length: 256.0
[2024-10-21 22:03:02,551][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 22:03:02,551][root][INFO] - Score: 72.93 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-21 22:03:14,424][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 22:03:14,424][root][INFO] - Score: 73.57 [%]  |  Evaluation Time: 11.87 [s]
[2024-10-21 22:03:14,425][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 22:03:14,426][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-21 22:03:16,089][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 22:03:16,138][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 22:03:16,138][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 22:03:16,138][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 22:03:16,138][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 22:03:16,138][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 22:03:16,140][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 22:03:17,574][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 22:06:34,029][root][INFO] - Step: 30000/73665  |  Loss: 0.5972  |  Score: 75.44 [%]  |  Seq Length: 256.0
[2024-10-21 22:09:26,983][root][INFO] - Step: 20000/63000  |  Loss: 0.9950  |  Score: 48.53 [%]  |  Seq Length: 256.0
[2024-10-21 22:10:34,896][root][INFO] - Step: 66070/66070  |  Loss: 0.4941  |  Score: 80.30 [%]  |  Seq Length: 256.0
[2024-10-21 22:10:39,819][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 22:10:39,819][root][INFO] - Score: 75.17 [%]  |  Evaluation Time: 4.92 [s]
[2024-10-21 22:10:48,973][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 22:10:48,973][root][INFO] - Score: 74.76 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-21 22:10:48,974][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 22:10:48,974][root][INFO] - - Epoch: 4
[2024-10-21 22:10:48,974][root][INFO] - - DEV score: 75.05 [%]
[2024-10-21 22:10:48,974][root][INFO] - - TEST score: 75.06 [%]
[2024-10-21 22:10:48,975][root][INFO] - Fine-tuning is done!
[2024-10-21 22:12:34,624][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,625][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,625][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,626][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,626][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,627][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,627][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,628][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,628][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,629][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,629][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,630][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,630][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,631][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,631][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,632][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,633][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,633][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,634][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,634][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,635][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,635][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,636][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 22:12:34,637][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 22:12:34,639][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 22:12:34,640][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 22:12:34,823][root][INFO] - 

[2024-10-21 22:12:34,824][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 22:12:34,824][root][INFO] - Data Preprocessing
[2024-10-21 22:12:34,824][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-21 22:12:34,824][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 22:12:34,824][root][INFO] - ㄴ data_remove                True

[2024-10-21 22:12:34,824][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 22:12:34,835][root][INFO] - vocab size              : 51200
[2024-10-21 22:12:34,836][root][INFO] - device                  : gpu
[2024-10-21 22:12:34,836][root][INFO] - random seed             : 2
[2024-10-21 22:12:34,837][root][INFO] - train data size         : 845696
[2024-10-21 22:12:34,837][root][INFO] - max epochs              : 5
[2024-10-21 22:12:34,837][root][INFO] - total steps             : 66070
[2024-10-21 22:12:34,837][root][INFO] - warmup steps            : 6607
[2024-10-21 22:12:34,837][root][INFO] - batch size              : 64
[2024-10-21 22:12:34,837][root][INFO] - accumulation steps      : 1
[2024-10-21 22:12:34,837][root][INFO] - optimizer               : adamwscale
[2024-10-21 22:12:34,837][root][INFO] - lr_scheduler            : cosine
[2024-10-21 22:12:34,837][root][INFO] - learning rate           : 0.02
[2024-10-21 22:12:34,837][root][INFO] - max length              : 256

[2024-10-21 22:12:34,837][root][INFO] - LoRA Configuration
[2024-10-21 22:12:34,837][root][INFO] - ㄴ r                    : 32
[2024-10-21 22:12:34,837][root][INFO] - ㄴ alpha                : 128
[2024-10-21 22:12:34,838][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 22:12:34,838][root][INFO] - 

[2024-10-21 22:12:34,838][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-21 22:12:34,838][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-21 22:12:34,838][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_en_punc_dr/256t_64b_1s_2rs/tb
[2024-10-21 22:12:34,838][root][INFO] - * tb interval   : 10000

[2024-10-21 22:12:34,838][root][INFO] - 

[2024-10-21 22:12:34,838][root][INFO] - Start the Training !
[2024-10-21 22:12:34,840][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 22:41:18,802][root][INFO] - Step: 25200/63000  |  Loss: 1.1257  |  Score: 33.43 [%]  |  Seq Length: 256.0
[2024-10-21 22:41:23,401][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 22:41:23,401][root][INFO] - Score: 33.74 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-21 22:41:31,528][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 22:41:31,528][root][INFO] - Score: 33.91 [%]  |  Evaluation Time: 8.12 [s]
[2024-10-21 22:41:31,530][root][INFO] - 
[3/ 5 Epoch]
[2024-10-21 23:07:41,919][root][INFO] - Step: 40000/73665  |  Loss: 0.5991  |  Score: 75.38 [%]  |  Seq Length: 256.0
[2024-10-21 23:10:56,223][root][INFO] - Step: 30000/63000  |  Loss: 1.1408  |  Score: 33.29 [%]  |  Seq Length: 256.0
[2024-10-21 23:14:15,625][root][INFO] - Step: 10000/66070  |  Loss: 0.7537  |  Score: 67.12 [%]  |  Seq Length: 256.0
[2024-10-21 23:29:07,531][root][INFO] - 

[2024-10-21 23:29:07,531][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:29:07,531][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:29:07,531][root][INFO] - 

[2024-10-21 23:29:07,532][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:29:12,248][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,248][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,249][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,249][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,249][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,250][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,250][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,251][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,251][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,252][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,252][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,253][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,253][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,254][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,254][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,255][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,255][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,255][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,256][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,256][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,262][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,263][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,263][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:12,264][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:12,265][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-21 23:29:12,449][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:29:14,359][root][INFO] - 

[2024-10-21 23:29:14,359][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-21 23:29:14,359][root][INFO] - Data Preprocessing
[2024-10-21 23:29:14,359][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:29:14,359][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:29:14,359][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:29:14,359][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:29:14,366][root][INFO] - vocab size              : 51200
[2024-10-21 23:29:14,366][root][INFO] - device                  : gpu
[2024-10-21 23:29:14,366][root][INFO] - random seed             : 1
[2024-10-21 23:29:14,366][root][INFO] - train data size         : 5760
[2024-10-21 23:29:14,367][root][INFO] - max epochs              : 15
[2024-10-21 23:29:14,367][root][INFO] - total steps             : 1350
[2024-10-21 23:29:14,367][root][INFO] - warmup steps            : 135
[2024-10-21 23:29:14,367][root][INFO] - batch size              : 64
[2024-10-21 23:29:14,367][root][INFO] - accumulation steps      : 1
[2024-10-21 23:29:14,367][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:29:14,367][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:29:14,367][root][INFO] - learning rate           : 0.01
[2024-10-21 23:29:14,367][root][INFO] - max length              : 256

[2024-10-21 23:29:14,367][root][INFO] - LoRA Configuration
[2024-10-21 23:29:14,367][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:29:14,367][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:29:14,367][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:29:14,368][root][INFO] - 

[2024-10-21 23:29:14,368][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:29:14,368][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:29:14,368][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:29:14,368][root][INFO] - * tb interval   : 10000

[2024-10-21 23:29:14,368][root][INFO] - 

[2024-10-21 23:29:14,368][root][INFO] - Start the Training !
[2024-10-21 23:29:14,371][root][INFO] - 
[1/ 15 Epoch]
[2024-10-21 23:29:24,531][root][INFO] - 

[2024-10-21 23:29:24,531][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:29:24,532][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:29:24,532][root][INFO] - 

[2024-10-21 23:29:24,532][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:29:36,152][root][INFO] - 

[2024-10-21 23:29:36,152][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:29:36,152][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:29:36,152][root][INFO] - 

[2024-10-21 23:29:36,152][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:29:48,013][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,014][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,014][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,015][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,015][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,016][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,016][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,017][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,017][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,018][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,018][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,018][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,019][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,019][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,020][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,020][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,021][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,021][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,022][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,022][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,023][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,023][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,024][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:29:48,025][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:29:48,026][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-21 23:29:48,220][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:29:48,913][root][INFO] - Step: 90/1350  |  Loss: 2.4113  |  Score: 33.10 [%]  |  Seq Length: 256.0
[2024-10-21 23:29:50,130][root][INFO] - 

[2024-10-21 23:29:50,131][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-21 23:29:50,131][root][INFO] - Data Preprocessing
[2024-10-21 23:29:50,131][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:29:50,131][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:29:50,131][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:29:50,131][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:29:50,139][root][INFO] - vocab size              : 51200
[2024-10-21 23:29:50,139][root][INFO] - device                  : gpu
[2024-10-21 23:29:50,139][root][INFO] - random seed             : 1
[2024-10-21 23:29:50,139][root][INFO] - train data size         : 135040
[2024-10-21 23:29:50,139][root][INFO] - max epochs              : 5
[2024-10-21 23:29:50,139][root][INFO] - total steps             : 10550
[2024-10-21 23:29:50,139][root][INFO] - warmup steps            : 1055
[2024-10-21 23:29:50,139][root][INFO] - batch size              : 64
[2024-10-21 23:29:50,139][root][INFO] - accumulation steps      : 1
[2024-10-21 23:29:50,140][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:29:50,140][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:29:50,140][root][INFO] - learning rate           : 0.01
[2024-10-21 23:29:50,140][root][INFO] - max length              : 256

[2024-10-21 23:29:50,140][root][INFO] - LoRA Configuration
[2024-10-21 23:29:50,140][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:29:50,140][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:29:50,140][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:29:50,140][root][INFO] - 

[2024-10-21 23:29:50,140][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:29:50,140][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:29:50,141][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:29:50,141][root][INFO] - * tb interval   : 10000

[2024-10-21 23:29:50,141][root][INFO] - 

[2024-10-21 23:29:50,141][root][INFO] - Start the Training !
[2024-10-21 23:29:50,144][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 23:29:52,784][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 23:29:52,784][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 3.87 [s]
[2024-10-21 23:29:56,397][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 23:29:56,397][root][INFO] - Score: 63.85 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-21 23:29:56,399][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 23:29:56,399][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:29:57,965][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:29:58,013][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:29:58,014][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:29:58,014][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:29:58,014][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:29:58,014][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:29:58,015][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:29:59,462][root][INFO] - 
[2/ 15 Epoch]
[2024-10-21 23:30:40,927][root][INFO] - 

[2024-10-21 23:30:40,927][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:30:40,927][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:30:40,927][root][INFO] - 

[2024-10-21 23:30:40,927][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:30:43,744][root][INFO] - 

[2024-10-21 23:30:43,744][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:30:43,744][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:30:43,744][root][INFO] - 

[2024-10-21 23:30:43,745][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:30:45,826][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,826][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,827][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,827][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,828][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,828][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,829][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,829][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,830][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,831][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,831][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,832][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,832][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,833][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,833][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,834][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,835][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,835][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,836][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,836][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,837][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,837][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,838][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:30:45,839][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:30:45,841][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-21 23:30:45,845][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-21 23:30:46,049][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 23:30:46,052][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-21 23:30:46,240][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:30:46,780][root][INFO] - 

[2024-10-21 23:30:46,780][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:30:46,780][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:30:46,780][root][INFO] - 

[2024-10-21 23:30:46,780][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:30:49,462][root][INFO] - 

[2024-10-21 23:30:49,462][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-21 23:30:49,462][root][INFO] - Data Preprocessing
[2024-10-21 23:30:49,462][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:30:49,462][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:30:49,462][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:30:49,462][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:30:49,470][root][INFO] - vocab size              : 51200
[2024-10-21 23:30:49,470][root][INFO] - device                  : gpu
[2024-10-21 23:30:49,470][root][INFO] - random seed             : 1
[2024-10-21 23:30:49,470][root][INFO] - train data size         : 5760
[2024-10-21 23:30:49,470][root][INFO] - max epochs              : 15
[2024-10-21 23:30:49,470][root][INFO] - total steps             : 1350
[2024-10-21 23:30:49,470][root][INFO] - warmup steps            : 135
[2024-10-21 23:30:49,470][root][INFO] - batch size              : 64
[2024-10-21 23:30:49,470][root][INFO] - accumulation steps      : 1
[2024-10-21 23:30:49,471][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:30:49,471][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:30:49,471][root][INFO] - learning rate           : 0.01
[2024-10-21 23:30:49,471][root][INFO] - max length              : 256

[2024-10-21 23:30:49,471][root][INFO] - LoRA Configuration
[2024-10-21 23:30:49,471][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:30:49,471][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:30:49,471][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:30:49,471][root][INFO] - KOMBO Configuration
[2024-10-21 23:30:49,471][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 23:30:49,471][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 23:30:49,472][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 23:30:49,472][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 23:30:49,472][root][INFO] - ㄴ do_combination       : True
[2024-10-21 23:30:49,472][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 23:30:49,472][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 23:30:49,472][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 23:30:49,472][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 23:30:49,472][root][INFO] - 

[2024-10-21 23:30:49,472][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:30:49,472][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:30:49,473][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:30:49,473][root][INFO] - * tb interval   : 10000

[2024-10-21 23:30:49,473][root][INFO] - 

[2024-10-21 23:30:49,473][root][INFO] - Start the Training !
[2024-10-21 23:30:49,476][root][INFO] - 
[1/ 15 Epoch]
[2024-10-21 23:31:06,188][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,189][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,190][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,190][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,191][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,191][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,191][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,192][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,192][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,193][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,193][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,194][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,194][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,194][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,195][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,195][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,196][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,196][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,197][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,197][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,198][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,198][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,198][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:31:06,199][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:31:06,201][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-21 23:31:06,206][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-21 23:31:06,405][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 23:31:06,407][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-21 23:31:06,616][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:31:09,674][root][INFO] - 

[2024-10-21 23:31:09,674][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-21 23:31:09,674][root][INFO] - Data Preprocessing
[2024-10-21 23:31:09,675][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:31:09,675][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:31:09,675][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:31:09,675][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:31:09,682][root][INFO] - vocab size              : 51200
[2024-10-21 23:31:09,683][root][INFO] - device                  : gpu
[2024-10-21 23:31:09,683][root][INFO] - random seed             : 1
[2024-10-21 23:31:09,683][root][INFO] - train data size         : 135040
[2024-10-21 23:31:09,683][root][INFO] - max epochs              : 5
[2024-10-21 23:31:09,683][root][INFO] - total steps             : 10550
[2024-10-21 23:31:09,683][root][INFO] - warmup steps            : 1055
[2024-10-21 23:31:09,683][root][INFO] - batch size              : 64
[2024-10-21 23:31:09,683][root][INFO] - accumulation steps      : 1
[2024-10-21 23:31:09,683][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:31:09,683][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:31:09,683][root][INFO] - learning rate           : 0.01
[2024-10-21 23:31:09,684][root][INFO] - max length              : 256

[2024-10-21 23:31:09,684][root][INFO] - LoRA Configuration
[2024-10-21 23:31:09,684][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:31:09,684][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:31:09,684][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:31:09,684][root][INFO] - KOMBO Configuration
[2024-10-21 23:31:09,684][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 23:31:09,684][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 23:31:09,684][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 23:31:09,684][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 23:31:09,684][root][INFO] - ㄴ do_combination       : True
[2024-10-21 23:31:09,685][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 23:31:09,685][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 23:31:09,685][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 23:31:09,685][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 23:31:09,685][root][INFO] - 

[2024-10-21 23:31:09,685][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:31:09,685][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:31:09,685][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:31:09,685][root][INFO] - * tb interval   : 10000

[2024-10-21 23:31:09,685][root][INFO] - 

[2024-10-21 23:31:09,685][root][INFO] - Start the Training !
[2024-10-21 23:31:09,688][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 23:31:37,835][root][INFO] - Step: 90/1350  |  Loss: 2.5070  |  Score: 31.39 [%]  |  Seq Length: 256.0
[2024-10-21 23:31:44,008][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 23:31:44,009][root][INFO] - Score: 70.55 [%]  |  Evaluation Time: 6.17 [s]
[2024-10-21 23:31:49,600][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 23:31:49,600][root][INFO] - Score: 62.66 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-21 23:31:49,601][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 23:31:49,601][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:31:49,604][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:31:51,332][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:31:51,588][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:31:51,589][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:31:51,589][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:31:51,590][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:31:51,590][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:31:51,593][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:31:53,220][root][INFO] - 
[2/ 15 Epoch]
[2024-10-21 23:32:44,969][root][INFO] - 

[2024-10-21 23:32:44,969][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:32:44,969][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:32:44,969][root][INFO] - 

[2024-10-21 23:32:44,969][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:32:48,040][root][INFO] - 

[2024-10-21 23:32:48,040][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:32:48,040][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:32:48,041][root][INFO] - 

[2024-10-21 23:32:48,041][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:32:49,974][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,974][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,975][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,975][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,976][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,976][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,977][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,977][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,978][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,978][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,979][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,979][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,980][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,980][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,981][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,981][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,982][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,982][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,983][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,983][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,984][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,985][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,985][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:32:49,985][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:32:49,987][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-21 23:32:49,992][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-21 23:32:50,194][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 23:32:50,196][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-21 23:32:50,382][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:32:52,454][root][INFO] - 

[2024-10-21 23:32:52,454][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-21 23:32:52,454][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:32:52,455][root][INFO] - 

[2024-10-21 23:32:52,455][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-21 23:32:53,604][root][INFO] - 

[2024-10-21 23:32:53,604][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-21 23:32:53,605][root][INFO] - Data Preprocessing
[2024-10-21 23:32:53,605][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:32:53,605][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:32:53,605][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:32:53,605][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:32:53,613][root][INFO] - vocab size              : 51200
[2024-10-21 23:32:53,613][root][INFO] - device                  : gpu
[2024-10-21 23:32:53,613][root][INFO] - random seed             : 1
[2024-10-21 23:32:53,614][root][INFO] - train data size         : 5760
[2024-10-21 23:32:53,614][root][INFO] - max epochs              : 15
[2024-10-21 23:32:53,614][root][INFO] - total steps             : 1350
[2024-10-21 23:32:53,614][root][INFO] - warmup steps            : 135
[2024-10-21 23:32:53,614][root][INFO] - batch size              : 64
[2024-10-21 23:32:53,614][root][INFO] - accumulation steps      : 1
[2024-10-21 23:32:53,614][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:32:53,614][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:32:53,614][root][INFO] - learning rate           : 0.01
[2024-10-21 23:32:53,614][root][INFO] - max length              : 256

[2024-10-21 23:32:53,614][root][INFO] - LoRA Configuration
[2024-10-21 23:32:53,614][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:32:53,615][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:32:53,615][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:32:53,615][root][INFO] - KOMBO Configuration
[2024-10-21 23:32:53,615][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 23:32:53,615][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 23:32:53,615][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 23:32:53,615][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 23:32:53,615][root][INFO] - ㄴ do_combination       : True
[2024-10-21 23:32:53,615][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 23:32:53,615][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 23:32:53,616][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 23:32:53,616][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 23:32:53,616][root][INFO] - 

[2024-10-21 23:32:53,616][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:32:53,616][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:32:53,616][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:32:53,616][root][INFO] - * tb interval   : 10000

[2024-10-21 23:32:53,616][root][INFO] - 

[2024-10-21 23:32:53,616][root][INFO] - Start the Training !
[2024-10-21 23:32:53,619][root][INFO] - 
[1/ 15 Epoch]
[2024-10-21 23:33:10,525][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,525][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,526][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,526][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,527][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,527][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,527][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,528][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,528][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,529][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,529][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,529][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,530][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,530][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,531][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,531][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,531][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,532][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,532][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,533][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,533][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,534][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,534][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:33:10,534][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:33:10,536][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-21 23:33:10,540][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-21 23:33:10,743][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 23:33:10,745][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-21 23:33:10,940][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:33:14,027][root][INFO] - 

[2024-10-21 23:33:14,028][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-21 23:33:14,028][root][INFO] - Data Preprocessing
[2024-10-21 23:33:14,028][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:33:14,028][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:33:14,028][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:33:14,028][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:33:14,035][root][INFO] - vocab size              : 51200
[2024-10-21 23:33:14,036][root][INFO] - device                  : gpu
[2024-10-21 23:33:14,036][root][INFO] - random seed             : 1
[2024-10-21 23:33:14,036][root][INFO] - train data size         : 135040
[2024-10-21 23:33:14,036][root][INFO] - max epochs              : 5
[2024-10-21 23:33:14,036][root][INFO] - total steps             : 10550
[2024-10-21 23:33:14,036][root][INFO] - warmup steps            : 1055
[2024-10-21 23:33:14,036][root][INFO] - batch size              : 64
[2024-10-21 23:33:14,036][root][INFO] - accumulation steps      : 1
[2024-10-21 23:33:14,036][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:33:14,036][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:33:14,036][root][INFO] - learning rate           : 0.01
[2024-10-21 23:33:14,037][root][INFO] - max length              : 256

[2024-10-21 23:33:14,037][root][INFO] - LoRA Configuration
[2024-10-21 23:33:14,037][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:33:14,037][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:33:14,037][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:33:14,037][root][INFO] - KOMBO Configuration
[2024-10-21 23:33:14,037][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 23:33:14,037][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 23:33:14,037][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 23:33:14,037][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 23:33:14,037][root][INFO] - ㄴ do_combination       : True
[2024-10-21 23:33:14,038][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 23:33:14,038][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 23:33:14,038][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 23:33:14,038][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 23:33:14,038][root][INFO] - 

[2024-10-21 23:33:14,038][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:33:14,038][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:33:14,038][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:33:14,038][root][INFO] - * tb interval   : 10000

[2024-10-21 23:33:14,038][root][INFO] - 

[2024-10-21 23:33:14,038][root][INFO] - Start the Training !
[2024-10-21 23:33:14,042][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 23:33:41,892][root][INFO] - Step: 90/1350  |  Loss: 2.5070  |  Score: 31.39 [%]  |  Seq Length: 256.0
[2024-10-21 23:33:48,095][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 23:33:48,095][root][INFO] - Score: 70.55 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-21 23:33:53,665][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 23:33:53,665][root][INFO] - Score: 62.66 [%]  |  Evaluation Time: 5.57 [s]
[2024-10-21 23:33:53,666][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 23:33:53,666][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:33:53,669][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:33:55,399][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:33:55,677][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:33:55,679][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:33:55,679][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:33:55,679][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:33:55,680][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:33:55,683][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:33:57,325][root][INFO] - 
[2/ 15 Epoch]
[2024-10-21 23:34:44,013][root][INFO] - Step: 180/1350  |  Loss: 1.2068  |  Score: 64.67 [%]  |  Seq Length: 256.0
[2024-10-21 23:34:50,192][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 23:34:50,192][root][INFO] - Score: 77.12 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-21 23:34:55,782][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 23:34:55,782][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-21 23:34:55,783][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 23:34:55,783][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:34:55,786][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:34:57,494][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:34:57,563][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,564][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,564][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,564][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,565][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,565][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,566][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,566][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,567][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,567][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,567][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,568][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,568][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,569][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,569][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,569][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,570][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,570][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,571][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,571][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,572][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,572][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,572][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:34:57,573][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:34:57,574][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-21 23:34:57,579][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-21 23:34:57,655][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:34:57,655][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:34:57,655][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:34:57,656][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:34:57,656][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:34:57,657][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:34:57,787][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 23:34:57,807][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-21 23:34:58,072][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:34:59,288][root][INFO] - 
[3/ 15 Epoch]
[2024-10-21 23:35:01,143][root][INFO] - 

[2024-10-21 23:35:01,144][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-21 23:35:01,144][root][INFO] - Data Preprocessing
[2024-10-21 23:35:01,144][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:35:01,144][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:35:01,144][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:35:01,144][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:35:01,152][root][INFO] - vocab size              : 51200
[2024-10-21 23:35:01,152][root][INFO] - device                  : gpu
[2024-10-21 23:35:01,152][root][INFO] - random seed             : 1
[2024-10-21 23:35:01,152][root][INFO] - train data size         : 942912
[2024-10-21 23:35:01,152][root][INFO] - max epochs              : 5
[2024-10-21 23:35:01,152][root][INFO] - total steps             : 73665
[2024-10-21 23:35:01,152][root][INFO] - warmup steps            : 7366
[2024-10-21 23:35:01,152][root][INFO] - batch size              : 64
[2024-10-21 23:35:01,153][root][INFO] - accumulation steps      : 1
[2024-10-21 23:35:01,153][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:35:01,153][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:35:01,153][root][INFO] - learning rate           : 0.01
[2024-10-21 23:35:01,153][root][INFO] - max length              : 256

[2024-10-21 23:35:01,153][root][INFO] - LoRA Configuration
[2024-10-21 23:35:01,153][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:35:01,153][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:35:01,153][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:35:01,153][root][INFO] - KOMBO Configuration
[2024-10-21 23:35:01,153][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 23:35:01,154][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 23:35:01,154][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 23:35:01,154][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 23:35:01,154][root][INFO] - ㄴ do_combination       : True
[2024-10-21 23:35:01,154][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 23:35:01,154][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 23:35:01,154][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 23:35:01,154][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 23:35:01,154][root][INFO] - 

[2024-10-21 23:35:01,154][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:35:01,155][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:35:01,155][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:35:01,155][root][INFO] - * tb interval   : 10000

[2024-10-21 23:35:01,155][root][INFO] - 

[2024-10-21 23:35:01,155][root][INFO] - Start the Training !
[2024-10-21 23:35:01,158][root][INFO] - 
[1/ 5 Epoch]
[2024-10-21 23:35:47,328][root][INFO] - Step: 270/1350  |  Loss: 1.0118  |  Score: 70.87 [%]  |  Seq Length: 256.0
[2024-10-21 23:35:53,566][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 23:35:53,566][root][INFO] - Score: 77.39 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-21 23:35:59,226][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 23:35:59,226][root][INFO] - Score: 70.46 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-21 23:35:59,227][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-21 23:35:59,228][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:35:59,230][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:36:00,941][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:36:01,159][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:36:01,161][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:36:01,161][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:36:01,162][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:36:01,162][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:36:01,164][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:36:02,859][root][INFO] - 
[4/ 15 Epoch]
[2024-10-21 23:36:50,895][root][INFO] - Step: 360/1350  |  Loss: 0.8741  |  Score: 75.09 [%]  |  Seq Length: 256.0
[2024-10-21 23:36:57,137][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 23:36:57,137][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-21 23:37:02,790][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 23:37:02,790][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-21 23:37:02,791][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 23:37:02,792][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:37:02,794][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:37:04,500][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:37:04,773][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:37:04,774][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:37:04,775][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:37:04,775][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:37:04,775][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:37:04,778][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:37:06,434][root][INFO] - 
[5/ 15 Epoch]
[2024-10-21 23:37:55,008][root][INFO] - Step: 450/1350  |  Loss: 0.7913  |  Score: 78.61 [%]  |  Seq Length: 256.0
[2024-10-21 23:38:01,358][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 23:38:01,358][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-21 23:38:07,044][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 23:38:07,044][root][INFO] - Score: 70.68 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-21 23:38:07,047][root][INFO] - 
[6/ 15 Epoch]
[2024-10-21 23:38:55,038][root][INFO] - Step: 540/1350  |  Loss: 0.6693  |  Score: 80.78 [%]  |  Seq Length: 256.0
[2024-10-21 23:39:01,316][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-21 23:39:01,316][root][INFO] - Score: 78.28 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-21 23:39:06,955][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-21 23:39:06,956][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-21 23:39:06,956][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-21 23:39:06,957][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:39:06,959][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:39:08,688][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:39:08,942][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:39:08,943][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:39:08,943][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:39:08,944][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:39:08,944][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:39:08,947][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:39:10,597][root][INFO] - 
[7/ 15 Epoch]
[2024-10-21 23:39:58,576][root][INFO] - Step: 630/1350  |  Loss: 0.5973  |  Score: 83.18 [%]  |  Seq Length: 256.0
[2024-10-21 23:40:04,808][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-21 23:40:04,808][root][INFO] - Score: 79.22 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-21 23:40:10,466][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-21 23:40:10,466][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-21 23:40:10,467][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-21 23:40:10,467][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:40:10,470][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:40:12,276][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:40:12,521][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:40:12,555][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:40:12,556][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:40:12,556][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:40:12,557][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:40:12,560][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:40:14,204][root][INFO] - 
[8/ 15 Epoch]
[2024-10-21 23:41:02,251][root][INFO] - Step: 720/1350  |  Loss: 0.5410  |  Score: 84.94 [%]  |  Seq Length: 256.0
[2024-10-21 23:41:08,529][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-21 23:41:08,530][root][INFO] - Score: 78.24 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-21 23:41:14,175][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-21 23:41:14,175][root][INFO] - Score: 72.29 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-21 23:41:14,177][root][INFO] - 
[9/ 15 Epoch]
[2024-10-21 23:42:02,180][root][INFO] - Step: 810/1350  |  Loss: 0.4807  |  Score: 86.12 [%]  |  Seq Length: 256.0
[2024-10-21 23:42:08,496][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-21 23:42:08,496][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-21 23:42:14,173][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-21 23:42:14,173][root][INFO] - Score: 72.51 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-21 23:42:14,176][root][INFO] - 
[10/ 15 Epoch]
[2024-10-21 23:43:02,221][root][INFO] - Step: 900/1350  |  Loss: 0.4214  |  Score: 87.56 [%]  |  Seq Length: 256.0
[2024-10-21 23:43:08,462][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-21 23:43:08,463][root][INFO] - Score: 78.57 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-21 23:43:14,079][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-21 23:43:14,079][root][INFO] - Score: 70.82 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-21 23:43:14,081][root][INFO] - 
[11/ 15 Epoch]
[2024-10-21 23:44:02,167][root][INFO] - Step: 990/1350  |  Loss: 0.3826  |  Score: 88.68 [%]  |  Seq Length: 256.0
[2024-10-21 23:44:08,409][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-21 23:44:08,409][root][INFO] - Score: 79.31 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-21 23:44:14,117][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-21 23:44:14,117][root][INFO] - Score: 72.57 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-21 23:44:14,118][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-21 23:44:14,118][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:44:14,121][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:44:15,827][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:44:16,097][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:44:16,098][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:44:16,098][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:44:16,098][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:44:16,099][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:44:16,101][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:44:17,705][root][INFO] - 
[12/ 15 Epoch]
[2024-10-21 23:45:05,894][root][INFO] - Step: 1080/1350  |  Loss: 0.3541  |  Score: 89.37 [%]  |  Seq Length: 256.0
[2024-10-21 23:45:12,128][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-21 23:45:12,128][root][INFO] - Score: 78.64 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-21 23:45:17,759][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-21 23:45:17,759][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-21 23:45:17,761][root][INFO] - 
[13/ 15 Epoch]
[2024-10-21 23:46:05,809][root][INFO] - Step: 1170/1350  |  Loss: 0.3481  |  Score: 89.35 [%]  |  Seq Length: 256.0
[2024-10-21 23:46:12,036][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-21 23:46:12,036][root][INFO] - Score: 79.26 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-21 23:46:17,680][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-21 23:46:17,680][root][INFO] - Score: 72.56 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-21 23:46:17,682][root][INFO] - 
[14/ 15 Epoch]
[2024-10-21 23:47:05,679][root][INFO] - Step: 1260/1350  |  Loss: 0.3253  |  Score: 90.13 [%]  |  Seq Length: 256.0
[2024-10-21 23:47:11,966][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-21 23:47:11,966][root][INFO] - Score: 79.20 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-21 23:47:17,579][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-21 23:47:17,580][root][INFO] - Score: 72.38 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-21 23:47:17,581][root][INFO] - 
[15/ 15 Epoch]
[2024-10-21 23:48:05,518][root][INFO] - Step: 1350/1350  |  Loss: 0.3235  |  Score: 90.44 [%]  |  Seq Length: 256.0
[2024-10-21 23:48:11,794][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-21 23:48:11,794][root][INFO] - Score: 79.32 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-21 23:48:17,459][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-21 23:48:17,459][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-21 23:48:17,460][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-21 23:48:17,460][root][INFO] - - Epoch: 11
[2024-10-21 23:48:17,460][root][INFO] - - DEV score: 79.31 [%]
[2024-10-21 23:48:17,460][root][INFO] - - TEST score: 72.57 [%]
[2024-10-21 23:48:17,461][root][INFO] - Fine-tuning is done!
[2024-10-21 23:48:20,783][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,784][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,785][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,785][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,786][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,786][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,787][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,788][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,788][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,789][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,789][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,790][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,790][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,791][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,791][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,792][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,792][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,793][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,794][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,794][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,795][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,795][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,796][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-21 23:48:20,796][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-21 23:48:20,798][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-21 23:48:21,001][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-21 23:48:21,003][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-21 23:48:21,004][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-21 23:48:21,171][root][INFO] - 

[2024-10-21 23:48:21,172][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-21 23:48:21,172][root][INFO] - Data Preprocessing
[2024-10-21 23:48:21,172][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-21 23:48:21,172][root][INFO] - ㄴ do_hangeulize              False
[2024-10-21 23:48:21,172][root][INFO] - ㄴ data_remove                False

[2024-10-21 23:48:21,172][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-21 23:48:21,179][root][INFO] - vocab size              : 51200
[2024-10-21 23:48:21,179][root][INFO] - device                  : gpu
[2024-10-21 23:48:21,179][root][INFO] - random seed             : 1
[2024-10-21 23:48:21,179][root][INFO] - train data size         : 5760
[2024-10-21 23:48:21,179][root][INFO] - max epochs              : 15
[2024-10-21 23:48:21,180][root][INFO] - total steps             : 1350
[2024-10-21 23:48:21,180][root][INFO] - warmup steps            : 135
[2024-10-21 23:48:21,180][root][INFO] - batch size              : 64
[2024-10-21 23:48:21,180][root][INFO] - accumulation steps      : 1
[2024-10-21 23:48:21,180][root][INFO] - optimizer               : adamwscale
[2024-10-21 23:48:21,180][root][INFO] - lr_scheduler            : cosine
[2024-10-21 23:48:21,180][root][INFO] - learning rate           : 0.02
[2024-10-21 23:48:21,180][root][INFO] - max length              : 256

[2024-10-21 23:48:21,180][root][INFO] - LoRA Configuration
[2024-10-21 23:48:21,180][root][INFO] - ㄴ r                    : 32
[2024-10-21 23:48:21,180][root][INFO] - ㄴ alpha                : 128
[2024-10-21 23:48:21,180][root][INFO] - ㄴ dropout              : 0.03

[2024-10-21 23:48:21,181][root][INFO] - KOMBO Configuration
[2024-10-21 23:48:21,181][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-21 23:48:21,181][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-21 23:48:21,181][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-21 23:48:21,181][root][INFO] - ㄴ embedding_norm       : False
[2024-10-21 23:48:21,181][root][INFO] - ㄴ do_combination       : True
[2024-10-21 23:48:21,181][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-21 23:48:21,181][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-21 23:48:21,181][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-21 23:48:21,181][root][INFO] -   ㄴ add_lora           : False

[2024-10-21 23:48:21,182][root][INFO] - 

[2024-10-21 23:48:21,182][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-21 23:48:21,182][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-21 23:48:21,182][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-21 23:48:21,182][root][INFO] - * tb interval   : 10000

[2024-10-21 23:48:21,182][root][INFO] - 

[2024-10-21 23:48:21,182][root][INFO] - Start the Training !
[2024-10-21 23:48:21,184][root][INFO] - 
[1/ 15 Epoch]
[2024-10-21 23:49:09,302][root][INFO] - Step: 90/1350  |  Loss: 2.0412  |  Score: 42.75 [%]  |  Seq Length: 256.0
[2024-10-21 23:49:15,595][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 23:49:15,596][root][INFO] - Score: 75.53 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-21 23:49:21,405][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 23:49:21,405][root][INFO] - Score: 68.06 [%]  |  Evaluation Time: 5.81 [s]
[2024-10-21 23:49:21,406][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 23:49:21,407][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:49:21,409][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:49:23,158][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:49:23,449][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:49:23,450][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:49:23,451][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:49:23,451][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:49:23,451][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:49:23,454][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:49:25,094][root][INFO] - 
[2/ 15 Epoch]
[2024-10-21 23:50:13,245][root][INFO] - Step: 180/1350  |  Loss: 1.0877  |  Score: 68.75 [%]  |  Seq Length: 256.0
[2024-10-21 23:50:19,631][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-21 23:50:19,631][root][INFO] - Score: 76.82 [%]  |  Evaluation Time: 6.38 [s]
[2024-10-21 23:50:25,318][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-21 23:50:25,318][root][INFO] - Score: 71.42 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-21 23:50:25,320][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-21 23:50:25,320][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:50:25,322][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:50:27,059][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:50:27,343][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:50:27,344][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:50:27,345][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:50:27,345][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:50:27,345][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:50:27,348][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:50:29,039][root][INFO] - 
[3/ 15 Epoch]
[2024-10-21 23:51:04,283][root][INFO] - Step: 2110/10550  |  Loss: 0.3662  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-21 23:51:17,148][root][INFO] - Step: 270/1350  |  Loss: 0.9647  |  Score: 73.71 [%]  |  Seq Length: 256.0
[2024-10-21 23:51:23,374][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-21 23:51:23,374][root][INFO] - Score: 77.64 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-21 23:51:29,039][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-21 23:51:29,039][root][INFO] - Score: 70.29 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-21 23:51:29,042][root][INFO] - 
[4/ 15 Epoch]
[2024-10-21 23:51:57,481][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-21 23:51:57,482][root][INFO] - Score: 86.39 [%]  |  Evaluation Time: 53.20 [s]
[2024-10-21 23:52:17,356][root][INFO] - Step: 360/1350  |  Loss: 0.7764  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-21 23:52:23,646][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-21 23:52:23,646][root][INFO] - Score: 77.98 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-21 23:52:29,384][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-21 23:52:29,384][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-21 23:52:29,385][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-21 23:52:29,385][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:52:29,388][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:52:31,121][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:52:31,401][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:52:31,402][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:52:31,403][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:52:31,403][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:52:31,404][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:52:31,406][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:52:33,096][root][INFO] - 
[5/ 15 Epoch]
[2024-10-21 23:53:21,326][root][INFO] - Step: 450/1350  |  Loss: 0.6467  |  Score: 82.10 [%]  |  Seq Length: 256.0
[2024-10-21 23:53:27,632][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-21 23:53:27,632][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-21 23:53:33,333][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-21 23:53:33,333][root][INFO] - Score: 70.43 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-21 23:53:33,334][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-21 23:53:33,335][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:53:33,337][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:53:35,144][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:53:35,433][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:53:35,435][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:53:35,435][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:53:35,436][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:53:35,436][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:53:35,439][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:53:37,097][root][INFO] - 
[6/ 15 Epoch]
[2024-10-21 23:54:25,213][root][INFO] - Step: 540/1350  |  Loss: 0.5402  |  Score: 85.15 [%]  |  Seq Length: 256.0
[2024-10-21 23:54:31,453][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-21 23:54:31,454][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-21 23:54:37,159][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-21 23:54:37,159][root][INFO] - Score: 70.07 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-21 23:54:37,161][root][INFO] - 
[7/ 15 Epoch]
[2024-10-21 23:54:53,364][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-21 23:54:53,364][root][INFO] - Score: 86.53 [%]  |  Evaluation Time: 175.88 [s]
[2024-10-21 23:54:53,365][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-21 23:54:53,366][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:54:53,368][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:54:54,301][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:54:54,412][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:54:54,412][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:54:54,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:54:54,413][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:54:54,413][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:54:54,414][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:54:55,197][root][INFO] - 
[2/ 5 Epoch]
[2024-10-21 23:55:25,192][root][INFO] - Step: 630/1350  |  Loss: 0.4346  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-21 23:55:31,504][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-21 23:55:31,504][root][INFO] - Score: 78.50 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-21 23:55:37,201][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-21 23:55:37,201][root][INFO] - Score: 69.22 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-21 23:55:37,203][root][INFO] - 
[8/ 15 Epoch]
[2024-10-21 23:56:25,286][root][INFO] - Step: 720/1350  |  Loss: 0.3652  |  Score: 89.48 [%]  |  Seq Length: 256.0
[2024-10-21 23:56:31,653][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-21 23:56:31,653][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-21 23:56:37,349][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-21 23:56:37,349][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-21 23:56:37,351][root][INFO] - 
[9/ 15 Epoch]
[2024-10-21 23:57:25,578][root][INFO] - Step: 810/1350  |  Loss: 0.3299  |  Score: 90.70 [%]  |  Seq Length: 256.0
[2024-10-21 23:57:31,849][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-21 23:57:31,849][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-21 23:57:37,515][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-21 23:57:37,515][root][INFO] - Score: 69.84 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-21 23:57:37,517][root][INFO] - 
[10/ 15 Epoch]
[2024-10-21 23:58:25,662][root][INFO] - Step: 900/1350  |  Loss: 0.2637  |  Score: 92.01 [%]  |  Seq Length: 256.0
[2024-10-21 23:58:31,948][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-21 23:58:31,948][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-21 23:58:37,633][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-21 23:58:37,633][root][INFO] - Score: 69.09 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-21 23:58:37,635][root][INFO] - 
[11/ 15 Epoch]
[2024-10-21 23:59:25,747][root][INFO] - Step: 990/1350  |  Loss: 0.2344  |  Score: 93.43 [%]  |  Seq Length: 256.0
[2024-10-21 23:59:32,010][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-21 23:59:32,010][root][INFO] - Score: 79.33 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-21 23:59:37,708][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-21 23:59:37,708][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-21 23:59:37,709][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-21 23:59:37,709][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-21 23:59:37,712][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-21 23:59:39,412][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-21 23:59:39,709][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-21 23:59:39,710][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-21 23:59:39,711][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-21 23:59:39,711][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-21 23:59:39,711][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-21 23:59:39,714][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-21 23:59:41,362][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 00:00:29,501][root][INFO] - Step: 1080/1350  |  Loss: 0.2078  |  Score: 93.73 [%]  |  Seq Length: 256.0
[2024-10-22 00:00:35,739][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 00:00:35,739][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 00:00:41,466][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 00:00:41,467][root][INFO] - Score: 70.22 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 00:00:41,469][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 00:01:29,473][root][INFO] - Step: 1170/1350  |  Loss: 0.1950  |  Score: 94.19 [%]  |  Seq Length: 256.0
[2024-10-22 00:01:35,722][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 00:01:35,722][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 00:01:41,420][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 00:01:41,420][root][INFO] - Score: 70.65 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 00:01:41,426][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 00:02:29,636][root][INFO] - Step: 1260/1350  |  Loss: 0.1833  |  Score: 94.46 [%]  |  Seq Length: 256.0
[2024-10-22 00:02:35,889][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 00:02:35,889][root][INFO] - Score: 78.91 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 00:02:41,638][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 00:02:41,638][root][INFO] - Score: 70.44 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 00:02:41,640][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 00:03:28,555][root][INFO] - Step: 1350/1350  |  Loss: 0.1737  |  Score: 94.76 [%]  |  Seq Length: 256.0
[2024-10-22 00:03:34,858][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 00:03:34,858][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 00:03:40,563][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 00:03:40,564][root][INFO] - Score: 70.27 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 00:03:40,565][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 00:03:40,565][root][INFO] - - Epoch: 11
[2024-10-22 00:03:40,565][root][INFO] - - DEV score: 79.33 [%]
[2024-10-22 00:03:40,565][root][INFO] - - TEST score: 70.70 [%]
[2024-10-22 00:03:40,566][root][INFO] - Fine-tuning is done!
[2024-10-22 00:03:40,566][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 00:03:40,566][root][INFO] - - BEST LR: 0.01
[2024-10-22 00:03:40,566][root][INFO] - - DEV score: 79.31 [%]
[2024-10-22 00:03:40,567][root][INFO] - - TEST score: 72.57 [%]
[2024-10-22 00:03:46,808][root][INFO] - 

[2024-10-22 00:03:46,808][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 00:03:46,808][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-22 00:03:46,808][root][INFO] - 

[2024-10-22 00:03:46,808][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 00:03:51,308][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,308][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,309][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,309][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,310][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,310][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,311][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,311][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,311][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,312][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,312][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,313][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,313][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,314][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,314][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,314][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,315][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,315][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,316][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,316][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,317][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,317][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,318][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 00:03:51,318][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 00:03:51,320][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 00:03:51,323][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 00:03:51,522][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 00:03:51,525][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 00:03:51,713][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 00:03:54,925][root][INFO] - 

[2024-10-22 00:03:54,925][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 00:03:54,925][root][INFO] - Data Preprocessing
[2024-10-22 00:03:54,925][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 00:03:54,925][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 00:03:54,925][root][INFO] - ㄴ data_remove                False

[2024-10-22 00:03:54,925][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 00:03:54,933][root][INFO] - vocab size              : 51200
[2024-10-22 00:03:54,933][root][INFO] - device                  : gpu
[2024-10-22 00:03:54,934][root][INFO] - random seed             : 2
[2024-10-22 00:03:54,934][root][INFO] - train data size         : 5760
[2024-10-22 00:03:54,934][root][INFO] - max epochs              : 15
[2024-10-22 00:03:54,934][root][INFO] - total steps             : 1350
[2024-10-22 00:03:54,934][root][INFO] - warmup steps            : 135
[2024-10-22 00:03:54,934][root][INFO] - batch size              : 64
[2024-10-22 00:03:54,934][root][INFO] - accumulation steps      : 1
[2024-10-22 00:03:54,934][root][INFO] - optimizer               : adamwscale
[2024-10-22 00:03:54,934][root][INFO] - lr_scheduler            : cosine
[2024-10-22 00:03:54,934][root][INFO] - learning rate           : 0.01
[2024-10-22 00:03:54,934][root][INFO] - max length              : 256

[2024-10-22 00:03:54,934][root][INFO] - LoRA Configuration
[2024-10-22 00:03:54,935][root][INFO] - ㄴ r                    : 32
[2024-10-22 00:03:54,935][root][INFO] - ㄴ alpha                : 128
[2024-10-22 00:03:54,935][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 00:03:54,935][root][INFO] - KOMBO Configuration
[2024-10-22 00:03:54,935][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 00:03:54,935][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 00:03:54,935][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 00:03:54,935][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 00:03:54,935][root][INFO] - ㄴ do_combination       : True
[2024-10-22 00:03:54,935][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 00:03:54,936][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 00:03:54,936][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 00:03:54,936][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 00:03:54,936][root][INFO] - 

[2024-10-22 00:03:54,936][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-22 00:03:54,936][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 00:03:54,936][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 00:03:54,936][root][INFO] - * tb interval   : 10000

[2024-10-22 00:03:54,936][root][INFO] - 

[2024-10-22 00:03:54,936][root][INFO] - Start the Training !
[2024-10-22 00:03:54,939][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 00:04:43,220][root][INFO] - Step: 90/1350  |  Loss: 2.0528  |  Score: 36.34 [%]  |  Seq Length: 256.0
[2024-10-22 00:04:49,489][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 00:04:49,489][root][INFO] - Score: 72.51 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:04:55,137][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 00:04:55,138][root][INFO] - Score: 60.47 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-22 00:04:55,139][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 00:04:55,140][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:04:55,147][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:04:56,054][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:04:56,175][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:04:56,176][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:04:56,176][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:04:56,176][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:04:56,176][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:04:56,177][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:04:56,947][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 00:05:44,901][root][INFO] - Step: 180/1350  |  Loss: 1.2527  |  Score: 65.10 [%]  |  Seq Length: 256.0
[2024-10-22 00:05:51,124][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 00:05:51,124][root][INFO] - Score: 77.02 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-22 00:05:56,748][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 00:05:56,748][root][INFO] - Score: 67.72 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-22 00:05:56,749][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 00:05:56,749][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:05:56,752][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:05:58,472][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:05:58,748][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:05:58,749][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:05:58,750][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:05:58,750][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:05:58,750][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:05:58,753][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:06:00,381][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 00:06:48,443][root][INFO] - Step: 270/1350  |  Loss: 0.9995  |  Score: 70.84 [%]  |  Seq Length: 256.0
[2024-10-22 00:06:54,652][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 00:06:54,653][root][INFO] - Score: 78.05 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-22 00:07:00,300][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 00:07:00,300][root][INFO] - Score: 70.16 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-22 00:07:00,301][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 00:07:00,301][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:07:00,304][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:07:02,003][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:07:02,291][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:07:02,293][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:07:02,293][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:07:02,293][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:07:02,294][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:07:02,296][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:07:03,910][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 00:07:51,948][root][INFO] - Step: 360/1350  |  Loss: 0.8748  |  Score: 75.10 [%]  |  Seq Length: 256.0
[2024-10-22 00:07:58,227][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 00:07:58,227][root][INFO] - Score: 78.04 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 00:08:03,823][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 00:08:03,823][root][INFO] - Score: 70.25 [%]  |  Evaluation Time: 5.59 [s]
[2024-10-22 00:08:03,824][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 00:08:03,825][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:08:03,827][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:08:05,527][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:08:05,799][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:08:05,826][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:08:05,826][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:08:05,827][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:08:05,827][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:08:05,830][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:08:07,463][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 00:08:55,397][root][INFO] - Step: 450/1350  |  Loss: 0.7541  |  Score: 78.31 [%]  |  Seq Length: 256.0
[2024-10-22 00:09:01,600][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 00:09:01,601][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-22 00:09:07,277][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 00:09:07,277][root][INFO] - Score: 71.66 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 00:09:07,278][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 00:09:07,278][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:09:07,281][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:09:09,077][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:09:09,355][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:09:09,356][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:09:09,357][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:09:09,357][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:09:09,357][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:09:09,360][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:09:10,986][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 00:09:58,989][root][INFO] - Step: 540/1350  |  Loss: 0.6182  |  Score: 82.05 [%]  |  Seq Length: 256.0
[2024-10-22 00:10:05,209][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 00:10:05,209][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-22 00:10:10,829][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 00:10:10,829][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-22 00:10:10,832][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 00:10:58,731][root][INFO] - Step: 630/1350  |  Loss: 0.5624  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-22 00:11:04,934][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 00:11:04,935][root][INFO] - Score: 78.80 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-22 00:11:10,587][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 00:11:10,588][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-22 00:11:10,590][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 00:11:58,483][root][INFO] - Step: 720/1350  |  Loss: 0.5091  |  Score: 85.61 [%]  |  Seq Length: 256.0
[2024-10-22 00:12:04,715][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 00:12:04,715][root][INFO] - Score: 77.62 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-22 00:12:10,346][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 00:12:10,346][root][INFO] - Score: 72.40 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-22 00:12:10,348][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 00:12:47,177][root][INFO] - Step: 4220/10550  |  Loss: 0.2895  |  Score: 87.73 [%]  |  Seq Length: 256.0
[2024-10-22 00:12:58,469][root][INFO] - Step: 810/1350  |  Loss: 0.4368  |  Score: 87.42 [%]  |  Seq Length: 256.0
[2024-10-22 00:13:04,664][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 00:13:04,664][root][INFO] - Score: 78.55 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-22 00:13:10,377][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 00:13:10,377][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 00:13:10,380][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 00:13:40,336][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 00:13:40,336][root][INFO] - Score: 88.22 [%]  |  Evaluation Time: 53.16 [s]
[2024-10-22 00:13:58,699][root][INFO] - Step: 900/1350  |  Loss: 0.3967  |  Score: 88.60 [%]  |  Seq Length: 256.0
[2024-10-22 00:14:04,938][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 00:14:04,938][root][INFO] - Score: 78.33 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 00:14:10,625][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 00:14:10,626][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 00:14:10,628][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 00:14:58,673][root][INFO] - Step: 990/1350  |  Loss: 0.3673  |  Score: 89.12 [%]  |  Seq Length: 256.0
[2024-10-22 00:15:04,860][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 00:15:04,860][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 6.18 [s]
[2024-10-22 00:15:10,524][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 00:15:10,524][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 00:15:10,526][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 00:15:58,567][root][INFO] - Step: 1080/1350  |  Loss: 0.3257  |  Score: 90.35 [%]  |  Seq Length: 256.0
[2024-10-22 00:16:04,993][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 00:16:04,993][root][INFO] - Score: 78.35 [%]  |  Evaluation Time: 6.42 [s]
[2024-10-22 00:16:10,607][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 00:16:10,607][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-22 00:16:10,609][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 00:16:37,483][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 00:16:37,483][root][INFO] - Score: 88.18 [%]  |  Evaluation Time: 177.14 [s]
[2024-10-22 00:16:37,484][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 00:16:37,484][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 00:16:37,487][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:16:39,200][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:16:39,467][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:16:39,469][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:16:39,469][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:16:39,469][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:16:39,469][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:16:39,472][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:16:41,070][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 00:16:58,551][root][INFO] - Step: 1170/1350  |  Loss: 0.3240  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-22 00:17:04,814][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 00:17:04,814][root][INFO] - Score: 78.18 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:17:10,429][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 00:17:10,429][root][INFO] - Score: 71.40 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-22 00:17:10,431][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 00:17:58,452][root][INFO] - Step: 1260/1350  |  Loss: 0.3043  |  Score: 90.68 [%]  |  Seq Length: 256.0
[2024-10-22 00:18:04,795][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 00:18:04,796][root][INFO] - Score: 78.05 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 00:18:10,557][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 00:18:10,558][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 5.76 [s]
[2024-10-22 00:18:10,560][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 00:18:58,679][root][INFO] - Step: 1350/1350  |  Loss: 0.3014  |  Score: 90.76 [%]  |  Seq Length: 256.0
[2024-10-22 00:19:04,907][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 00:19:04,907][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-22 00:19:10,551][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 00:19:10,551][root][INFO] - Score: 71.21 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-22 00:19:10,552][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 00:19:10,553][root][INFO] - - Epoch: 5
[2024-10-22 00:19:10,553][root][INFO] - - DEV score: 79.59 [%]
[2024-10-22 00:19:10,553][root][INFO] - - TEST score: 71.66 [%]
[2024-10-22 00:19:10,553][root][INFO] - Fine-tuning is done!
[2024-10-22 00:19:13,898][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,899][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,900][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,900][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,901][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,901][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,903][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,903][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,904][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,904][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,905][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,905][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,906][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,906][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,907][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,907][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,908][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,908][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,909][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,909][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,910][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,910][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,911][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 00:19:13,911][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 00:19:13,913][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 00:19:14,122][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 00:19:14,124][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 00:19:14,125][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 00:19:14,296][root][INFO] - 

[2024-10-22 00:19:14,296][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 00:19:14,296][root][INFO] - Data Preprocessing
[2024-10-22 00:19:14,296][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 00:19:14,296][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 00:19:14,296][root][INFO] - ㄴ data_remove                False

[2024-10-22 00:19:14,296][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 00:19:14,303][root][INFO] - vocab size              : 51200
[2024-10-22 00:19:14,303][root][INFO] - device                  : gpu
[2024-10-22 00:19:14,303][root][INFO] - random seed             : 2
[2024-10-22 00:19:14,304][root][INFO] - train data size         : 5760
[2024-10-22 00:19:14,304][root][INFO] - max epochs              : 15
[2024-10-22 00:19:14,304][root][INFO] - total steps             : 1350
[2024-10-22 00:19:14,304][root][INFO] - warmup steps            : 135
[2024-10-22 00:19:14,304][root][INFO] - batch size              : 64
[2024-10-22 00:19:14,304][root][INFO] - accumulation steps      : 1
[2024-10-22 00:19:14,304][root][INFO] - optimizer               : adamwscale
[2024-10-22 00:19:14,304][root][INFO] - lr_scheduler            : cosine
[2024-10-22 00:19:14,304][root][INFO] - learning rate           : 0.02
[2024-10-22 00:19:14,304][root][INFO] - max length              : 256

[2024-10-22 00:19:14,304][root][INFO] - LoRA Configuration
[2024-10-22 00:19:14,304][root][INFO] - ㄴ r                    : 32
[2024-10-22 00:19:14,305][root][INFO] - ㄴ alpha                : 128
[2024-10-22 00:19:14,305][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 00:19:14,305][root][INFO] - KOMBO Configuration
[2024-10-22 00:19:14,305][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 00:19:14,305][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 00:19:14,305][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 00:19:14,305][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 00:19:14,305][root][INFO] - ㄴ do_combination       : True
[2024-10-22 00:19:14,305][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 00:19:14,305][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 00:19:14,306][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 00:19:14,306][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 00:19:14,306][root][INFO] - 

[2024-10-22 00:19:14,306][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs
[2024-10-22 00:19:14,306][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 00:19:14,306][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 00:19:14,306][root][INFO] - * tb interval   : 10000

[2024-10-22 00:19:14,306][root][INFO] - 

[2024-10-22 00:19:14,306][root][INFO] - Start the Training !
[2024-10-22 00:19:14,308][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 00:20:02,489][root][INFO] - Step: 90/1350  |  Loss: 1.8175  |  Score: 45.41 [%]  |  Seq Length: 256.0
[2024-10-22 00:20:08,822][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 00:20:08,823][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 00:20:14,573][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 00:20:14,573][root][INFO] - Score: 64.34 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 00:20:14,574][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 00:20:14,575][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:20:14,577][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:20:16,318][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:20:16,603][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:20:16,605][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:20:16,605][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:20:16,605][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:20:16,605][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:20:16,608][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:20:18,238][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 00:21:06,432][root][INFO] - Step: 180/1350  |  Loss: 1.0927  |  Score: 67.88 [%]  |  Seq Length: 256.0
[2024-10-22 00:21:12,692][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 00:21:12,692][root][INFO] - Score: 77.26 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:21:18,391][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 00:21:18,391][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 00:21:18,392][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 00:21:18,393][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:21:18,395][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:21:20,142][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:21:20,426][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:21:20,427][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:21:20,428][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:21:20,428][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:21:20,428][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:21:20,431][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:21:22,063][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 00:22:10,234][root][INFO] - Step: 270/1350  |  Loss: 0.9015  |  Score: 74.46 [%]  |  Seq Length: 256.0
[2024-10-22 00:22:16,526][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 00:22:16,526][root][INFO] - Score: 78.15 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 00:22:22,335][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 00:22:22,335][root][INFO] - Score: 70.89 [%]  |  Evaluation Time: 5.81 [s]
[2024-10-22 00:22:22,336][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 00:22:22,337][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:22:22,339][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:22:24,049][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:22:24,340][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:22:24,341][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:22:24,342][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:22:24,342][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:22:24,342][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:22:24,345][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:22:25,961][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 00:23:14,296][root][INFO] - Step: 360/1350  |  Loss: 0.7460  |  Score: 79.24 [%]  |  Seq Length: 256.0
[2024-10-22 00:23:20,536][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 00:23:20,536][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 00:23:26,369][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 00:23:26,370][root][INFO] - Score: 69.29 [%]  |  Evaluation Time: 5.83 [s]
[2024-10-22 00:23:26,372][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 00:24:14,701][root][INFO] - Step: 450/1350  |  Loss: 0.6289  |  Score: 82.70 [%]  |  Seq Length: 256.0
[2024-10-22 00:24:20,956][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 00:24:20,956][root][INFO] - Score: 79.05 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 00:24:26,744][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 00:24:26,744][root][INFO] - Score: 70.23 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-22 00:24:26,745][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 00:24:26,745][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:24:26,748][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:24:28,496][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:24:28,757][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:24:28,759][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:24:28,759][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:24:28,760][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:24:28,760][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:24:28,762][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:24:30,417][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 00:25:18,623][root][INFO] - Step: 540/1350  |  Loss: 0.5106  |  Score: 86.26 [%]  |  Seq Length: 256.0
[2024-10-22 00:25:25,021][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 00:25:25,021][root][INFO] - Score: 77.19 [%]  |  Evaluation Time: 6.39 [s]
[2024-10-22 00:25:30,674][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 00:25:30,674][root][INFO] - Score: 70.36 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-22 00:25:30,676][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 00:26:18,847][root][INFO] - Step: 630/1350  |  Loss: 0.4245  |  Score: 87.66 [%]  |  Seq Length: 256.0
[2024-10-22 00:26:25,170][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 00:26:25,170][root][INFO] - Score: 77.77 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 00:26:30,942][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 00:26:30,942][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 5.77 [s]
[2024-10-22 00:26:30,945][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 00:27:19,232][root][INFO] - Step: 720/1350  |  Loss: 0.3709  |  Score: 89.80 [%]  |  Seq Length: 256.0
[2024-10-22 00:27:25,540][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 00:27:25,541][root][INFO] - Score: 78.10 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 00:27:31,214][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 00:27:31,214][root][INFO] - Score: 71.18 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 00:27:31,215][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 00:27:31,215][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:27:31,218][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:27:32,945][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:27:33,229][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:27:33,230][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:27:33,231][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:27:33,231][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:27:33,231][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:27:33,234][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:27:34,865][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 00:28:23,056][root][INFO] - Step: 810/1350  |  Loss: 0.2888  |  Score: 91.81 [%]  |  Seq Length: 256.0
[2024-10-22 00:28:29,266][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 00:28:29,266][root][INFO] - Score: 77.85 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-22 00:28:34,978][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 00:28:34,978][root][INFO] - Score: 70.33 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 00:28:34,980][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 00:29:23,708][root][INFO] - Step: 900/1350  |  Loss: 0.2524  |  Score: 92.90 [%]  |  Seq Length: 256.0
[2024-10-22 00:29:29,973][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 00:29:29,973][root][INFO] - Score: 77.75 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:29:35,694][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 00:29:35,695][root][INFO] - Score: 70.62 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 00:29:35,697][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 00:30:23,345][root][INFO] - Step: 990/1350  |  Loss: 0.2191  |  Score: 93.31 [%]  |  Seq Length: 256.0
[2024-10-22 00:30:29,578][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 00:30:29,578][root][INFO] - Score: 78.99 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-22 00:30:35,249][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 00:30:35,249][root][INFO] - Score: 70.48 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 00:30:35,250][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-22 00:30:35,250][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:30:35,253][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:30:36,985][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:30:37,267][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:30:37,268][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:30:37,268][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:30:37,269][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:30:37,269][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:30:37,272][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:30:38,882][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 00:31:25,791][root][INFO] - Step: 1080/1350  |  Loss: 0.1850  |  Score: 94.48 [%]  |  Seq Length: 256.0
[2024-10-22 00:31:32,079][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 00:31:32,079][root][INFO] - Score: 78.39 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 00:31:37,747][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 00:31:37,747][root][INFO] - Score: 70.56 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 00:31:37,749][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 00:32:25,789][root][INFO] - Step: 1170/1350  |  Loss: 0.1837  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-22 00:32:32,065][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 00:32:32,066][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 00:32:37,801][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 00:32:37,802][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 00:32:37,803][root][INFO] - 
Save new Best Score (Epoch: 13)
[2024-10-22 00:32:37,803][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 00:32:37,806][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:32:39,524][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:32:39,811][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:32:39,812][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:32:39,813][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:32:39,813][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:32:39,813][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:32:39,816][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:32:41,438][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 00:33:29,690][root][INFO] - Step: 1260/1350  |  Loss: 0.1689  |  Score: 94.86 [%]  |  Seq Length: 256.0
[2024-10-22 00:33:35,964][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 00:33:35,964][root][INFO] - Score: 78.55 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 00:33:41,634][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 00:33:41,634][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 00:33:41,636][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 00:34:26,701][root][INFO] - Step: 6330/10550  |  Loss: 0.2511  |  Score: 89.54 [%]  |  Seq Length: 256.0
[2024-10-22 00:34:29,703][root][INFO] - Step: 1350/1350  |  Loss: 0.1582  |  Score: 95.16 [%]  |  Seq Length: 256.0
[2024-10-22 00:34:35,951][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 00:34:35,951][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 00:34:41,692][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 00:34:41,692][root][INFO] - Score: 70.44 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-22 00:34:41,693][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 00:34:41,693][root][INFO] - - Epoch: 13
[2024-10-22 00:34:41,693][root][INFO] - - DEV score: 78.92 [%]
[2024-10-22 00:34:41,693][root][INFO] - - TEST score: 70.60 [%]
[2024-10-22 00:34:41,694][root][INFO] - Fine-tuning is done!
[2024-10-22 00:34:41,694][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 00:34:41,694][root][INFO] - - BEST LR: 0.01
[2024-10-22 00:34:41,694][root][INFO] - - DEV score: 79.59 [%]
[2024-10-22 00:34:41,695][root][INFO] - - TEST score: 71.66 [%]
[2024-10-22 00:34:47,953][root][INFO] - 

[2024-10-22 00:34:47,953][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 00:34:47,953][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-22 00:34:47,953][root][INFO] - 

[2024-10-22 00:34:47,953][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 00:34:52,342][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,343][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,344][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,344][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,345][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,345][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,346][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,346][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,347][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,347][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,348][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,348][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,349][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,349][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,350][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,350][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,351][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,351][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,352][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,352][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,353][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,353][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,354][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 00:34:52,354][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 00:34:52,356][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 00:34:52,360][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 00:34:52,564][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 00:34:52,566][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 00:34:52,762][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 00:34:55,975][root][INFO] - 

[2024-10-22 00:34:55,975][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 00:34:55,975][root][INFO] - Data Preprocessing
[2024-10-22 00:34:55,975][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 00:34:55,975][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 00:34:55,975][root][INFO] - ㄴ data_remove                False

[2024-10-22 00:34:55,976][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 00:34:55,983][root][INFO] - vocab size              : 51200
[2024-10-22 00:34:55,983][root][INFO] - device                  : gpu
[2024-10-22 00:34:55,983][root][INFO] - random seed             : 3
[2024-10-22 00:34:55,984][root][INFO] - train data size         : 5760
[2024-10-22 00:34:55,984][root][INFO] - max epochs              : 15
[2024-10-22 00:34:55,984][root][INFO] - total steps             : 1350
[2024-10-22 00:34:55,984][root][INFO] - warmup steps            : 135
[2024-10-22 00:34:55,984][root][INFO] - batch size              : 64
[2024-10-22 00:34:55,984][root][INFO] - accumulation steps      : 1
[2024-10-22 00:34:55,984][root][INFO] - optimizer               : adamwscale
[2024-10-22 00:34:55,984][root][INFO] - lr_scheduler            : cosine
[2024-10-22 00:34:55,984][root][INFO] - learning rate           : 0.01
[2024-10-22 00:34:55,984][root][INFO] - max length              : 256

[2024-10-22 00:34:55,984][root][INFO] - LoRA Configuration
[2024-10-22 00:34:55,984][root][INFO] - ㄴ r                    : 32
[2024-10-22 00:34:55,985][root][INFO] - ㄴ alpha                : 128
[2024-10-22 00:34:55,985][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 00:34:55,985][root][INFO] - KOMBO Configuration
[2024-10-22 00:34:55,985][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 00:34:55,985][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 00:34:55,985][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 00:34:55,985][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 00:34:55,985][root][INFO] - ㄴ do_combination       : True
[2024-10-22 00:34:55,985][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 00:34:55,985][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 00:34:55,986][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 00:34:55,986][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 00:34:55,986][root][INFO] - 

[2024-10-22 00:34:55,986][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-22 00:34:55,986][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 00:34:55,986][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb
[2024-10-22 00:34:55,986][root][INFO] - * tb interval   : 10000

[2024-10-22 00:34:55,986][root][INFO] - 

[2024-10-22 00:34:55,986][root][INFO] - Start the Training !
[2024-10-22 00:34:55,989][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 00:35:20,041][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 00:35:20,042][root][INFO] - Score: 88.63 [%]  |  Evaluation Time: 53.34 [s]
[2024-10-22 00:35:44,557][root][INFO] - Step: 90/1350  |  Loss: 2.2909  |  Score: 31.85 [%]  |  Seq Length: 256.0
[2024-10-22 00:35:50,752][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 00:35:50,752][root][INFO] - Score: 71.61 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-22 00:35:56,365][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 00:35:56,365][root][INFO] - Score: 62.39 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-22 00:35:56,366][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 00:35:56,367][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:35:56,369][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:35:57,252][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:35:57,383][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:35:57,384][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:35:57,384][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:35:57,384][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:35:57,384][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:35:57,385][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:35:58,143][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 00:36:45,623][root][INFO] - Step: 180/1350  |  Loss: 1.1913  |  Score: 65.25 [%]  |  Seq Length: 256.0
[2024-10-22 00:36:51,819][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 00:36:51,819][root][INFO] - Score: 76.04 [%]  |  Evaluation Time: 6.19 [s]
[2024-10-22 00:36:57,445][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 00:36:57,445][root][INFO] - Score: 68.27 [%]  |  Evaluation Time: 5.62 [s]
[2024-10-22 00:36:57,446][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 00:36:57,446][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:36:57,449][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:36:59,189][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:36:59,469][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:36:59,470][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:36:59,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:36:59,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:36:59,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:36:59,474][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:37:01,170][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 00:37:49,559][root][INFO] - Step: 270/1350  |  Loss: 1.0420  |  Score: 70.73 [%]  |  Seq Length: 256.0
[2024-10-22 00:37:55,903][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 00:37:55,903][root][INFO] - Score: 77.02 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 00:38:01,603][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 00:38:01,603][root][INFO] - Score: 69.75 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 00:38:01,604][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 00:38:01,605][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:38:01,607][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:38:03,333][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:38:03,620][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:38:03,621][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:38:03,621][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:38:03,622][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:38:03,622][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:38:03,625][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:38:05,272][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 00:38:16,832][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 00:38:16,833][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 176.79 [s]
[2024-10-22 00:38:16,834][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 00:38:16,834][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 00:38:16,837][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:38:18,555][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:38:18,817][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:38:18,818][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:38:18,818][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:38:18,819][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:38:18,819][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:38:18,831][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:38:20,437][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 00:38:53,409][root][INFO] - Step: 360/1350  |  Loss: 0.8905  |  Score: 74.54 [%]  |  Seq Length: 256.0
[2024-10-22 00:38:59,639][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 00:38:59,640][root][INFO] - Score: 77.14 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-22 00:39:05,255][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 00:39:05,255][root][INFO] - Score: 70.94 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-22 00:39:05,256][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 00:39:05,256][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:39:05,259][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:39:06,972][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:39:07,253][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:39:07,254][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:39:07,254][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:39:07,255][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:39:07,255][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:39:07,258][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:39:08,866][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 00:39:57,084][root][INFO] - Step: 450/1350  |  Loss: 0.7969  |  Score: 77.96 [%]  |  Seq Length: 256.0
[2024-10-22 00:40:03,352][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 00:40:03,352][root][INFO] - Score: 76.97 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:40:09,040][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 00:40:09,040][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 00:40:09,042][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 00:40:57,028][root][INFO] - Step: 540/1350  |  Loss: 0.6642  |  Score: 80.61 [%]  |  Seq Length: 256.0
[2024-10-22 00:41:03,248][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 00:41:03,248][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-22 00:41:08,863][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 00:41:08,864][root][INFO] - Score: 71.87 [%]  |  Evaluation Time: 5.61 [s]
[2024-10-22 00:41:08,865][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 00:41:08,865][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:41:08,868][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:41:10,580][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:41:10,860][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:41:10,861][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:41:10,862][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:41:10,862][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:41:10,862][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:41:10,865][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:41:12,494][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 00:42:00,527][root][INFO] - Step: 630/1350  |  Loss: 0.6012  |  Score: 83.11 [%]  |  Seq Length: 256.0
[2024-10-22 00:42:06,754][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 00:42:06,755][root][INFO] - Score: 79.22 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-22 00:42:12,387][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 00:42:12,387][root][INFO] - Score: 71.72 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-22 00:42:12,388][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 00:42:12,388][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:42:12,391][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:42:14,106][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:42:14,390][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:42:14,391][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:42:14,391][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:42:14,392][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:42:14,392][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:42:14,395][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:42:16,009][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 00:43:04,123][root][INFO] - Step: 720/1350  |  Loss: 0.5148  |  Score: 84.92 [%]  |  Seq Length: 256.0
[2024-10-22 00:43:10,345][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 00:43:10,345][root][INFO] - Score: 79.21 [%]  |  Evaluation Time: 6.22 [s]
[2024-10-22 00:43:15,982][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 00:43:15,982][root][INFO] - Score: 71.67 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-22 00:43:15,984][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 00:44:03,932][root][INFO] - Step: 810/1350  |  Loss: 0.4701  |  Score: 86.44 [%]  |  Seq Length: 256.0
[2024-10-22 00:44:10,161][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 00:44:10,161][root][INFO] - Score: 79.08 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-22 00:44:15,740][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 00:44:15,741][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 5.58 [s]
[2024-10-22 00:44:15,743][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 00:45:03,745][root][INFO] - Step: 900/1350  |  Loss: 0.4315  |  Score: 87.36 [%]  |  Seq Length: 256.0
[2024-10-22 00:45:10,009][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 00:45:10,009][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:45:15,696][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 00:45:15,696][root][INFO] - Score: 71.13 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 00:45:15,698][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 00:46:03,828][root][INFO] - Step: 990/1350  |  Loss: 0.3807  |  Score: 88.94 [%]  |  Seq Length: 256.0
[2024-10-22 00:46:10,166][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 00:46:10,166][root][INFO] - Score: 78.54 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 00:46:15,802][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 00:46:15,803][root][INFO] - Score: 70.97 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-22 00:46:15,805][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 00:47:03,966][root][INFO] - Step: 1080/1350  |  Loss: 0.3468  |  Score: 89.74 [%]  |  Seq Length: 256.0
[2024-10-22 00:47:10,246][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 00:47:10,247][root][INFO] - Score: 78.20 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 00:47:15,890][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 00:47:15,890][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-22 00:47:15,893][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 00:48:04,062][root][INFO] - Step: 1170/1350  |  Loss: 0.3371  |  Score: 89.86 [%]  |  Seq Length: 256.0
[2024-10-22 00:48:10,347][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 00:48:10,348][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 00:48:16,029][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 00:48:16,029][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 00:48:16,031][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 00:49:04,020][root][INFO] - Step: 1260/1350  |  Loss: 0.3290  |  Score: 90.16 [%]  |  Seq Length: 256.0
[2024-10-22 00:49:10,353][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 00:49:10,353][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 00:49:16,050][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 00:49:16,050][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 00:49:16,052][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 00:50:04,242][root][INFO] - Step: 1350/1350  |  Loss: 0.3204  |  Score: 90.41 [%]  |  Seq Length: 256.0
[2024-10-22 00:50:10,505][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 00:50:10,505][root][INFO] - Score: 78.94 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:50:16,196][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 00:50:16,196][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 00:50:16,198][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 00:50:16,198][root][INFO] - - Epoch: 7
[2024-10-22 00:50:16,198][root][INFO] - - DEV score: 79.22 [%]
[2024-10-22 00:50:16,198][root][INFO] - - TEST score: 71.72 [%]
[2024-10-22 00:50:16,199][root][INFO] - Fine-tuning is done!
[2024-10-22 00:50:19,465][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,466][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,467][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,467][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,468][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,469][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,469][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,470][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,470][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,471][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,472][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,472][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,473][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,473][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,474][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,474][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,475][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,475][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,476][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,476][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,477][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,478][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,478][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 00:50:19,479][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 00:50:19,481][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 00:50:19,688][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 00:50:19,690][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 00:50:19,691][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 00:50:19,876][root][INFO] - 

[2024-10-22 00:50:19,876][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 00:50:19,876][root][INFO] - Data Preprocessing
[2024-10-22 00:50:19,876][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 00:50:19,876][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 00:50:19,876][root][INFO] - ㄴ data_remove                False

[2024-10-22 00:50:19,876][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 00:50:19,883][root][INFO] - vocab size              : 51200
[2024-10-22 00:50:19,884][root][INFO] - device                  : gpu
[2024-10-22 00:50:19,884][root][INFO] - random seed             : 3
[2024-10-22 00:50:19,884][root][INFO] - train data size         : 5760
[2024-10-22 00:50:19,884][root][INFO] - max epochs              : 15
[2024-10-22 00:50:19,884][root][INFO] - total steps             : 1350
[2024-10-22 00:50:19,884][root][INFO] - warmup steps            : 135
[2024-10-22 00:50:19,884][root][INFO] - batch size              : 64
[2024-10-22 00:50:19,884][root][INFO] - accumulation steps      : 1
[2024-10-22 00:50:19,884][root][INFO] - optimizer               : adamwscale
[2024-10-22 00:50:19,884][root][INFO] - lr_scheduler            : cosine
[2024-10-22 00:50:19,885][root][INFO] - learning rate           : 0.02
[2024-10-22 00:50:19,885][root][INFO] - max length              : 256

[2024-10-22 00:50:19,885][root][INFO] - LoRA Configuration
[2024-10-22 00:50:19,885][root][INFO] - ㄴ r                    : 32
[2024-10-22 00:50:19,885][root][INFO] - ㄴ alpha                : 128
[2024-10-22 00:50:19,885][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 00:50:19,885][root][INFO] - KOMBO Configuration
[2024-10-22 00:50:19,885][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 00:50:19,885][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 00:50:19,885][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 00:50:19,885][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 00:50:19,886][root][INFO] - ㄴ do_combination       : True
[2024-10-22 00:50:19,886][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 00:50:19,886][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 00:50:19,886][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 00:50:19,886][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 00:50:19,886][root][INFO] - 

[2024-10-22 00:50:19,886][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs
[2024-10-22 00:50:19,886][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 00:50:19,886][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/tb
[2024-10-22 00:50:19,886][root][INFO] - * tb interval   : 10000

[2024-10-22 00:50:19,886][root][INFO] - 

[2024-10-22 00:50:19,887][root][INFO] - Start the Training !
[2024-10-22 00:50:19,889][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 00:51:08,049][root][INFO] - Step: 90/1350  |  Loss: 2.0050  |  Score: 41.73 [%]  |  Seq Length: 256.0
[2024-10-22 00:51:14,314][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 00:51:14,314][root][INFO] - Score: 73.18 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 00:51:19,967][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 00:51:19,967][root][INFO] - Score: 58.86 [%]  |  Evaluation Time: 5.65 [s]
[2024-10-22 00:51:19,968][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 00:51:19,968][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:51:19,971][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:51:21,667][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:51:21,967][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:51:21,968][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:51:21,968][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:51:21,969][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:51:21,969][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:51:21,972][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:51:23,582][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 00:52:11,542][root][INFO] - Step: 180/1350  |  Loss: 1.2052  |  Score: 67.39 [%]  |  Seq Length: 256.0
[2024-10-22 00:52:17,755][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 00:52:17,756][root][INFO] - Score: 75.49 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-22 00:52:23,472][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 00:52:23,473][root][INFO] - Score: 68.24 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 00:52:23,473][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 00:52:23,474][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:52:23,476][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:52:25,164][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:52:25,445][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:52:25,470][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:52:25,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:52:25,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:52:25,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:52:25,474][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:52:27,084][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 00:53:15,161][root][INFO] - Step: 270/1350  |  Loss: 0.9816  |  Score: 73.08 [%]  |  Seq Length: 256.0
[2024-10-22 00:53:21,434][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 00:53:21,434][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 00:53:27,109][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 00:53:27,109][root][INFO] - Score: 69.28 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 00:53:27,111][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 00:53:27,111][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:53:27,114][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:53:28,876][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:53:29,129][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:53:29,156][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:53:29,156][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:53:29,156][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:53:29,157][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:53:29,160][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:53:30,765][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 00:54:18,837][root][INFO] - Step: 360/1350  |  Loss: 0.7653  |  Score: 77.96 [%]  |  Seq Length: 256.0
[2024-10-22 00:54:25,112][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 00:54:25,112][root][INFO] - Score: 75.94 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 00:54:30,774][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 00:54:30,774][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 00:54:30,777][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 00:55:18,864][root][INFO] - Step: 450/1350  |  Loss: 0.6423  |  Score: 82.10 [%]  |  Seq Length: 256.0
[2024-10-22 00:55:25,066][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 00:55:25,066][root][INFO] - Score: 76.74 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-22 00:55:30,729][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 00:55:30,730][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 00:55:30,732][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 00:56:09,800][root][INFO] - Step: 8440/10550  |  Loss: 0.2142  |  Score: 91.21 [%]  |  Seq Length: 256.0
[2024-10-22 00:56:19,026][root][INFO] - Step: 540/1350  |  Loss: 0.5126  |  Score: 85.43 [%]  |  Seq Length: 256.0
[2024-10-22 00:56:25,233][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 00:56:25,234][root][INFO] - Score: 77.19 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-22 00:56:30,982][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 00:56:30,982][root][INFO] - Score: 69.87 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 00:56:30,983][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 00:56:30,983][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:56:30,986][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:56:32,685][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:56:32,957][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:56:32,983][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:56:32,984][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:56:32,984][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:56:32,984][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:56:32,987][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:56:34,604][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 00:57:03,377][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 00:57:03,378][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 53.57 [s]
[2024-10-22 00:57:22,632][root][INFO] - Step: 630/1350  |  Loss: 0.4348  |  Score: 87.71 [%]  |  Seq Length: 256.0
[2024-10-22 00:57:28,871][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 00:57:28,871][root][INFO] - Score: 77.76 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 00:57:34,530][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 00:57:34,531][root][INFO] - Score: 69.95 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 00:57:34,532][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 00:57:34,532][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 00:57:34,534][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 00:57:36,239][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 00:57:36,539][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 00:57:36,540][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 00:57:36,541][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 00:57:36,541][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 00:57:36,541][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 00:57:36,544][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 00:57:38,154][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 00:58:26,290][root][INFO] - Step: 720/1350  |  Loss: 0.3535  |  Score: 89.66 [%]  |  Seq Length: 256.0
[2024-10-22 00:58:32,570][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 00:58:32,570][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 00:58:38,216][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 00:58:38,216][root][INFO] - Score: 69.39 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-22 00:58:38,218][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 00:59:26,365][root][INFO] - Step: 810/1350  |  Loss: 0.2966  |  Score: 91.24 [%]  |  Seq Length: 256.0
[2024-10-22 00:59:32,688][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 00:59:32,689][root][INFO] - Score: 77.57 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 00:59:38,409][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 00:59:38,409][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 00:59:38,411][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 01:00:00,113][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 01:00:00,113][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 176.73 [s]
[2024-10-22 01:00:00,114][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 01:00:00,115][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 01:00:00,118][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:00:01,839][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:00:02,122][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:00:02,124][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:00:02,124][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:00:02,124][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:00:02,125][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:00:02,128][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:00:03,754][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 01:00:26,632][root][INFO] - Step: 900/1350  |  Loss: 0.2655  |  Score: 92.25 [%]  |  Seq Length: 256.0
[2024-10-22 01:00:32,839][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 01:00:32,839][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 6.20 [s]
[2024-10-22 01:00:38,523][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 01:00:38,523][root][INFO] - Score: 69.66 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 01:00:38,524][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 01:00:38,525][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 01:00:38,527][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:00:40,242][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:00:40,523][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:00:40,524][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:00:40,525][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:00:40,525][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:00:40,525][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:00:40,528][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:00:42,182][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 01:01:30,249][root][INFO] - Step: 990/1350  |  Loss: 0.2164  |  Score: 93.52 [%]  |  Seq Length: 256.0
[2024-10-22 01:01:36,460][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 01:01:36,460][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-22 01:01:42,132][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 01:01:42,133][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 01:01:42,134][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 01:02:30,410][root][INFO] - Step: 1080/1350  |  Loss: 0.1939  |  Score: 94.05 [%]  |  Seq Length: 256.0
[2024-10-22 01:02:36,645][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 01:02:36,645][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-22 01:02:42,414][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 01:02:42,414][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 5.77 [s]
[2024-10-22 01:02:42,416][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 01:03:30,516][root][INFO] - Step: 1170/1350  |  Loss: 0.1854  |  Score: 94.32 [%]  |  Seq Length: 256.0
[2024-10-22 01:03:36,787][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 01:03:36,788][root][INFO] - Score: 77.65 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 01:03:42,526][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 01:03:42,526][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-22 01:03:42,529][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 01:04:30,846][root][INFO] - Step: 1260/1350  |  Loss: 0.1681  |  Score: 94.92 [%]  |  Seq Length: 256.0
[2024-10-22 01:04:35,350][root][INFO] - Step: 10000/73665  |  Loss: 0.7300  |  Score: 68.42 [%]  |  Seq Length: 256.0
[2024-10-22 01:04:37,186][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 01:04:37,186][root][INFO] - Score: 78.48 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 01:04:42,910][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 01:04:42,911][root][INFO] - Score: 69.62 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 01:04:42,913][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 01:05:31,091][root][INFO] - Step: 1350/1350  |  Loss: 0.1612  |  Score: 95.13 [%]  |  Seq Length: 256.0
[2024-10-22 01:05:37,408][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 01:05:37,408][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 01:05:43,090][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 01:05:43,090][root][INFO] - Score: 70.32 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 01:05:43,091][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-22 01:05:43,092][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 01:05:43,094][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:05:44,786][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:05:45,061][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:05:45,062][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:05:45,063][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:05:45,063][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:05:45,063][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:05:45,066][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:05:46,702][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 01:05:46,702][root][INFO] - - Epoch: 15
[2024-10-22 01:05:46,703][root][INFO] - - DEV score: 78.17 [%]
[2024-10-22 01:05:46,703][root][INFO] - - TEST score: 70.32 [%]
[2024-10-22 01:05:46,705][root][INFO] - Fine-tuning is done!
[2024-10-22 01:05:46,706][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 01:05:46,706][root][INFO] - - BEST LR: 0.01
[2024-10-22 01:05:46,706][root][INFO] - - DEV score: 79.22 [%]
[2024-10-22 01:05:46,707][root][INFO] - - TEST score: 71.72 [%]
[2024-10-22 01:13:12,785][root][INFO] - Step: 10000/10550  |  Loss: 0.1915  |  Score: 92.27 [%]  |  Seq Length: 256.0
[2024-10-22 01:17:49,373][root][INFO] - Step: 10550/10550  |  Loss: 0.1878  |  Score: 92.42 [%]  |  Seq Length: 256.0
[2024-10-22 01:18:42,084][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 01:18:42,084][root][INFO] - Score: 88.91 [%]  |  Evaluation Time: 52.71 [s]
[2024-10-22 01:21:36,763][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 01:21:36,764][root][INFO] - Score: 88.73 [%]  |  Evaluation Time: 174.68 [s]
[2024-10-22 01:21:36,765][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 01:21:36,765][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 01:21:36,768][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:21:38,665][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:21:38,843][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:21:38,844][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:21:38,845][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:21:38,845][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:21:38,845][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:21:38,847][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:21:40,599][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 01:21:40,600][root][INFO] - - Epoch: 5
[2024-10-22 01:21:40,600][root][INFO] - - DEV score: 88.91 [%]
[2024-10-22 01:21:40,600][root][INFO] - - TEST score: 88.73 [%]
[2024-10-22 01:21:40,602][root][INFO] - Fine-tuning is done!
[2024-10-22 01:22:01,164][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,165][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,165][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,166][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,167][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,167][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,168][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,168][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,169][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,169][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,170][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,170][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,171][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,171][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,172][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,172][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,173][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,173][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,174][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,174][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,176][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,176][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,177][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 01:22:01,177][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 01:22:01,179][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 01:22:01,369][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 01:22:01,371][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 01:22:01,372][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 01:22:01,560][root][INFO] - 

[2024-10-22 01:22:01,560][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 01:22:01,560][root][INFO] - Data Preprocessing
[2024-10-22 01:22:01,560][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 01:22:01,560][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 01:22:01,560][root][INFO] - ㄴ data_remove                False

[2024-10-22 01:22:01,560][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 01:22:01,570][root][INFO] - vocab size              : 51200
[2024-10-22 01:22:01,570][root][INFO] - device                  : gpu
[2024-10-22 01:22:01,570][root][INFO] - random seed             : 1
[2024-10-22 01:22:01,570][root][INFO] - train data size         : 135040
[2024-10-22 01:22:01,570][root][INFO] - max epochs              : 5
[2024-10-22 01:22:01,571][root][INFO] - total steps             : 10550
[2024-10-22 01:22:01,571][root][INFO] - warmup steps            : 1055
[2024-10-22 01:22:01,571][root][INFO] - batch size              : 64
[2024-10-22 01:22:01,571][root][INFO] - accumulation steps      : 1
[2024-10-22 01:22:01,571][root][INFO] - optimizer               : adamwscale
[2024-10-22 01:22:01,571][root][INFO] - lr_scheduler            : cosine
[2024-10-22 01:22:01,571][root][INFO] - learning rate           : 0.02
[2024-10-22 01:22:01,571][root][INFO] - max length              : 256

[2024-10-22 01:22:01,572][root][INFO] - LoRA Configuration
[2024-10-22 01:22:01,572][root][INFO] - ㄴ r                    : 32
[2024-10-22 01:22:01,572][root][INFO] - ㄴ alpha                : 128
[2024-10-22 01:22:01,572][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 01:22:01,572][root][INFO] - KOMBO Configuration
[2024-10-22 01:22:01,572][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 01:22:01,572][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 01:22:01,572][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 01:22:01,572][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 01:22:01,572][root][INFO] - ㄴ do_combination       : True
[2024-10-22 01:22:01,573][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 01:22:01,573][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 01:22:01,573][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 01:22:01,573][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 01:22:01,573][root][INFO] - 

[2024-10-22 01:22:01,573][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs
[2024-10-22 01:22:01,573][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 01:22:01,573][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/tb
[2024-10-22 01:22:01,573][root][INFO] - * tb interval   : 10000

[2024-10-22 01:22:01,573][root][INFO] - 

[2024-10-22 01:22:01,573][root][INFO] - Start the Training !
[2024-10-22 01:22:01,576][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 01:39:45,802][root][INFO] - Step: 2110/10550  |  Loss: 0.3662  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-22 01:40:39,182][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 01:40:39,182][root][INFO] - Score: 84.94 [%]  |  Evaluation Time: 53.38 [s]
[2024-10-22 01:43:33,942][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 01:43:33,942][root][INFO] - Score: 85.19 [%]  |  Evaluation Time: 174.76 [s]
[2024-10-22 01:43:33,943][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 01:43:33,944][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 01:43:33,946][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:43:35,858][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:43:36,026][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:43:36,027][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:43:36,028][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:43:36,028][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:43:36,028][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:43:36,030][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:43:37,783][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 01:46:57,307][root][INFO] - Step: 14733/73665  |  Loss: 0.6589  |  Score: 72.32 [%]  |  Seq Length: 256.0
[2024-10-22 01:47:07,906][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 01:47:07,906][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 10.59 [s]
[2024-10-22 01:47:28,499][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 01:47:28,500][root][INFO] - Score: 71.58 [%]  |  Evaluation Time: 20.59 [s]
[2024-10-22 01:47:28,501][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 01:47:28,502][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 01:47:28,505][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:47:29,445][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:47:29,559][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:47:29,559][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:47:29,560][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:47:29,560][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:47:29,560][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:47:29,561][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:47:30,314][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 01:51:27,213][root][INFO] - 

[2024-10-22 01:51:27,213][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 01:51:27,213][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-22 01:51:27,213][root][INFO] - 

[2024-10-22 01:51:27,213][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 01:51:40,620][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,620][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,621][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,621][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,622][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,622][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,623][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,623][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,624][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,624][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,625][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,625][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,626][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,626][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,627][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,627][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,628][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,628][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,629][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,629][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,630][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,630][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,631][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 01:51:40,631][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 01:51:40,633][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 01:51:40,639][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 01:51:40,839][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 01:51:40,842][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 01:51:41,035][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 01:51:44,109][root][INFO] - 

[2024-10-22 01:51:44,109][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-22 01:51:44,110][root][INFO] - Data Preprocessing
[2024-10-22 01:51:44,110][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 01:51:44,110][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 01:51:44,110][root][INFO] - ㄴ data_remove                False

[2024-10-22 01:51:44,110][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 01:51:44,118][root][INFO] - vocab size              : 51200
[2024-10-22 01:51:44,118][root][INFO] - device                  : gpu
[2024-10-22 01:51:44,118][root][INFO] - random seed             : 1
[2024-10-22 01:51:44,118][root][INFO] - train data size         : 49152
[2024-10-22 01:51:44,118][root][INFO] - max epochs              : 10
[2024-10-22 01:51:44,118][root][INFO] - total steps             : 7680
[2024-10-22 01:51:44,118][root][INFO] - warmup steps            : 768
[2024-10-22 01:51:44,118][root][INFO] - batch size              : 64
[2024-10-22 01:51:44,119][root][INFO] - accumulation steps      : 1
[2024-10-22 01:51:44,119][root][INFO] - optimizer               : adamwscale
[2024-10-22 01:51:44,119][root][INFO] - lr_scheduler            : cosine
[2024-10-22 01:51:44,119][root][INFO] - learning rate           : 0.01
[2024-10-22 01:51:44,119][root][INFO] - max length              : 256

[2024-10-22 01:51:44,119][root][INFO] - LoRA Configuration
[2024-10-22 01:51:44,119][root][INFO] - ㄴ r                    : 32
[2024-10-22 01:51:44,119][root][INFO] - ㄴ alpha                : 128
[2024-10-22 01:51:44,119][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 01:51:44,119][root][INFO] - KOMBO Configuration
[2024-10-22 01:51:44,119][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 01:51:44,119][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 01:51:44,120][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 01:51:44,120][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 01:51:44,120][root][INFO] - ㄴ do_combination       : True
[2024-10-22 01:51:44,120][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 01:51:44,120][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 01:51:44,120][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 01:51:44,120][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 01:51:44,120][root][INFO] - 

[2024-10-22 01:51:44,120][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-22 01:51:44,121][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 01:51:44,121][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-22 01:51:44,121][root][INFO] - * tb interval   : 10000

[2024-10-22 01:51:44,121][root][INFO] - 

[2024-10-22 01:51:44,121][root][INFO] - Start the Training !
[2024-10-22 01:51:44,124][root][INFO] - 
[1/ 10 Epoch]
[2024-10-22 01:59:17,458][root][INFO] - Step: 768/7680  |  Loss: 0.6573  |  Score: 60.00 [%]  |  Seq Length: 256.0
[2024-10-22 01:59:26,496][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 01:59:26,496][root][INFO] - Score: 65.70 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 01:59:35,641][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 01:59:35,641][root][INFO] - Score: 65.01 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-22 01:59:35,643][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 01:59:35,643][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 01:59:35,646][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 01:59:36,580][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 01:59:36,692][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 01:59:36,693][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 01:59:36,693][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 01:59:36,693][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 01:59:36,693][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 01:59:36,694][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 01:59:37,450][root][INFO] - 
[2/ 10 Epoch]
[2024-10-22 02:01:24,581][root][INFO] - Step: 4220/10550  |  Loss: 0.3130  |  Score: 86.60 [%]  |  Seq Length: 256.0
[2024-10-22 02:02:17,857][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 02:02:17,857][root][INFO] - Score: 87.51 [%]  |  Evaluation Time: 53.27 [s]
[2024-10-22 02:05:13,971][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 02:05:13,972][root][INFO] - Score: 87.27 [%]  |  Evaluation Time: 176.11 [s]
[2024-10-22 02:05:13,973][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 02:05:13,973][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:05:13,976][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:05:15,876][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:05:16,045][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:05:16,046][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:05:16,046][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:05:16,047][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:05:16,047][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:05:16,049][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:05:17,821][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 02:07:09,998][root][INFO] - Step: 1536/7680  |  Loss: 0.5328  |  Score: 73.17 [%]  |  Seq Length: 256.0
[2024-10-22 02:07:19,069][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 02:07:19,070][root][INFO] - Score: 71.83 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 02:07:28,159][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 02:07:28,159][root][INFO] - Score: 69.56 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-22 02:07:28,160][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 02:07:28,160][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:07:28,163][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:07:29,890][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:07:30,085][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:07:30,087][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:07:30,087][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:07:30,087][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:07:30,088][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:07:30,091][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:07:31,686][root][INFO] - 
[3/ 10 Epoch]
[2024-10-22 02:15:04,156][root][INFO] - Step: 2304/7680  |  Loss: 0.4654  |  Score: 77.39 [%]  |  Seq Length: 256.0
[2024-10-22 02:15:13,241][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 02:15:13,241][root][INFO] - Score: 72.05 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-22 02:15:22,363][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 02:15:22,363][root][INFO] - Score: 70.15 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 02:15:22,364][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 02:15:22,364][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:15:22,367][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:15:24,061][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:15:24,274][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:15:24,276][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:15:24,276][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:15:24,276][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:15:24,277][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:15:24,279][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:15:25,866][root][INFO] - 
[4/ 10 Epoch]
[2024-10-22 02:22:59,418][root][INFO] - Step: 3072/7680  |  Loss: 0.4085  |  Score: 80.69 [%]  |  Seq Length: 256.0
[2024-10-22 02:23:08,583][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 02:23:08,583][root][INFO] - Score: 73.91 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-22 02:23:09,809][root][INFO] - Step: 6330/10550  |  Loss: 0.2810  |  Score: 88.15 [%]  |  Seq Length: 256.0
[2024-10-22 02:23:17,661][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 02:23:17,661][root][INFO] - Score: 71.08 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-22 02:23:17,662][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 02:23:17,663][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:23:17,666][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:23:19,382][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:23:19,681][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:23:19,682][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:23:19,683][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:23:19,683][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:23:19,683][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:23:19,686][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:23:21,304][root][INFO] - 
[5/ 10 Epoch]
[2024-10-22 02:24:03,615][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 02:24:03,615][root][INFO] - Score: 87.83 [%]  |  Evaluation Time: 53.80 [s]
[2024-10-22 02:27:01,014][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 02:27:01,014][root][INFO] - Score: 88.01 [%]  |  Evaluation Time: 177.40 [s]
[2024-10-22 02:27:01,016][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 02:27:01,016][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:27:01,019][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:27:02,907][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:27:03,073][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:27:03,075][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:27:03,075][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:27:03,075][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:27:03,075][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:27:03,078][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:27:04,845][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 02:30:54,977][root][INFO] - Step: 3840/7680  |  Loss: 0.3681  |  Score: 82.95 [%]  |  Seq Length: 256.0
[2024-10-22 02:31:04,137][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 02:31:04,137][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-22 02:31:13,249][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 02:31:13,250][root][INFO] - Score: 71.48 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-22 02:31:13,251][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 02:31:13,251][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:31:13,254][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:31:15,029][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:31:15,314][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:31:15,315][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:31:15,316][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:31:15,316][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:31:15,316][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:31:15,319][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:31:16,977][root][INFO] - 
[6/ 10 Epoch]
[2024-10-22 02:34:37,474][root][INFO] - Step: 20000/73665  |  Loss: 0.6343  |  Score: 73.66 [%]  |  Seq Length: 256.0
[2024-10-22 02:38:50,547][root][INFO] - Step: 4608/7680  |  Loss: 0.3276  |  Score: 84.92 [%]  |  Seq Length: 256.0
[2024-10-22 02:38:59,653][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 02:38:59,653][root][INFO] - Score: 74.48 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 02:39:08,770][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 02:39:08,771][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-22 02:39:08,771][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 02:39:08,772][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:39:08,775][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:39:10,480][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:39:10,773][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:39:10,774][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:39:10,774][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:39:10,775][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:39:10,775][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:39:10,778][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:39:12,416][root][INFO] - 
[7/ 10 Epoch]
[2024-10-22 02:44:57,418][root][INFO] - Step: 8440/10550  |  Loss: 0.2341  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-22 02:45:51,042][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 02:45:51,042][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 53.62 [s]
[2024-10-22 02:46:46,179][root][INFO] - Step: 5376/7680  |  Loss: 0.2967  |  Score: 86.79 [%]  |  Seq Length: 256.0
[2024-10-22 02:46:55,357][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 02:46:55,357][root][INFO] - Score: 75.51 [%]  |  Evaluation Time: 9.17 [s]
[2024-10-22 02:47:04,497][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 02:47:04,497][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-22 02:47:04,499][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 02:47:04,499][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:47:04,502][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:47:06,231][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:47:06,515][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:47:06,517][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:47:06,517][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:47:06,517][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:47:06,518][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:47:06,521][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:47:08,147][root][INFO] - 
[8/ 10 Epoch]
[2024-10-22 02:48:48,664][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 02:48:48,665][root][INFO] - Score: 88.66 [%]  |  Evaluation Time: 177.62 [s]
[2024-10-22 02:48:48,666][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 02:48:48,666][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:48:48,669][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:48:50,564][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:48:50,734][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:48:50,735][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:48:50,735][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:48:50,735][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:48:50,736][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:48:50,737][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:48:52,509][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 02:54:42,421][root][INFO] - Step: 6144/7680  |  Loss: 0.2655  |  Score: 88.29 [%]  |  Seq Length: 256.0
[2024-10-22 02:54:51,569][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 02:54:51,569][root][INFO] - Score: 75.98 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 02:55:00,624][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 02:55:00,625][root][INFO] - Score: 72.62 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 02:55:00,626][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 02:55:00,626][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 02:55:00,629][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 02:55:02,388][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 02:55:02,684][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 02:55:02,685][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 02:55:02,686][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 02:55:02,686][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 02:55:02,686][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 02:55:02,689][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 02:55:04,363][root][INFO] - 
[9/ 10 Epoch]
[2024-10-22 03:02:06,901][root][INFO] - Step: 10000/10550  |  Loss: 0.1952  |  Score: 92.21 [%]  |  Seq Length: 256.0
[2024-10-22 03:02:37,083][root][INFO] - Step: 6912/7680  |  Loss: 0.2469  |  Score: 89.09 [%]  |  Seq Length: 256.0
[2024-10-22 03:02:46,202][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 03:02:46,202][root][INFO] - Score: 75.82 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 03:02:55,355][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 03:02:55,355][root][INFO] - Score: 71.94 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 03:02:55,358][root][INFO] - 
[10/ 10 Epoch]
[2024-10-22 03:06:46,930][root][INFO] - Step: 10550/10550  |  Loss: 0.1883  |  Score: 92.55 [%]  |  Seq Length: 256.0
[2024-10-22 03:07:40,748][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 03:07:40,748][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 53.81 [s]
[2024-10-22 03:10:28,921][root][INFO] - Step: 7680/7680  |  Loss: 0.2386  |  Score: 89.64 [%]  |  Seq Length: 256.0
[2024-10-22 03:10:36,867][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 03:10:36,868][root][INFO] - Score: 88.82 [%]  |  Evaluation Time: 176.12 [s]
[2024-10-22 03:10:36,869][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 03:10:36,869][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:10:36,872][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:10:38,048][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 03:10:38,049][root][INFO] - Score: 76.29 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 03:10:38,766][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:10:38,936][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:10:38,937][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:10:38,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:10:38,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:10:38,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:10:38,940][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:10:40,701][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 03:10:40,702][root][INFO] - - Epoch: 5
[2024-10-22 03:10:40,702][root][INFO] - - DEV score: 88.77 [%]
[2024-10-22 03:10:40,702][root][INFO] - - TEST score: 88.82 [%]
[2024-10-22 03:10:40,705][root][INFO] - Fine-tuning is done!
[2024-10-22 03:10:40,706][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 03:10:40,706][root][INFO] - - BEST LR: 0.01
[2024-10-22 03:10:40,707][root][INFO] - - DEV score: 88.91 [%]
[2024-10-22 03:10:40,707][root][INFO] - - TEST score: 88.73 [%]
[2024-10-22 03:10:47,030][root][INFO] - 

[2024-10-22 03:10:47,031][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 03:10:47,031][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-22 03:10:47,031][root][INFO] - 

[2024-10-22 03:10:47,031][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 03:10:47,268][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 03:10:47,268][root][INFO] - Score: 72.44 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-22 03:10:47,269][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 03:10:47,270][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:10:47,272][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:10:49,157][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:10:49,341][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:10:49,342][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:10:49,343][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:10:49,343][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:10:49,343][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:10:49,345][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:10:51,115][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 03:10:51,115][root][INFO] - - Epoch: 10
[2024-10-22 03:10:51,115][root][INFO] - - DEV score: 76.29 [%]
[2024-10-22 03:10:51,115][root][INFO] - - TEST score: 72.44 [%]
[2024-10-22 03:10:51,117][root][INFO] - Fine-tuning is done!
[2024-10-22 03:11:02,286][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,287][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,288][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,288][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,289][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,289][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,290][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,290][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,291][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,291][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,292][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,292][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,293][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,293][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,294][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,294][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,295][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,295][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,296][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,296][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,297][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,297][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,298][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:02,298][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:02,300][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 03:11:02,488][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 03:11:02,491][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 03:11:02,492][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 03:11:02,659][root][INFO] - 

[2024-10-22 03:11:02,659][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-22 03:11:02,659][root][INFO] - Data Preprocessing
[2024-10-22 03:11:02,659][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 03:11:02,659][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 03:11:02,659][root][INFO] - ㄴ data_remove                False

[2024-10-22 03:11:02,659][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 03:11:02,667][root][INFO] - vocab size              : 51200
[2024-10-22 03:11:02,667][root][INFO] - device                  : gpu
[2024-10-22 03:11:02,667][root][INFO] - random seed             : 1
[2024-10-22 03:11:02,668][root][INFO] - train data size         : 49152
[2024-10-22 03:11:02,668][root][INFO] - max epochs              : 10
[2024-10-22 03:11:02,668][root][INFO] - total steps             : 7680
[2024-10-22 03:11:02,668][root][INFO] - warmup steps            : 768
[2024-10-22 03:11:02,668][root][INFO] - batch size              : 64
[2024-10-22 03:11:02,668][root][INFO] - accumulation steps      : 1
[2024-10-22 03:11:02,668][root][INFO] - optimizer               : adamwscale
[2024-10-22 03:11:02,668][root][INFO] - lr_scheduler            : cosine
[2024-10-22 03:11:02,668][root][INFO] - learning rate           : 0.02
[2024-10-22 03:11:02,668][root][INFO] - max length              : 256

[2024-10-22 03:11:02,668][root][INFO] - LoRA Configuration
[2024-10-22 03:11:02,668][root][INFO] - ㄴ r                    : 32
[2024-10-22 03:11:02,669][root][INFO] - ㄴ alpha                : 128
[2024-10-22 03:11:02,669][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 03:11:02,669][root][INFO] - KOMBO Configuration
[2024-10-22 03:11:02,669][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 03:11:02,669][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 03:11:02,669][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 03:11:02,669][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 03:11:02,669][root][INFO] - ㄴ do_combination       : True
[2024-10-22 03:11:02,669][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 03:11:02,669][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 03:11:02,670][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 03:11:02,670][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 03:11:02,670][root][INFO] - 

[2024-10-22 03:11:02,670][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs
[2024-10-22 03:11:02,670][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 03:11:02,670][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/tb
[2024-10-22 03:11:02,670][root][INFO] - * tb interval   : 10000

[2024-10-22 03:11:02,670][root][INFO] - 

[2024-10-22 03:11:02,670][root][INFO] - Start the Training !
[2024-10-22 03:11:02,672][root][INFO] - 
[1/ 10 Epoch]
[2024-10-22 03:11:09,490][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,491][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,492][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,492][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,492][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,493][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,493][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,494][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,494][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,494][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,495][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,495][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,496][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,496][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,497][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,497][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,497][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,498][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,498][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,499][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,499][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,500][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,500][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 03:11:09,500][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 03:11:09,502][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 03:11:09,506][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 03:11:09,709][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 03:11:09,711][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 03:11:09,908][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 03:11:13,146][root][INFO] - 

[2024-10-22 03:11:13,146][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 03:11:13,146][root][INFO] - Data Preprocessing
[2024-10-22 03:11:13,146][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 03:11:13,146][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 03:11:13,146][root][INFO] - ㄴ data_remove                False

[2024-10-22 03:11:13,146][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 03:11:13,154][root][INFO] - vocab size              : 51200
[2024-10-22 03:11:13,154][root][INFO] - device                  : gpu
[2024-10-22 03:11:13,154][root][INFO] - random seed             : 2
[2024-10-22 03:11:13,155][root][INFO] - train data size         : 135040
[2024-10-22 03:11:13,155][root][INFO] - max epochs              : 5
[2024-10-22 03:11:13,155][root][INFO] - total steps             : 10550
[2024-10-22 03:11:13,155][root][INFO] - warmup steps            : 1055
[2024-10-22 03:11:13,155][root][INFO] - batch size              : 64
[2024-10-22 03:11:13,155][root][INFO] - accumulation steps      : 1
[2024-10-22 03:11:13,155][root][INFO] - optimizer               : adamwscale
[2024-10-22 03:11:13,155][root][INFO] - lr_scheduler            : cosine
[2024-10-22 03:11:13,155][root][INFO] - learning rate           : 0.01
[2024-10-22 03:11:13,155][root][INFO] - max length              : 256

[2024-10-22 03:11:13,155][root][INFO] - LoRA Configuration
[2024-10-22 03:11:13,155][root][INFO] - ㄴ r                    : 32
[2024-10-22 03:11:13,156][root][INFO] - ㄴ alpha                : 128
[2024-10-22 03:11:13,156][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 03:11:13,156][root][INFO] - KOMBO Configuration
[2024-10-22 03:11:13,156][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 03:11:13,156][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 03:11:13,156][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 03:11:13,156][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 03:11:13,156][root][INFO] - ㄴ do_combination       : True
[2024-10-22 03:11:13,156][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 03:11:13,156][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 03:11:13,157][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 03:11:13,157][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 03:11:13,157][root][INFO] - 

[2024-10-22 03:11:13,157][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-22 03:11:13,157][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 03:11:13,157][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 03:11:13,157][root][INFO] - * tb interval   : 10000

[2024-10-22 03:11:13,157][root][INFO] - 

[2024-10-22 03:11:13,157][root][INFO] - Start the Training !
[2024-10-22 03:11:13,160][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 03:18:33,604][root][INFO] - Step: 768/7680  |  Loss: 0.6371  |  Score: 62.25 [%]  |  Seq Length: 256.0
[2024-10-22 03:18:42,613][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 03:18:42,613][root][INFO] - Score: 68.94 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 03:18:51,624][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 03:18:51,624][root][INFO] - Score: 66.96 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 03:18:51,625][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 03:18:51,626][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:18:51,628][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:18:53,491][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:18:53,656][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:18:53,658][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:18:53,658][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:18:53,658][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:18:53,658][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:18:53,662][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:18:55,423][root][INFO] - 
[2/ 10 Epoch]
[2024-10-22 03:26:26,026][root][INFO] - Step: 1536/7680  |  Loss: 0.5264  |  Score: 73.57 [%]  |  Seq Length: 256.0
[2024-10-22 03:26:35,057][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 03:26:35,057][root][INFO] - Score: 71.70 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 03:26:44,104][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 03:26:44,104][root][INFO] - Score: 70.14 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 03:26:44,105][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 03:26:44,106][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:26:44,108][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:26:46,003][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:26:46,172][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:26:46,173][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:26:46,174][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:26:46,174][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:26:46,174][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:26:46,176][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:26:47,943][root][INFO] - 
[3/ 10 Epoch]
[2024-10-22 03:29:04,528][root][INFO] - Step: 2110/10550  |  Loss: 0.3658  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-22 03:29:58,323][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 03:29:58,324][root][INFO] - Score: 86.86 [%]  |  Evaluation Time: 53.79 [s]
[2024-10-22 03:32:56,954][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 03:32:56,954][root][INFO] - Score: 86.87 [%]  |  Evaluation Time: 178.63 [s]
[2024-10-22 03:32:56,956][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 03:32:56,957][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 03:32:56,964][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:32:57,866][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:32:57,979][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:32:57,979][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:32:57,979][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:32:57,979][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:32:57,980][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:32:57,981][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:32:58,734][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 03:34:17,419][root][INFO] - Step: 2304/7680  |  Loss: 0.4776  |  Score: 76.81 [%]  |  Seq Length: 256.0
[2024-10-22 03:34:26,435][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 03:34:26,435][root][INFO] - Score: 73.10 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 03:34:35,527][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 03:34:35,528][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-22 03:34:35,529][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 03:34:35,529][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:34:35,531][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:34:37,416][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:34:37,602][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:34:37,603][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:34:37,603][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:34:37,604][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:34:37,604][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:34:37,607][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:34:39,377][root][INFO] - 
[4/ 10 Epoch]
[2024-10-22 03:42:10,171][root][INFO] - Step: 3072/7680  |  Loss: 0.4320  |  Score: 79.42 [%]  |  Seq Length: 256.0
[2024-10-22 03:42:19,251][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 03:42:19,251][root][INFO] - Score: 74.18 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-22 03:42:28,334][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 03:42:28,334][root][INFO] - Score: 72.57 [%]  |  Evaluation Time: 9.08 [s]
[2024-10-22 03:42:28,335][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 03:42:28,335][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:42:28,338][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:42:30,213][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:42:30,410][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:42:30,411][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:42:30,411][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:42:30,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:42:30,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:42:30,414][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:42:32,174][root][INFO] - 
[5/ 10 Epoch]
[2024-10-22 03:50:02,754][root][INFO] - Step: 3840/7680  |  Loss: 0.3907  |  Score: 81.76 [%]  |  Seq Length: 256.0
[2024-10-22 03:50:11,764][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 03:50:11,764][root][INFO] - Score: 75.02 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 03:50:20,784][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 03:50:20,784][root][INFO] - Score: 73.64 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 03:50:20,785][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 03:50:20,785][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:50:20,788][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:50:22,674][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:50:22,839][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:50:22,841][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:50:22,841][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:50:22,841][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:50:22,842][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:50:22,845][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:50:24,620][root][INFO] - 
[6/ 10 Epoch]
[2024-10-22 03:50:53,600][root][INFO] - Step: 4220/10550  |  Loss: 0.2904  |  Score: 87.70 [%]  |  Seq Length: 256.0
[2024-10-22 03:51:46,749][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 03:51:46,750][root][INFO] - Score: 88.12 [%]  |  Evaluation Time: 53.15 [s]
[2024-10-22 03:54:42,482][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 03:54:42,482][root][INFO] - Score: 88.08 [%]  |  Evaluation Time: 175.73 [s]
[2024-10-22 03:54:42,484][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 03:54:42,484][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 03:54:42,488][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:54:44,267][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:54:44,553][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:54:44,554][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:54:44,554][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:54:44,555][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:54:44,555][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:54:44,558][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:54:46,207][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 03:57:56,253][root][INFO] - Step: 4608/7680  |  Loss: 0.3441  |  Score: 84.19 [%]  |  Seq Length: 256.0
[2024-10-22 03:58:05,289][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 03:58:05,289][root][INFO] - Score: 76.30 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 03:58:14,440][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 03:58:14,440][root][INFO] - Score: 73.62 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 03:58:14,441][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 03:58:14,442][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:58:14,444][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 03:58:16,330][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 03:58:16,514][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 03:58:16,515][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 03:58:16,515][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 03:58:16,515][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 03:58:16,516][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 03:58:16,518][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 03:58:18,314][root][INFO] - 
[7/ 10 Epoch]
[2024-10-22 03:59:27,731][root][INFO] - Step: 29466/73665  |  Loss: 0.6284  |  Score: 73.93 [%]  |  Seq Length: 256.0
[2024-10-22 03:59:38,356][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 03:59:38,356][root][INFO] - Score: 72.93 [%]  |  Evaluation Time: 10.62 [s]
[2024-10-22 03:59:59,203][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 03:59:59,203][root][INFO] - Score: 73.42 [%]  |  Evaluation Time: 20.84 [s]
[2024-10-22 03:59:59,205][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 03:59:59,205][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 03:59:59,208][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:00:00,940][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:00:01,074][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:00:01,075][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:00:01,075][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:00:01,075][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:00:01,075][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:00:01,076][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:00:02,702][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 04:04:52,565][root][INFO] - Step: 30000/73665  |  Loss: 0.5997  |  Score: 75.62 [%]  |  Seq Length: 256.0
[2024-10-22 04:05:49,668][root][INFO] - Step: 5376/7680  |  Loss: 0.2994  |  Score: 86.59 [%]  |  Seq Length: 256.0
[2024-10-22 04:05:58,705][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 04:05:58,705][root][INFO] - Score: 76.44 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 04:06:07,735][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 04:06:07,735][root][INFO] - Score: 74.28 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 04:06:07,736][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 04:06:07,736][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 04:06:07,739][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:06:09,637][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:06:09,804][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:06:09,805][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:06:09,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:06:09,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:06:09,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:06:09,808][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:06:11,568][root][INFO] - 
[8/ 10 Epoch]
[2024-10-22 04:12:41,379][root][INFO] - Step: 6330/10550  |  Loss: 0.2519  |  Score: 89.55 [%]  |  Seq Length: 256.0
[2024-10-22 04:13:34,875][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 04:13:34,876][root][INFO] - Score: 88.64 [%]  |  Evaluation Time: 53.49 [s]
[2024-10-22 04:13:42,662][root][INFO] - Step: 6144/7680  |  Loss: 0.2523  |  Score: 88.79 [%]  |  Seq Length: 256.0
[2024-10-22 04:13:51,689][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 04:13:51,689][root][INFO] - Score: 76.44 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 04:14:00,791][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 04:14:00,791][root][INFO] - Score: 74.61 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 04:14:00,792][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 04:14:00,793][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 04:14:00,796][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:14:02,686][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:14:02,855][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:14:02,856][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:14:02,857][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:14:02,857][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:14:02,857][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:14:02,860][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:14:04,625][root][INFO] - 
[9/ 10 Epoch]
[2024-10-22 04:16:30,527][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 04:16:30,527][root][INFO] - Score: 88.51 [%]  |  Evaluation Time: 175.65 [s]
[2024-10-22 04:16:30,528][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 04:16:30,529][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 04:16:30,532][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:16:32,255][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:16:32,535][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:16:32,536][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:16:32,537][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:16:32,537][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:16:32,537][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:16:32,540][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:16:34,194][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 04:21:37,622][root][INFO] - Step: 6912/7680  |  Loss: 0.2182  |  Score: 90.50 [%]  |  Seq Length: 256.0
[2024-10-22 04:21:46,724][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 04:21:46,725][root][INFO] - Score: 76.85 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 04:21:55,773][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 04:21:55,773][root][INFO] - Score: 74.10 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 04:21:55,775][root][INFO] - 
[10/ 10 Epoch]
[2024-10-22 04:29:27,107][root][INFO] - Step: 7680/7680  |  Loss: 0.1995  |  Score: 91.40 [%]  |  Seq Length: 256.0
[2024-10-22 04:29:36,150][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 04:29:36,150][root][INFO] - Score: 77.03 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 04:29:45,190][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 04:29:45,190][root][INFO] - Score: 74.49 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 04:29:45,191][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 04:29:45,191][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 04:29:45,194][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:29:47,081][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:29:47,250][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:29:47,252][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:29:47,252][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:29:47,252][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:29:47,252][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:29:47,255][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:29:49,014][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 04:29:49,015][root][INFO] - - Epoch: 10
[2024-10-22 04:29:49,015][root][INFO] - - DEV score: 77.03 [%]
[2024-10-22 04:29:49,015][root][INFO] - - TEST score: 74.49 [%]
[2024-10-22 04:29:49,017][root][INFO] - Fine-tuning is done!
[2024-10-22 04:29:49,017][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 04:29:49,017][root][INFO] - - BEST LR: 0.02
[2024-10-22 04:29:49,018][root][INFO] - - DEV score: 77.03 [%]
[2024-10-22 04:29:49,018][root][INFO] - - TEST score: 74.49 [%]
[2024-10-22 04:29:55,475][root][INFO] - 

[2024-10-22 04:29:55,475][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 04:29:55,475][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-22 04:29:55,475][root][INFO] - 

[2024-10-22 04:29:55,475][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 04:30:08,347][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,348][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,349][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,349][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,350][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,351][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,352][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,352][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,353][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,354][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,354][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,355][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,356][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,356][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,357][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,358][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,359][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,359][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,360][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,361][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,362][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,363][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,363][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 04:30:08,364][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 04:30:08,367][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 04:30:08,373][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 04:30:08,576][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 04:30:08,579][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 04:30:08,768][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 04:30:11,998][root][INFO] - 

[2024-10-22 04:30:11,999][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-22 04:30:11,999][root][INFO] - Data Preprocessing
[2024-10-22 04:30:11,999][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 04:30:11,999][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 04:30:11,999][root][INFO] - ㄴ data_remove                False

[2024-10-22 04:30:11,999][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 04:30:12,007][root][INFO] - vocab size              : 51200
[2024-10-22 04:30:12,007][root][INFO] - device                  : gpu
[2024-10-22 04:30:12,007][root][INFO] - random seed             : 2
[2024-10-22 04:30:12,007][root][INFO] - train data size         : 49152
[2024-10-22 04:30:12,007][root][INFO] - max epochs              : 10
[2024-10-22 04:30:12,007][root][INFO] - total steps             : 7680
[2024-10-22 04:30:12,007][root][INFO] - warmup steps            : 768
[2024-10-22 04:30:12,008][root][INFO] - batch size              : 64
[2024-10-22 04:30:12,008][root][INFO] - accumulation steps      : 1
[2024-10-22 04:30:12,008][root][INFO] - optimizer               : adamwscale
[2024-10-22 04:30:12,008][root][INFO] - lr_scheduler            : cosine
[2024-10-22 04:30:12,008][root][INFO] - learning rate           : 0.01
[2024-10-22 04:30:12,008][root][INFO] - max length              : 256

[2024-10-22 04:30:12,008][root][INFO] - LoRA Configuration
[2024-10-22 04:30:12,008][root][INFO] - ㄴ r                    : 32
[2024-10-22 04:30:12,008][root][INFO] - ㄴ alpha                : 128
[2024-10-22 04:30:12,008][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 04:30:12,008][root][INFO] - KOMBO Configuration
[2024-10-22 04:30:12,009][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 04:30:12,009][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 04:30:12,009][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 04:30:12,009][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 04:30:12,009][root][INFO] - ㄴ do_combination       : True
[2024-10-22 04:30:12,009][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 04:30:12,009][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 04:30:12,009][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 04:30:12,009][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 04:30:12,010][root][INFO] - 

[2024-10-22 04:30:12,010][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-22 04:30:12,010][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 04:30:12,010][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 04:30:12,010][root][INFO] - * tb interval   : 10000

[2024-10-22 04:30:12,010][root][INFO] - 

[2024-10-22 04:30:12,010][root][INFO] - Start the Training !
[2024-10-22 04:30:12,013][root][INFO] - 
[1/ 10 Epoch]
[2024-10-22 04:34:25,377][root][INFO] - Step: 8440/10550  |  Loss: 0.2166  |  Score: 91.12 [%]  |  Seq Length: 256.0
[2024-10-22 04:35:18,877][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 04:35:18,877][root][INFO] - Score: 88.95 [%]  |  Evaluation Time: 53.50 [s]
[2024-10-22 04:37:44,031][root][INFO] - Step: 768/7680  |  Loss: 0.6379  |  Score: 62.70 [%]  |  Seq Length: 256.0
[2024-10-22 04:37:53,049][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 04:37:53,049][root][INFO] - Score: 68.12 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 04:38:02,057][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 04:38:02,057][root][INFO] - Score: 66.59 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 04:38:02,058][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 04:38:02,058][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 04:38:02,061][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:38:02,953][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:38:03,071][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:38:03,072][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:38:03,072][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:38:03,072][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:38:03,072][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:38:03,073][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:38:03,833][root][INFO] - 
[2/ 10 Epoch]
[2024-10-22 04:38:15,846][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 04:38:15,846][root][INFO] - Score: 88.75 [%]  |  Evaluation Time: 176.97 [s]
[2024-10-22 04:38:15,847][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 04:38:15,848][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 04:38:15,851][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:38:17,575][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:38:17,870][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:38:17,872][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:38:17,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:38:17,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:38:17,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:38:17,875][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:38:19,525][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 04:45:35,612][root][INFO] - Step: 1536/7680  |  Loss: 0.5181  |  Score: 74.33 [%]  |  Seq Length: 256.0
[2024-10-22 04:45:44,618][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 04:45:44,619][root][INFO] - Score: 71.87 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 04:45:53,648][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 04:45:53,648][root][INFO] - Score: 68.11 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 04:45:53,649][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 04:45:53,649][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 04:45:53,652][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:45:55,356][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:45:55,614][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:45:55,615][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:45:55,615][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:45:55,616][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:45:55,616][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:45:55,619][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:45:57,205][root][INFO] - 
[3/ 10 Epoch]
[2024-10-22 04:51:34,052][root][INFO] - Step: 10000/10550  |  Loss: 0.1907  |  Score: 92.33 [%]  |  Seq Length: 256.0
[2024-10-22 04:53:27,591][root][INFO] - Step: 2304/7680  |  Loss: 0.4558  |  Score: 78.08 [%]  |  Seq Length: 256.0
[2024-10-22 04:53:36,567][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 04:53:36,568][root][INFO] - Score: 72.02 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-22 04:53:45,576][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 04:53:45,576][root][INFO] - Score: 69.99 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 04:53:45,577][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 04:53:45,578][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 04:53:45,580][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 04:53:47,287][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 04:53:47,546][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 04:53:47,547][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 04:53:47,548][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 04:53:47,548][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 04:53:47,548][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 04:53:47,551][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 04:53:49,146][root][INFO] - 
[4/ 10 Epoch]
[2024-10-22 04:56:13,586][root][INFO] - Step: 10550/10550  |  Loss: 0.1915  |  Score: 92.35 [%]  |  Seq Length: 256.0
[2024-10-22 04:57:07,055][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 04:57:07,055][root][INFO] - Score: 88.96 [%]  |  Evaluation Time: 53.47 [s]
[2024-10-22 05:00:03,307][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 05:00:03,307][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 176.25 [s]
[2024-10-22 05:00:03,309][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 05:00:03,309][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:00:03,312][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:00:05,057][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:00:05,341][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:00:05,343][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:00:05,344][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:00:05,344][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:00:05,344][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:00:05,347][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:00:06,964][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 05:00:06,964][root][INFO] - - Epoch: 5
[2024-10-22 05:00:06,964][root][INFO] - - DEV score: 88.96 [%]
[2024-10-22 05:00:06,965][root][INFO] - - TEST score: 88.80 [%]
[2024-10-22 05:00:06,967][root][INFO] - Fine-tuning is done!
[2024-10-22 05:00:28,378][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,379][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,380][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,380][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,381][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,381][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,382][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,382][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,383][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,383][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,384][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,385][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,385][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,386][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,386][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,386][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,387][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,387][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,388][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,388][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,389][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,390][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,390][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 05:00:28,391][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 05:00:28,392][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 05:00:28,596][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 05:00:28,598][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 05:00:28,599][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 05:00:28,813][root][INFO] - 

[2024-10-22 05:00:28,813][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 05:00:28,813][root][INFO] - Data Preprocessing
[2024-10-22 05:00:28,813][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 05:00:28,813][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 05:00:28,813][root][INFO] - ㄴ data_remove                False

[2024-10-22 05:00:28,813][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 05:00:28,823][root][INFO] - vocab size              : 51200
[2024-10-22 05:00:28,823][root][INFO] - device                  : gpu
[2024-10-22 05:00:28,823][root][INFO] - random seed             : 2
[2024-10-22 05:00:28,823][root][INFO] - train data size         : 135040
[2024-10-22 05:00:28,823][root][INFO] - max epochs              : 5
[2024-10-22 05:00:28,823][root][INFO] - total steps             : 10550
[2024-10-22 05:00:28,823][root][INFO] - warmup steps            : 1055
[2024-10-22 05:00:28,823][root][INFO] - batch size              : 64
[2024-10-22 05:00:28,823][root][INFO] - accumulation steps      : 1
[2024-10-22 05:00:28,823][root][INFO] - optimizer               : adamwscale
[2024-10-22 05:00:28,824][root][INFO] - lr_scheduler            : cosine
[2024-10-22 05:00:28,824][root][INFO] - learning rate           : 0.02
[2024-10-22 05:00:28,824][root][INFO] - max length              : 256

[2024-10-22 05:00:28,824][root][INFO] - LoRA Configuration
[2024-10-22 05:00:28,824][root][INFO] - ㄴ r                    : 32
[2024-10-22 05:00:28,824][root][INFO] - ㄴ alpha                : 128
[2024-10-22 05:00:28,824][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 05:00:28,824][root][INFO] - KOMBO Configuration
[2024-10-22 05:00:28,824][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 05:00:28,824][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 05:00:28,824][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 05:00:28,824][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 05:00:28,825][root][INFO] - ㄴ do_combination       : True
[2024-10-22 05:00:28,825][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 05:00:28,825][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 05:00:28,825][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 05:00:28,825][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 05:00:28,825][root][INFO] - 

[2024-10-22 05:00:28,825][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs
[2024-10-22 05:00:28,825][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 05:00:28,825][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 05:00:28,825][root][INFO] - * tb interval   : 10000

[2024-10-22 05:00:28,825][root][INFO] - 

[2024-10-22 05:00:28,826][root][INFO] - Start the Training !
[2024-10-22 05:00:28,828][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 05:01:18,989][root][INFO] - Step: 3072/7680  |  Loss: 0.4081  |  Score: 80.72 [%]  |  Seq Length: 256.0
[2024-10-22 05:01:27,952][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 05:01:27,952][root][INFO] - Score: 74.84 [%]  |  Evaluation Time: 8.96 [s]
[2024-10-22 05:01:36,952][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 05:01:36,952][root][INFO] - Score: 72.72 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 05:01:36,953][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 05:01:36,953][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:01:36,956][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:01:38,664][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:01:38,950][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:01:38,952][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:01:38,952][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:01:38,952][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:01:38,952][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:01:38,955][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:01:40,580][root][INFO] - 
[5/ 10 Epoch]
[2024-10-22 05:09:10,001][root][INFO] - Step: 3840/7680  |  Loss: 0.3673  |  Score: 82.99 [%]  |  Seq Length: 256.0
[2024-10-22 05:09:18,969][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 05:09:18,969][root][INFO] - Score: 73.94 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-22 05:09:27,942][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 05:09:27,942][root][INFO] - Score: 72.37 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-22 05:09:27,944][root][INFO] - 
[6/ 10 Epoch]
[2024-10-22 05:16:57,268][root][INFO] - Step: 4608/7680  |  Loss: 0.3305  |  Score: 84.84 [%]  |  Seq Length: 256.0
[2024-10-22 05:17:06,372][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 05:17:06,372][root][INFO] - Score: 74.23 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 05:17:15,371][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 05:17:15,371][root][INFO] - Score: 73.96 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 05:17:15,372][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 05:17:15,372][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:17:15,375][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:17:17,095][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:17:17,381][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:17:17,382][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:17:17,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:17:17,383][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:17:17,383][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:17:17,386][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:17:19,008][root][INFO] - 
[7/ 10 Epoch]
[2024-10-22 05:18:17,798][root][INFO] - Step: 2110/10550  |  Loss: 0.3669  |  Score: 83.77 [%]  |  Seq Length: 256.0
[2024-10-22 05:19:10,982][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 05:19:10,982][root][INFO] - Score: 86.54 [%]  |  Evaluation Time: 53.18 [s]
[2024-10-22 05:22:07,640][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 05:22:07,641][root][INFO] - Score: 86.49 [%]  |  Evaluation Time: 176.66 [s]
[2024-10-22 05:22:07,642][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 05:22:07,642][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:22:07,645][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:22:09,403][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:22:09,691][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:22:09,693][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:22:09,694][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:22:09,694][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:22:09,694][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:22:09,698][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:22:11,380][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 05:24:49,304][root][INFO] - Step: 5376/7680  |  Loss: 0.3001  |  Score: 86.54 [%]  |  Seq Length: 256.0
[2024-10-22 05:24:58,301][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 05:24:58,302][root][INFO] - Score: 74.75 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-22 05:25:07,356][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 05:25:07,356][root][INFO] - Score: 73.07 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 05:25:07,358][root][INFO] - 
[8/ 10 Epoch]
[2024-10-22 05:32:38,200][root][INFO] - Step: 6144/7680  |  Loss: 0.2663  |  Score: 88.06 [%]  |  Seq Length: 256.0
[2024-10-22 05:32:47,194][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 05:32:47,194][root][INFO] - Score: 75.82 [%]  |  Evaluation Time: 8.99 [s]
[2024-10-22 05:32:56,195][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 05:32:56,195][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 05:32:56,196][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 05:32:56,197][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:32:56,199][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:32:57,917][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:32:58,206][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:32:58,207][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:32:58,207][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:32:58,208][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:32:58,208][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:32:58,211][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:32:59,863][root][INFO] - 
[9/ 10 Epoch]
[2024-10-22 05:34:41,240][root][INFO] - Step: 40000/73665  |  Loss: 0.5970  |  Score: 75.40 [%]  |  Seq Length: 256.0
[2024-10-22 05:40:00,937][root][INFO] - Step: 4220/10550  |  Loss: 0.3142  |  Score: 86.53 [%]  |  Seq Length: 256.0
[2024-10-22 05:40:29,965][root][INFO] - Step: 6912/7680  |  Loss: 0.2489  |  Score: 89.12 [%]  |  Seq Length: 256.0
[2024-10-22 05:40:39,105][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 05:40:39,105][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-22 05:40:48,232][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 05:40:48,233][root][INFO] - Score: 73.21 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 05:40:48,234][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-22 05:40:48,234][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:40:48,237][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:40:49,955][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:40:50,240][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:40:50,241][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:40:50,242][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:40:50,242][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:40:50,242][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:40:50,245][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:40:51,880][root][INFO] - 
[10/ 10 Epoch]
[2024-10-22 05:40:54,612][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 05:40:54,612][root][INFO] - Score: 87.40 [%]  |  Evaluation Time: 53.67 [s]
[2024-10-22 05:43:51,009][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 05:43:51,009][root][INFO] - Score: 87.24 [%]  |  Evaluation Time: 176.39 [s]
[2024-10-22 05:43:51,010][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 05:43:51,011][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:43:51,014][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:43:52,741][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:43:53,029][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:43:53,031][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:43:53,034][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:43:53,035][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:43:53,035][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:43:53,039][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:43:54,755][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 05:48:21,939][root][INFO] - Step: 7680/7680  |  Loss: 0.2392  |  Score: 89.52 [%]  |  Seq Length: 256.0
[2024-10-22 05:48:30,939][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 05:48:30,940][root][INFO] - Score: 76.07 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 05:48:39,967][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 05:48:39,967][root][INFO] - Score: 72.90 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 05:48:39,968][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 05:48:39,968][root][INFO] - - Epoch: 9
[2024-10-22 05:48:39,968][root][INFO] - - DEV score: 75.85 [%]
[2024-10-22 05:48:39,968][root][INFO] - - TEST score: 73.21 [%]
[2024-10-22 05:48:39,969][root][INFO] - Fine-tuning is done!
[2024-10-22 05:48:51,385][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,386][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,386][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,387][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,387][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,388][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,389][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,389][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,390][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,391][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,391][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,392][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,392][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,393][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,393][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,394][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,394][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,395][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,395][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,396][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,396][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,397][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,397][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 05:48:51,398][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 05:48:51,400][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 05:48:51,596][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 05:48:51,598][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 05:48:51,600][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 05:48:51,765][root][INFO] - 

[2024-10-22 05:48:51,765][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-22 05:48:51,765][root][INFO] - Data Preprocessing
[2024-10-22 05:48:51,765][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 05:48:51,765][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 05:48:51,765][root][INFO] - ㄴ data_remove                False

[2024-10-22 05:48:51,765][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 05:48:51,773][root][INFO] - vocab size              : 51200
[2024-10-22 05:48:51,774][root][INFO] - device                  : gpu
[2024-10-22 05:48:51,774][root][INFO] - random seed             : 2
[2024-10-22 05:48:51,774][root][INFO] - train data size         : 49152
[2024-10-22 05:48:51,774][root][INFO] - max epochs              : 10
[2024-10-22 05:48:51,774][root][INFO] - total steps             : 7680
[2024-10-22 05:48:51,774][root][INFO] - warmup steps            : 768
[2024-10-22 05:48:51,774][root][INFO] - batch size              : 64
[2024-10-22 05:48:51,774][root][INFO] - accumulation steps      : 1
[2024-10-22 05:48:51,774][root][INFO] - optimizer               : adamwscale
[2024-10-22 05:48:51,774][root][INFO] - lr_scheduler            : cosine
[2024-10-22 05:48:51,774][root][INFO] - learning rate           : 0.02
[2024-10-22 05:48:51,775][root][INFO] - max length              : 256

[2024-10-22 05:48:51,775][root][INFO] - LoRA Configuration
[2024-10-22 05:48:51,775][root][INFO] - ㄴ r                    : 32
[2024-10-22 05:48:51,775][root][INFO] - ㄴ alpha                : 128
[2024-10-22 05:48:51,775][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 05:48:51,775][root][INFO] - KOMBO Configuration
[2024-10-22 05:48:51,775][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 05:48:51,775][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 05:48:51,775][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 05:48:51,775][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 05:48:51,775][root][INFO] - ㄴ do_combination       : True
[2024-10-22 05:48:51,776][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 05:48:51,776][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 05:48:51,776][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 05:48:51,776][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 05:48:51,776][root][INFO] - 

[2024-10-22 05:48:51,776][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs
[2024-10-22 05:48:51,776][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 05:48:51,776][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 05:48:51,776][root][INFO] - * tb interval   : 10000

[2024-10-22 05:48:51,776][root][INFO] - 

[2024-10-22 05:48:51,776][root][INFO] - Start the Training !
[2024-10-22 05:48:51,779][root][INFO] - 
[1/ 10 Epoch]
[2024-10-22 05:56:21,330][root][INFO] - Step: 768/7680  |  Loss: 0.6258  |  Score: 64.09 [%]  |  Seq Length: 256.0
[2024-10-22 05:56:30,335][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 05:56:30,335][root][INFO] - Score: 68.22 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 05:56:39,433][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 05:56:39,433][root][INFO] - Score: 66.73 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 05:56:39,434][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 05:56:39,434][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 05:56:39,437][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 05:56:41,143][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 05:56:41,439][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 05:56:41,440][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 05:56:41,440][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 05:56:41,441][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 05:56:41,441][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 05:56:41,444][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 05:56:43,045][root][INFO] - 
[2/ 10 Epoch]
[2024-10-22 06:01:45,797][root][INFO] - Step: 6330/10550  |  Loss: 0.2813  |  Score: 88.27 [%]  |  Seq Length: 256.0
[2024-10-22 06:02:39,769][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 06:02:39,769][root][INFO] - Score: 88.12 [%]  |  Evaluation Time: 53.97 [s]
[2024-10-22 06:04:13,866][root][INFO] - Step: 1536/7680  |  Loss: 0.5182  |  Score: 74.14 [%]  |  Seq Length: 256.0
[2024-10-22 06:04:22,926][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 06:04:22,926][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 9.06 [s]
[2024-10-22 06:04:31,999][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 06:04:31,999][root][INFO] - Score: 67.75 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 06:04:32,000][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 06:04:32,000][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:04:32,003][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:04:33,709][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:04:33,992][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:04:33,993][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:04:33,993][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:04:33,993][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:04:33,994][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:04:33,997][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:04:35,614][root][INFO] - 
[3/ 10 Epoch]
[2024-10-22 06:05:35,851][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 06:05:35,851][root][INFO] - Score: 88.10 [%]  |  Evaluation Time: 176.08 [s]
[2024-10-22 06:05:35,852][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 06:05:35,853][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:05:35,855][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:05:37,557][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:05:37,846][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:05:37,847][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:05:37,847][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:05:37,848][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:05:37,848][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:05:37,851][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:05:39,584][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 06:12:05,833][root][INFO] - Step: 2304/7680  |  Loss: 0.4702  |  Score: 77.39 [%]  |  Seq Length: 256.0
[2024-10-22 06:12:14,996][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 06:12:14,996][root][INFO] - Score: 72.61 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-22 06:12:19,105][root][INFO] - Step: 44199/73665  |  Loss: 0.5820  |  Score: 76.23 [%]  |  Seq Length: 256.0
[2024-10-22 06:12:24,067][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 06:12:24,068][root][INFO] - Score: 69.81 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 06:12:24,069][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 06:12:24,069][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:12:24,072][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:12:25,752][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:12:26,049][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:12:26,050][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:12:26,051][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:12:26,051][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:12:26,051][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:12:26,054][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:12:27,654][root][INFO] - 
[4/ 10 Epoch]
[2024-10-22 06:12:29,715][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 06:12:29,715][root][INFO] - Score: 74.65 [%]  |  Evaluation Time: 10.61 [s]
[2024-10-22 06:12:50,154][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 06:12:50,154][root][INFO] - Score: 74.29 [%]  |  Evaluation Time: 20.44 [s]
[2024-10-22 06:12:50,156][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 06:12:50,156][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 06:12:50,161][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:12:51,882][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:12:52,081][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:12:52,082][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:12:52,083][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:12:52,083][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:12:52,083][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:12:52,086][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:12:53,710][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 06:19:58,693][root][INFO] - Step: 3072/7680  |  Loss: 0.4284  |  Score: 79.54 [%]  |  Seq Length: 256.0
[2024-10-22 06:20:07,807][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 06:20:07,807][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-22 06:20:16,829][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 06:20:16,829][root][INFO] - Score: 71.30 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 06:20:16,829][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 06:20:16,830][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:20:16,833][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:20:18,539][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:20:18,822][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:20:18,823][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:20:18,824][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:20:18,824][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:20:18,825][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:20:18,828][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:20:20,474][root][INFO] - 
[5/ 10 Epoch]
[2024-10-22 06:23:31,675][root][INFO] - Step: 8440/10550  |  Loss: 0.2368  |  Score: 90.25 [%]  |  Seq Length: 256.0
[2024-10-22 06:24:25,758][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 06:24:25,758][root][INFO] - Score: 88.92 [%]  |  Evaluation Time: 54.08 [s]
[2024-10-22 06:27:21,959][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 06:27:21,960][root][INFO] - Score: 88.84 [%]  |  Evaluation Time: 176.20 [s]
[2024-10-22 06:27:21,961][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 06:27:21,961][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:27:21,964][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:27:23,700][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:27:23,987][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:27:23,988][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:27:23,989][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:27:23,989][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:27:23,990][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:27:23,993][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:27:25,770][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 06:27:48,419][root][INFO] - Step: 3840/7680  |  Loss: 0.3868  |  Score: 81.91 [%]  |  Seq Length: 256.0
[2024-10-22 06:27:57,525][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 06:27:57,525][root][INFO] - Score: 75.28 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 06:28:06,672][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 06:28:06,672][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-22 06:28:06,673][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 06:28:06,673][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:28:06,676][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:28:08,406][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:28:08,687][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:28:08,688][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:28:08,688][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:28:08,689][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:28:08,689][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:28:08,692][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:28:10,329][root][INFO] - 
[6/ 10 Epoch]
[2024-10-22 06:35:43,528][root][INFO] - Step: 4608/7680  |  Loss: 0.3395  |  Score: 84.43 [%]  |  Seq Length: 256.0
[2024-10-22 06:35:52,640][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 06:35:52,640][root][INFO] - Score: 75.38 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-22 06:36:01,745][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 06:36:01,745][root][INFO] - Score: 73.27 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 06:36:01,747][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 06:36:01,747][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:36:01,750][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:36:03,471][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:36:03,752][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:36:03,753][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:36:03,754][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:36:03,754][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:36:03,754][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:36:03,758][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:36:05,401][root][INFO] - 
[7/ 10 Epoch]
[2024-10-22 06:40:37,926][root][INFO] - Step: 10000/10550  |  Loss: 0.1957  |  Score: 92.16 [%]  |  Seq Length: 256.0
[2024-10-22 06:43:37,367][root][INFO] - Step: 5376/7680  |  Loss: 0.2917  |  Score: 86.83 [%]  |  Seq Length: 256.0
[2024-10-22 06:43:46,512][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 06:43:46,513][root][INFO] - Score: 76.06 [%]  |  Evaluation Time: 9.14 [s]
[2024-10-22 06:43:55,667][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 06:43:55,668][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 06:43:55,669][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 06:43:55,669][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:43:55,672][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:43:57,384][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:43:57,681][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:43:57,682][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:43:57,682][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:43:57,683][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:43:57,683][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:43:57,686][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:43:59,323][root][INFO] - 
[8/ 10 Epoch]
[2024-10-22 06:45:17,363][root][INFO] - Step: 10550/10550  |  Loss: 0.1950  |  Score: 92.01 [%]  |  Seq Length: 256.0
[2024-10-22 06:46:10,823][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 06:46:10,824][root][INFO] - Score: 88.83 [%]  |  Evaluation Time: 53.46 [s]
[2024-10-22 06:49:07,623][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 06:49:07,623][root][INFO] - Score: 88.87 [%]  |  Evaluation Time: 176.80 [s]
[2024-10-22 06:49:07,624][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 06:49:07,624][root][INFO] - - Epoch: 4
[2024-10-22 06:49:07,625][root][INFO] - - DEV score: 88.92 [%]
[2024-10-22 06:49:07,625][root][INFO] - - TEST score: 88.84 [%]
[2024-10-22 06:49:07,626][root][INFO] - Fine-tuning is done!
[2024-10-22 06:49:07,626][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 06:49:07,626][root][INFO] - - BEST LR: 0.02
[2024-10-22 06:49:07,626][root][INFO] - - DEV score: 88.92 [%]
[2024-10-22 06:49:07,626][root][INFO] - - TEST score: 88.84 [%]
[2024-10-22 06:49:13,569][root][INFO] - 

[2024-10-22 06:49:13,569][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 06:49:13,569][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-22 06:49:13,570][root][INFO] - 

[2024-10-22 06:49:13,570][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 06:49:35,635][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,636][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,637][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,638][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,639][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,640][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,641][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,642][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,643][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,643][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,644][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,645][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,645][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,646][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,647][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,647][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,648][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,649][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,650][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,650][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,651][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,652][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,652][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 06:49:35,653][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 06:49:35,656][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 06:49:35,662][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 06:49:35,871][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 06:49:35,873][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 06:49:36,070][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 06:49:39,240][root][INFO] - 

[2024-10-22 06:49:39,241][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 06:49:39,241][root][INFO] - Data Preprocessing
[2024-10-22 06:49:39,241][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 06:49:39,241][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 06:49:39,241][root][INFO] - ㄴ data_remove                False

[2024-10-22 06:49:39,241][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 06:49:39,249][root][INFO] - vocab size              : 51200
[2024-10-22 06:49:39,249][root][INFO] - device                  : gpu
[2024-10-22 06:49:39,249][root][INFO] - random seed             : 3
[2024-10-22 06:49:39,249][root][INFO] - train data size         : 135040
[2024-10-22 06:49:39,249][root][INFO] - max epochs              : 5
[2024-10-22 06:49:39,249][root][INFO] - total steps             : 10550
[2024-10-22 06:49:39,249][root][INFO] - warmup steps            : 1055
[2024-10-22 06:49:39,249][root][INFO] - batch size              : 64
[2024-10-22 06:49:39,249][root][INFO] - accumulation steps      : 1
[2024-10-22 06:49:39,249][root][INFO] - optimizer               : adamwscale
[2024-10-22 06:49:39,249][root][INFO] - lr_scheduler            : cosine
[2024-10-22 06:49:39,250][root][INFO] - learning rate           : 0.01
[2024-10-22 06:49:39,250][root][INFO] - max length              : 256

[2024-10-22 06:49:39,250][root][INFO] - LoRA Configuration
[2024-10-22 06:49:39,250][root][INFO] - ㄴ r                    : 32
[2024-10-22 06:49:39,250][root][INFO] - ㄴ alpha                : 128
[2024-10-22 06:49:39,250][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 06:49:39,250][root][INFO] - KOMBO Configuration
[2024-10-22 06:49:39,250][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 06:49:39,250][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 06:49:39,250][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 06:49:39,250][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 06:49:39,251][root][INFO] - ㄴ do_combination       : True
[2024-10-22 06:49:39,251][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 06:49:39,251][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 06:49:39,251][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 06:49:39,251][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 06:49:39,251][root][INFO] - 

[2024-10-22 06:49:39,251][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-22 06:49:39,251][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 06:49:39,251][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb
[2024-10-22 06:49:39,251][root][INFO] - * tb interval   : 10000

[2024-10-22 06:49:39,251][root][INFO] - 

[2024-10-22 06:49:39,251][root][INFO] - Start the Training !
[2024-10-22 06:49:39,254][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 06:51:32,134][root][INFO] - Step: 6144/7680  |  Loss: 0.2481  |  Score: 89.14 [%]  |  Seq Length: 256.0
[2024-10-22 06:51:41,157][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 06:51:41,157][root][INFO] - Score: 77.24 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 06:51:50,203][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 06:51:50,203][root][INFO] - Score: 73.17 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 06:51:50,204][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 06:51:50,205][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:51:50,208][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:51:51,937][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:51:52,220][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:51:52,221][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:51:52,221][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:51:52,222][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:51:52,222][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:51:52,225][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:51:53,833][root][INFO] - 
[9/ 10 Epoch]
[2024-10-22 06:59:24,292][root][INFO] - Step: 6912/7680  |  Loss: 0.2128  |  Score: 90.76 [%]  |  Seq Length: 256.0
[2024-10-22 06:59:33,315][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 06:59:33,315][root][INFO] - Score: 77.46 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 06:59:42,352][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 06:59:42,352][root][INFO] - Score: 74.14 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 06:59:42,354][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-22 06:59:42,354][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 06:59:42,357][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 06:59:44,039][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 06:59:44,334][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 06:59:44,335][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 06:59:44,336][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 06:59:44,336][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 06:59:44,336][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 06:59:44,340][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 06:59:45,965][root][INFO] - 
[10/ 10 Epoch]
[2024-10-22 07:04:58,403][root][INFO] - Step: 50000/73665  |  Loss: 0.5497  |  Score: 77.70 [%]  |  Seq Length: 256.0
[2024-10-22 07:07:16,664][root][INFO] - Step: 7680/7680  |  Loss: 0.1948  |  Score: 91.67 [%]  |  Seq Length: 256.0
[2024-10-22 07:07:25,701][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 07:07:25,701][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 07:07:34,547][root][INFO] - Step: 2110/10550  |  Loss: 0.3660  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-22 07:07:34,738][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 07:07:34,739][root][INFO] - Score: 73.74 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 07:07:34,740][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 07:07:34,740][root][INFO] - - Epoch: 9
[2024-10-22 07:07:34,740][root][INFO] - - DEV score: 77.46 [%]
[2024-10-22 07:07:34,740][root][INFO] - - TEST score: 74.14 [%]
[2024-10-22 07:07:34,741][root][INFO] - Fine-tuning is done!
[2024-10-22 07:07:34,741][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 07:07:34,741][root][INFO] - - BEST LR: 0.02
[2024-10-22 07:07:34,741][root][INFO] - - DEV score: 77.46 [%]
[2024-10-22 07:07:34,741][root][INFO] - - TEST score: 74.14 [%]
[2024-10-22 07:07:41,012][root][INFO] - 

[2024-10-22 07:07:41,012][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 07:07:41,013][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-22 07:07:41,013][root][INFO] - 

[2024-10-22 07:07:41,013][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'PAWS_X'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 10, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 07:07:54,248][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,249][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,249][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,249][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,250][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,250][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,251][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,251][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,252][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,252][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,253][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,253][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,254][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,254][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,255][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,255][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,255][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,256][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,256][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,257][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,258][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,259][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,259][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 07:07:54,260][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 07:07:54,261][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 07:07:54,265][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 07:07:54,460][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 07:07:54,462][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 07:07:54,648][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 07:07:57,729][root][INFO] - 

[2024-10-22 07:07:57,729][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-22 07:07:57,729][root][INFO] - Data Preprocessing
[2024-10-22 07:07:57,729][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 07:07:57,729][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 07:07:57,729][root][INFO] - ㄴ data_remove                False

[2024-10-22 07:07:57,729][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 07:07:57,737][root][INFO] - vocab size              : 51200
[2024-10-22 07:07:57,737][root][INFO] - device                  : gpu
[2024-10-22 07:07:57,737][root][INFO] - random seed             : 3
[2024-10-22 07:07:57,738][root][INFO] - train data size         : 49152
[2024-10-22 07:07:57,738][root][INFO] - max epochs              : 10
[2024-10-22 07:07:57,738][root][INFO] - total steps             : 7680
[2024-10-22 07:07:57,738][root][INFO] - warmup steps            : 768
[2024-10-22 07:07:57,738][root][INFO] - batch size              : 64
[2024-10-22 07:07:57,738][root][INFO] - accumulation steps      : 1
[2024-10-22 07:07:57,738][root][INFO] - optimizer               : adamwscale
[2024-10-22 07:07:57,738][root][INFO] - lr_scheduler            : cosine
[2024-10-22 07:07:57,738][root][INFO] - learning rate           : 0.01
[2024-10-22 07:07:57,738][root][INFO] - max length              : 256

[2024-10-22 07:07:57,738][root][INFO] - LoRA Configuration
[2024-10-22 07:07:57,738][root][INFO] - ㄴ r                    : 32
[2024-10-22 07:07:57,739][root][INFO] - ㄴ alpha                : 128
[2024-10-22 07:07:57,739][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 07:07:57,739][root][INFO] - KOMBO Configuration
[2024-10-22 07:07:57,739][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 07:07:57,739][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 07:07:57,739][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 07:07:57,739][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 07:07:57,739][root][INFO] - ㄴ do_combination       : True
[2024-10-22 07:07:57,739][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 07:07:57,740][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 07:07:57,740][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 07:07:57,740][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 07:07:57,740][root][INFO] - 

[2024-10-22 07:07:57,740][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-22 07:07:57,740][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 07:07:57,740][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb
[2024-10-22 07:07:57,740][root][INFO] - * tb interval   : 10000

[2024-10-22 07:07:57,740][root][INFO] - 

[2024-10-22 07:07:57,740][root][INFO] - Start the Training !
[2024-10-22 07:07:57,743][root][INFO] - 
[1/ 10 Epoch]
[2024-10-22 07:08:27,812][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 07:08:27,813][root][INFO] - Score: 86.70 [%]  |  Evaluation Time: 53.26 [s]
[2024-10-22 07:11:26,414][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 07:11:26,414][root][INFO] - Score: 86.85 [%]  |  Evaluation Time: 178.60 [s]
[2024-10-22 07:11:26,416][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 07:11:26,416][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:11:26,419][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:11:27,309][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:11:27,419][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:11:27,420][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:11:27,420][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:11:27,420][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:11:27,420][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:11:27,421][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:11:28,173][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 07:15:29,464][root][INFO] - Step: 768/7680  |  Loss: 0.6400  |  Score: 62.32 [%]  |  Seq Length: 256.0
[2024-10-22 07:15:38,463][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 07:15:38,463][root][INFO] - Score: 66.72 [%]  |  Evaluation Time: 9.00 [s]
[2024-10-22 07:15:47,483][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 07:15:47,483][root][INFO] - Score: 66.19 [%]  |  Evaluation Time: 9.02 [s]
[2024-10-22 07:15:47,484][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 07:15:47,484][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:15:47,487][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:15:48,395][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:15:48,506][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:15:48,506][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:15:48,506][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:15:48,506][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:15:48,507][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:15:48,508][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:15:49,257][root][INFO] - 
[2/ 10 Epoch]
[2024-10-22 07:23:19,158][root][INFO] - Step: 1536/7680  |  Loss: 0.5216  |  Score: 74.11 [%]  |  Seq Length: 256.0
[2024-10-22 07:23:28,143][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 07:23:28,144][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-22 07:23:37,151][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 07:23:37,151][root][INFO] - Score: 69.33 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 07:23:37,152][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 07:23:37,152][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:23:37,155][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:23:38,859][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:23:39,056][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:23:39,058][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:23:39,058][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:23:39,058][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:23:39,058][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:23:39,061][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:23:40,632][root][INFO] - 
[3/ 10 Epoch]
[2024-10-22 07:29:23,298][root][INFO] - Step: 4220/10550  |  Loss: 0.2916  |  Score: 87.61 [%]  |  Seq Length: 256.0
[2024-10-22 07:30:16,835][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 07:30:16,836][root][INFO] - Score: 87.72 [%]  |  Evaluation Time: 53.53 [s]
[2024-10-22 07:31:10,985][root][INFO] - Step: 2304/7680  |  Loss: 0.4589  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-22 07:31:20,000][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 07:31:20,000][root][INFO] - Score: 72.30 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 07:31:29,017][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 07:31:29,017][root][INFO] - Score: 70.81 [%]  |  Evaluation Time: 9.01 [s]
[2024-10-22 07:31:29,018][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 07:31:29,018][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:31:29,021][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:31:30,726][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:31:30,924][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:31:30,925][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:31:30,926][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:31:30,926][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:31:30,926][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:31:30,929][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:31:32,496][root][INFO] - 
[4/ 10 Epoch]
[2024-10-22 07:33:11,569][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 07:33:11,569][root][INFO] - Score: 87.77 [%]  |  Evaluation Time: 174.73 [s]
[2024-10-22 07:33:11,570][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 07:33:11,571][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:33:11,573][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:33:13,286][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:33:13,582][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:33:13,583][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:33:13,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:33:13,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:33:13,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:33:13,588][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:33:15,244][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 07:39:03,122][root][INFO] - Step: 3072/7680  |  Loss: 0.4090  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-22 07:39:12,166][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 07:39:12,166][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 07:39:21,234][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 07:39:21,234][root][INFO] - Score: 71.74 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 07:39:21,235][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 07:39:21,235][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:39:21,238][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:39:22,940][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:39:23,206][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:39:23,207][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:39:23,208][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:39:23,208][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:39:23,208][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:39:23,211][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:39:24,780][root][INFO] - 
[5/ 10 Epoch]
[2024-10-22 07:46:56,313][root][INFO] - Step: 3840/7680  |  Loss: 0.3733  |  Score: 82.73 [%]  |  Seq Length: 256.0
[2024-10-22 07:47:05,472][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 07:47:05,472][root][INFO] - Score: 75.41 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-22 07:47:14,576][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 07:47:14,577][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 07:47:14,578][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 07:47:14,578][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:47:14,581][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:47:16,296][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:47:16,559][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:47:16,560][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:47:16,561][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:47:16,561][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:47:16,561][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:47:16,564][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:47:18,145][root][INFO] - 
[6/ 10 Epoch]
[2024-10-22 07:51:09,567][root][INFO] - Step: 6330/10550  |  Loss: 0.2520  |  Score: 89.49 [%]  |  Seq Length: 256.0
[2024-10-22 07:52:03,291][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 07:52:03,291][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 53.72 [s]
[2024-10-22 07:54:49,653][root][INFO] - Step: 4608/7680  |  Loss: 0.3334  |  Score: 84.82 [%]  |  Seq Length: 256.0
[2024-10-22 07:54:58,810][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 07:54:58,811][root][INFO] - Score: 75.17 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-22 07:54:58,816][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 07:54:58,817][root][INFO] - Score: 88.53 [%]  |  Evaluation Time: 175.52 [s]
[2024-10-22 07:54:58,818][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 07:54:58,818][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:54:58,821][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:55:00,562][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:55:00,819][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:55:00,820][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:55:00,820][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:55:00,820][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:55:00,820][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:55:00,823][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:55:02,460][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 07:55:07,879][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 07:55:07,879][root][INFO] - Score: 72.38 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 07:55:07,880][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 07:55:07,881][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 07:55:07,884][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 07:55:09,595][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 07:55:09,881][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 07:55:09,883][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 07:55:09,883][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 07:55:09,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 07:55:09,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 07:55:09,887][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 07:55:11,507][root][INFO] - 
[7/ 10 Epoch]
[2024-10-22 08:02:43,804][root][INFO] - Step: 5376/7680  |  Loss: 0.2978  |  Score: 86.62 [%]  |  Seq Length: 256.0
[2024-10-22 08:02:52,933][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 08:02:52,933][root][INFO] - Score: 76.18 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-22 08:03:01,981][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 08:03:01,981][root][INFO] - Score: 72.19 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 08:03:01,983][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 08:03:01,983][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:03:01,986][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:03:03,681][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:03:03,966][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:03:03,967][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:03:03,968][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:03:03,969][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:03:03,969][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:03:03,972][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:03:05,595][root][INFO] - 
[8/ 10 Epoch]
[2024-10-22 08:10:35,820][root][INFO] - Step: 6144/7680  |  Loss: 0.2700  |  Score: 87.86 [%]  |  Seq Length: 256.0
[2024-10-22 08:10:44,797][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 08:10:44,797][root][INFO] - Score: 76.41 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-22 08:10:53,784][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 08:10:53,784][root][INFO] - Score: 72.11 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-22 08:10:53,785][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 08:10:53,785][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:10:53,788][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:10:55,488][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:10:55,770][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:10:55,771][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:10:55,772][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:10:55,772][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:10:55,773][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:10:55,775][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:10:57,402][root][INFO] - 
[9/ 10 Epoch]
[2024-10-22 08:12:55,521][root][INFO] - Step: 8440/10550  |  Loss: 0.2165  |  Score: 91.18 [%]  |  Seq Length: 256.0
[2024-10-22 08:13:48,842][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 08:13:48,843][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 53.32 [s]
[2024-10-22 08:16:46,080][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 08:16:46,080][root][INFO] - Score: 88.74 [%]  |  Evaluation Time: 177.24 [s]
[2024-10-22 08:16:46,082][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 08:16:46,082][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:16:46,085][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:16:47,821][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:16:48,102][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:16:48,103][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:16:48,104][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:16:48,104][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:16:48,104][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:16:48,107][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:16:49,712][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 08:18:27,522][root][INFO] - Step: 6912/7680  |  Loss: 0.2533  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-22 08:18:36,497][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 08:18:36,497][root][INFO] - Score: 76.75 [%]  |  Evaluation Time: 8.97 [s]
[2024-10-22 08:18:45,538][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 08:18:45,538][root][INFO] - Score: 72.51 [%]  |  Evaluation Time: 9.04 [s]
[2024-10-22 08:18:45,539][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-22 08:18:45,540][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:18:45,542][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:18:47,246][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:18:47,502][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:18:47,503][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:18:47,503][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:18:47,503][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:18:47,504][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:18:47,507][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:18:49,090][root][INFO] - 
[10/ 10 Epoch]
[2024-10-22 08:25:07,221][root][INFO] - Step: 58932/73665  |  Loss: 0.5404  |  Score: 78.17 [%]  |  Seq Length: 256.0
[2024-10-22 08:25:17,819][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 08:25:17,820][root][INFO] - Score: 75.28 [%]  |  Evaluation Time: 10.59 [s]
[2024-10-22 08:25:38,244][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 08:25:38,245][root][INFO] - Score: 76.15 [%]  |  Evaluation Time: 20.42 [s]
[2024-10-22 08:25:38,246][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 08:25:38,247][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 08:25:38,251][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:25:39,950][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:25:40,209][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:25:40,210][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:25:40,211][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:25:40,211][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:25:40,211][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:25:40,214][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:25:41,929][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 08:26:19,674][root][INFO] - Step: 7680/7680  |  Loss: 0.2400  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-22 08:26:28,662][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 08:26:28,662][root][INFO] - Score: 76.84 [%]  |  Evaluation Time: 8.98 [s]
[2024-10-22 08:26:37,715][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 08:26:37,715][root][INFO] - Score: 72.62 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 08:26:37,716][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 08:26:37,716][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:26:37,719][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:26:39,440][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:26:39,723][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:26:39,724][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:26:39,725][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:26:39,725][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:26:39,725][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:26:39,728][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:26:41,324][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 08:26:41,324][root][INFO] - - Epoch: 10
[2024-10-22 08:26:41,324][root][INFO] - - DEV score: 76.84 [%]
[2024-10-22 08:26:41,324][root][INFO] - - TEST score: 72.62 [%]
[2024-10-22 08:26:41,325][root][INFO] - Fine-tuning is done!
[2024-10-22 08:26:52,555][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,555][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,556][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,556][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,557][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,557][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,558][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,558][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,559][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,560][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,561][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,562][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,562][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,563][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,564][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,564][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,565][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,565][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,566][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,566][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,567][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,567][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,568][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 08:26:52,568][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 08:26:52,570][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 08:26:52,770][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 08:26:52,772][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 08:26:52,773][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 08:26:52,941][root][INFO] - 

[2024-10-22 08:26:52,941][root][INFO] - ========== Fine-tuning on PAWS_X ==========
[2024-10-22 08:26:52,941][root][INFO] - Data Preprocessing
[2024-10-22 08:26:52,941][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 08:26:52,941][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 08:26:52,941][root][INFO] - ㄴ data_remove                False

[2024-10-22 08:26:52,941][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 08:26:52,950][root][INFO] - vocab size              : 51200
[2024-10-22 08:26:52,950][root][INFO] - device                  : gpu
[2024-10-22 08:26:52,950][root][INFO] - random seed             : 3
[2024-10-22 08:26:52,950][root][INFO] - train data size         : 49152
[2024-10-22 08:26:52,950][root][INFO] - max epochs              : 10
[2024-10-22 08:26:52,950][root][INFO] - total steps             : 7680
[2024-10-22 08:26:52,951][root][INFO] - warmup steps            : 768
[2024-10-22 08:26:52,951][root][INFO] - batch size              : 64
[2024-10-22 08:26:52,951][root][INFO] - accumulation steps      : 1
[2024-10-22 08:26:52,951][root][INFO] - optimizer               : adamwscale
[2024-10-22 08:26:52,951][root][INFO] - lr_scheduler            : cosine
[2024-10-22 08:26:52,951][root][INFO] - learning rate           : 0.02
[2024-10-22 08:26:52,951][root][INFO] - max length              : 256

[2024-10-22 08:26:52,951][root][INFO] - LoRA Configuration
[2024-10-22 08:26:52,951][root][INFO] - ㄴ r                    : 32
[2024-10-22 08:26:52,951][root][INFO] - ㄴ alpha                : 128
[2024-10-22 08:26:52,951][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 08:26:52,951][root][INFO] - KOMBO Configuration
[2024-10-22 08:26:52,952][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 08:26:52,952][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 08:26:52,952][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 08:26:52,952][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 08:26:52,952][root][INFO] - ㄴ do_combination       : True
[2024-10-22 08:26:52,952][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 08:26:52,952][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 08:26:52,952][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 08:26:52,952][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 08:26:52,952][root][INFO] - 

[2024-10-22 08:26:52,953][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs
[2024-10-22 08:26:52,953][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 08:26:52,953][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/tb
[2024-10-22 08:26:52,953][root][INFO] - * tb interval   : 10000

[2024-10-22 08:26:52,953][root][INFO] - 

[2024-10-22 08:26:52,953][root][INFO] - Start the Training !
[2024-10-22 08:26:52,955][root][INFO] - 
[1/ 10 Epoch]
[2024-10-22 08:30:05,330][root][INFO] - Step: 10000/10550  |  Loss: 0.1937  |  Score: 92.20 [%]  |  Seq Length: 256.0
[2024-10-22 08:34:23,439][root][INFO] - Step: 768/7680  |  Loss: 0.6239  |  Score: 64.42 [%]  |  Seq Length: 256.0
[2024-10-22 08:34:32,594][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 08:34:32,594][root][INFO] - Score: 67.83 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 08:34:41,720][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 08:34:41,720][root][INFO] - Score: 66.58 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 08:34:41,721][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 08:34:41,721][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:34:41,724][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:34:43,432][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:34:43,730][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:34:43,731][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:34:43,732][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:34:43,732][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:34:43,732][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:34:43,736][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:34:44,975][root][INFO] - Step: 10550/10550  |  Loss: 0.1923  |  Score: 92.26 [%]  |  Seq Length: 256.0
[2024-10-22 08:34:45,353][root][INFO] - 
[2/ 10 Epoch]
[2024-10-22 08:35:17,808][root][INFO] - Step: 60000/73665  |  Loss: 0.5120  |  Score: 79.39 [%]  |  Seq Length: 256.0
[2024-10-22 08:35:38,622][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 08:35:38,623][root][INFO] - Score: 89.06 [%]  |  Evaluation Time: 53.64 [s]
[2024-10-22 08:38:35,487][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 08:38:35,487][root][INFO] - Score: 88.82 [%]  |  Evaluation Time: 176.86 [s]
[2024-10-22 08:38:35,488][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 08:38:35,489][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:38:35,491][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:38:37,213][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:38:37,499][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:38:37,501][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:38:37,502][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:38:37,502][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:38:37,502][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:38:37,506][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:38:39,119][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 08:38:39,119][root][INFO] - - Epoch: 5
[2024-10-22 08:38:39,119][root][INFO] - - DEV score: 89.06 [%]
[2024-10-22 08:38:39,119][root][INFO] - - TEST score: 88.82 [%]
[2024-10-22 08:38:39,121][root][INFO] - Fine-tuning is done!
[2024-10-22 08:38:59,641][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,641][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,642][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,643][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,643][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,644][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,644][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,645][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,645][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,646][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,647][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,647][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,648][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,648][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,649][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,649][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,650][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,650][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,651][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,651][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,652][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,653][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,653][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 08:38:59,654][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 08:38:59,656][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 08:38:59,858][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 08:38:59,861][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 08:38:59,862][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 08:39:00,045][root][INFO] - 

[2024-10-22 08:39:00,045][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 08:39:00,045][root][INFO] - Data Preprocessing
[2024-10-22 08:39:00,045][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 08:39:00,045][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 08:39:00,045][root][INFO] - ㄴ data_remove                False

[2024-10-22 08:39:00,045][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 08:39:00,054][root][INFO] - vocab size              : 51200
[2024-10-22 08:39:00,054][root][INFO] - device                  : gpu
[2024-10-22 08:39:00,054][root][INFO] - random seed             : 3
[2024-10-22 08:39:00,054][root][INFO] - train data size         : 135040
[2024-10-22 08:39:00,054][root][INFO] - max epochs              : 5
[2024-10-22 08:39:00,054][root][INFO] - total steps             : 10550
[2024-10-22 08:39:00,054][root][INFO] - warmup steps            : 1055
[2024-10-22 08:39:00,054][root][INFO] - batch size              : 64
[2024-10-22 08:39:00,055][root][INFO] - accumulation steps      : 1
[2024-10-22 08:39:00,055][root][INFO] - optimizer               : adamwscale
[2024-10-22 08:39:00,055][root][INFO] - lr_scheduler            : cosine
[2024-10-22 08:39:00,055][root][INFO] - learning rate           : 0.02
[2024-10-22 08:39:00,055][root][INFO] - max length              : 256

[2024-10-22 08:39:00,055][root][INFO] - LoRA Configuration
[2024-10-22 08:39:00,055][root][INFO] - ㄴ r                    : 32
[2024-10-22 08:39:00,055][root][INFO] - ㄴ alpha                : 128
[2024-10-22 08:39:00,055][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 08:39:00,055][root][INFO] - KOMBO Configuration
[2024-10-22 08:39:00,055][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 08:39:00,055][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 08:39:00,056][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 08:39:00,056][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 08:39:00,056][root][INFO] - ㄴ do_combination       : True
[2024-10-22 08:39:00,056][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 08:39:00,056][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 08:39:00,056][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 08:39:00,056][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 08:39:00,056][root][INFO] - 

[2024-10-22 08:39:00,056][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs
[2024-10-22 08:39:00,057][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 08:39:00,057][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/tb
[2024-10-22 08:39:00,057][root][INFO] - * tb interval   : 10000

[2024-10-22 08:39:00,057][root][INFO] - 

[2024-10-22 08:39:00,057][root][INFO] - Start the Training !
[2024-10-22 08:39:00,059][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 08:42:16,704][root][INFO] - Step: 1536/7680  |  Loss: 0.5208  |  Score: 73.98 [%]  |  Seq Length: 256.0
[2024-10-22 08:42:25,833][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 08:42:25,834][root][INFO] - Score: 70.14 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-22 08:42:34,888][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 08:42:34,888][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 9.05 [s]
[2024-10-22 08:42:34,889][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 08:42:34,889][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:42:34,892][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:42:36,601][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:42:36,885][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:42:36,886][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:42:36,887][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:42:36,887][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:42:36,888][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:42:36,890][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:42:38,528][root][INFO] - 
[3/ 10 Epoch]
[2024-10-22 08:50:09,133][root][INFO] - Step: 2304/7680  |  Loss: 0.4730  |  Score: 76.98 [%]  |  Seq Length: 256.0
[2024-10-22 08:50:18,254][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 08:50:18,254][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 08:50:27,409][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 08:50:27,410][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 08:50:27,411][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 08:50:27,411][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:50:27,414][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:50:29,119][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:50:29,411][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:50:29,412][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:50:29,413][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:50:29,413][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:50:29,413][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:50:29,416][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:50:31,101][root][INFO] - 
[4/ 10 Epoch]
[2024-10-22 08:56:51,953][root][INFO] - Step: 2110/10550  |  Loss: 0.3675  |  Score: 83.75 [%]  |  Seq Length: 256.0
[2024-10-22 08:57:45,075][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 08:57:45,075][root][INFO] - Score: 86.21 [%]  |  Evaluation Time: 53.12 [s]
[2024-10-22 08:58:02,670][root][INFO] - Step: 3072/7680  |  Loss: 0.4311  |  Score: 79.50 [%]  |  Seq Length: 256.0
[2024-10-22 08:58:11,790][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 08:58:11,791][root][INFO] - Score: 72.43 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 08:58:20,909][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 08:58:20,909][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 08:58:20,910][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 08:58:20,910][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 08:58:20,913][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 08:58:22,626][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 08:58:22,907][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 08:58:22,908][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 08:58:22,909][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 08:58:22,909][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 08:58:22,909][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 08:58:22,912][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 08:58:24,526][root][INFO] - 
[5/ 10 Epoch]
[2024-10-22 09:00:41,587][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 09:00:41,587][root][INFO] - Score: 86.35 [%]  |  Evaluation Time: 176.51 [s]
[2024-10-22 09:00:41,589][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 09:00:41,589][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:00:41,593][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:00:43,345][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:00:43,631][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:00:43,632][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:00:43,632][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:00:43,633][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:00:43,633][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:00:43,636][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:00:45,245][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 09:05:57,302][root][INFO] - Step: 3840/7680  |  Loss: 0.3907  |  Score: 81.73 [%]  |  Seq Length: 256.0
[2024-10-22 09:06:06,409][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 09:06:06,409][root][INFO] - Score: 76.50 [%]  |  Evaluation Time: 9.10 [s]
[2024-10-22 09:06:15,532][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 09:06:15,533][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 9.12 [s]
[2024-10-22 09:06:15,534][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 09:06:15,534][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:06:15,537][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:06:17,278][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:06:17,522][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:06:17,524][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:06:17,524][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:06:17,524][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:06:17,525][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:06:17,528][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:06:19,172][root][INFO] - 
[6/ 10 Epoch]
[2024-10-22 09:13:51,760][root][INFO] - Step: 4608/7680  |  Loss: 0.3439  |  Score: 84.20 [%]  |  Seq Length: 256.0
[2024-10-22 09:14:00,985][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 09:14:00,986][root][INFO] - Score: 76.34 [%]  |  Evaluation Time: 9.22 [s]
[2024-10-22 09:14:10,145][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 09:14:10,146][root][INFO] - Score: 72.90 [%]  |  Evaluation Time: 9.16 [s]
[2024-10-22 09:14:10,147][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 09:14:10,147][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:14:10,150][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:14:11,952][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:14:12,246][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:14:12,248][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:14:12,248][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:14:12,248][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:14:12,249][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:14:12,253][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:14:13,906][root][INFO] - 
[7/ 10 Epoch]
[2024-10-22 09:18:37,945][root][INFO] - Step: 4220/10550  |  Loss: 0.3118  |  Score: 86.60 [%]  |  Seq Length: 256.0
[2024-10-22 09:19:31,373][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 09:19:31,373][root][INFO] - Score: 86.65 [%]  |  Evaluation Time: 53.42 [s]
[2024-10-22 09:21:46,465][root][INFO] - Step: 5376/7680  |  Loss: 0.2979  |  Score: 86.56 [%]  |  Seq Length: 256.0
[2024-10-22 09:21:55,499][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 09:21:55,499][root][INFO] - Score: 76.04 [%]  |  Evaluation Time: 9.03 [s]
[2024-10-22 09:22:04,569][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 09:22:04,570][root][INFO] - Score: 73.37 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 09:22:04,571][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 09:22:04,571][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:22:04,574][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:22:06,283][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:22:06,582][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:22:06,583][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:22:06,583][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:22:06,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:22:06,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:22:06,587][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:22:08,216][root][INFO] - 
[8/ 10 Epoch]
[2024-10-22 09:22:30,020][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 09:22:30,020][root][INFO] - Score: 86.86 [%]  |  Evaluation Time: 178.64 [s]
[2024-10-22 09:22:30,021][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 09:22:30,022][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:22:30,025][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:22:31,741][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:22:32,024][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:22:32,025][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:22:32,026][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:22:32,026][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:22:32,026][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:22:32,029][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:22:33,677][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 09:29:39,513][root][INFO] - Step: 6144/7680  |  Loss: 0.2506  |  Score: 88.89 [%]  |  Seq Length: 256.0
[2024-10-22 09:29:48,627][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 09:29:48,628][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 9.11 [s]
[2024-10-22 09:29:57,718][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 09:29:57,719][root][INFO] - Score: 74.18 [%]  |  Evaluation Time: 9.09 [s]
[2024-10-22 09:29:57,720][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 09:29:57,720][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:29:57,723][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:29:59,434][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:29:59,721][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:29:59,722][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:29:59,722][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:29:59,722][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:29:59,723][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:29:59,726][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/PAWS_X/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:30:01,393][root][INFO] - 
[9/ 10 Epoch]
[2024-10-22 09:37:32,558][root][INFO] - Step: 6912/7680  |  Loss: 0.2193  |  Score: 90.61 [%]  |  Seq Length: 256.0
[2024-10-22 09:37:41,631][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 09:37:41,631][root][INFO] - Score: 77.25 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 09:37:50,707][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 09:37:50,707][root][INFO] - Score: 74.83 [%]  |  Evaluation Time: 9.07 [s]
[2024-10-22 09:37:50,709][root][INFO] - 
[10/ 10 Epoch]
[2024-10-22 09:40:25,708][root][INFO] - Step: 6330/10550  |  Loss: 0.2815  |  Score: 88.09 [%]  |  Seq Length: 256.0
[2024-10-22 09:41:18,909][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 09:41:18,909][root][INFO] - Score: 87.99 [%]  |  Evaluation Time: 53.20 [s]
[2024-10-22 09:44:16,972][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 09:44:16,973][root][INFO] - Score: 88.23 [%]  |  Evaluation Time: 178.06 [s]
[2024-10-22 09:44:16,974][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 09:44:16,974][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 09:44:16,977][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 09:44:18,725][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 09:44:19,006][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 09:44:19,007][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 09:44:19,007][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 09:44:19,008][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 09:44:19,008][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 09:44:19,011][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 09:44:20,769][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 09:45:22,229][root][INFO] - Step: 7680/7680  |  Loss: 0.2011  |  Score: 91.41 [%]  |  Seq Length: 256.0
[2024-10-22 09:45:31,385][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 09:45:31,385][root][INFO] - Score: 77.41 [%]  |  Evaluation Time: 9.15 [s]
[2024-10-22 09:45:40,514][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 09:45:40,514][root][INFO] - Score: 74.62 [%]  |  Evaluation Time: 9.13 [s]
[2024-10-22 09:45:40,515][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 09:45:40,515][root][INFO] - - Epoch: 8
[2024-10-22 09:45:40,515][root][INFO] - - DEV score: 77.95 [%]
[2024-10-22 09:45:40,515][root][INFO] - - TEST score: 74.18 [%]
[2024-10-22 09:45:40,516][root][INFO] - Fine-tuning is done!
[2024-10-22 09:45:40,516][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 09:45:40,516][root][INFO] - - BEST LR: 0.02
[2024-10-22 09:45:40,516][root][INFO] - - DEV score: 77.95 [%]
[2024-10-22 09:45:40,516][root][INFO] - - TEST score: 74.18 [%]
[2024-10-22 10:02:12,154][root][INFO] - Step: 8440/10550  |  Loss: 0.2346  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-22 10:03:06,367][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 10:03:06,368][root][INFO] - Score: 88.66 [%]  |  Evaluation Time: 54.21 [s]
[2024-10-22 10:04:58,713][root][INFO] - Step: 70000/73665  |  Loss: 0.5053  |  Score: 79.76 [%]  |  Seq Length: 256.0
[2024-10-22 10:06:04,748][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 10:06:04,748][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 178.38 [s]
[2024-10-22 10:06:04,750][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 10:06:04,750][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 10:06:04,753][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 10:06:06,530][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 10:06:06,810][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 10:06:06,811][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 10:06:06,812][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 10:06:06,812][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 10:06:06,812][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 10:06:06,815][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 10:06:08,580][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 10:19:18,905][root][INFO] - Step: 10000/10550  |  Loss: 0.1945  |  Score: 92.15 [%]  |  Seq Length: 256.0
[2024-10-22 10:23:55,903][root][INFO] - Step: 10550/10550  |  Loss: 0.1926  |  Score: 92.26 [%]  |  Seq Length: 256.0
[2024-10-22 10:24:48,522][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 10:24:48,522][root][INFO] - Score: 88.72 [%]  |  Evaluation Time: 52.62 [s]
[2024-10-22 10:27:44,747][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 10:27:44,747][root][INFO] - Score: 88.93 [%]  |  Evaluation Time: 176.22 [s]
[2024-10-22 10:27:44,749][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 10:27:44,749][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 10:27:44,752][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 10:27:46,524][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 10:27:46,804][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 10:27:46,805][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 10:27:46,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 10:27:46,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 10:27:46,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 10:27:46,809][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 10:27:48,568][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 10:27:48,568][root][INFO] - - Epoch: 5
[2024-10-22 10:27:48,569][root][INFO] - - DEV score: 88.72 [%]
[2024-10-22 10:27:48,569][root][INFO] - - TEST score: 88.93 [%]
[2024-10-22 10:27:48,571][root][INFO] - Fine-tuning is done!
[2024-10-22 10:27:48,572][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 10:27:48,572][root][INFO] - - BEST LR: 0.01
[2024-10-22 10:27:48,572][root][INFO] - - DEV score: 89.06 [%]
[2024-10-22 10:27:48,572][root][INFO] - - TEST score: 88.82 [%]
[2024-10-22 10:37:46,813][root][INFO] - Step: 73665/73665  |  Loss: 0.5028  |  Score: 79.94 [%]  |  Seq Length: 256.0
[2024-10-22 10:37:57,295][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 10:37:57,295][root][INFO] - Score: 75.47 [%]  |  Evaluation Time: 10.48 [s]
[2024-10-22 10:38:17,479][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 10:38:17,479][root][INFO] - Score: 76.41 [%]  |  Evaluation Time: 20.18 [s]
[2024-10-22 10:38:17,481][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 10:38:17,481][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 10:38:17,484][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 10:38:19,367][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 10:38:19,532][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 10:38:19,534][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 10:38:19,534][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 10:38:19,534][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 10:38:19,535][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 10:38:19,538][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 10:38:21,343][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 10:38:21,343][root][INFO] - - Epoch: 5
[2024-10-22 10:38:21,343][root][INFO] - - DEV score: 75.47 [%]
[2024-10-22 10:38:21,344][root][INFO] - - TEST score: 76.41 [%]
[2024-10-22 10:38:21,345][root][INFO] - Fine-tuning is done!
[2024-10-22 10:40:19,296][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,297][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,297][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,298][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,298][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,298][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,299][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,299][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,300][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,300][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,300][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,301][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,301][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,302][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,302][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,302][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,303][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,303][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,304][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,304][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,305][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,305][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,305][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 10:40:19,306][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 10:40:19,307][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-22 10:40:19,503][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 10:40:19,505][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-22 10:40:19,507][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 10:40:19,719][root][INFO] - 

[2024-10-22 10:40:19,719][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-22 10:40:19,719][root][INFO] - Data Preprocessing
[2024-10-22 10:40:19,719][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 10:40:19,719][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 10:40:19,719][root][INFO] - ㄴ data_remove                False

[2024-10-22 10:40:19,719][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 10:40:19,734][root][INFO] - vocab size              : 51200
[2024-10-22 10:40:19,735][root][INFO] - device                  : gpu
[2024-10-22 10:40:19,735][root][INFO] - random seed             : 1
[2024-10-22 10:40:19,735][root][INFO] - train data size         : 942912
[2024-10-22 10:40:19,735][root][INFO] - max epochs              : 5
[2024-10-22 10:40:19,735][root][INFO] - total steps             : 73665
[2024-10-22 10:40:19,735][root][INFO] - warmup steps            : 7366
[2024-10-22 10:40:19,735][root][INFO] - batch size              : 64
[2024-10-22 10:40:19,735][root][INFO] - accumulation steps      : 1
[2024-10-22 10:40:19,735][root][INFO] - optimizer               : adamwscale
[2024-10-22 10:40:19,736][root][INFO] - lr_scheduler            : cosine
[2024-10-22 10:40:19,736][root][INFO] - learning rate           : 0.02
[2024-10-22 10:40:19,736][root][INFO] - max length              : 256

[2024-10-22 10:40:19,736][root][INFO] - LoRA Configuration
[2024-10-22 10:40:19,736][root][INFO] - ㄴ r                    : 32
[2024-10-22 10:40:19,736][root][INFO] - ㄴ alpha                : 128
[2024-10-22 10:40:19,736][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 10:40:19,736][root][INFO] - KOMBO Configuration
[2024-10-22 10:40:19,736][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 10:40:19,736][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 10:40:19,736][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 10:40:19,737][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 10:40:19,737][root][INFO] - ㄴ do_combination       : True
[2024-10-22 10:40:19,737][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 10:40:19,737][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 10:40:19,737][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 10:40:19,737][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 10:40:19,737][root][INFO] - 

[2024-10-22 10:40:19,737][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs
[2024-10-22 10:40:19,737][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 10:40:19,737][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/tb
[2024-10-22 10:40:19,737][root][INFO] - * tb interval   : 10000

[2024-10-22 10:40:19,738][root][INFO] - 

[2024-10-22 10:40:19,738][root][INFO] - Start the Training !
[2024-10-22 10:40:19,740][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 12:08:23,096][root][INFO] - Step: 10000/73665  |  Loss: 0.7558  |  Score: 67.06 [%]  |  Seq Length: 256.0
[2024-10-22 12:49:56,416][root][INFO] - Step: 14733/73665  |  Loss: 0.8300  |  Score: 62.50 [%]  |  Seq Length: 256.0
[2024-10-22 12:50:06,795][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 12:50:06,795][root][INFO] - Score: 53.81 [%]  |  Evaluation Time: 10.38 [s]
[2024-10-22 12:50:26,864][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 12:50:26,864][root][INFO] - Score: 54.01 [%]  |  Evaluation Time: 20.06 [s]
[2024-10-22 12:50:26,865][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 12:50:26,865][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 12:50:26,868][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 12:50:28,728][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 12:50:28,920][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 12:50:28,921][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 12:50:28,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 12:50:28,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 12:50:28,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 12:50:28,925][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 12:50:30,672][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 13:36:39,799][root][INFO] - Step: 20000/73665  |  Loss: nan  |  Score: 40.61 [%]  |  Seq Length: 256.0
[2024-10-22 14:59:15,192][root][INFO] - Step: 29466/73665  |  Loss: nan  |  Score: 33.35 [%]  |  Seq Length: 256.0
[2024-10-22 14:59:25,540][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 14:59:25,540][root][INFO] - Score: 33.32 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-22 14:59:45,793][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 14:59:45,794][root][INFO] - Score: 33.59 [%]  |  Evaluation Time: 20.25 [s]
[2024-10-22 14:59:45,796][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 15:04:27,263][root][INFO] - Step: 30000/73665  |  Loss: nan  |  Score: 33.68 [%]  |  Seq Length: 256.0
[2024-10-22 16:31:58,430][root][INFO] - Step: 40000/73665  |  Loss: nan  |  Score: 33.33 [%]  |  Seq Length: 256.0
[2024-10-22 17:08:44,833][root][INFO] - Step: 44199/73665  |  Loss: nan  |  Score: 33.30 [%]  |  Seq Length: 256.0
[2024-10-22 17:08:55,205][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 17:08:55,205][root][INFO] - Score: 33.34 [%]  |  Evaluation Time: 10.37 [s]
[2024-10-22 17:09:15,413][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 17:09:15,413][root][INFO] - Score: 33.28 [%]  |  Evaluation Time: 20.21 [s]
[2024-10-22 17:09:15,415][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 17:56:02,702][root][INFO] - 

[2024-10-22 17:56:02,702][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 17:56:02,702][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-22 17:56:02,702][root][INFO] - 

[2024-10-22 17:56:02,702][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 5e-03', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 17:56:25,697][root][INFO] - 

[2024-10-22 17:56:25,697][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 17:56:25,697][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-22 17:56:25,697][root][INFO] - 

[2024-10-22 17:56:25,697][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '7e-03 5e-03', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 17:56:30,299][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,299][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,300][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,301][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,302][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,302][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,303][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,304][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,304][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,305][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,305][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,306][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,307][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,307][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,308][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,309][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,309][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,310][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,311][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,311][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,312][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,313][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,313][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 17:56:30,314][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 17:56:30,316][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 17:56:30,322][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 17:56:30,530][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 17:56:30,532][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 17:56:30,718][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 17:56:34,004][root][INFO] - 

[2024-10-22 17:56:34,004][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 17:56:34,005][root][INFO] - Data Preprocessing
[2024-10-22 17:56:34,005][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 17:56:34,005][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 17:56:34,005][root][INFO] - ㄴ data_remove                False

[2024-10-22 17:56:34,005][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 17:56:34,013][root][INFO] - vocab size              : 51200
[2024-10-22 17:56:34,013][root][INFO] - device                  : gpu
[2024-10-22 17:56:34,013][root][INFO] - random seed             : 1
[2024-10-22 17:56:34,014][root][INFO] - train data size         : 5760
[2024-10-22 17:56:34,014][root][INFO] - max epochs              : 15
[2024-10-22 17:56:34,014][root][INFO] - total steps             : 1350
[2024-10-22 17:56:34,014][root][INFO] - warmup steps            : 135
[2024-10-22 17:56:34,014][root][INFO] - batch size              : 64
[2024-10-22 17:56:34,014][root][INFO] - accumulation steps      : 1
[2024-10-22 17:56:34,014][root][INFO] - optimizer               : adamwscale
[2024-10-22 17:56:34,014][root][INFO] - lr_scheduler            : cosine
[2024-10-22 17:56:34,014][root][INFO] - learning rate           : 0.007
[2024-10-22 17:56:34,014][root][INFO] - max length              : 256

[2024-10-22 17:56:34,014][root][INFO] - LoRA Configuration
[2024-10-22 17:56:34,014][root][INFO] - ㄴ r                    : 32
[2024-10-22 17:56:34,015][root][INFO] - ㄴ alpha                : 128
[2024-10-22 17:56:34,015][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 17:56:34,015][root][INFO] - KOMBO Configuration
[2024-10-22 17:56:34,015][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 17:56:34,015][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 17:56:34,015][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 17:56:34,015][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 17:56:34,015][root][INFO] - ㄴ do_combination       : True
[2024-10-22 17:56:34,015][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 17:56:34,016][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 17:56:34,016][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 17:56:34,016][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 17:56:34,016][root][INFO] - 

[2024-10-22 17:56:34,016][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs
[2024-10-22 17:56:34,016][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 17:56:34,016][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc/256t_64b_1s_1rs/tb
[2024-10-22 17:56:34,016][root][INFO] - * tb interval   : 10000

[2024-10-22 17:56:34,016][root][INFO] - 

[2024-10-22 17:56:34,016][root][INFO] - Start the Training !
[2024-10-22 17:56:34,020][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 17:58:00,830][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,831][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,832][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,832][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,833][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,833][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,834][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,834][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,835][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,835][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,836][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,836][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,837][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,837][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,838][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,838][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,839][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,839][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,840][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,840][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,841][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,841][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,842][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 17:58:00,842][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 17:58:00,844][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-22 17:58:00,849][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 17:58:01,048][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 17:58:01,051][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-22 17:58:01,336][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 17:58:04,535][root][INFO] - 

[2024-10-22 17:58:04,535][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-22 17:58:04,535][root][INFO] - Data Preprocessing
[2024-10-22 17:58:04,535][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-22 17:58:04,536][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 17:58:04,536][root][INFO] - ㄴ data_remove                False

[2024-10-22 17:58:04,536][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 17:58:04,543][root][INFO] - vocab size              : 51200
[2024-10-22 17:58:04,543][root][INFO] - device                  : gpu
[2024-10-22 17:58:04,543][root][INFO] - random seed             : 2
[2024-10-22 17:58:04,544][root][INFO] - train data size         : 942912
[2024-10-22 17:58:04,544][root][INFO] - max epochs              : 5
[2024-10-22 17:58:04,544][root][INFO] - total steps             : 73665
[2024-10-22 17:58:04,544][root][INFO] - warmup steps            : 7366
[2024-10-22 17:58:04,544][root][INFO] - batch size              : 64
[2024-10-22 17:58:04,544][root][INFO] - accumulation steps      : 1
[2024-10-22 17:58:04,544][root][INFO] - optimizer               : adamwscale
[2024-10-22 17:58:04,544][root][INFO] - lr_scheduler            : cosine
[2024-10-22 17:58:04,544][root][INFO] - learning rate           : 0.01
[2024-10-22 17:58:04,544][root][INFO] - max length              : 256

[2024-10-22 17:58:04,544][root][INFO] - LoRA Configuration
[2024-10-22 17:58:04,545][root][INFO] - ㄴ r                    : 32
[2024-10-22 17:58:04,545][root][INFO] - ㄴ alpha                : 128
[2024-10-22 17:58:04,545][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 17:58:04,545][root][INFO] - KOMBO Configuration
[2024-10-22 17:58:04,545][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 17:58:04,545][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 17:58:04,545][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 17:58:04,545][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 17:58:04,545][root][INFO] - ㄴ do_combination       : True
[2024-10-22 17:58:04,545][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 17:58:04,546][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 17:58:04,546][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 17:58:04,546][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 17:58:04,546][root][INFO] - 

[2024-10-22 17:58:04,546][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-22 17:58:04,546][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 17:58:04,546][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb
[2024-10-22 17:58:04,546][root][INFO] - * tb interval   : 10000

[2024-10-22 17:58:04,546][root][INFO] - 

[2024-10-22 17:58:04,546][root][INFO] - Start the Training !
[2024-10-22 17:58:04,549][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 18:02:04,654][root][INFO] - 

[2024-10-22 18:02:04,654][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 18:02:04,654][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs
[2024-10-22 18:02:04,654][root][INFO] - 

[2024-10-22 18:02:04,654][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'F', 'do_hangeulize': False, 'data_remove': '', 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 18:02:09,407][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,408][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,408][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,409][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,409][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,410][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,411][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,411][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,412][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,412][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,413][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,413][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,414][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,415][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,415][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,416][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,416][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,417][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,418][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,418][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,424][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,424][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,425][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:02:09,426][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:02:09,428][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 18:02:09,626][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:02:11,648][root][INFO] - 

[2024-10-22 18:02:11,649][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 18:02:11,649][root][INFO] - Data Preprocessing
[2024-10-22 18:02:11,649][root][INFO] - ㄴ remain_lang                F
[2024-10-22 18:02:11,649][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:02:11,649][root][INFO] - ㄴ data_remove                

[2024-10-22 18:02:11,649][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:02:11,657][root][INFO] - vocab size              : 51200
[2024-10-22 18:02:11,658][root][INFO] - device                  : gpu
[2024-10-22 18:02:11,658][root][INFO] - random seed             : 1
[2024-10-22 18:02:11,658][root][INFO] - train data size         : 5760
[2024-10-22 18:02:11,658][root][INFO] - max epochs              : 15
[2024-10-22 18:02:11,658][root][INFO] - total steps             : 1350
[2024-10-22 18:02:11,658][root][INFO] - warmup steps            : 135
[2024-10-22 18:02:11,658][root][INFO] - batch size              : 64
[2024-10-22 18:02:11,658][root][INFO] - accumulation steps      : 1
[2024-10-22 18:02:11,658][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:02:11,658][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:02:11,658][root][INFO] - learning rate           : 0.01
[2024-10-22 18:02:11,659][root][INFO] - max length              : 256

[2024-10-22 18:02:11,659][root][INFO] - LoRA Configuration
[2024-10-22 18:02:11,659][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:02:11,659][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:02:11,659][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:02:11,659][root][INFO] - 

[2024-10-22 18:02:11,659][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs
[2024-10-22 18:02:11,659][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs/ckpt
[2024-10-22 18:02:11,659][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/F/256t_64b_1s_1rs/tb
[2024-10-22 18:02:11,659][root][INFO] - * tb interval   : 10000

[2024-10-22 18:02:11,659][root][INFO] - 

[2024-10-22 18:02:11,659][root][INFO] - Start the Training !
[2024-10-22 18:02:11,662][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 18:02:45,883][root][INFO] - Step: 90/1350  |  Loss: 2.4113  |  Score: 33.10 [%]  |  Seq Length: 256.0
[2024-10-22 18:03:02,184][root][INFO] - 

[2024-10-22 18:03:02,184][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 18:03:02,185][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:03:02,185][root][INFO] - 

[2024-10-22 18:03:02,185][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 18:03:06,835][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,835][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,836][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,836][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,837][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,837][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,838][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,838][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,838][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,839][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,839][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,840][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,840][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,841][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,841][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,841][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,842][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,842][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,843][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,843][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,848][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,849][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,849][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:03:06,850][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:03:06,851][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 18:03:07,026][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:03:08,943][root][INFO] - 

[2024-10-22 18:03:08,944][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 18:03:08,944][root][INFO] - Data Preprocessing
[2024-10-22 18:03:08,944][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 18:03:08,944][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:03:08,944][root][INFO] - ㄴ data_remove                False

[2024-10-22 18:03:08,944][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:03:08,953][root][INFO] - vocab size              : 51200
[2024-10-22 18:03:08,953][root][INFO] - device                  : gpu
[2024-10-22 18:03:08,953][root][INFO] - random seed             : 1
[2024-10-22 18:03:08,953][root][INFO] - train data size         : 5760
[2024-10-22 18:03:08,953][root][INFO] - max epochs              : 15
[2024-10-22 18:03:08,954][root][INFO] - total steps             : 1350
[2024-10-22 18:03:08,954][root][INFO] - warmup steps            : 135
[2024-10-22 18:03:08,954][root][INFO] - batch size              : 64
[2024-10-22 18:03:08,954][root][INFO] - accumulation steps      : 1
[2024-10-22 18:03:08,954][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:03:08,954][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:03:08,954][root][INFO] - learning rate           : 0.01
[2024-10-22 18:03:08,954][root][INFO] - max length              : 256

[2024-10-22 18:03:08,954][root][INFO] - LoRA Configuration
[2024-10-22 18:03:08,954][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:03:08,954][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:03:08,955][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:03:08,955][root][INFO] - 

[2024-10-22 18:03:08,955][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:03:08,959][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 18:03:08,959][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 18:03:08,959][root][INFO] - * tb interval   : 10000

[2024-10-22 18:03:08,959][root][INFO] - 

[2024-10-22 18:03:08,959][root][INFO] - Start the Training !
[2024-10-22 18:03:08,963][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 18:03:43,549][root][INFO] - Step: 90/1350  |  Loss: 2.4113  |  Score: 33.10 [%]  |  Seq Length: 256.0
[2024-10-22 18:03:47,336][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 18:03:47,337][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 3.78 [s]
[2024-10-22 18:03:50,872][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 18:03:50,872][root][INFO] - Score: 63.85 [%]  |  Evaluation Time: 3.53 [s]
[2024-10-22 18:03:50,873][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 18:03:50,874][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:03:51,696][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:03:51,734][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:03:51,735][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:03:51,735][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:03:51,735][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:03:51,735][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:03:51,736][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:03:52,389][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 18:04:00,306][root][INFO] - 

[2024-10-22 18:04:00,306][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 18:04:00,306][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:04:00,306][root][INFO] - 

[2024-10-22 18:04:00,306][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 18:04:25,967][root][INFO] - Step: 180/1350  |  Loss: 1.2280  |  Score: 64.41 [%]  |  Seq Length: 256.0
[2024-10-22 18:04:26,418][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,419][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,419][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,420][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,420][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,421][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,421][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,422][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,422][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,423][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,423][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,424][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,424][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,425][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,425][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,426][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,426][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,427][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,427][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,428][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,428][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,429][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,429][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:04:26,430][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:04:26,432][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 18:04:26,621][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:04:28,410][root][INFO] - 

[2024-10-22 18:04:28,410][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 18:04:28,410][root][INFO] - Data Preprocessing
[2024-10-22 18:04:28,410][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 18:04:28,410][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:04:28,410][root][INFO] - ㄴ data_remove                False

[2024-10-22 18:04:28,411][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:04:28,418][root][INFO] - vocab size              : 51200
[2024-10-22 18:04:28,418][root][INFO] - device                  : gpu
[2024-10-22 18:04:28,418][root][INFO] - random seed             : 1
[2024-10-22 18:04:28,418][root][INFO] - train data size         : 135040
[2024-10-22 18:04:28,418][root][INFO] - max epochs              : 5
[2024-10-22 18:04:28,418][root][INFO] - total steps             : 10550
[2024-10-22 18:04:28,419][root][INFO] - warmup steps            : 1055
[2024-10-22 18:04:28,419][root][INFO] - batch size              : 64
[2024-10-22 18:04:28,419][root][INFO] - accumulation steps      : 1
[2024-10-22 18:04:28,419][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:04:28,419][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:04:28,419][root][INFO] - learning rate           : 0.01
[2024-10-22 18:04:28,419][root][INFO] - max length              : 256

[2024-10-22 18:04:28,419][root][INFO] - LoRA Configuration
[2024-10-22 18:04:28,419][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:04:28,419][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:04:28,419][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:04:28,420][root][INFO] - 

[2024-10-22 18:04:28,420][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:04:28,420][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 18:04:28,420][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 18:04:28,420][root][INFO] - * tb interval   : 10000

[2024-10-22 18:04:28,420][root][INFO] - 

[2024-10-22 18:04:28,420][root][INFO] - Start the Training !
[2024-10-22 18:04:28,423][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 18:04:29,820][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 18:04:29,820][root][INFO] - Score: 76.92 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 18:04:33,394][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 18:04:33,394][root][INFO] - Score: 67.38 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 18:04:33,396][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 18:04:33,396][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:04:34,925][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:04:34,960][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:04:34,961][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:04:34,961][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:04:34,961][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:04:34,961][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:04:34,962][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:04:36,405][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 18:05:09,971][root][INFO] - Step: 270/1350  |  Loss: 1.0473  |  Score: 70.26 [%]  |  Seq Length: 256.0
[2024-10-22 18:05:13,797][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 18:05:13,798][root][INFO] - Score: 77.97 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-22 18:05:17,323][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 18:05:17,323][root][INFO] - Score: 71.22 [%]  |  Evaluation Time: 3.52 [s]
[2024-10-22 18:05:17,324][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 18:05:17,324][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:05:18,835][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:05:18,881][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:05:18,882][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:05:18,882][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:05:18,882][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:05:18,883][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:05:18,884][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:05:20,322][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 18:05:53,787][root][INFO] - Step: 360/1350  |  Loss: 0.8776  |  Score: 73.84 [%]  |  Seq Length: 256.0
[2024-10-22 18:05:57,602][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 18:05:57,603][root][INFO] - Score: 78.87 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-22 18:06:01,141][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 18:06:01,142][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 18:06:01,142][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 18:06:01,143][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:06:02,655][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:06:02,689][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:06:02,690][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:06:02,690][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:06:02,690][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:06:02,690][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:06:02,691][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:06:04,092][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 18:06:37,675][root][INFO] - Step: 450/1350  |  Loss: 0.7642  |  Score: 78.10 [%]  |  Seq Length: 256.0
[2024-10-22 18:06:41,511][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 18:06:41,511][root][INFO] - Score: 77.14 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:06:45,125][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 18:06:45,125][root][INFO] - Score: 69.45 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-22 18:06:45,130][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 18:07:18,792][root][INFO] - Step: 540/1350  |  Loss: 0.7207  |  Score: 79.89 [%]  |  Seq Length: 256.0
[2024-10-22 18:07:22,623][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 18:07:22,624][root][INFO] - Score: 77.76 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:07:26,214][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 18:07:26,214][root][INFO] - Score: 72.65 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 18:07:26,215][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 18:07:26,216][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:07:27,663][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:07:27,703][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:07:27,703][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:07:27,704][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:07:27,704][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:07:27,704][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:07:27,705][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:07:29,162][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 18:08:02,800][root][INFO] - Step: 630/1350  |  Loss: 0.6084  |  Score: 82.72 [%]  |  Seq Length: 256.0
[2024-10-22 18:08:06,644][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 18:08:06,644][root][INFO] - Score: 78.49 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:08:10,208][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 18:08:10,208][root][INFO] - Score: 72.55 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 18:08:10,210][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 18:08:10,210][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:08:11,763][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:08:11,800][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:08:11,801][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:08:11,801][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:08:11,801][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:08:11,801][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:08:11,802][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:08:13,220][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 18:08:46,886][root][INFO] - Step: 720/1350  |  Loss: 0.5348  |  Score: 84.41 [%]  |  Seq Length: 256.0
[2024-10-22 18:08:50,730][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 18:08:50,731][root][INFO] - Score: 78.69 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:08:54,303][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 18:08:54,303][root][INFO] - Score: 72.04 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 18:08:54,305][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 18:09:28,073][root][INFO] - Step: 810/1350  |  Loss: 0.4850  |  Score: 85.78 [%]  |  Seq Length: 256.0
[2024-10-22 18:09:31,941][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 18:09:31,941][root][INFO] - Score: 77.98 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 18:09:35,523][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 18:09:35,524][root][INFO] - Score: 71.85 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 18:09:35,526][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 18:10:09,317][root][INFO] - Step: 900/1350  |  Loss: 0.4437  |  Score: 86.97 [%]  |  Seq Length: 256.0
[2024-10-22 18:10:13,178][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 18:10:13,178][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 18:10:16,734][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 18:10:16,734][root][INFO] - Score: 72.33 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 18:10:16,736][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 18:10:50,462][root][INFO] - Step: 990/1350  |  Loss: 0.3923  |  Score: 88.22 [%]  |  Seq Length: 256.0
[2024-10-22 18:10:54,307][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 18:10:54,307][root][INFO] - Score: 78.26 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:10:57,866][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 18:10:57,867][root][INFO] - Score: 71.44 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 18:10:57,868][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 18:11:31,850][root][INFO] - Step: 1080/1350  |  Loss: 0.3720  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-22 18:11:35,695][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 18:11:35,696][root][INFO] - Score: 78.88 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:11:39,315][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 18:11:39,315][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 3.62 [s]
[2024-10-22 18:11:39,318][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 18:12:13,044][root][INFO] - Step: 1170/1350  |  Loss: 0.3427  |  Score: 89.73 [%]  |  Seq Length: 256.0
[2024-10-22 18:12:16,877][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 18:12:16,878][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:12:20,443][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 18:12:20,443][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 18:12:20,445][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 18:12:54,177][root][INFO] - Step: 1260/1350  |  Loss: 0.3397  |  Score: 89.75 [%]  |  Seq Length: 256.0
[2024-10-22 18:12:58,025][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 18:12:58,025][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 18:13:01,579][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 18:13:01,580][root][INFO] - Score: 71.06 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 18:13:01,582][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 18:13:35,257][root][INFO] - Step: 1350/1350  |  Loss: 0.3280  |  Score: 90.13 [%]  |  Seq Length: 256.0
[2024-10-22 18:13:39,093][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 18:13:39,094][root][INFO] - Score: 78.76 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:13:42,614][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 18:13:42,614][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 3.52 [s]
[2024-10-22 18:13:42,616][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 18:13:42,616][root][INFO] - - Epoch: 7
[2024-10-22 18:13:42,616][root][INFO] - - DEV score: 78.49 [%]
[2024-10-22 18:13:42,617][root][INFO] - - TEST score: 72.55 [%]
[2024-10-22 18:13:42,618][root][INFO] - Fine-tuning is done!
[2024-10-22 18:13:46,384][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,384][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,385][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,385][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,385][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,386][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,386][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,387][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,387][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,388][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,388][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,388][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,389][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,389][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,390][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,390][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,390][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,391][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,391][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,392][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,392][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,393][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,393][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:13:46,394][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:13:46,395][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 18:13:46,397][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:13:46,550][root][INFO] - 

[2024-10-22 18:13:46,550][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 18:13:46,550][root][INFO] - Data Preprocessing
[2024-10-22 18:13:46,551][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 18:13:46,551][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:13:46,551][root][INFO] - ㄴ data_remove                False

[2024-10-22 18:13:46,551][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:13:46,557][root][INFO] - vocab size              : 51200
[2024-10-22 18:13:46,558][root][INFO] - device                  : gpu
[2024-10-22 18:13:46,558][root][INFO] - random seed             : 1
[2024-10-22 18:13:46,558][root][INFO] - train data size         : 5760
[2024-10-22 18:13:46,558][root][INFO] - max epochs              : 15
[2024-10-22 18:13:46,558][root][INFO] - total steps             : 1350
[2024-10-22 18:13:46,558][root][INFO] - warmup steps            : 135
[2024-10-22 18:13:46,558][root][INFO] - batch size              : 64
[2024-10-22 18:13:46,558][root][INFO] - accumulation steps      : 1
[2024-10-22 18:13:46,558][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:13:46,559][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:13:46,559][root][INFO] - learning rate           : 0.02
[2024-10-22 18:13:46,559][root][INFO] - max length              : 256

[2024-10-22 18:13:46,559][root][INFO] - LoRA Configuration
[2024-10-22 18:13:46,559][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:13:46,559][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:13:46,559][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:13:46,559][root][INFO] - 

[2024-10-22 18:13:46,559][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:13:46,559][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 18:13:46,559][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 18:13:46,560][root][INFO] - * tb interval   : 10000

[2024-10-22 18:13:46,560][root][INFO] - 

[2024-10-22 18:13:46,560][root][INFO] - Start the Training !
[2024-10-22 18:13:46,562][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 18:14:20,248][root][INFO] - Step: 90/1350  |  Loss: 2.1060  |  Score: 41.54 [%]  |  Seq Length: 256.0
[2024-10-22 18:14:24,106][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 18:14:24,106][root][INFO] - Score: 73.34 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 18:14:27,691][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 18:14:27,691][root][INFO] - Score: 64.22 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 18:14:27,692][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 18:14:27,692][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:14:29,238][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:14:29,272][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:14:29,273][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:14:29,273][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:14:29,273][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:14:29,273][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:14:29,275][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:14:30,702][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 18:15:04,371][root][INFO] - Step: 180/1350  |  Loss: 1.1812  |  Score: 66.75 [%]  |  Seq Length: 256.0
[2024-10-22 18:15:08,236][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 18:15:08,236][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 18:15:11,834][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 18:15:11,834][root][INFO] - Score: 66.63 [%]  |  Evaluation Time: 3.60 [s]
[2024-10-22 18:15:11,835][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 18:15:11,836][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:15:13,342][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:15:13,381][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:15:13,382][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:15:13,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:15:13,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:15:13,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:15:13,383][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:15:14,789][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 18:15:48,450][root][INFO] - Step: 270/1350  |  Loss: 0.9981  |  Score: 72.86 [%]  |  Seq Length: 256.0
[2024-10-22 18:15:52,292][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 18:15:52,292][root][INFO] - Score: 77.08 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:15:55,950][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 18:15:55,951][root][INFO] - Score: 70.47 [%]  |  Evaluation Time: 3.66 [s]
[2024-10-22 18:15:55,952][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 18:15:55,952][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:15:57,450][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:15:57,491][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:15:57,492][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:15:57,492][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:15:57,492][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:15:57,492][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:15:57,493][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:15:58,892][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 18:16:32,683][root][INFO] - Step: 360/1350  |  Loss: 0.7879  |  Score: 77.81 [%]  |  Seq Length: 256.0
[2024-10-22 18:16:36,529][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 18:16:36,530][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:16:40,137][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 18:16:40,137][root][INFO] - Score: 69.48 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-22 18:16:40,138][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 18:16:40,139][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:16:41,660][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:16:41,694][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:16:41,694][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:16:41,694][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:16:41,695][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:16:41,695][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:16:41,696][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:16:43,141][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 18:17:16,849][root][INFO] - Step: 450/1350  |  Loss: 0.6225  |  Score: 82.20 [%]  |  Seq Length: 256.0
[2024-10-22 18:17:20,707][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 18:17:20,707][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 18:17:23,188][root][INFO] - Step: 2110/10550  |  Loss: 0.3669  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-22 18:17:24,268][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 18:17:24,268][root][INFO] - Score: 69.48 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 18:17:24,270][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 18:17:57,193][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 18:17:57,193][root][INFO] - Score: 87.43 [%]  |  Evaluation Time: 34.00 [s]
[2024-10-22 18:17:57,978][root][INFO] - Step: 540/1350  |  Loss: 0.5384  |  Score: 85.06 [%]  |  Seq Length: 256.0
[2024-10-22 18:18:01,808][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 18:18:01,808][root][INFO] - Score: 77.38 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:18:05,413][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 18:18:05,413][root][INFO] - Score: 71.01 [%]  |  Evaluation Time: 3.60 [s]
[2024-10-22 18:18:05,414][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 18:18:05,414][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:18:06,969][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:18:07,028][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:18:07,029][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:18:07,029][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:18:07,029][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:18:07,030][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:18:07,031][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:18:08,465][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 18:18:42,195][root][INFO] - Step: 630/1350  |  Loss: 0.4523  |  Score: 87.09 [%]  |  Seq Length: 256.0
[2024-10-22 18:18:46,105][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 18:18:46,105][root][INFO] - Score: 78.75 [%]  |  Evaluation Time: 3.91 [s]
[2024-10-22 18:18:49,717][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 18:18:49,717][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-22 18:18:49,718][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 18:18:49,719][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:18:51,296][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:18:51,331][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:18:51,332][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:18:51,332][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:18:51,332][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:18:51,332][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:18:51,333][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:18:52,959][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 18:19:26,772][root][INFO] - Step: 720/1350  |  Loss: 0.3620  |  Score: 89.49 [%]  |  Seq Length: 256.0
[2024-10-22 18:19:30,652][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 18:19:30,652][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 3.88 [s]
[2024-10-22 18:19:34,222][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 18:19:34,222][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 18:19:34,224][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 18:19:49,767][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 18:19:49,767][root][INFO] - Score: 87.10 [%]  |  Evaluation Time: 112.57 [s]
[2024-10-22 18:19:49,769][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 18:19:49,769][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:19:50,592][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:19:50,616][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:19:50,617][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:19:50,617][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:19:50,617][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:19:50,617][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:19:50,618][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:19:51,272][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 18:20:07,937][root][INFO] - Step: 810/1350  |  Loss: 0.3020  |  Score: 91.14 [%]  |  Seq Length: 256.0
[2024-10-22 18:20:11,795][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 18:20:11,795][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 18:20:15,363][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 18:20:15,363][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 18:20:15,367][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 18:20:49,360][root][INFO] - Step: 900/1350  |  Loss: 0.2615  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-22 18:20:53,226][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 18:20:53,226][root][INFO] - Score: 78.81 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 18:20:56,815][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 18:20:56,815][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 18:20:56,817][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 18:20:56,817][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:20:58,369][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:20:58,400][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:20:58,400][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:20:58,400][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:20:58,400][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:20:58,401][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:20:58,402][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:20:59,974][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 18:21:33,692][root][INFO] - Step: 990/1350  |  Loss: 0.2212  |  Score: 93.51 [%]  |  Seq Length: 256.0
[2024-10-22 18:21:37,542][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 18:21:37,542][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 18:21:41,149][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 18:21:41,149][root][INFO] - Score: 69.68 [%]  |  Evaluation Time: 3.60 [s]
[2024-10-22 18:21:41,151][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 18:22:14,918][root][INFO] - Step: 1080/1350  |  Loss: 0.2071  |  Score: 93.79 [%]  |  Seq Length: 256.0
[2024-10-22 18:22:18,752][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 18:22:18,753][root][INFO] - Score: 79.36 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:22:22,307][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 18:22:22,307][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 18:22:22,308][root][INFO] - 
Save new Best Score (Epoch: 12)
[2024-10-22 18:22:22,308][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:22:23,877][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:22:23,919][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:22:23,919][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:22:23,920][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:22:23,920][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:22:23,920][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:22:23,921][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:22:25,475][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 18:22:59,178][root][INFO] - Step: 1170/1350  |  Loss: 0.1868  |  Score: 94.24 [%]  |  Seq Length: 256.0
[2024-10-22 18:23:03,031][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 18:23:03,031][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 18:23:06,638][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 18:23:06,639][root][INFO] - Score: 70.31 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-22 18:23:06,641][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 18:23:40,412][root][INFO] - Step: 1260/1350  |  Loss: 0.1798  |  Score: 94.50 [%]  |  Seq Length: 256.0
[2024-10-22 18:23:44,308][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 18:23:44,308][root][INFO] - Score: 78.40 [%]  |  Evaluation Time: 3.89 [s]
[2024-10-22 18:23:47,918][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 18:23:47,918][root][INFO] - Score: 69.70 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-22 18:23:47,920][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 18:24:21,653][root][INFO] - Step: 1350/1350  |  Loss: 0.1723  |  Score: 94.64 [%]  |  Seq Length: 256.0
[2024-10-22 18:24:25,530][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 18:24:25,530][root][INFO] - Score: 79.43 [%]  |  Evaluation Time: 3.87 [s]
[2024-10-22 18:24:29,092][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 18:24:29,092][root][INFO] - Score: 69.99 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 18:24:29,093][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 18:24:29,093][root][INFO] - - Epoch: 12
[2024-10-22 18:24:29,093][root][INFO] - - DEV score: 79.36 [%]
[2024-10-22 18:24:29,093][root][INFO] - - TEST score: 70.60 [%]
[2024-10-22 18:24:29,095][root][INFO] - Fine-tuning is done!
[2024-10-22 18:24:29,095][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 18:24:29,096][root][INFO] - - BEST LR: 0.01
[2024-10-22 18:24:29,096][root][INFO] - - DEV score: 78.49 [%]
[2024-10-22 18:24:29,096][root][INFO] - - TEST score: 72.55 [%]
[2024-10-22 18:24:34,819][root][INFO] - 

[2024-10-22 18:24:34,820][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 18:24:34,820][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:24:34,820][root][INFO] - 

[2024-10-22 18:24:34,820][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 18:24:39,490][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,491][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,491][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,492][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,492][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,493][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,493][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,494][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,494][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,495][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,495][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,496][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,496][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,497][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,497][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,498][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,498][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,499][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,499][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,500][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,500][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,501][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,501][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:24:39,502][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:24:39,503][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 18:24:39,507][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 18:24:39,708][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 18:24:39,710][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 18:24:39,896][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:24:43,128][root][INFO] - 

[2024-10-22 18:24:43,128][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 18:24:43,128][root][INFO] - Data Preprocessing
[2024-10-22 18:24:43,128][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 18:24:43,128][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:24:43,128][root][INFO] - ㄴ data_remove                False

[2024-10-22 18:24:43,128][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:24:43,138][root][INFO] - vocab size              : 51200
[2024-10-22 18:24:43,138][root][INFO] - device                  : gpu
[2024-10-22 18:24:43,138][root][INFO] - random seed             : 1
[2024-10-22 18:24:43,138][root][INFO] - train data size         : 5760
[2024-10-22 18:24:43,139][root][INFO] - max epochs              : 15
[2024-10-22 18:24:43,139][root][INFO] - total steps             : 1350
[2024-10-22 18:24:43,139][root][INFO] - warmup steps            : 135
[2024-10-22 18:24:43,139][root][INFO] - batch size              : 64
[2024-10-22 18:24:43,139][root][INFO] - accumulation steps      : 1
[2024-10-22 18:24:43,139][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:24:43,139][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:24:43,139][root][INFO] - learning rate           : 0.01
[2024-10-22 18:24:43,139][root][INFO] - max length              : 256

[2024-10-22 18:24:43,139][root][INFO] - LoRA Configuration
[2024-10-22 18:24:43,139][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:24:43,139][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:24:43,140][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:24:43,140][root][INFO] - KOMBO Configuration
[2024-10-22 18:24:43,140][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 18:24:43,140][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 18:24:43,140][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 18:24:43,140][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 18:24:43,140][root][INFO] - ㄴ do_combination       : True
[2024-10-22 18:24:43,140][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 18:24:43,140][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 18:24:43,140][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 18:24:43,141][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 18:24:43,141][root][INFO] - 

[2024-10-22 18:24:43,141][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:24:43,141][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 18:24:43,141][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 18:24:43,141][root][INFO] - * tb interval   : 10000

[2024-10-22 18:24:43,141][root][INFO] - 

[2024-10-22 18:24:43,141][root][INFO] - Start the Training !
[2024-10-22 18:24:43,144][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 18:25:31,778][root][INFO] - Step: 90/1350  |  Loss: 2.5070  |  Score: 31.39 [%]  |  Seq Length: 256.0
[2024-10-22 18:25:38,071][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 18:25:38,071][root][INFO] - Score: 70.55 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 18:25:43,770][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 18:25:43,771][root][INFO] - Score: 62.66 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 18:25:43,772][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 18:25:43,772][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:25:43,776][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:25:44,648][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:25:44,779][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:25:44,780][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:25:44,780][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:25:44,780][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:25:44,780][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:25:44,782][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:25:45,532][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 18:26:34,214][root][INFO] - Step: 180/1350  |  Loss: 1.2068  |  Score: 64.67 [%]  |  Seq Length: 256.0
[2024-10-22 18:26:40,467][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 18:26:40,468][root][INFO] - Score: 77.12 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 18:26:46,135][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 18:26:46,135][root][INFO] - Score: 69.32 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 18:26:46,137][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 18:26:46,137][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:26:46,140][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:26:47,820][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:26:48,117][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:26:48,118][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:26:48,119][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:26:48,119][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:26:48,119][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:26:48,123][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:26:49,743][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 18:27:37,858][root][INFO] - Step: 270/1350  |  Loss: 1.0118  |  Score: 70.87 [%]  |  Seq Length: 256.0
[2024-10-22 18:27:44,153][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 18:27:44,153][root][INFO] - Score: 77.39 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 18:27:49,862][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 18:27:49,863][root][INFO] - Score: 70.46 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 18:27:49,864][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 18:27:49,864][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:27:49,867][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:27:51,569][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:27:51,850][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:27:51,851][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:27:51,851][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:27:51,852][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:27:51,852][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:27:51,855][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:27:53,477][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 18:28:42,040][root][INFO] - Step: 360/1350  |  Loss: 0.8741  |  Score: 75.09 [%]  |  Seq Length: 256.0
[2024-10-22 18:28:48,318][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 18:28:48,318][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 18:28:54,182][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 18:28:54,182][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 5.86 [s]
[2024-10-22 18:28:54,183][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 18:28:54,184][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:28:54,186][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:28:55,871][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:28:56,154][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:28:56,155][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:28:56,155][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:28:56,155][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:28:56,156][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:28:56,157][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:28:57,832][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 18:29:46,083][root][INFO] - Step: 450/1350  |  Loss: 0.7913  |  Score: 78.61 [%]  |  Seq Length: 256.0
[2024-10-22 18:29:52,347][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 18:29:52,347][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 18:29:58,018][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 18:29:58,018][root][INFO] - Score: 70.68 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 18:29:58,020][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 18:30:46,475][root][INFO] - Step: 540/1350  |  Loss: 0.6693  |  Score: 80.78 [%]  |  Seq Length: 256.0
[2024-10-22 18:30:52,733][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 18:30:52,733][root][INFO] - Score: 78.28 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 18:30:58,401][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 18:30:58,402][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 18:30:58,402][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 18:30:58,403][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:30:58,405][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:31:00,109][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:31:00,391][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:31:00,392][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:31:00,393][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:31:00,393][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:31:00,393][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:31:00,396][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:31:02,020][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 18:31:50,459][root][INFO] - Step: 630/1350  |  Loss: 0.5973  |  Score: 83.18 [%]  |  Seq Length: 256.0
[2024-10-22 18:31:56,722][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 18:31:56,722][root][INFO] - Score: 79.22 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 18:32:02,510][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 18:32:02,511][root][INFO] - Score: 71.78 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-22 18:32:02,512][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 18:32:02,512][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:32:02,515][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:32:04,221][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:32:04,507][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:32:04,508][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:32:04,509][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:32:04,509][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:32:04,509][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:32:04,511][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:32:06,127][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 18:32:45,172][root][INFO] - Step: 4220/10550  |  Loss: 0.2914  |  Score: 87.66 [%]  |  Seq Length: 256.0
[2024-10-22 18:32:54,401][root][INFO] - Step: 720/1350  |  Loss: 0.5410  |  Score: 84.94 [%]  |  Seq Length: 256.0
[2024-10-22 18:33:00,653][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 18:33:00,653][root][INFO] - Score: 78.24 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 18:33:06,367][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 18:33:06,367][root][INFO] - Score: 72.29 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 18:33:06,370][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 18:33:19,201][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 18:33:19,202][root][INFO] - Score: 88.35 [%]  |  Evaluation Time: 34.03 [s]
[2024-10-22 18:33:54,739][root][INFO] - Step: 810/1350  |  Loss: 0.4807  |  Score: 86.12 [%]  |  Seq Length: 256.0
[2024-10-22 18:34:01,115][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 18:34:01,115][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.37 [s]
[2024-10-22 18:34:06,901][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 18:34:06,901][root][INFO] - Score: 72.51 [%]  |  Evaluation Time: 5.78 [s]
[2024-10-22 18:34:06,903][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 18:34:55,099][root][INFO] - Step: 900/1350  |  Loss: 0.4214  |  Score: 87.56 [%]  |  Seq Length: 256.0
[2024-10-22 18:35:01,335][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 18:35:01,336][root][INFO] - Score: 78.57 [%]  |  Evaluation Time: 6.23 [s]
[2024-10-22 18:35:07,018][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 18:35:07,019][root][INFO] - Score: 70.82 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 18:35:07,021][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 18:35:11,630][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 18:35:11,631][root][INFO] - Score: 87.89 [%]  |  Evaluation Time: 112.43 [s]
[2024-10-22 18:35:11,632][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 18:35:11,632][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:35:13,141][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:35:13,171][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:35:13,172][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:35:13,172][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:35:13,172][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:35:13,172][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:35:13,173][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:35:14,559][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 18:35:55,250][root][INFO] - Step: 990/1350  |  Loss: 0.3826  |  Score: 88.68 [%]  |  Seq Length: 256.0
[2024-10-22 18:36:01,637][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 18:36:01,637][root][INFO] - Score: 79.31 [%]  |  Evaluation Time: 6.38 [s]
[2024-10-22 18:36:07,328][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 18:36:07,328][root][INFO] - Score: 72.57 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 18:36:07,329][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-22 18:36:07,330][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:36:07,332][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:36:09,051][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:36:09,310][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:36:09,311][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:36:09,312][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:36:09,312][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:36:09,312][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:36:09,315][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:36:10,927][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 18:36:59,429][root][INFO] - Step: 1080/1350  |  Loss: 0.3541  |  Score: 89.37 [%]  |  Seq Length: 256.0
[2024-10-22 18:37:05,852][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 18:37:05,852][root][INFO] - Score: 78.64 [%]  |  Evaluation Time: 6.42 [s]
[2024-10-22 18:37:11,482][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 18:37:11,483][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 5.63 [s]
[2024-10-22 18:37:11,485][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 18:37:59,704][root][INFO] - Step: 1170/1350  |  Loss: 0.3481  |  Score: 89.35 [%]  |  Seq Length: 256.0
[2024-10-22 18:38:05,980][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 18:38:05,980][root][INFO] - Score: 79.26 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 18:38:11,702][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 18:38:11,702][root][INFO] - Score: 72.56 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 18:38:11,704][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 18:38:59,957][root][INFO] - Step: 1260/1350  |  Loss: 0.3253  |  Score: 90.13 [%]  |  Seq Length: 256.0
[2024-10-22 18:39:06,243][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 18:39:06,244][root][INFO] - Score: 79.20 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 18:39:11,926][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 18:39:11,927][root][INFO] - Score: 72.38 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 18:39:11,929][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 18:40:00,495][root][INFO] - Step: 1350/1350  |  Loss: 0.3235  |  Score: 90.44 [%]  |  Seq Length: 256.0
[2024-10-22 18:40:06,782][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 18:40:06,783][root][INFO] - Score: 79.32 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 18:40:12,476][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 18:40:12,476][root][INFO] - Score: 72.34 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 18:40:12,477][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 18:40:12,477][root][INFO] - - Epoch: 11
[2024-10-22 18:40:12,478][root][INFO] - - DEV score: 79.31 [%]
[2024-10-22 18:40:12,478][root][INFO] - - TEST score: 72.57 [%]
[2024-10-22 18:40:12,478][root][INFO] - Fine-tuning is done!
[2024-10-22 18:40:15,812][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,813][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,814][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,814][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,815][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,815][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,816][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,817][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,817][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,818][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,818][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,819][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,820][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,820][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,821][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,822][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,822][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,823][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,823][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,824][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,825][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,825][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,826][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:40:15,826][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:40:15,829][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 18:40:16,036][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 18:40:16,038][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 18:40:16,039][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:40:16,225][root][INFO] - 

[2024-10-22 18:40:16,225][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 18:40:16,225][root][INFO] - Data Preprocessing
[2024-10-22 18:40:16,225][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 18:40:16,225][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:40:16,226][root][INFO] - ㄴ data_remove                False

[2024-10-22 18:40:16,226][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:40:16,233][root][INFO] - vocab size              : 51200
[2024-10-22 18:40:16,233][root][INFO] - device                  : gpu
[2024-10-22 18:40:16,233][root][INFO] - random seed             : 1
[2024-10-22 18:40:16,233][root][INFO] - train data size         : 5760
[2024-10-22 18:40:16,233][root][INFO] - max epochs              : 15
[2024-10-22 18:40:16,233][root][INFO] - total steps             : 1350
[2024-10-22 18:40:16,233][root][INFO] - warmup steps            : 135
[2024-10-22 18:40:16,234][root][INFO] - batch size              : 64
[2024-10-22 18:40:16,234][root][INFO] - accumulation steps      : 1
[2024-10-22 18:40:16,234][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:40:16,234][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:40:16,234][root][INFO] - learning rate           : 0.02
[2024-10-22 18:40:16,234][root][INFO] - max length              : 256

[2024-10-22 18:40:16,234][root][INFO] - LoRA Configuration
[2024-10-22 18:40:16,234][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:40:16,234][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:40:16,234][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:40:16,234][root][INFO] - KOMBO Configuration
[2024-10-22 18:40:16,234][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 18:40:16,235][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 18:40:16,235][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 18:40:16,235][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 18:40:16,235][root][INFO] - ㄴ do_combination       : True
[2024-10-22 18:40:16,235][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 18:40:16,235][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 18:40:16,235][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 18:40:16,235][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 18:40:16,236][root][INFO] - 

[2024-10-22 18:40:16,236][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 18:40:16,236][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 18:40:16,236][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 18:40:16,236][root][INFO] - * tb interval   : 10000

[2024-10-22 18:40:16,236][root][INFO] - 

[2024-10-22 18:40:16,236][root][INFO] - Start the Training !
[2024-10-22 18:40:16,238][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 18:41:04,824][root][INFO] - Step: 90/1350  |  Loss: 2.0412  |  Score: 42.75 [%]  |  Seq Length: 256.0
[2024-10-22 18:41:11,122][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 18:41:11,122][root][INFO] - Score: 75.53 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 18:41:16,854][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 18:41:16,854][root][INFO] - Score: 68.06 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 18:41:16,855][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 18:41:16,856][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:41:16,859][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:41:18,574][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:41:18,858][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:41:18,859][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:41:18,859][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:41:18,859][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:41:18,860][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:41:18,863][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:41:20,490][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 18:42:09,237][root][INFO] - Step: 180/1350  |  Loss: 1.0877  |  Score: 68.75 [%]  |  Seq Length: 256.0
[2024-10-22 18:42:15,648][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 18:42:15,648][root][INFO] - Score: 76.82 [%]  |  Evaluation Time: 6.41 [s]
[2024-10-22 18:42:21,419][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 18:42:21,419][root][INFO] - Score: 71.42 [%]  |  Evaluation Time: 5.77 [s]
[2024-10-22 18:42:21,420][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 18:42:21,420][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:42:21,423][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:42:23,128][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:42:23,410][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:42:23,412][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:42:23,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:42:23,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:42:23,412][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:42:23,415][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:42:25,018][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 18:43:13,402][root][INFO] - Step: 270/1350  |  Loss: 0.9647  |  Score: 73.71 [%]  |  Seq Length: 256.0
[2024-10-22 18:43:19,715][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 18:43:19,715][root][INFO] - Score: 77.64 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 18:43:25,431][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 18:43:25,432][root][INFO] - Score: 70.29 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 18:43:25,434][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 18:44:13,827][root][INFO] - Step: 360/1350  |  Loss: 0.7764  |  Score: 78.59 [%]  |  Seq Length: 256.0
[2024-10-22 18:44:20,161][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 18:44:20,161][root][INFO] - Score: 77.98 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 18:44:25,867][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 18:44:25,867][root][INFO] - Score: 70.67 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 18:44:25,869][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 18:44:25,869][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:44:25,872][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:44:27,567][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:44:27,851][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:44:27,852][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:44:27,853][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:44:27,853][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:44:27,853][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:44:27,857][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:44:29,468][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 18:45:17,692][root][INFO] - Step: 450/1350  |  Loss: 0.6467  |  Score: 82.10 [%]  |  Seq Length: 256.0
[2024-10-22 18:45:23,984][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 18:45:23,984][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 18:45:29,677][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 18:45:29,677][root][INFO] - Score: 70.43 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 18:45:29,678][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 18:45:29,679][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:45:29,681][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:45:31,387][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:45:31,670][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:45:31,672][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:45:31,672][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:45:31,673][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:45:31,673][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:45:31,676][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:45:33,279][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 18:46:21,632][root][INFO] - Step: 540/1350  |  Loss: 0.5402  |  Score: 85.15 [%]  |  Seq Length: 256.0
[2024-10-22 18:46:28,023][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 18:46:28,024][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.39 [s]
[2024-10-22 18:46:33,729][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 18:46:33,730][root][INFO] - Score: 70.07 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 18:46:33,732][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 18:47:22,007][root][INFO] - Step: 630/1350  |  Loss: 0.4346  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-22 18:47:28,397][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 18:47:28,398][root][INFO] - Score: 78.50 [%]  |  Evaluation Time: 6.39 [s]
[2024-10-22 18:47:34,096][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 18:47:34,096][root][INFO] - Score: 69.22 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 18:47:34,099][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 18:48:07,761][root][INFO] - Step: 6330/10550  |  Loss: 0.2516  |  Score: 89.56 [%]  |  Seq Length: 256.0
[2024-10-22 18:48:22,676][root][INFO] - Step: 720/1350  |  Loss: 0.3652  |  Score: 89.48 [%]  |  Seq Length: 256.0
[2024-10-22 18:48:28,999][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 18:48:28,999][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 18:48:34,744][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 18:48:34,744][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-22 18:48:34,746][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 18:48:41,813][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 18:48:41,814][root][INFO] - Score: 88.40 [%]  |  Evaluation Time: 34.05 [s]
[2024-10-22 18:49:23,171][root][INFO] - Step: 810/1350  |  Loss: 0.3299  |  Score: 90.70 [%]  |  Seq Length: 256.0
[2024-10-22 18:49:29,582][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 18:49:29,583][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 6.41 [s]
[2024-10-22 18:49:35,329][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 18:49:35,329][root][INFO] - Score: 69.84 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-22 18:49:35,332][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 18:50:23,684][root][INFO] - Step: 900/1350  |  Loss: 0.2637  |  Score: 92.01 [%]  |  Seq Length: 256.0
[2024-10-22 18:50:30,039][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 18:50:30,040][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-22 18:50:34,293][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 18:50:34,294][root][INFO] - Score: 88.53 [%]  |  Evaluation Time: 112.48 [s]
[2024-10-22 18:50:34,296][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 18:50:34,297][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:50:35,838][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:50:35,944][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:50:35,945][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:50:35,945][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:50:35,945][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:50:35,945][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:50:35,946][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 18:50:35,946][root][INFO] - Score: 69.09 [%]  |  Evaluation Time: 5.90 [s]
[2024-10-22 18:50:35,946][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:50:35,949][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 18:50:37,358][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 18:51:24,219][root][INFO] - Step: 990/1350  |  Loss: 0.2344  |  Score: 93.43 [%]  |  Seq Length: 256.0
[2024-10-22 18:51:30,566][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 18:51:30,567][root][INFO] - Score: 79.33 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 18:51:36,331][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 18:51:36,331][root][INFO] - Score: 70.70 [%]  |  Evaluation Time: 5.76 [s]
[2024-10-22 18:51:36,333][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-22 18:51:36,333][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 18:51:36,336][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 18:51:38,039][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:51:38,333][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:51:38,334][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:51:38,335][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:51:38,335][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:51:38,335][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:51:38,338][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:51:39,855][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 18:52:28,417][root][INFO] - Step: 1080/1350  |  Loss: 0.2078  |  Score: 93.73 [%]  |  Seq Length: 256.0
[2024-10-22 18:52:34,752][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 18:52:34,752][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 18:52:40,436][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 18:52:40,437][root][INFO] - Score: 70.22 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 18:52:40,439][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 18:53:28,809][root][INFO] - Step: 1170/1350  |  Loss: 0.1950  |  Score: 94.19 [%]  |  Seq Length: 256.0
[2024-10-22 18:53:35,066][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 18:53:35,067][root][INFO] - Score: 78.86 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 18:53:40,758][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 18:53:40,758][root][INFO] - Score: 70.65 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 18:53:40,760][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 18:54:29,404][root][INFO] - Step: 1260/1350  |  Loss: 0.1833  |  Score: 94.46 [%]  |  Seq Length: 256.0
[2024-10-22 18:54:35,744][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 18:54:35,745][root][INFO] - Score: 78.91 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 18:54:41,460][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 18:54:41,460][root][INFO] - Score: 70.44 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 18:54:41,463][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 18:55:29,679][root][INFO] - Step: 1350/1350  |  Loss: 0.1737  |  Score: 94.76 [%]  |  Seq Length: 256.0
[2024-10-22 18:55:36,033][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 18:55:36,033][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-22 18:55:41,746][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 18:55:41,746][root][INFO] - Score: 70.27 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 18:55:41,747][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 18:55:41,747][root][INFO] - - Epoch: 11
[2024-10-22 18:55:41,747][root][INFO] - - DEV score: 79.33 [%]
[2024-10-22 18:55:41,747][root][INFO] - - TEST score: 70.70 [%]
[2024-10-22 18:55:41,748][root][INFO] - Fine-tuning is done!
[2024-10-22 18:55:41,749][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 18:55:41,749][root][INFO] - - BEST LR: 0.01
[2024-10-22 18:55:41,749][root][INFO] - - DEV score: 79.31 [%]
[2024-10-22 18:55:41,749][root][INFO] - - TEST score: 72.57 [%]
[2024-10-22 18:55:48,004][root][INFO] - 

[2024-10-22 18:55:48,004][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 18:55:48,004][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs
[2024-10-22 18:55:48,004][root][INFO] - 

[2024-10-22 18:55:48,005][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 18:55:52,694][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,695][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,696][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,696][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,696][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,697][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,697][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,698][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,698][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,699][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,699][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,700][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,700][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,701][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,701][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,701][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,702][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,702][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,703][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,703][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,708][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,708][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,709][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 18:55:52,709][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 18:55:52,711][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 18:55:52,884][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 18:55:54,806][root][INFO] - 

[2024-10-22 18:55:54,807][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 18:55:54,807][root][INFO] - Data Preprocessing
[2024-10-22 18:55:54,807][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 18:55:54,807][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 18:55:54,807][root][INFO] - ㄴ data_remove                False

[2024-10-22 18:55:54,807][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 18:55:54,815][root][INFO] - vocab size              : 51200
[2024-10-22 18:55:54,815][root][INFO] - device                  : gpu
[2024-10-22 18:55:54,815][root][INFO] - random seed             : 2
[2024-10-22 18:55:54,815][root][INFO] - train data size         : 5760
[2024-10-22 18:55:54,815][root][INFO] - max epochs              : 15
[2024-10-22 18:55:54,816][root][INFO] - total steps             : 1350
[2024-10-22 18:55:54,816][root][INFO] - warmup steps            : 135
[2024-10-22 18:55:54,816][root][INFO] - batch size              : 64
[2024-10-22 18:55:54,816][root][INFO] - accumulation steps      : 1
[2024-10-22 18:55:54,816][root][INFO] - optimizer               : adamwscale
[2024-10-22 18:55:54,816][root][INFO] - lr_scheduler            : cosine
[2024-10-22 18:55:54,816][root][INFO] - learning rate           : 0.01
[2024-10-22 18:55:54,816][root][INFO] - max length              : 256

[2024-10-22 18:55:54,816][root][INFO] - LoRA Configuration
[2024-10-22 18:55:54,816][root][INFO] - ㄴ r                    : 32
[2024-10-22 18:55:54,817][root][INFO] - ㄴ alpha                : 128
[2024-10-22 18:55:54,817][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 18:55:54,817][root][INFO] - 

[2024-10-22 18:55:54,817][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs
[2024-10-22 18:55:54,817][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 18:55:54,817][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-22 18:55:54,817][root][INFO] - * tb interval   : 10000

[2024-10-22 18:55:54,817][root][INFO] - 

[2024-10-22 18:55:54,817][root][INFO] - Start the Training !
[2024-10-22 18:55:54,820][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 18:56:29,649][root][INFO] - Step: 90/1350  |  Loss: 2.0775  |  Score: 34.92 [%]  |  Seq Length: 256.0
[2024-10-22 18:56:33,512][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 18:56:33,512][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 18:56:37,032][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 18:56:37,033][root][INFO] - Score: 62.95 [%]  |  Evaluation Time: 3.52 [s]
[2024-10-22 18:56:37,034][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 18:56:37,034][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 18:56:37,862][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:56:37,887][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:56:37,887][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:56:37,888][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:56:37,888][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:56:37,888][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:56:37,889][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:56:38,551][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 18:57:12,133][root][INFO] - Step: 180/1350  |  Loss: 1.2192  |  Score: 65.37 [%]  |  Seq Length: 256.0
[2024-10-22 18:57:15,954][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 18:57:15,954][root][INFO] - Score: 76.19 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-22 18:57:19,590][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 18:57:19,590][root][INFO] - Score: 67.79 [%]  |  Evaluation Time: 3.63 [s]
[2024-10-22 18:57:19,592][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 18:57:19,592][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 18:57:21,094][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:57:21,137][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:57:21,138][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:57:21,138][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:57:21,138][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:57:21,138][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:57:21,139][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:57:22,519][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 18:57:56,204][root][INFO] - Step: 270/1350  |  Loss: 0.9830  |  Score: 71.69 [%]  |  Seq Length: 256.0
[2024-10-22 18:58:00,050][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 18:58:00,050][root][INFO] - Score: 77.16 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 18:58:03,602][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 18:58:03,602][root][INFO] - Score: 68.65 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 18:58:03,603][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 18:58:03,604][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 18:58:05,109][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:58:05,138][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:58:05,139][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:58:05,139][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:58:05,139][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:58:05,139][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:58:05,140][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:58:06,532][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 18:58:40,221][root][INFO] - Step: 360/1350  |  Loss: 0.8472  |  Score: 75.44 [%]  |  Seq Length: 256.0
[2024-10-22 18:58:44,050][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 18:58:44,050][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:58:47,627][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 18:58:47,628][root][INFO] - Score: 70.85 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 18:58:47,629][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 18:58:47,629][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 18:58:49,128][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:58:49,158][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:58:49,158][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:58:49,159][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:58:49,159][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:58:49,159][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:58:49,160][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:58:50,569][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 18:59:24,274][root][INFO] - Step: 450/1350  |  Loss: 0.7274  |  Score: 79.19 [%]  |  Seq Length: 256.0
[2024-10-22 18:59:28,108][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 18:59:28,109][root][INFO] - Score: 78.01 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 18:59:31,705][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 18:59:31,705][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 18:59:31,707][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 18:59:31,707][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 18:59:33,217][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 18:59:33,246][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 18:59:33,247][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 18:59:33,247][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 18:59:33,247][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 18:59:33,247][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 18:59:33,248][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 18:59:34,657][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 19:00:08,341][root][INFO] - Step: 540/1350  |  Loss: 0.6402  |  Score: 81.55 [%]  |  Seq Length: 256.0
[2024-10-22 19:00:12,159][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 19:00:12,159][root][INFO] - Score: 78.22 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-22 19:00:15,712][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 19:00:15,712][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 19:00:15,714][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 19:00:49,429][root][INFO] - Step: 630/1350  |  Loss: 0.5440  |  Score: 84.55 [%]  |  Seq Length: 256.0
[2024-10-22 19:00:53,274][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 19:00:53,274][root][INFO] - Score: 77.54 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 19:00:56,852][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 19:00:56,853][root][INFO] - Score: 71.08 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:00:56,855][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 19:01:30,577][root][INFO] - Step: 720/1350  |  Loss: 0.5012  |  Score: 86.05 [%]  |  Seq Length: 256.0
[2024-10-22 19:01:34,390][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 19:01:34,390][root][INFO] - Score: 77.61 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-22 19:01:38,063][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 19:01:38,063][root][INFO] - Score: 70.81 [%]  |  Evaluation Time: 3.67 [s]
[2024-10-22 19:01:38,066][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 19:02:11,784][root][INFO] - Step: 810/1350  |  Loss: 0.4181  |  Score: 87.64 [%]  |  Seq Length: 256.0
[2024-10-22 19:02:15,623][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 19:02:15,623][root][INFO] - Score: 77.75 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 19:02:19,208][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 19:02:19,209][root][INFO] - Score: 70.52 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:02:19,211][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 19:02:52,979][root][INFO] - Step: 900/1350  |  Loss: 0.3975  |  Score: 88.49 [%]  |  Seq Length: 256.0
[2024-10-22 19:02:56,833][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 19:02:56,833][root][INFO] - Score: 78.22 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:03:00,366][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 19:03:00,366][root][INFO] - Score: 72.56 [%]  |  Evaluation Time: 3.53 [s]
[2024-10-22 19:03:00,367][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 19:03:00,368][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:03:01,924][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:03:01,967][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:03:01,968][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:03:01,968][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:03:01,968][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:03:01,968][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:03:01,969][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:03:03,403][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 19:03:31,535][root][INFO] - Step: 8440/10550  |  Loss: 0.2164  |  Score: 91.16 [%]  |  Seq Length: 256.0
[2024-10-22 19:03:37,194][root][INFO] - Step: 990/1350  |  Loss: 0.3550  |  Score: 89.57 [%]  |  Seq Length: 256.0
[2024-10-22 19:03:41,059][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 19:03:41,059][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 19:03:44,625][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 19:03:44,625][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:03:44,627][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 19:04:05,566][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 19:04:05,567][root][INFO] - Score: 88.91 [%]  |  Evaluation Time: 34.03 [s]
[2024-10-22 19:04:18,368][root][INFO] - Step: 1080/1350  |  Loss: 0.3345  |  Score: 90.06 [%]  |  Seq Length: 256.0
[2024-10-22 19:04:22,195][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 19:04:22,195][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-22 19:04:25,735][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 19:04:25,735][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:04:25,737][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 19:04:59,438][root][INFO] - Step: 1170/1350  |  Loss: 0.3175  |  Score: 90.68 [%]  |  Seq Length: 256.0
[2024-10-22 19:05:03,275][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 19:05:03,275][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:05:06,821][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 19:05:06,821][root][INFO] - Score: 71.71 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:05:06,823][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 19:05:40,665][root][INFO] - Step: 1260/1350  |  Loss: 0.3008  |  Score: 91.06 [%]  |  Seq Length: 256.0
[2024-10-22 19:05:44,518][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 19:05:44,518][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:05:48,087][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 19:05:48,087][root][INFO] - Score: 72.42 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 19:05:48,089][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 19:05:58,070][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 19:05:58,070][root][INFO] - Score: 88.91 [%]  |  Evaluation Time: 112.50 [s]
[2024-10-22 19:05:58,072][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 19:05:58,072][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 19:05:59,578][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:05:59,608][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:05:59,608][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:05:59,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:05:59,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:05:59,609][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:05:59,610][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:06:01,010][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 19:06:21,815][root][INFO] - Step: 1350/1350  |  Loss: 0.3021  |  Score: 91.01 [%]  |  Seq Length: 256.0
[2024-10-22 19:06:25,646][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 19:06:25,646][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:06:29,186][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 19:06:29,186][root][INFO] - Score: 70.69 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:06:29,187][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 19:06:29,187][root][INFO] - - Epoch: 10
[2024-10-22 19:06:29,187][root][INFO] - - DEV score: 78.22 [%]
[2024-10-22 19:06:29,187][root][INFO] - - TEST score: 72.56 [%]
[2024-10-22 19:06:29,188][root][INFO] - Fine-tuning is done!
[2024-10-22 19:06:32,563][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,563][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,564][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,565][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,565][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,566][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,566][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,567][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,567][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,568][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,568][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,569][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,569][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,570][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,571][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,571][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,572][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,572][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,573][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,573][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,574][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,575][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,575][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 19:06:32,576][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 19:06:32,578][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 19:06:32,579][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 19:06:32,743][root][INFO] - 

[2024-10-22 19:06:32,743][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 19:06:32,743][root][INFO] - Data Preprocessing
[2024-10-22 19:06:32,743][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 19:06:32,743][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 19:06:32,743][root][INFO] - ㄴ data_remove                False

[2024-10-22 19:06:32,743][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 19:06:32,750][root][INFO] - vocab size              : 51200
[2024-10-22 19:06:32,750][root][INFO] - device                  : gpu
[2024-10-22 19:06:32,750][root][INFO] - random seed             : 2
[2024-10-22 19:06:32,750][root][INFO] - train data size         : 5760
[2024-10-22 19:06:32,750][root][INFO] - max epochs              : 15
[2024-10-22 19:06:32,751][root][INFO] - total steps             : 1350
[2024-10-22 19:06:32,751][root][INFO] - warmup steps            : 135
[2024-10-22 19:06:32,751][root][INFO] - batch size              : 64
[2024-10-22 19:06:32,751][root][INFO] - accumulation steps      : 1
[2024-10-22 19:06:32,751][root][INFO] - optimizer               : adamwscale
[2024-10-22 19:06:32,751][root][INFO] - lr_scheduler            : cosine
[2024-10-22 19:06:32,751][root][INFO] - learning rate           : 0.02
[2024-10-22 19:06:32,751][root][INFO] - max length              : 256

[2024-10-22 19:06:32,751][root][INFO] - LoRA Configuration
[2024-10-22 19:06:32,751][root][INFO] - ㄴ r                    : 32
[2024-10-22 19:06:32,751][root][INFO] - ㄴ alpha                : 128
[2024-10-22 19:06:32,751][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 19:06:32,752][root][INFO] - 

[2024-10-22 19:06:32,752][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs
[2024-10-22 19:06:32,752][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 19:06:32,752][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-22 19:06:32,752][root][INFO] - * tb interval   : 10000

[2024-10-22 19:06:32,752][root][INFO] - 

[2024-10-22 19:06:32,752][root][INFO] - Start the Training !
[2024-10-22 19:06:32,754][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 19:07:06,439][root][INFO] - Step: 90/1350  |  Loss: 1.8011  |  Score: 44.78 [%]  |  Seq Length: 256.0
[2024-10-22 19:07:10,288][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 19:07:10,288][root][INFO] - Score: 74.37 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:07:13,848][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 19:07:13,848][root][INFO] - Score: 67.10 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:07:13,849][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 19:07:13,849][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:07:15,367][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:07:15,414][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:07:15,415][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:07:15,415][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:07:15,415][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:07:15,415][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:07:15,417][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:07:16,878][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 19:07:50,611][root][INFO] - Step: 180/1350  |  Loss: 1.1911  |  Score: 68.20 [%]  |  Seq Length: 256.0
[2024-10-22 19:07:54,442][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 19:07:54,443][root][INFO] - Score: 76.93 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:07:58,061][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 19:07:58,061][root][INFO] - Score: 67.81 [%]  |  Evaluation Time: 3.62 [s]
[2024-10-22 19:07:58,062][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 19:07:58,062][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:07:59,548][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:07:59,592][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:07:59,593][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:07:59,593][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:07:59,593][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:07:59,593][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:07:59,594][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:08:01,003][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 19:08:34,714][root][INFO] - Step: 270/1350  |  Loss: 0.9066  |  Score: 74.35 [%]  |  Seq Length: 256.0
[2024-10-22 19:08:38,562][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 19:08:38,562][root][INFO] - Score: 76.99 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:08:42,108][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 19:08:42,108][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:08:42,109][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 19:08:42,110][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:08:43,621][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:08:43,650][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:08:43,651][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:08:43,651][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:08:43,651][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:08:43,651][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:08:43,652][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:08:45,045][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 19:09:18,778][root][INFO] - Step: 360/1350  |  Loss: 0.7819  |  Score: 78.60 [%]  |  Seq Length: 256.0
[2024-10-22 19:09:22,636][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 19:09:22,636][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:09:26,210][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 19:09:26,210][root][INFO] - Score: 71.61 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 19:09:26,211][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 19:09:26,211][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:09:27,708][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:09:27,753][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:09:27,754][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:09:27,754][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:09:27,754][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:09:27,754][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:09:27,755][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:09:29,138][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 19:10:02,819][root][INFO] - Step: 450/1350  |  Loss: 0.6166  |  Score: 82.76 [%]  |  Seq Length: 256.0
[2024-10-22 19:10:06,651][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 19:10:06,651][root][INFO] - Score: 77.49 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:10:10,229][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 19:10:10,229][root][INFO] - Score: 70.44 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:10:10,231][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 19:10:43,977][root][INFO] - Step: 540/1350  |  Loss: 0.5005  |  Score: 85.68 [%]  |  Seq Length: 256.0
[2024-10-22 19:10:47,826][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 19:10:47,826][root][INFO] - Score: 76.62 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:10:51,407][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 19:10:51,408][root][INFO] - Score: 69.78 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:10:51,409][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 19:11:25,294][root][INFO] - Step: 630/1350  |  Loss: 0.4048  |  Score: 88.92 [%]  |  Seq Length: 256.0
[2024-10-22 19:11:29,147][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 19:11:29,147][root][INFO] - Score: 78.04 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:11:32,706][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 19:11:32,706][root][INFO] - Score: 68.84 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:11:32,708][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 19:12:06,563][root][INFO] - Step: 720/1350  |  Loss: 0.3505  |  Score: 90.00 [%]  |  Seq Length: 256.0
[2024-10-22 19:12:10,406][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 19:12:10,407][root][INFO] - Score: 77.75 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 19:12:13,942][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 19:12:13,942][root][INFO] - Score: 69.53 [%]  |  Evaluation Time: 3.53 [s]
[2024-10-22 19:12:13,944][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 19:12:47,633][root][INFO] - Step: 810/1350  |  Loss: 0.2864  |  Score: 91.58 [%]  |  Seq Length: 256.0
[2024-10-22 19:12:51,468][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 19:12:51,468][root][INFO] - Score: 78.64 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:12:54,989][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 19:12:54,989][root][INFO] - Score: 69.65 [%]  |  Evaluation Time: 3.52 [s]
[2024-10-22 19:12:54,991][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 19:13:28,699][root][INFO] - Step: 900/1350  |  Loss: 0.2603  |  Score: 92.71 [%]  |  Seq Length: 256.0
[2024-10-22 19:13:32,535][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 19:13:32,535][root][INFO] - Score: 78.41 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:13:36,109][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 19:13:36,109][root][INFO] - Score: 71.37 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 19:13:36,110][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 19:13:36,110][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:13:37,629][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:13:37,659][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:13:37,659][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:13:37,659][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:13:37,659][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:13:37,659][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:13:37,660][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:13:39,061][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 19:14:12,794][root][INFO] - Step: 990/1350  |  Loss: 0.2214  |  Score: 93.61 [%]  |  Seq Length: 256.0
[2024-10-22 19:14:16,634][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 19:14:16,635][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 19:14:20,288][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 19:14:20,289][root][INFO] - Score: 69.88 [%]  |  Evaluation Time: 3.65 [s]
[2024-10-22 19:14:20,291][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 19:14:53,945][root][INFO] - Step: 1080/1350  |  Loss: 0.1980  |  Score: 94.16 [%]  |  Seq Length: 256.0
[2024-10-22 19:14:57,732][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 19:14:57,732][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 3.78 [s]
[2024-10-22 19:15:01,297][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 19:15:01,297][root][INFO] - Score: 70.02 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:15:01,299][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 19:15:33,462][root][INFO] - Step: 10000/10550  |  Loss: 0.1941  |  Score: 92.17 [%]  |  Seq Length: 256.0
[2024-10-22 19:15:34,964][root][INFO] - Step: 1170/1350  |  Loss: 0.1773  |  Score: 94.60 [%]  |  Seq Length: 256.0
[2024-10-22 19:15:38,828][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 19:15:38,828][root][INFO] - Score: 78.91 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 19:15:42,437][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 19:15:42,437][root][INFO] - Score: 69.80 [%]  |  Evaluation Time: 3.61 [s]
[2024-10-22 19:15:42,440][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 19:16:16,227][root][INFO] - Step: 1260/1350  |  Loss: 0.1743  |  Score: 94.77 [%]  |  Seq Length: 256.0
[2024-10-22 19:16:20,097][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 19:16:20,097][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 3.87 [s]
[2024-10-22 19:16:23,662][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 19:16:23,662][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:16:23,664][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 19:16:57,365][root][INFO] - Step: 1350/1350  |  Loss: 0.1640  |  Score: 95.00 [%]  |  Seq Length: 256.0
[2024-10-22 19:17:01,253][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 19:17:01,253][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 3.89 [s]
[2024-10-22 19:17:04,849][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 19:17:04,849][root][INFO] - Score: 69.41 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 19:17:04,850][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 19:17:04,850][root][INFO] - - Epoch: 10
[2024-10-22 19:17:04,850][root][INFO] - - DEV score: 78.41 [%]
[2024-10-22 19:17:04,850][root][INFO] - - TEST score: 71.37 [%]
[2024-10-22 19:17:04,851][root][INFO] - Fine-tuning is done!
[2024-10-22 19:17:04,852][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 19:17:04,852][root][INFO] - - BEST LR: 0.01
[2024-10-22 19:17:04,852][root][INFO] - - DEV score: 78.22 [%]
[2024-10-22 19:17:04,852][root][INFO] - - TEST score: 72.56 [%]
[2024-10-22 19:17:10,693][root][INFO] - 

[2024-10-22 19:17:10,693][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 19:17:10,693][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs
[2024-10-22 19:17:10,693][root][INFO] - 

[2024-10-22 19:17:10,693][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 19:17:15,195][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,196][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,196][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,197][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,197][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,198][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,198][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,199][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,199][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,200][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,200][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,201][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,201][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,202][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,202][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,203][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,203][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,204][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,204][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,205][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,205][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,206][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,206][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 19:17:15,207][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 19:17:15,209][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 19:17:15,213][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 19:17:15,422][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 19:17:15,424][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 19:17:15,618][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 19:17:18,786][root][INFO] - 

[2024-10-22 19:17:18,787][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 19:17:18,787][root][INFO] - Data Preprocessing
[2024-10-22 19:17:18,787][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 19:17:18,787][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 19:17:18,787][root][INFO] - ㄴ data_remove                False

[2024-10-22 19:17:18,787][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 19:17:18,795][root][INFO] - vocab size              : 51200
[2024-10-22 19:17:18,795][root][INFO] - device                  : gpu
[2024-10-22 19:17:18,795][root][INFO] - random seed             : 2
[2024-10-22 19:17:18,795][root][INFO] - train data size         : 5760
[2024-10-22 19:17:18,796][root][INFO] - max epochs              : 15
[2024-10-22 19:17:18,796][root][INFO] - total steps             : 1350
[2024-10-22 19:17:18,796][root][INFO] - warmup steps            : 135
[2024-10-22 19:17:18,796][root][INFO] - batch size              : 64
[2024-10-22 19:17:18,796][root][INFO] - accumulation steps      : 1
[2024-10-22 19:17:18,796][root][INFO] - optimizer               : adamwscale
[2024-10-22 19:17:18,796][root][INFO] - lr_scheduler            : cosine
[2024-10-22 19:17:18,796][root][INFO] - learning rate           : 0.01
[2024-10-22 19:17:18,796][root][INFO] - max length              : 256

[2024-10-22 19:17:18,796][root][INFO] - LoRA Configuration
[2024-10-22 19:17:18,796][root][INFO] - ㄴ r                    : 32
[2024-10-22 19:17:18,796][root][INFO] - ㄴ alpha                : 128
[2024-10-22 19:17:18,797][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 19:17:18,797][root][INFO] - KOMBO Configuration
[2024-10-22 19:17:18,797][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 19:17:18,797][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 19:17:18,797][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 19:17:18,797][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 19:17:18,797][root][INFO] - ㄴ do_combination       : True
[2024-10-22 19:17:18,797][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 19:17:18,797][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 19:17:18,797][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 19:17:18,798][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 19:17:18,798][root][INFO] - 

[2024-10-22 19:17:18,798][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs
[2024-10-22 19:17:18,798][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 19:17:18,798][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-22 19:17:18,798][root][INFO] - * tb interval   : 10000

[2024-10-22 19:17:18,798][root][INFO] - 

[2024-10-22 19:17:18,798][root][INFO] - Start the Training !
[2024-10-22 19:17:18,801][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 19:18:07,212][root][INFO] - Step: 90/1350  |  Loss: 2.0528  |  Score: 36.34 [%]  |  Seq Length: 256.0
[2024-10-22 19:18:13,473][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 19:18:13,474][root][INFO] - Score: 72.51 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 19:18:19,162][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 19:18:19,162][root][INFO] - Score: 60.47 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 19:18:19,163][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 19:18:19,163][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:18:19,166][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:18:20,052][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:18:20,165][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:18:20,165][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:18:20,166][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:18:20,166][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:18:20,166][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:18:20,167][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:18:20,920][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 19:18:54,893][root][INFO] - Step: 10550/10550  |  Loss: 0.1865  |  Score: 92.55 [%]  |  Seq Length: 256.0
[2024-10-22 19:19:09,118][root][INFO] - Step: 180/1350  |  Loss: 1.2527  |  Score: 65.10 [%]  |  Seq Length: 256.0
[2024-10-22 19:19:15,528][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 19:19:15,528][root][INFO] - Score: 77.02 [%]  |  Evaluation Time: 6.41 [s]
[2024-10-22 19:19:21,206][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 19:19:21,207][root][INFO] - Score: 67.72 [%]  |  Evaluation Time: 5.68 [s]
[2024-10-22 19:19:21,208][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 19:19:21,208][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:19:21,211][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:19:22,920][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:19:23,192][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:19:23,194][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:19:23,194][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:19:23,195][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:19:23,195][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:19:23,198][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:19:24,833][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 19:19:29,065][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 19:19:29,065][root][INFO] - Score: 88.96 [%]  |  Evaluation Time: 34.17 [s]
[2024-10-22 19:20:13,178][root][INFO] - Step: 270/1350  |  Loss: 0.9995  |  Score: 70.84 [%]  |  Seq Length: 256.0
[2024-10-22 19:20:19,464][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 19:20:19,464][root][INFO] - Score: 78.05 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 19:20:25,172][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 19:20:25,173][root][INFO] - Score: 70.16 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 19:20:25,173][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 19:20:25,174][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:20:25,176][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:20:26,965][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:20:27,247][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:20:27,248][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:20:27,248][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:20:27,249][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:20:27,249][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:20:27,252][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:20:28,874][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 19:21:17,018][root][INFO] - Step: 360/1350  |  Loss: 0.8748  |  Score: 75.10 [%]  |  Seq Length: 256.0
[2024-10-22 19:21:21,543][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 19:21:21,543][root][INFO] - Score: 89.03 [%]  |  Evaluation Time: 112.47 [s]
[2024-10-22 19:21:21,545][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 19:21:21,545][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 19:21:23,088][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:21:23,118][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:21:23,119][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:21:23,119][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:21:23,119][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:21:23,119][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:21:23,120][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:21:23,363][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 19:21:23,363][root][INFO] - Score: 78.04 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 19:21:24,579][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 19:21:24,579][root][INFO] - - Epoch: 5
[2024-10-22 19:21:24,579][root][INFO] - - DEV score: 88.96 [%]
[2024-10-22 19:21:24,580][root][INFO] - - TEST score: 89.03 [%]
[2024-10-22 19:21:24,581][root][INFO] - Fine-tuning is done!
[2024-10-22 19:21:29,055][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 19:21:29,055][root][INFO] - Score: 70.25 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 19:21:29,057][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 19:21:29,057][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:21:29,060][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:21:30,758][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:21:31,042][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:21:31,044][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:21:31,044][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:21:31,044][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:21:31,044][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:21:31,047][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:21:32,674][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 19:21:45,722][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,723][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,724][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,724][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,724][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,725][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,725][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,726][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,726][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,727][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,727][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,727][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,728][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,728][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,729][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,729][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,730][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,730][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,730][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,731][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,731][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,732][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,732][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 19:21:45,733][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 19:21:45,734][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 19:21:45,736][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 19:21:45,872][root][INFO] - 

[2024-10-22 19:21:45,872][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 19:21:45,872][root][INFO] - Data Preprocessing
[2024-10-22 19:21:45,872][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 19:21:45,872][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 19:21:45,872][root][INFO] - ㄴ data_remove                False

[2024-10-22 19:21:45,873][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 19:21:45,880][root][INFO] - vocab size              : 51200
[2024-10-22 19:21:45,880][root][INFO] - device                  : gpu
[2024-10-22 19:21:45,880][root][INFO] - random seed             : 1
[2024-10-22 19:21:45,880][root][INFO] - train data size         : 135040
[2024-10-22 19:21:45,881][root][INFO] - max epochs              : 5
[2024-10-22 19:21:45,881][root][INFO] - total steps             : 10550
[2024-10-22 19:21:45,881][root][INFO] - warmup steps            : 1055
[2024-10-22 19:21:45,881][root][INFO] - batch size              : 64
[2024-10-22 19:21:45,881][root][INFO] - accumulation steps      : 1
[2024-10-22 19:21:45,881][root][INFO] - optimizer               : adamwscale
[2024-10-22 19:21:45,881][root][INFO] - lr_scheduler            : cosine
[2024-10-22 19:21:45,881][root][INFO] - learning rate           : 0.02
[2024-10-22 19:21:45,881][root][INFO] - max length              : 256

[2024-10-22 19:21:45,881][root][INFO] - LoRA Configuration
[2024-10-22 19:21:45,881][root][INFO] - ㄴ r                    : 32
[2024-10-22 19:21:45,882][root][INFO] - ㄴ alpha                : 128
[2024-10-22 19:21:45,882][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 19:21:45,882][root][INFO] - 

[2024-10-22 19:21:45,882][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 19:21:45,882][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 19:21:45,882][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 19:21:45,882][root][INFO] - * tb interval   : 10000

[2024-10-22 19:21:45,882][root][INFO] - 

[2024-10-22 19:21:45,882][root][INFO] - Start the Training !
[2024-10-22 19:21:45,884][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 19:22:20,819][root][INFO] - Step: 450/1350  |  Loss: 0.7541  |  Score: 78.31 [%]  |  Seq Length: 256.0
[2024-10-22 19:22:27,258][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 19:22:27,259][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 6.44 [s]
[2024-10-22 19:22:33,031][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 19:22:33,031][root][INFO] - Score: 71.66 [%]  |  Evaluation Time: 5.77 [s]
[2024-10-22 19:22:33,032][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 19:22:33,032][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:22:33,035][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:22:34,753][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:22:35,028][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:22:35,029][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:22:35,030][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:22:35,030][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:22:35,030][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:22:35,032][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:22:36,660][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 19:23:24,859][root][INFO] - Step: 540/1350  |  Loss: 0.6182  |  Score: 82.05 [%]  |  Seq Length: 256.0
[2024-10-22 19:23:31,113][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 19:23:31,114][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 6.25 [s]
[2024-10-22 19:23:36,781][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 19:23:36,782][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 19:23:36,784][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 19:24:24,979][root][INFO] - Step: 630/1350  |  Loss: 0.5624  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-22 19:24:31,289][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 19:24:31,289][root][INFO] - Score: 78.80 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 19:24:36,995][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 19:24:36,995][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 19:24:36,997][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 19:25:25,271][root][INFO] - Step: 720/1350  |  Loss: 0.5091  |  Score: 85.61 [%]  |  Seq Length: 256.0
[2024-10-22 19:25:31,569][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 19:25:31,570][root][INFO] - Score: 77.62 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 19:25:37,227][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 19:25:37,227][root][INFO] - Score: 72.40 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 19:25:37,229][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 19:26:25,628][root][INFO] - Step: 810/1350  |  Loss: 0.4368  |  Score: 87.42 [%]  |  Seq Length: 256.0
[2024-10-22 19:26:31,990][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 19:26:31,990][root][INFO] - Score: 78.55 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-22 19:26:37,793][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 19:26:37,794][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-22 19:26:37,796][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 19:27:06,042][root][INFO] - Step: 10000/73665  |  Loss: 0.7337  |  Score: 68.23 [%]  |  Seq Length: 256.0
[2024-10-22 19:27:26,312][root][INFO] - Step: 900/1350  |  Loss: 0.3967  |  Score: 88.60 [%]  |  Seq Length: 256.0
[2024-10-22 19:27:32,571][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 19:27:32,571][root][INFO] - Score: 78.33 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 19:27:38,409][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 19:27:38,409][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 5.84 [s]
[2024-10-22 19:27:38,411][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 19:28:26,630][root][INFO] - Step: 990/1350  |  Loss: 0.3673  |  Score: 89.12 [%]  |  Seq Length: 256.0
[2024-10-22 19:28:32,901][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 19:28:32,901][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 19:28:38,595][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 19:28:38,595][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 19:28:38,597][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 19:29:27,059][root][INFO] - Step: 1080/1350  |  Loss: 0.3257  |  Score: 90.35 [%]  |  Seq Length: 256.0
[2024-10-22 19:29:33,338][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 19:29:33,339][root][INFO] - Score: 78.35 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 19:29:39,063][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 19:29:39,063][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 19:29:39,065][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 19:30:27,723][root][INFO] - Step: 1170/1350  |  Loss: 0.3240  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-22 19:30:33,966][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 19:30:33,966][root][INFO] - Score: 78.18 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 19:30:39,673][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 19:30:39,673][root][INFO] - Score: 71.40 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 19:30:39,675][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 19:31:27,948][root][INFO] - Step: 1260/1350  |  Loss: 0.3043  |  Score: 90.68 [%]  |  Seq Length: 256.0
[2024-10-22 19:31:34,210][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 19:31:34,210][root][INFO] - Score: 78.05 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 19:31:39,874][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 19:31:39,874][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 19:31:39,877][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 19:32:28,298][root][INFO] - Step: 1350/1350  |  Loss: 0.3014  |  Score: 90.76 [%]  |  Seq Length: 256.0
[2024-10-22 19:32:34,563][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 19:32:34,563][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 19:32:40,221][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 19:32:40,221][root][INFO] - Score: 71.21 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 19:32:40,222][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 19:32:40,222][root][INFO] - - Epoch: 5
[2024-10-22 19:32:40,222][root][INFO] - - DEV score: 79.59 [%]
[2024-10-22 19:32:40,222][root][INFO] - - TEST score: 71.66 [%]
[2024-10-22 19:32:40,223][root][INFO] - Fine-tuning is done!
[2024-10-22 19:32:43,621][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,622][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,622][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,623][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,624][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,624][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,625][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,626][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,626][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,627][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,627][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,628][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,628][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,629][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,630][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,630][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,631][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,631][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,632][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,632][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,633][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,633][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,634][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 19:32:43,634][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 19:32:43,637][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 19:32:43,846][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 19:32:43,848][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 19:32:43,850][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 19:32:44,020][root][INFO] - 

[2024-10-22 19:32:44,020][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 19:32:44,020][root][INFO] - Data Preprocessing
[2024-10-22 19:32:44,020][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 19:32:44,020][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 19:32:44,020][root][INFO] - ㄴ data_remove                False

[2024-10-22 19:32:44,020][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 19:32:44,027][root][INFO] - vocab size              : 51200
[2024-10-22 19:32:44,027][root][INFO] - device                  : gpu
[2024-10-22 19:32:44,027][root][INFO] - random seed             : 2
[2024-10-22 19:32:44,028][root][INFO] - train data size         : 5760
[2024-10-22 19:32:44,028][root][INFO] - max epochs              : 15
[2024-10-22 19:32:44,028][root][INFO] - total steps             : 1350
[2024-10-22 19:32:44,028][root][INFO] - warmup steps            : 135
[2024-10-22 19:32:44,028][root][INFO] - batch size              : 64
[2024-10-22 19:32:44,028][root][INFO] - accumulation steps      : 1
[2024-10-22 19:32:44,028][root][INFO] - optimizer               : adamwscale
[2024-10-22 19:32:44,028][root][INFO] - lr_scheduler            : cosine
[2024-10-22 19:32:44,028][root][INFO] - learning rate           : 0.02
[2024-10-22 19:32:44,028][root][INFO] - max length              : 256

[2024-10-22 19:32:44,028][root][INFO] - LoRA Configuration
[2024-10-22 19:32:44,029][root][INFO] - ㄴ r                    : 32
[2024-10-22 19:32:44,029][root][INFO] - ㄴ alpha                : 128
[2024-10-22 19:32:44,029][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 19:32:44,029][root][INFO] - KOMBO Configuration
[2024-10-22 19:32:44,029][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 19:32:44,029][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 19:32:44,029][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 19:32:44,029][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 19:32:44,029][root][INFO] - ㄴ do_combination       : True
[2024-10-22 19:32:44,029][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 19:32:44,030][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 19:32:44,030][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 19:32:44,030][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 19:32:44,030][root][INFO] - 

[2024-10-22 19:32:44,030][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs
[2024-10-22 19:32:44,030][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-22 19:32:44,030][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-22 19:32:44,030][root][INFO] - * tb interval   : 10000

[2024-10-22 19:32:44,030][root][INFO] - 

[2024-10-22 19:32:44,030][root][INFO] - Start the Training !
[2024-10-22 19:32:44,033][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 19:33:32,665][root][INFO] - Step: 90/1350  |  Loss: 1.8175  |  Score: 45.41 [%]  |  Seq Length: 256.0
[2024-10-22 19:33:39,055][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 19:33:39,055][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 6.39 [s]
[2024-10-22 19:33:44,857][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 19:33:44,858][root][INFO] - Score: 64.34 [%]  |  Evaluation Time: 5.80 [s]
[2024-10-22 19:33:44,859][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 19:33:44,859][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:33:44,862][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:33:46,616][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:33:46,865][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:33:46,867][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:33:46,867][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:33:46,868][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:33:46,868][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:33:46,871][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:33:48,521][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 19:34:37,332][root][INFO] - Step: 180/1350  |  Loss: 1.0927  |  Score: 67.88 [%]  |  Seq Length: 256.0
[2024-10-22 19:34:40,300][root][INFO] - Step: 2110/10550  |  Loss: 0.3670  |  Score: 83.76 [%]  |  Seq Length: 256.0
[2024-10-22 19:34:43,653][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 19:34:43,653][root][INFO] - Score: 77.26 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 19:34:49,378][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 19:34:49,378][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 19:34:49,379][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 19:34:49,379][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:34:49,382][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:34:51,072][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:34:51,361][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:34:51,363][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:34:51,363][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:34:51,363][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:34:51,363][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:34:51,367][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:34:53,046][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 19:35:14,416][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 19:35:14,416][root][INFO] - Score: 86.84 [%]  |  Evaluation Time: 34.11 [s]
[2024-10-22 19:35:41,328][root][INFO] - Step: 270/1350  |  Loss: 0.9015  |  Score: 74.46 [%]  |  Seq Length: 256.0
[2024-10-22 19:35:47,690][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 19:35:47,690][root][INFO] - Score: 78.15 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-22 19:35:53,397][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 19:35:53,397][root][INFO] - Score: 70.89 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 19:35:53,398][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 19:35:53,399][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:35:53,401][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:35:55,098][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:35:55,367][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:35:55,369][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:35:55,369][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:35:55,369][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:35:55,369][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:35:55,372][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:35:56,983][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 19:36:45,217][root][INFO] - Step: 360/1350  |  Loss: 0.7460  |  Score: 79.24 [%]  |  Seq Length: 256.0
[2024-10-22 19:36:51,533][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 19:36:51,533][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 19:36:57,259][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 19:36:57,260][root][INFO] - Score: 69.29 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 19:36:57,262][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 19:37:07,011][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 19:37:07,011][root][INFO] - Score: 86.38 [%]  |  Evaluation Time: 112.59 [s]
[2024-10-22 19:37:07,012][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 19:37:07,013][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 19:37:08,560][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:37:08,589][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:37:08,589][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:37:08,590][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:37:08,590][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:37:08,590][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:37:08,591][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:37:09,983][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 19:37:45,478][root][INFO] - Step: 450/1350  |  Loss: 0.6289  |  Score: 82.70 [%]  |  Seq Length: 256.0
[2024-10-22 19:37:51,778][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 19:37:51,779][root][INFO] - Score: 79.05 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 19:37:57,509][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 19:37:57,509][root][INFO] - Score: 70.23 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 19:37:57,510][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 19:37:57,511][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:37:57,514][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:37:59,216][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:37:59,486][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:37:59,487][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:37:59,488][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:37:59,489][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:37:59,489][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:37:59,492][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:38:01,127][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 19:38:49,679][root][INFO] - Step: 540/1350  |  Loss: 0.5106  |  Score: 86.26 [%]  |  Seq Length: 256.0
[2024-10-22 19:38:55,972][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 19:38:55,972][root][INFO] - Score: 77.19 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 19:39:01,670][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 19:39:01,670][root][INFO] - Score: 70.36 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 19:39:01,673][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 19:39:49,029][root][INFO] - Step: 630/1350  |  Loss: 0.4245  |  Score: 87.66 [%]  |  Seq Length: 256.0
[2024-10-22 19:39:55,306][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 19:39:55,306][root][INFO] - Score: 77.77 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 19:40:01,020][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 19:40:01,020][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 19:40:01,022][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 19:40:48,821][root][INFO] - Step: 720/1350  |  Loss: 0.3709  |  Score: 89.80 [%]  |  Seq Length: 256.0
[2024-10-22 19:40:55,148][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 19:40:55,149][root][INFO] - Score: 78.10 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 19:41:00,880][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 19:41:00,880][root][INFO] - Score: 71.18 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 19:41:00,881][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-22 19:41:00,882][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:41:00,885][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:41:02,584][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:41:02,870][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:41:02,871][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:41:02,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:41:02,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:41:02,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:41:02,875][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:41:04,528][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 19:41:52,827][root][INFO] - Step: 810/1350  |  Loss: 0.2888  |  Score: 91.81 [%]  |  Seq Length: 256.0
[2024-10-22 19:41:59,144][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 19:41:59,144][root][INFO] - Score: 77.85 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 19:42:04,851][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 19:42:04,852][root][INFO] - Score: 70.33 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 19:42:04,853][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 19:42:52,612][root][INFO] - Step: 900/1350  |  Loss: 0.2524  |  Score: 92.90 [%]  |  Seq Length: 256.0
[2024-10-22 19:42:58,911][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 19:42:58,911][root][INFO] - Score: 77.75 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 19:43:04,605][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 19:43:04,606][root][INFO] - Score: 70.62 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 19:43:04,608][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 19:43:52,893][root][INFO] - Step: 990/1350  |  Loss: 0.2191  |  Score: 93.31 [%]  |  Seq Length: 256.0
[2024-10-22 19:43:59,169][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 19:43:59,169][root][INFO] - Score: 78.99 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 19:44:04,888][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 19:44:04,888][root][INFO] - Score: 70.48 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 19:44:04,889][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-22 19:44:04,890][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:44:04,892][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:44:06,602][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:44:06,887][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:44:06,888][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:44:06,888][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:44:06,889][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:44:06,889][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:44:06,891][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:44:08,505][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 19:44:56,736][root][INFO] - Step: 1080/1350  |  Loss: 0.1850  |  Score: 94.48 [%]  |  Seq Length: 256.0
[2024-10-22 19:45:03,036][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 19:45:03,036][root][INFO] - Score: 78.39 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 19:45:08,753][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 19:45:08,753][root][INFO] - Score: 70.56 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 19:45:08,755][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 19:45:56,946][root][INFO] - Step: 1170/1350  |  Loss: 0.1837  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-22 19:46:03,264][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 19:46:03,264][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 19:46:08,973][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 19:46:08,973][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 5.71 [s]
[2024-10-22 19:46:08,974][root][INFO] - 
Save new Best Score (Epoch: 13)
[2024-10-22 19:46:08,975][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 19:46:08,977][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 19:46:10,672][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:46:10,958][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:46:10,959][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:46:10,959][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:46:10,960][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:46:10,960][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:46:10,963][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:46:12,643][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 19:47:00,887][root][INFO] - Step: 1260/1350  |  Loss: 0.1689  |  Score: 94.86 [%]  |  Seq Length: 256.0
[2024-10-22 19:47:07,202][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 19:47:07,202][root][INFO] - Score: 78.55 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 19:47:12,899][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 19:47:12,899][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.69 [s]
[2024-10-22 19:47:12,902][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 19:48:01,103][root][INFO] - Step: 1350/1350  |  Loss: 0.1582  |  Score: 95.16 [%]  |  Seq Length: 256.0
[2024-10-22 19:48:07,444][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 19:48:07,444][root][INFO] - Score: 78.44 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 19:48:13,193][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 19:48:13,193][root][INFO] - Score: 70.44 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 19:48:13,194][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 19:48:13,195][root][INFO] - - Epoch: 13
[2024-10-22 19:48:13,195][root][INFO] - - DEV score: 78.92 [%]
[2024-10-22 19:48:13,195][root][INFO] - - TEST score: 70.60 [%]
[2024-10-22 19:48:13,196][root][INFO] - Fine-tuning is done!
[2024-10-22 19:48:13,196][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 19:48:13,196][root][INFO] - - BEST LR: 0.01
[2024-10-22 19:48:13,196][root][INFO] - - DEV score: 79.59 [%]
[2024-10-22 19:48:13,196][root][INFO] - - TEST score: 71.66 [%]
[2024-10-22 19:48:19,375][root][INFO] - 

[2024-10-22 19:48:19,375][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 19:48:19,376][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs
[2024-10-22 19:48:19,376][root][INFO] - 

[2024-10-22 19:48:19,376][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 19:48:23,958][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,959][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,959][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,960][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,960][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,960][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,961][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,961][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,962][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,962][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,963][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,963][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,963][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,964][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,964][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,965][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,965][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,966][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,966][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,966][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,971][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,971][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,972][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 19:48:23,972][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 19:48:23,974][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 19:48:24,163][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 19:48:26,089][root][INFO] - 

[2024-10-22 19:48:26,089][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 19:48:26,089][root][INFO] - Data Preprocessing
[2024-10-22 19:48:26,089][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 19:48:26,089][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 19:48:26,089][root][INFO] - ㄴ data_remove                False

[2024-10-22 19:48:26,090][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 19:48:26,097][root][INFO] - vocab size              : 51200
[2024-10-22 19:48:26,097][root][INFO] - device                  : gpu
[2024-10-22 19:48:26,097][root][INFO] - random seed             : 3
[2024-10-22 19:48:26,097][root][INFO] - train data size         : 5760
[2024-10-22 19:48:26,097][root][INFO] - max epochs              : 15
[2024-10-22 19:48:26,097][root][INFO] - total steps             : 1350
[2024-10-22 19:48:26,097][root][INFO] - warmup steps            : 135
[2024-10-22 19:48:26,097][root][INFO] - batch size              : 64
[2024-10-22 19:48:26,098][root][INFO] - accumulation steps      : 1
[2024-10-22 19:48:26,098][root][INFO] - optimizer               : adamwscale
[2024-10-22 19:48:26,098][root][INFO] - lr_scheduler            : cosine
[2024-10-22 19:48:26,098][root][INFO] - learning rate           : 0.01
[2024-10-22 19:48:26,098][root][INFO] - max length              : 256

[2024-10-22 19:48:26,098][root][INFO] - LoRA Configuration
[2024-10-22 19:48:26,098][root][INFO] - ㄴ r                    : 32
[2024-10-22 19:48:26,098][root][INFO] - ㄴ alpha                : 128
[2024-10-22 19:48:26,098][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 19:48:26,098][root][INFO] - 

[2024-10-22 19:48:26,098][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs
[2024-10-22 19:48:26,099][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 19:48:26,099][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-22 19:48:26,099][root][INFO] - * tb interval   : 10000

[2024-10-22 19:48:26,099][root][INFO] - 

[2024-10-22 19:48:26,099][root][INFO] - Start the Training !
[2024-10-22 19:48:26,101][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 19:49:00,675][root][INFO] - Step: 90/1350  |  Loss: 2.3167  |  Score: 32.00 [%]  |  Seq Length: 256.0
[2024-10-22 19:49:04,478][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 19:49:04,479][root][INFO] - Score: 69.48 [%]  |  Evaluation Time: 3.80 [s]
[2024-10-22 19:49:07,987][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 19:49:07,987][root][INFO] - Score: 61.24 [%]  |  Evaluation Time: 3.51 [s]
[2024-10-22 19:49:07,988][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 19:49:07,988][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 19:49:08,816][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:49:08,841][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:49:08,841][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:49:08,842][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:49:08,842][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:49:08,842][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:49:08,843][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:49:09,503][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 19:49:43,406][root][INFO] - Step: 180/1350  |  Loss: 1.2255  |  Score: 63.98 [%]  |  Seq Length: 256.0
[2024-10-22 19:49:47,255][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 19:49:47,255][root][INFO] - Score: 75.70 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:49:50,797][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 19:49:50,797][root][INFO] - Score: 68.52 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:49:50,798][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 19:49:50,799][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 19:49:52,308][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:49:52,344][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:49:52,344][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:49:52,344][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:49:52,344][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:49:52,345][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:49:52,346][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:49:53,757][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 19:50:05,650][root][INFO] - Step: 4220/10550  |  Loss: 0.3135  |  Score: 86.61 [%]  |  Seq Length: 256.0
[2024-10-22 19:50:27,435][root][INFO] - Step: 270/1350  |  Loss: 1.0451  |  Score: 71.34 [%]  |  Seq Length: 256.0
[2024-10-22 19:50:31,285][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 19:50:31,286][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:50:34,872][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 19:50:34,872][root][INFO] - Score: 68.66 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:50:34,873][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 19:50:34,873][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 19:50:36,365][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:50:36,410][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:50:36,410][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:50:36,411][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:50:36,411][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:50:36,411][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:50:36,412][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:50:37,796][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 19:50:39,768][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 19:50:39,768][root][INFO] - Score: 87.52 [%]  |  Evaluation Time: 34.11 [s]
[2024-10-22 19:51:11,499][root][INFO] - Step: 360/1350  |  Loss: 0.8745  |  Score: 74.81 [%]  |  Seq Length: 256.0
[2024-10-22 19:51:15,341][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 19:51:15,341][root][INFO] - Score: 77.19 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 19:51:18,903][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 19:51:18,904][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:51:18,905][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 19:51:18,905][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 19:51:20,440][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:51:20,470][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:51:20,471][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:51:20,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:51:20,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:51:20,471][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:51:20,472][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:51:21,857][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 19:51:55,505][root][INFO] - Step: 450/1350  |  Loss: 0.7797  |  Score: 77.58 [%]  |  Seq Length: 256.0
[2024-10-22 19:51:59,357][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 19:51:59,357][root][INFO] - Score: 78.01 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:52:02,895][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 19:52:02,896][root][INFO] - Score: 69.62 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:52:02,897][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 19:52:32,438][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 19:52:32,438][root][INFO] - Score: 87.01 [%]  |  Evaluation Time: 112.67 [s]
[2024-10-22 19:52:32,440][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 19:52:32,440][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 19:52:34,038][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:52:34,068][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:52:34,069][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:52:34,069][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:52:34,069][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:52:34,069][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:52:34,070][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:52:35,476][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 19:52:36,618][root][INFO] - Step: 540/1350  |  Loss: 0.6611  |  Score: 81.27 [%]  |  Seq Length: 256.0
[2024-10-22 19:52:40,471][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 19:52:40,471][root][INFO] - Score: 79.08 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:52:44,052][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 19:52:44,052][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:52:44,054][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 19:52:44,054][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 19:52:45,563][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:52:45,594][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:52:45,595][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:52:45,595][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:52:45,595][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:52:45,595][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:52:45,596][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:52:46,982][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 19:53:20,770][root][INFO] - Step: 630/1350  |  Loss: 0.6004  |  Score: 83.36 [%]  |  Seq Length: 256.0
[2024-10-22 19:53:24,585][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 19:53:24,585][root][INFO] - Score: 78.33 [%]  |  Evaluation Time: 3.81 [s]
[2024-10-22 19:53:28,145][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 19:53:28,146][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:53:28,148][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 19:54:01,880][root][INFO] - Step: 720/1350  |  Loss: 0.5254  |  Score: 84.93 [%]  |  Seq Length: 256.0
[2024-10-22 19:54:05,713][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 19:54:05,713][root][INFO] - Score: 77.71 [%]  |  Evaluation Time: 3.83 [s]
[2024-10-22 19:54:09,238][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 19:54:09,239][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 3.52 [s]
[2024-10-22 19:54:09,241][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 19:54:42,899][root][INFO] - Step: 810/1350  |  Loss: 0.4674  |  Score: 86.86 [%]  |  Seq Length: 256.0
[2024-10-22 19:54:46,740][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 19:54:46,741][root][INFO] - Score: 77.82 [%]  |  Evaluation Time: 3.84 [s]
[2024-10-22 19:54:50,288][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 19:54:50,289][root][INFO] - Score: 72.22 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 19:54:50,291][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 19:55:23,975][root][INFO] - Step: 900/1350  |  Loss: 0.4276  |  Score: 87.94 [%]  |  Seq Length: 256.0
[2024-10-22 19:55:27,826][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 19:55:27,827][root][INFO] - Score: 78.46 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:55:31,370][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 19:55:31,370][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:55:31,372][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 19:56:05,036][root][INFO] - Step: 990/1350  |  Loss: 0.3816  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-22 19:56:08,887][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 19:56:08,887][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:56:12,447][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 19:56:12,448][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 3.56 [s]
[2024-10-22 19:56:12,450][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 19:56:46,119][root][INFO] - Step: 1080/1350  |  Loss: 0.3498  |  Score: 89.58 [%]  |  Seq Length: 256.0
[2024-10-22 19:56:49,939][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 19:56:49,939][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 3.82 [s]
[2024-10-22 19:56:53,480][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 19:56:53,481][root][INFO] - Score: 71.84 [%]  |  Evaluation Time: 3.54 [s]
[2024-10-22 19:56:53,483][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 19:57:27,270][root][INFO] - Step: 1170/1350  |  Loss: 0.3294  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-22 19:57:31,122][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 19:57:31,122][root][INFO] - Score: 78.15 [%]  |  Evaluation Time: 3.85 [s]
[2024-10-22 19:57:34,707][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 19:57:34,708][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 19:57:34,710][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 19:58:08,488][root][INFO] - Step: 1260/1350  |  Loss: 0.3282  |  Score: 90.20 [%]  |  Seq Length: 256.0
[2024-10-22 19:58:12,356][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 19:58:12,356][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 19:58:15,904][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 19:58:15,904][root][INFO] - Score: 71.77 [%]  |  Evaluation Time: 3.55 [s]
[2024-10-22 19:58:15,906][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 19:58:49,700][root][INFO] - Step: 1350/1350  |  Loss: 0.3230  |  Score: 90.66 [%]  |  Seq Length: 256.0
[2024-10-22 19:58:53,617][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 19:58:53,617][root][INFO] - Score: 78.15 [%]  |  Evaluation Time: 3.91 [s]
[2024-10-22 19:58:57,210][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 19:58:57,210][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 19:58:57,211][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 19:58:57,211][root][INFO] - - Epoch: 6
[2024-10-22 19:58:57,211][root][INFO] - - DEV score: 79.08 [%]
[2024-10-22 19:58:57,211][root][INFO] - - TEST score: 71.56 [%]
[2024-10-22 19:58:57,213][root][INFO] - Fine-tuning is done!
[2024-10-22 19:59:00,570][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,570][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,571][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,572][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,572][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,573][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,573][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,574][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,574][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,575][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,575][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,576][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,576][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,577][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,578][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,578][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,579][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,579][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,580][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,580][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,581][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,581][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,582][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 19:59:00,583][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 19:59:00,585][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 19:59:00,586][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 19:59:00,744][root][INFO] - 

[2024-10-22 19:59:00,745][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 19:59:00,745][root][INFO] - Data Preprocessing
[2024-10-22 19:59:00,745][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 19:59:00,745][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 19:59:00,745][root][INFO] - ㄴ data_remove                False

[2024-10-22 19:59:00,745][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 19:59:00,752][root][INFO] - vocab size              : 51200
[2024-10-22 19:59:00,752][root][INFO] - device                  : gpu
[2024-10-22 19:59:00,752][root][INFO] - random seed             : 3
[2024-10-22 19:59:00,752][root][INFO] - train data size         : 5760
[2024-10-22 19:59:00,752][root][INFO] - max epochs              : 15
[2024-10-22 19:59:00,753][root][INFO] - total steps             : 1350
[2024-10-22 19:59:00,753][root][INFO] - warmup steps            : 135
[2024-10-22 19:59:00,753][root][INFO] - batch size              : 64
[2024-10-22 19:59:00,753][root][INFO] - accumulation steps      : 1
[2024-10-22 19:59:00,753][root][INFO] - optimizer               : adamwscale
[2024-10-22 19:59:00,753][root][INFO] - lr_scheduler            : cosine
[2024-10-22 19:59:00,753][root][INFO] - learning rate           : 0.02
[2024-10-22 19:59:00,753][root][INFO] - max length              : 256

[2024-10-22 19:59:00,753][root][INFO] - LoRA Configuration
[2024-10-22 19:59:00,753][root][INFO] - ㄴ r                    : 32
[2024-10-22 19:59:00,753][root][INFO] - ㄴ alpha                : 128
[2024-10-22 19:59:00,754][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 19:59:00,754][root][INFO] - 

[2024-10-22 19:59:00,754][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs
[2024-10-22 19:59:00,754][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 19:59:00,754][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-22 19:59:00,754][root][INFO] - * tb interval   : 10000

[2024-10-22 19:59:00,754][root][INFO] - 

[2024-10-22 19:59:00,754][root][INFO] - Start the Training !
[2024-10-22 19:59:00,756][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 19:59:34,555][root][INFO] - Step: 90/1350  |  Loss: 2.0265  |  Score: 42.13 [%]  |  Seq Length: 256.0
[2024-10-22 19:59:38,433][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 19:59:38,434][root][INFO] - Score: 73.26 [%]  |  Evaluation Time: 3.87 [s]
[2024-10-22 19:59:42,038][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 19:59:42,038][root][INFO] - Score: 63.55 [%]  |  Evaluation Time: 3.60 [s]
[2024-10-22 19:59:42,039][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 19:59:42,040][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 19:59:43,602][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 19:59:43,637][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 19:59:43,638][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 19:59:43,638][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 19:59:43,638][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 19:59:43,639][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 19:59:43,640][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 19:59:45,068][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 20:00:18,773][root][INFO] - Step: 180/1350  |  Loss: 1.1913  |  Score: 66.10 [%]  |  Seq Length: 256.0
[2024-10-22 20:00:22,660][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 20:00:22,660][root][INFO] - Score: 76.82 [%]  |  Evaluation Time: 3.88 [s]
[2024-10-22 20:00:26,230][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 20:00:26,231][root][INFO] - Score: 68.74 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 20:00:26,232][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 20:00:26,232][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:00:27,811][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:00:27,844][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:00:27,844][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:00:27,844][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:00:27,845][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:00:27,845][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:00:27,846][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:00:29,294][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 20:01:02,985][root][INFO] - Step: 270/1350  |  Loss: 0.9770  |  Score: 74.07 [%]  |  Seq Length: 256.0
[2024-10-22 20:01:06,849][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 20:01:06,849][root][INFO] - Score: 78.11 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 20:01:10,427][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 20:01:10,427][root][INFO] - Score: 68.87 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 20:01:10,428][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 20:01:10,429][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:01:11,969][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:01:12,002][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:01:12,003][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:01:12,003][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:01:12,003][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:01:12,003][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:01:12,004][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:01:13,484][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 20:01:47,190][root][INFO] - Step: 360/1350  |  Loss: 0.7758  |  Score: 78.25 [%]  |  Seq Length: 256.0
[2024-10-22 20:01:51,065][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 20:01:51,066][root][INFO] - Score: 78.07 [%]  |  Evaluation Time: 3.87 [s]
[2024-10-22 20:01:54,658][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 20:01:54,658][root][INFO] - Score: 71.18 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 20:01:54,659][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 20:01:54,659][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:01:56,246][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:01:56,282][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:01:56,282][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:01:56,283][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:01:56,283][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:01:56,283][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:01:56,284][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:01:57,703][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 20:02:31,458][root][INFO] - Step: 450/1350  |  Loss: 0.6623  |  Score: 82.02 [%]  |  Seq Length: 256.0
[2024-10-22 20:02:35,343][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 20:02:35,343][root][INFO] - Score: 78.58 [%]  |  Evaluation Time: 3.88 [s]
[2024-10-22 20:02:38,939][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 20:02:38,940][root][INFO] - Score: 70.18 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 20:02:38,942][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 20:03:12,701][root][INFO] - Step: 540/1350  |  Loss: 0.5039  |  Score: 85.64 [%]  |  Seq Length: 256.0
[2024-10-22 20:03:16,610][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 20:03:16,610][root][INFO] - Score: 79.25 [%]  |  Evaluation Time: 3.91 [s]
[2024-10-22 20:03:20,185][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 20:03:20,185][root][INFO] - Score: 71.01 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 20:03:20,186][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 20:03:20,187][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:03:21,722][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:03:21,756][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:03:21,757][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:03:21,757][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:03:21,757][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:03:21,757][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:03:21,758][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:03:23,263][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 20:03:56,998][root][INFO] - Step: 630/1350  |  Loss: 0.4413  |  Score: 88.05 [%]  |  Seq Length: 256.0
[2024-10-22 20:04:00,905][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 20:04:00,905][root][INFO] - Score: 78.14 [%]  |  Evaluation Time: 3.90 [s]
[2024-10-22 20:04:04,523][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 20:04:04,523][root][INFO] - Score: 70.24 [%]  |  Evaluation Time: 3.62 [s]
[2024-10-22 20:04:04,526][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 20:04:38,367][root][INFO] - Step: 720/1350  |  Loss: 0.3614  |  Score: 89.72 [%]  |  Seq Length: 256.0
[2024-10-22 20:04:42,250][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 20:04:42,250][root][INFO] - Score: 77.65 [%]  |  Evaluation Time: 3.88 [s]
[2024-10-22 20:04:45,830][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 20:04:45,830][root][INFO] - Score: 70.85 [%]  |  Evaluation Time: 3.58 [s]
[2024-10-22 20:04:45,832][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 20:05:19,608][root][INFO] - Step: 810/1350  |  Loss: 0.3080  |  Score: 91.23 [%]  |  Seq Length: 256.0
[2024-10-22 20:05:23,473][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 20:05:23,473][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 20:05:27,101][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 20:05:27,101][root][INFO] - Score: 71.55 [%]  |  Evaluation Time: 3.63 [s]
[2024-10-22 20:05:27,104][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 20:05:31,275][root][INFO] - Step: 6330/10550  |  Loss: 0.2825  |  Score: 88.13 [%]  |  Seq Length: 256.0
[2024-10-22 20:06:00,863][root][INFO] - Step: 900/1350  |  Loss: 0.2658  |  Score: 92.45 [%]  |  Seq Length: 256.0
[2024-10-22 20:06:04,756][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 20:06:04,756][root][INFO] - Score: 78.41 [%]  |  Evaluation Time: 3.89 [s]
[2024-10-22 20:06:05,450][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 20:06:05,450][root][INFO] - Score: 87.80 [%]  |  Evaluation Time: 34.17 [s]
[2024-10-22 20:06:08,388][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 20:06:08,388][root][INFO] - Score: 71.36 [%]  |  Evaluation Time: 3.63 [s]
[2024-10-22 20:06:08,391][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 20:06:42,216][root][INFO] - Step: 990/1350  |  Loss: 0.2254  |  Score: 93.29 [%]  |  Seq Length: 256.0
[2024-10-22 20:06:46,095][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 20:06:46,096][root][INFO] - Score: 78.80 [%]  |  Evaluation Time: 3.88 [s]
[2024-10-22 20:06:49,733][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 20:06:49,733][root][INFO] - Score: 71.32 [%]  |  Evaluation Time: 3.63 [s]
[2024-10-22 20:06:49,735][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 20:07:23,550][root][INFO] - Step: 1080/1350  |  Loss: 0.1990  |  Score: 94.10 [%]  |  Seq Length: 256.0
[2024-10-22 20:07:27,465][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 20:07:27,466][root][INFO] - Score: 78.57 [%]  |  Evaluation Time: 3.91 [s]
[2024-10-22 20:07:31,117][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 20:07:31,117][root][INFO] - Score: 71.31 [%]  |  Evaluation Time: 3.65 [s]
[2024-10-22 20:07:31,119][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 20:07:58,156][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 20:07:58,156][root][INFO] - Score: 87.86 [%]  |  Evaluation Time: 112.70 [s]
[2024-10-22 20:07:58,157][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 20:07:58,158][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 20:07:59,693][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:07:59,743][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:07:59,744][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:07:59,744][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:07:59,744][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:07:59,744][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:07:59,745][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:08:01,260][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 20:08:04,993][root][INFO] - Step: 1170/1350  |  Loss: 0.1795  |  Score: 94.67 [%]  |  Seq Length: 256.0
[2024-10-22 20:08:08,887][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 20:08:08,888][root][INFO] - Score: 78.54 [%]  |  Evaluation Time: 3.89 [s]
[2024-10-22 20:08:12,483][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 20:08:12,484][root][INFO] - Score: 70.63 [%]  |  Evaluation Time: 3.59 [s]
[2024-10-22 20:08:12,486][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 20:08:46,391][root][INFO] - Step: 1260/1350  |  Loss: 0.1747  |  Score: 94.79 [%]  |  Seq Length: 256.0
[2024-10-22 20:08:50,282][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 20:08:50,283][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 3.89 [s]
[2024-10-22 20:08:53,928][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 20:08:53,928][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 3.64 [s]
[2024-10-22 20:08:53,931][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 20:09:15,718][root][INFO] - Step: 14733/73665  |  Loss: 0.6625  |  Score: 72.22 [%]  |  Seq Length: 256.0
[2024-10-22 20:09:26,052][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 20:09:26,052][root][INFO] - Score: 70.72 [%]  |  Evaluation Time: 10.33 [s]
[2024-10-22 20:09:27,785][root][INFO] - Step: 1350/1350  |  Loss: 0.1668  |  Score: 95.16 [%]  |  Seq Length: 256.0
[2024-10-22 20:09:31,648][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 20:09:31,648][root][INFO] - Score: 78.53 [%]  |  Evaluation Time: 3.86 [s]
[2024-10-22 20:09:35,216][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 20:09:35,216][root][INFO] - Score: 70.50 [%]  |  Evaluation Time: 3.57 [s]
[2024-10-22 20:09:35,218][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 20:09:35,218][root][INFO] - - Epoch: 6
[2024-10-22 20:09:35,218][root][INFO] - - DEV score: 79.25 [%]
[2024-10-22 20:09:35,218][root][INFO] - - TEST score: 71.01 [%]
[2024-10-22 20:09:35,219][root][INFO] - Fine-tuning is done!
[2024-10-22 20:09:35,220][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 20:09:35,220][root][INFO] - - BEST LR: 0.01
[2024-10-22 20:09:35,220][root][INFO] - - DEV score: 79.08 [%]
[2024-10-22 20:09:35,220][root][INFO] - - TEST score: 71.56 [%]
[2024-10-22 20:09:41,181][root][INFO] - 

[2024-10-22 20:09:41,181][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 20:09:41,181][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs
[2024-10-22 20:09:41,181][root][INFO] - 

[2024-10-22 20:09:41,181][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 20:09:46,206][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,207][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,207][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,207][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,208][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,208][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,209][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,209][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,210][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,210][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,211][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,211][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,211][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,212][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,212][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,213][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,213][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,213][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,214][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,214][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,215][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,215][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,216][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 20:09:46,216][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 20:09:46,217][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 20:09:46,221][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 20:09:46,260][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 20:09:46,261][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 20.21 [s]
[2024-10-22 20:09:46,262][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 20:09:46,262][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 20:09:46,265][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:09:46,430][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 20:09:46,433][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 20:09:46,638][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 20:09:47,159][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:09:47,270][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:09:47,270][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:09:47,271][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:09:47,271][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:09:47,271][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:09:47,272][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:09:48,012][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 20:09:49,878][root][INFO] - 

[2024-10-22 20:09:49,878][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 20:09:49,878][root][INFO] - Data Preprocessing
[2024-10-22 20:09:49,878][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 20:09:49,878][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 20:09:49,878][root][INFO] - ㄴ data_remove                False

[2024-10-22 20:09:49,878][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 20:09:49,886][root][INFO] - vocab size              : 51200
[2024-10-22 20:09:49,886][root][INFO] - device                  : gpu
[2024-10-22 20:09:49,886][root][INFO] - random seed             : 3
[2024-10-22 20:09:49,887][root][INFO] - train data size         : 5760
[2024-10-22 20:09:49,887][root][INFO] - max epochs              : 15
[2024-10-22 20:09:49,887][root][INFO] - total steps             : 1350
[2024-10-22 20:09:49,887][root][INFO] - warmup steps            : 135
[2024-10-22 20:09:49,887][root][INFO] - batch size              : 64
[2024-10-22 20:09:49,887][root][INFO] - accumulation steps      : 1
[2024-10-22 20:09:49,887][root][INFO] - optimizer               : adamwscale
[2024-10-22 20:09:49,887][root][INFO] - lr_scheduler            : cosine
[2024-10-22 20:09:49,887][root][INFO] - learning rate           : 0.01
[2024-10-22 20:09:49,887][root][INFO] - max length              : 256

[2024-10-22 20:09:49,887][root][INFO] - LoRA Configuration
[2024-10-22 20:09:49,887][root][INFO] - ㄴ r                    : 32
[2024-10-22 20:09:49,888][root][INFO] - ㄴ alpha                : 128
[2024-10-22 20:09:49,888][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 20:09:49,888][root][INFO] - KOMBO Configuration
[2024-10-22 20:09:49,888][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 20:09:49,888][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 20:09:49,888][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 20:09:49,888][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 20:09:49,888][root][INFO] - ㄴ do_combination       : True
[2024-10-22 20:09:49,888][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 20:09:49,888][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 20:09:49,889][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 20:09:49,889][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 20:09:49,889][root][INFO] - 

[2024-10-22 20:09:49,889][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs
[2024-10-22 20:09:49,889][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 20:09:49,889][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-22 20:09:49,889][root][INFO] - * tb interval   : 10000

[2024-10-22 20:09:49,889][root][INFO] - 

[2024-10-22 20:09:49,889][root][INFO] - Start the Training !
[2024-10-22 20:09:49,892][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 20:10:38,463][root][INFO] - Step: 90/1350  |  Loss: 2.2909  |  Score: 31.85 [%]  |  Seq Length: 256.0
[2024-10-22 20:10:44,750][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 20:10:44,750][root][INFO] - Score: 71.61 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 20:10:50,470][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 20:10:50,470][root][INFO] - Score: 62.39 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 20:10:50,471][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 20:10:50,472][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:10:50,475][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:10:51,356][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:10:51,469][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:10:51,470][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:10:51,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:10:51,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:10:51,470][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:10:51,471][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:10:52,231][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 20:11:40,701][root][INFO] - Step: 180/1350  |  Loss: 1.1913  |  Score: 65.25 [%]  |  Seq Length: 256.0
[2024-10-22 20:11:47,002][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 20:11:47,002][root][INFO] - Score: 76.04 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 20:11:52,858][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 20:11:52,858][root][INFO] - Score: 68.27 [%]  |  Evaluation Time: 5.85 [s]
[2024-10-22 20:11:52,859][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 20:11:52,860][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:11:52,863][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:11:54,641][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:11:54,851][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:11:54,852][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:11:54,853][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:11:54,853][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:11:54,853][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:11:54,856][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:11:56,488][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 20:12:45,367][root][INFO] - Step: 270/1350  |  Loss: 1.0420  |  Score: 70.73 [%]  |  Seq Length: 256.0
[2024-10-22 20:12:51,751][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 20:12:51,751][root][INFO] - Score: 77.02 [%]  |  Evaluation Time: 6.38 [s]
[2024-10-22 20:12:57,484][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 20:12:57,484][root][INFO] - Score: 69.75 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 20:12:57,485][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 20:12:57,486][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:12:57,489][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:12:59,192][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:12:59,477][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:12:59,479][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:12:59,479][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:12:59,479][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:12:59,479][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:12:59,483][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:13:01,092][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 20:13:49,378][root][INFO] - Step: 360/1350  |  Loss: 0.8905  |  Score: 74.54 [%]  |  Seq Length: 256.0
[2024-10-22 20:13:55,668][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 20:13:55,668][root][INFO] - Score: 77.14 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 20:14:01,402][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 20:14:01,402][root][INFO] - Score: 70.94 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 20:14:01,403][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 20:14:01,404][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:14:01,406][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:14:03,161][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:14:03,404][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:14:03,406][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:14:03,406][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:14:03,406][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:14:03,407][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:14:03,409][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:14:05,047][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 20:14:53,305][root][INFO] - Step: 450/1350  |  Loss: 0.7969  |  Score: 77.96 [%]  |  Seq Length: 256.0
[2024-10-22 20:14:59,567][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 20:14:59,567][root][INFO] - Score: 76.97 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 20:15:05,241][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 20:15:05,241][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 20:15:05,244][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 20:15:53,533][root][INFO] - Step: 540/1350  |  Loss: 0.6642  |  Score: 80.61 [%]  |  Seq Length: 256.0
[2024-10-22 20:15:59,800][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 20:15:59,800][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 6.26 [s]
[2024-10-22 20:16:05,474][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 20:16:05,474][root][INFO] - Score: 71.87 [%]  |  Evaluation Time: 5.67 [s]
[2024-10-22 20:16:05,476][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 20:16:05,476][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:16:05,479][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:16:07,205][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:16:07,484][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:16:07,485][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:16:07,485][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:16:07,486][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:16:07,486][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:16:07,488][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:16:09,131][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 20:16:57,637][root][INFO] - Step: 630/1350  |  Loss: 0.6012  |  Score: 83.11 [%]  |  Seq Length: 256.0
[2024-10-22 20:17:03,956][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 20:17:03,956][root][INFO] - Score: 79.22 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 20:17:09,679][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 20:17:09,679][root][INFO] - Score: 71.72 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 20:17:09,680][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 20:17:09,680][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:17:09,683][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:17:11,408][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:17:11,692][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:17:11,693][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:17:11,693][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:17:11,693][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:17:11,693][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:17:11,694][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:17:13,339][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 20:18:01,907][root][INFO] - Step: 720/1350  |  Loss: 0.5148  |  Score: 84.92 [%]  |  Seq Length: 256.0
[2024-10-22 20:18:08,253][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 20:18:08,254][root][INFO] - Score: 79.21 [%]  |  Evaluation Time: 6.34 [s]
[2024-10-22 20:18:14,002][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 20:18:14,002][root][INFO] - Score: 71.67 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 20:18:14,005][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 20:19:02,667][root][INFO] - Step: 810/1350  |  Loss: 0.4701  |  Score: 86.44 [%]  |  Seq Length: 256.0
[2024-10-22 20:19:09,029][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 20:19:09,029][root][INFO] - Score: 79.08 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-22 20:19:14,753][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 20:19:14,753][root][INFO] - Score: 71.09 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 20:19:14,756][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 20:20:03,572][root][INFO] - Step: 900/1350  |  Loss: 0.4315  |  Score: 87.36 [%]  |  Seq Length: 256.0
[2024-10-22 20:20:09,874][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 20:20:09,875][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 20:20:15,667][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 20:20:15,667][root][INFO] - Score: 71.13 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-22 20:20:15,670][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 20:20:58,949][root][INFO] - Step: 8440/10550  |  Loss: 0.2363  |  Score: 90.34 [%]  |  Seq Length: 256.0
[2024-10-22 20:21:04,097][root][INFO] - Step: 990/1350  |  Loss: 0.3807  |  Score: 88.94 [%]  |  Seq Length: 256.0
[2024-10-22 20:21:10,413][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 20:21:10,413][root][INFO] - Score: 78.54 [%]  |  Evaluation Time: 6.31 [s]
[2024-10-22 20:21:16,162][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 20:21:16,162][root][INFO] - Score: 70.97 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 20:21:16,165][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 20:21:33,115][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 20:21:33,115][root][INFO] - Score: 88.54 [%]  |  Evaluation Time: 34.16 [s]
[2024-10-22 20:22:04,175][root][INFO] - Step: 1080/1350  |  Loss: 0.3468  |  Score: 89.74 [%]  |  Seq Length: 256.0
[2024-10-22 20:22:10,541][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 20:22:10,542][root][INFO] - Score: 78.20 [%]  |  Evaluation Time: 6.36 [s]
[2024-10-22 20:22:16,275][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 20:22:16,275][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 20:22:16,278][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 20:23:05,147][root][INFO] - Step: 1170/1350  |  Loss: 0.3371  |  Score: 89.86 [%]  |  Seq Length: 256.0
[2024-10-22 20:23:11,600][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 20:23:11,600][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 6.45 [s]
[2024-10-22 20:23:17,553][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 20:23:17,553][root][INFO] - Score: 71.91 [%]  |  Evaluation Time: 5.95 [s]
[2024-10-22 20:23:17,556][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 20:23:25,954][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 20:23:25,955][root][INFO] - Score: 88.66 [%]  |  Evaluation Time: 112.84 [s]
[2024-10-22 20:23:25,957][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 20:23:25,958][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 20:23:27,512][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:23:27,557][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:23:27,558][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:23:27,558][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:23:27,558][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:23:27,558][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:23:27,559][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:23:28,985][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 20:24:06,129][root][INFO] - Step: 1260/1350  |  Loss: 0.3290  |  Score: 90.16 [%]  |  Seq Length: 256.0
[2024-10-22 20:24:12,464][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 20:24:12,465][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 20:24:18,365][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 20:24:18,365][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 5.90 [s]
[2024-10-22 20:24:18,367][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 20:25:06,854][root][INFO] - Step: 1350/1350  |  Loss: 0.3204  |  Score: 90.41 [%]  |  Seq Length: 256.0
[2024-10-22 20:25:13,156][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 20:25:13,156][root][INFO] - Score: 78.94 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 20:25:19,035][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 20:25:19,035][root][INFO] - Score: 71.41 [%]  |  Evaluation Time: 5.88 [s]
[2024-10-22 20:25:19,036][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 20:25:19,037][root][INFO] - - Epoch: 7
[2024-10-22 20:25:19,037][root][INFO] - - DEV score: 79.22 [%]
[2024-10-22 20:25:19,037][root][INFO] - - TEST score: 71.72 [%]
[2024-10-22 20:25:19,038][root][INFO] - Fine-tuning is done!
[2024-10-22 20:25:22,433][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,434][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,435][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,435][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,436][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,437][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,437][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,438][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,439][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,439][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,440][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,440][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,441][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,441][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,442][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,442][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,443][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,443][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,444][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,444][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,446][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,447][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,447][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 20:25:22,448][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 20:25:22,449][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-22 20:25:22,658][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 20:25:22,661][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-22 20:25:22,662][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 20:25:22,832][root][INFO] - 

[2024-10-22 20:25:22,832][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-22 20:25:22,833][root][INFO] - Data Preprocessing
[2024-10-22 20:25:22,833][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 20:25:22,833][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 20:25:22,833][root][INFO] - ㄴ data_remove                False

[2024-10-22 20:25:22,833][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 20:25:22,840][root][INFO] - vocab size              : 51200
[2024-10-22 20:25:22,840][root][INFO] - device                  : gpu
[2024-10-22 20:25:22,840][root][INFO] - random seed             : 3
[2024-10-22 20:25:22,840][root][INFO] - train data size         : 5760
[2024-10-22 20:25:22,841][root][INFO] - max epochs              : 15
[2024-10-22 20:25:22,841][root][INFO] - total steps             : 1350
[2024-10-22 20:25:22,841][root][INFO] - warmup steps            : 135
[2024-10-22 20:25:22,841][root][INFO] - batch size              : 64
[2024-10-22 20:25:22,841][root][INFO] - accumulation steps      : 1
[2024-10-22 20:25:22,841][root][INFO] - optimizer               : adamwscale
[2024-10-22 20:25:22,841][root][INFO] - lr_scheduler            : cosine
[2024-10-22 20:25:22,841][root][INFO] - learning rate           : 0.02
[2024-10-22 20:25:22,841][root][INFO] - max length              : 256

[2024-10-22 20:25:22,841][root][INFO] - LoRA Configuration
[2024-10-22 20:25:22,841][root][INFO] - ㄴ r                    : 32
[2024-10-22 20:25:22,841][root][INFO] - ㄴ alpha                : 128
[2024-10-22 20:25:22,841][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 20:25:22,842][root][INFO] - KOMBO Configuration
[2024-10-22 20:25:22,842][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 20:25:22,842][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 20:25:22,842][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 20:25:22,842][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 20:25:22,842][root][INFO] - ㄴ do_combination       : True
[2024-10-22 20:25:22,842][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 20:25:22,842][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 20:25:22,842][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 20:25:22,842][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 20:25:22,843][root][INFO] - 

[2024-10-22 20:25:22,843][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs
[2024-10-22 20:25:22,843][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-22 20:25:22,843][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-22 20:25:22,843][root][INFO] - * tb interval   : 10000

[2024-10-22 20:25:22,843][root][INFO] - 

[2024-10-22 20:25:22,843][root][INFO] - Start the Training !
[2024-10-22 20:25:22,845][root][INFO] - 
[1/ 15 Epoch]
[2024-10-22 20:26:11,625][root][INFO] - Step: 90/1350  |  Loss: 2.0050  |  Score: 41.73 [%]  |  Seq Length: 256.0
[2024-10-22 20:26:18,070][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 20:26:18,070][root][INFO] - Score: 73.18 [%]  |  Evaluation Time: 6.44 [s]
[2024-10-22 20:26:23,859][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 20:26:23,859][root][INFO] - Score: 58.86 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-22 20:26:23,860][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 20:26:23,860][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:26:23,863][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:26:25,600][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:26:25,885][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:26:25,886][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:26:25,886][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:26:25,887][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:26:25,887][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:26:25,890][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:26:27,517][root][INFO] - 
[2/ 15 Epoch]
[2024-10-22 20:27:16,173][root][INFO] - Step: 180/1350  |  Loss: 1.2052  |  Score: 67.39 [%]  |  Seq Length: 256.0
[2024-10-22 20:27:22,604][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 20:27:22,604][root][INFO] - Score: 75.49 [%]  |  Evaluation Time: 6.43 [s]
[2024-10-22 20:27:28,503][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 20:27:28,504][root][INFO] - Score: 68.24 [%]  |  Evaluation Time: 5.90 [s]
[2024-10-22 20:27:28,505][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 20:27:28,505][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:27:28,508][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:27:30,232][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:27:30,534][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:27:30,535][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:27:30,536][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:27:30,536][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:27:30,536][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:27:30,539][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:27:32,185][root][INFO] - 
[3/ 15 Epoch]
[2024-10-22 20:28:20,650][root][INFO] - Step: 270/1350  |  Loss: 0.9816  |  Score: 73.08 [%]  |  Seq Length: 256.0
[2024-10-22 20:28:26,987][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 20:28:26,987][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 6.33 [s]
[2024-10-22 20:28:32,707][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 20:28:32,707][root][INFO] - Score: 69.28 [%]  |  Evaluation Time: 5.72 [s]
[2024-10-22 20:28:32,708][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 20:28:32,709][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:28:32,711][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:28:34,445][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:28:34,750][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:28:34,751][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:28:34,752][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:28:34,752][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:28:34,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:28:34,755][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:28:36,421][root][INFO] - 
[4/ 15 Epoch]
[2024-10-22 20:29:24,589][root][INFO] - Step: 360/1350  |  Loss: 0.7653  |  Score: 77.96 [%]  |  Seq Length: 256.0
[2024-10-22 20:29:30,893][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 20:29:30,894][root][INFO] - Score: 75.94 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 20:29:36,633][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 20:29:36,633][root][INFO] - Score: 70.04 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-22 20:29:36,637][root][INFO] - 
[5/ 15 Epoch]
[2024-10-22 20:30:25,050][root][INFO] - Step: 450/1350  |  Loss: 0.6423  |  Score: 82.10 [%]  |  Seq Length: 256.0
[2024-10-22 20:30:31,345][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 20:30:31,346][root][INFO] - Score: 76.74 [%]  |  Evaluation Time: 6.29 [s]
[2024-10-22 20:30:37,082][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 20:30:37,082][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 20:30:37,085][root][INFO] - 
[6/ 15 Epoch]
[2024-10-22 20:31:25,501][root][INFO] - Step: 540/1350  |  Loss: 0.5126  |  Score: 85.43 [%]  |  Seq Length: 256.0
[2024-10-22 20:31:31,855][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-22 20:31:31,855][root][INFO] - Score: 77.19 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-22 20:31:37,588][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-22 20:31:37,588][root][INFO] - Score: 69.87 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 20:31:37,589][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-22 20:31:37,590][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:31:37,595][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:31:39,330][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:31:39,603][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:31:39,604][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:31:39,605][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:31:39,605][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:31:39,605][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:31:39,608][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:31:41,268][root][INFO] - 
[7/ 15 Epoch]
[2024-10-22 20:32:29,458][root][INFO] - Step: 630/1350  |  Loss: 0.4348  |  Score: 87.71 [%]  |  Seq Length: 256.0
[2024-10-22 20:32:35,744][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-22 20:32:35,744][root][INFO] - Score: 77.76 [%]  |  Evaluation Time: 6.28 [s]
[2024-10-22 20:32:41,501][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-22 20:32:41,502][root][INFO] - Score: 69.95 [%]  |  Evaluation Time: 5.75 [s]
[2024-10-22 20:32:41,503][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-22 20:32:41,503][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:32:41,506][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:32:43,281][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:32:43,581][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:32:43,582][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:32:43,583][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:32:43,583][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:32:43,583][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:32:43,587][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:32:45,272][root][INFO] - 
[8/ 15 Epoch]
[2024-10-22 20:33:04,048][root][INFO] - Step: 10000/10550  |  Loss: 0.1989  |  Score: 92.03 [%]  |  Seq Length: 256.0
[2024-10-22 20:33:33,436][root][INFO] - Step: 720/1350  |  Loss: 0.3535  |  Score: 89.66 [%]  |  Seq Length: 256.0
[2024-10-22 20:33:39,790][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-22 20:33:39,790][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-22 20:33:45,496][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-22 20:33:45,497][root][INFO] - Score: 69.39 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 20:33:45,498][root][INFO] - 
[9/ 15 Epoch]
[2024-10-22 20:34:32,922][root][INFO] - Step: 810/1350  |  Loss: 0.2966  |  Score: 91.24 [%]  |  Seq Length: 256.0
[2024-10-22 20:34:39,137][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-22 20:34:39,137][root][INFO] - Score: 77.57 [%]  |  Evaluation Time: 6.21 [s]
[2024-10-22 20:34:44,803][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-22 20:34:44,803][root][INFO] - Score: 69.02 [%]  |  Evaluation Time: 5.66 [s]
[2024-10-22 20:34:44,808][root][INFO] - 
[10/ 15 Epoch]
[2024-10-22 20:35:32,939][root][INFO] - Step: 900/1350  |  Loss: 0.2655  |  Score: 92.25 [%]  |  Seq Length: 256.0
[2024-10-22 20:35:39,179][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-22 20:35:39,180][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 6.24 [s]
[2024-10-22 20:35:44,886][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-22 20:35:44,887][root][INFO] - Score: 69.66 [%]  |  Evaluation Time: 5.70 [s]
[2024-10-22 20:35:44,888][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-22 20:35:44,888][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:35:44,891][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:35:46,603][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:35:46,888][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:35:46,889][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:35:46,890][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:35:46,890][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:35:46,890][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:35:46,893][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:35:48,567][root][INFO] - 
[11/ 15 Epoch]
[2024-10-22 20:36:26,092][root][INFO] - Step: 10550/10550  |  Loss: 0.1884  |  Score: 92.40 [%]  |  Seq Length: 256.0
[2024-10-22 20:36:36,607][root][INFO] - Step: 990/1350  |  Loss: 0.2164  |  Score: 93.52 [%]  |  Seq Length: 256.0
[2024-10-22 20:36:42,935][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-22 20:36:42,935][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 6.32 [s]
[2024-10-22 20:36:48,681][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-22 20:36:48,681][root][INFO] - Score: 69.43 [%]  |  Evaluation Time: 5.74 [s]
[2024-10-22 20:36:48,686][root][INFO] - 
[12/ 15 Epoch]
[2024-10-22 20:37:00,189][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 20:37:00,189][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 34.09 [s]
[2024-10-22 20:37:37,461][root][INFO] - Step: 1080/1350  |  Loss: 0.1939  |  Score: 94.05 [%]  |  Seq Length: 256.0
[2024-10-22 20:37:43,820][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-22 20:37:43,820][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 6.35 [s]
[2024-10-22 20:37:49,607][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-22 20:37:49,607][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 5.79 [s]
[2024-10-22 20:37:49,610][root][INFO] - 
[13/ 15 Epoch]
[2024-10-22 20:38:38,137][root][INFO] - Step: 1170/1350  |  Loss: 0.1854  |  Score: 94.32 [%]  |  Seq Length: 256.0
[2024-10-22 20:38:44,523][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-22 20:38:44,524][root][INFO] - Score: 77.65 [%]  |  Evaluation Time: 6.38 [s]
[2024-10-22 20:38:50,167][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-22 20:38:50,167][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 5.64 [s]
[2024-10-22 20:38:50,170][root][INFO] - 
[14/ 15 Epoch]
[2024-10-22 20:38:52,469][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 20:38:52,469][root][INFO] - Score: 88.91 [%]  |  Evaluation Time: 112.28 [s]
[2024-10-22 20:38:52,470][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-22 20:38:52,471][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 20:38:53,977][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:38:54,024][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:38:54,025][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:38:54,025][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:38:54,025][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:38:54,025][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:38:54,026][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:38:55,480][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 20:38:55,481][root][INFO] - - Epoch: 5
[2024-10-22 20:38:55,481][root][INFO] - - DEV score: 88.65 [%]
[2024-10-22 20:38:55,481][root][INFO] - - TEST score: 88.91 [%]
[2024-10-22 20:38:55,484][root][INFO] - Fine-tuning is done!
[2024-10-22 20:38:55,485][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 20:38:55,485][root][INFO] - - BEST LR: 0.01
[2024-10-22 20:38:55,485][root][INFO] - - DEV score: 88.96 [%]
[2024-10-22 20:38:55,486][root][INFO] - - TEST score: 89.03 [%]
[2024-10-22 20:39:01,464][root][INFO] - 

[2024-10-22 20:39:01,464][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-22 20:39:01,464][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 20:39:01,464][root][INFO] - 

[2024-10-22 20:39:01,465][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-22 20:39:23,849][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,850][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,850][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,851][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,851][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,852][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,852][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,853][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,853][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,854][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,854][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,855][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,855][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,856][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,856][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,857][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,857][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,858][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,858][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,859][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,859][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,860][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,860][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 20:39:23,861][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 20:39:23,863][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 20:39:23,867][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-22 20:39:24,069][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 20:39:24,072][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 20:39:24,255][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 20:39:27,294][root][INFO] - 

[2024-10-22 20:39:27,294][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 20:39:27,294][root][INFO] - Data Preprocessing
[2024-10-22 20:39:27,294][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 20:39:27,294][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 20:39:27,294][root][INFO] - ㄴ data_remove                False

[2024-10-22 20:39:27,295][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 20:39:27,302][root][INFO] - vocab size              : 51200
[2024-10-22 20:39:27,302][root][INFO] - device                  : gpu
[2024-10-22 20:39:27,302][root][INFO] - random seed             : 1
[2024-10-22 20:39:27,302][root][INFO] - train data size         : 135040
[2024-10-22 20:39:27,302][root][INFO] - max epochs              : 5
[2024-10-22 20:39:27,303][root][INFO] - total steps             : 10550
[2024-10-22 20:39:27,303][root][INFO] - warmup steps            : 1055
[2024-10-22 20:39:27,303][root][INFO] - batch size              : 64
[2024-10-22 20:39:27,303][root][INFO] - accumulation steps      : 1
[2024-10-22 20:39:27,303][root][INFO] - optimizer               : adamwscale
[2024-10-22 20:39:27,303][root][INFO] - lr_scheduler            : cosine
[2024-10-22 20:39:27,303][root][INFO] - learning rate           : 0.01
[2024-10-22 20:39:27,303][root][INFO] - max length              : 256

[2024-10-22 20:39:27,303][root][INFO] - LoRA Configuration
[2024-10-22 20:39:27,303][root][INFO] - ㄴ r                    : 32
[2024-10-22 20:39:27,303][root][INFO] - ㄴ alpha                : 128
[2024-10-22 20:39:27,303][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 20:39:27,304][root][INFO] - KOMBO Configuration
[2024-10-22 20:39:27,304][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 20:39:27,304][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 20:39:27,304][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 20:39:27,304][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 20:39:27,304][root][INFO] - ㄴ do_combination       : True
[2024-10-22 20:39:27,304][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 20:39:27,304][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 20:39:27,304][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 20:39:27,304][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 20:39:27,305][root][INFO] - 

[2024-10-22 20:39:27,305][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 20:39:27,305][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 20:39:27,305][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 20:39:27,305][root][INFO] - * tb interval   : 10000

[2024-10-22 20:39:27,305][root][INFO] - 

[2024-10-22 20:39:27,305][root][INFO] - Start the Training !
[2024-10-22 20:39:27,308][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 20:39:38,569][root][INFO] - Step: 1260/1350  |  Loss: 0.1681  |  Score: 94.92 [%]  |  Seq Length: 256.0
[2024-10-22 20:39:44,846][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-22 20:39:44,846][root][INFO] - Score: 78.48 [%]  |  Evaluation Time: 6.27 [s]
[2024-10-22 20:39:50,661][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-22 20:39:50,661][root][INFO] - Score: 69.62 [%]  |  Evaluation Time: 5.81 [s]
[2024-10-22 20:39:50,666][root][INFO] - 
[15/ 15 Epoch]
[2024-10-22 20:40:38,828][root][INFO] - Step: 1350/1350  |  Loss: 0.1612  |  Score: 95.13 [%]  |  Seq Length: 256.0
[2024-10-22 20:40:45,133][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-22 20:40:45,133][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 6.30 [s]
[2024-10-22 20:40:50,861][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-22 20:40:50,861][root][INFO] - Score: 70.32 [%]  |  Evaluation Time: 5.73 [s]
[2024-10-22 20:40:50,863][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-22 20:40:50,864][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-22 20:40:50,870][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 20:40:52,589][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 20:40:52,871][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 20:40:52,872][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 20:40:52,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 20:40:52,873][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 20:40:52,873][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 20:40:52,876][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 20:40:54,530][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 20:40:54,530][root][INFO] - - Epoch: 15
[2024-10-22 20:40:54,530][root][INFO] - - DEV score: 78.17 [%]
[2024-10-22 20:40:54,531][root][INFO] - - TEST score: 70.32 [%]
[2024-10-22 20:40:54,532][root][INFO] - Fine-tuning is done!
[2024-10-22 20:40:54,533][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-22 20:40:54,533][root][INFO] - - BEST LR: 0.01
[2024-10-22 20:40:54,533][root][INFO] - - DEV score: 79.22 [%]
[2024-10-22 20:40:54,533][root][INFO] - - TEST score: 71.72 [%]
[2024-10-22 20:56:37,896][root][INFO] - Step: 20000/73665  |  Loss: 0.6383  |  Score: 73.55 [%]  |  Seq Length: 256.0
[2024-10-22 20:57:18,664][root][INFO] - Step: 2110/10550  |  Loss: 0.3669  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-22 20:58:12,000][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 20:58:12,000][root][INFO] - Score: 86.80 [%]  |  Evaluation Time: 53.33 [s]
[2024-10-22 21:01:08,057][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 21:01:08,058][root][INFO] - Score: 86.82 [%]  |  Evaluation Time: 176.05 [s]
[2024-10-22 21:01:08,059][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 21:01:08,059][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 21:01:08,062][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 21:01:09,004][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 21:01:09,128][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 21:01:09,129][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 21:01:09,129][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 21:01:09,129][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 21:01:09,129][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 21:01:09,130][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 21:01:09,890][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 21:18:55,317][root][INFO] - Step: 4220/10550  |  Loss: 0.2904  |  Score: 87.75 [%]  |  Seq Length: 256.0
[2024-10-22 21:19:49,072][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 21:19:49,072][root][INFO] - Score: 88.25 [%]  |  Evaluation Time: 53.75 [s]
[2024-10-22 21:22:45,475][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 21:22:45,476][root][INFO] - Score: 87.83 [%]  |  Evaluation Time: 176.40 [s]
[2024-10-22 21:22:45,477][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 21:22:45,478][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 21:22:45,481][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 21:22:47,394][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 21:22:47,566][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 21:22:47,568][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 21:22:47,568][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 21:22:47,569][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 21:22:47,569][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 21:22:47,572][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 21:22:49,236][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 21:40:42,737][root][INFO] - Step: 6330/10550  |  Loss: 0.2507  |  Score: 89.63 [%]  |  Seq Length: 256.0
[2024-10-22 21:41:36,197][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 21:41:36,197][root][INFO] - Score: 88.41 [%]  |  Evaluation Time: 53.46 [s]
[2024-10-22 21:44:32,187][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 21:44:32,188][root][INFO] - Score: 88.48 [%]  |  Evaluation Time: 175.99 [s]
[2024-10-22 21:44:32,189][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 21:44:32,190][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 21:44:32,193][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 21:44:33,989][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 21:44:34,233][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 21:44:34,235][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 21:44:34,235][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 21:44:34,236][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 21:44:34,236][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 21:44:34,239][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 21:44:35,883][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 22:02:25,283][root][INFO] - Step: 8440/10550  |  Loss: 0.2146  |  Score: 91.24 [%]  |  Seq Length: 256.0
[2024-10-22 22:03:18,843][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 22:03:18,843][root][INFO] - Score: 89.14 [%]  |  Evaluation Time: 53.56 [s]
[2024-10-22 22:06:15,226][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 22:06:15,226][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 176.38 [s]
[2024-10-22 22:06:15,228][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 22:06:15,228][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 22:06:15,231][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 22:06:16,975][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 22:06:17,232][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 22:06:17,233][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 22:06:17,234][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 22:06:17,234][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 22:06:17,234][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 22:06:17,237][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 22:06:18,914][root][INFO] - 
[5/ 5 Epoch]
[2024-10-22 22:19:28,895][root][INFO] - Step: 10000/10550  |  Loss: 0.1913  |  Score: 92.32 [%]  |  Seq Length: 256.0
[2024-10-22 22:20:28,226][root][INFO] - Step: 29466/73665  |  Loss: 0.6294  |  Score: 73.88 [%]  |  Seq Length: 256.0
[2024-10-22 22:20:38,369][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 22:20:38,370][root][INFO] - Score: 72.12 [%]  |  Evaluation Time: 10.14 [s]
[2024-10-22 22:20:58,308][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 22:20:58,308][root][INFO] - Score: 73.39 [%]  |  Evaluation Time: 19.94 [s]
[2024-10-22 22:20:58,309][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 22:20:58,309][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-22 22:20:58,312][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 22:21:00,059][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 22:21:00,312][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 22:21:00,313][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 22:21:00,314][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 22:21:00,314][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 22:21:00,314][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 22:21:00,318][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 22:21:01,955][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 22:24:06,908][root][INFO] - Step: 10550/10550  |  Loss: 0.1876  |  Score: 92.54 [%]  |  Seq Length: 256.0
[2024-10-22 22:25:00,728][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-22 22:25:00,728][root][INFO] - Score: 89.11 [%]  |  Evaluation Time: 53.82 [s]
[2024-10-22 22:25:46,461][root][INFO] - Step: 30000/73665  |  Loss: 0.6022  |  Score: 75.19 [%]  |  Seq Length: 256.0
[2024-10-22 22:27:57,633][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-22 22:27:57,633][root][INFO] - Score: 88.90 [%]  |  Evaluation Time: 176.90 [s]
[2024-10-22 22:27:57,634][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-22 22:27:57,635][root][INFO] - - Epoch: 4
[2024-10-22 22:27:57,635][root][INFO] - - DEV score: 89.14 [%]
[2024-10-22 22:27:57,635][root][INFO] - - TEST score: 88.88 [%]
[2024-10-22 22:27:57,636][root][INFO] - Fine-tuning is done!
[2024-10-22 22:28:19,096][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,097][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,097][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,098][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,098][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,099][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,100][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,101][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,101][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,102][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,103][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,103][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,104][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,104][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,105][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,105][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,106][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,106][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,107][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,107][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,107][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,108][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,108][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-22 22:28:19,109][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-22 22:28:19,110][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-22 22:28:19,358][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-22 22:28:19,361][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-22 22:28:19,362][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-22 22:28:19,551][root][INFO] - 

[2024-10-22 22:28:19,551][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-22 22:28:19,551][root][INFO] - Data Preprocessing
[2024-10-22 22:28:19,551][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-22 22:28:19,551][root][INFO] - ㄴ do_hangeulize              False
[2024-10-22 22:28:19,552][root][INFO] - ㄴ data_remove                False

[2024-10-22 22:28:19,552][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-22 22:28:19,561][root][INFO] - vocab size              : 51200
[2024-10-22 22:28:19,561][root][INFO] - device                  : gpu
[2024-10-22 22:28:19,561][root][INFO] - random seed             : 1
[2024-10-22 22:28:19,561][root][INFO] - train data size         : 135040
[2024-10-22 22:28:19,561][root][INFO] - max epochs              : 5
[2024-10-22 22:28:19,561][root][INFO] - total steps             : 10550
[2024-10-22 22:28:19,561][root][INFO] - warmup steps            : 1055
[2024-10-22 22:28:19,562][root][INFO] - batch size              : 64
[2024-10-22 22:28:19,562][root][INFO] - accumulation steps      : 1
[2024-10-22 22:28:19,562][root][INFO] - optimizer               : adamwscale
[2024-10-22 22:28:19,562][root][INFO] - lr_scheduler            : cosine
[2024-10-22 22:28:19,562][root][INFO] - learning rate           : 0.02
[2024-10-22 22:28:19,562][root][INFO] - max length              : 256

[2024-10-22 22:28:19,562][root][INFO] - LoRA Configuration
[2024-10-22 22:28:19,562][root][INFO] - ㄴ r                    : 32
[2024-10-22 22:28:19,562][root][INFO] - ㄴ alpha                : 128
[2024-10-22 22:28:19,562][root][INFO] - ㄴ dropout              : 0.03

[2024-10-22 22:28:19,562][root][INFO] - KOMBO Configuration
[2024-10-22 22:28:19,562][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-22 22:28:19,563][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-22 22:28:19,563][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-22 22:28:19,563][root][INFO] - ㄴ embedding_norm       : False
[2024-10-22 22:28:19,563][root][INFO] - ㄴ do_combination       : True
[2024-10-22 22:28:19,563][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-22 22:28:19,563][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-22 22:28:19,563][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-22 22:28:19,563][root][INFO] -   ㄴ add_lora           : False

[2024-10-22 22:28:19,563][root][INFO] - 

[2024-10-22 22:28:19,564][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs
[2024-10-22 22:28:19,564][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt
[2024-10-22 22:28:19,564][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/tb
[2024-10-22 22:28:19,564][root][INFO] - * tb interval   : 10000

[2024-10-22 22:28:19,564][root][INFO] - 

[2024-10-22 22:28:19,564][root][INFO] - Start the Training !
[2024-10-22 22:28:19,566][root][INFO] - 
[1/ 5 Epoch]
[2024-10-22 22:46:09,855][root][INFO] - Step: 2110/10550  |  Loss: 0.3664  |  Score: 83.80 [%]  |  Seq Length: 256.0
[2024-10-22 22:47:03,585][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-22 22:47:03,585][root][INFO] - Score: 86.38 [%]  |  Evaluation Time: 53.73 [s]
[2024-10-22 22:50:00,128][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-22 22:50:00,128][root][INFO] - Score: 86.33 [%]  |  Evaluation Time: 176.54 [s]
[2024-10-22 22:50:00,129][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-22 22:50:00,129][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 22:50:00,132][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 22:50:01,898][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 22:50:02,198][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 22:50:02,199][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 22:50:02,200][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 22:50:02,200][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 22:50:02,201][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 22:50:02,204][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 22:50:04,047][root][INFO] - 
[2/ 5 Epoch]
[2024-10-22 23:07:56,458][root][INFO] - Step: 4220/10550  |  Loss: 0.3142  |  Score: 86.51 [%]  |  Seq Length: 256.0
[2024-10-22 23:08:50,115][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-22 23:08:50,115][root][INFO] - Score: 87.57 [%]  |  Evaluation Time: 53.65 [s]
[2024-10-22 23:11:47,498][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-22 23:11:47,498][root][INFO] - Score: 87.24 [%]  |  Evaluation Time: 177.38 [s]
[2024-10-22 23:11:47,499][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-22 23:11:47,500][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 23:11:47,502][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 23:11:49,265][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 23:11:49,546][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 23:11:49,548][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 23:11:49,548][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 23:11:49,548][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 23:11:49,548][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 23:11:49,551][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 23:11:51,189][root][INFO] - 
[3/ 5 Epoch]
[2024-10-22 23:29:42,685][root][INFO] - Step: 6330/10550  |  Loss: 0.2807  |  Score: 88.11 [%]  |  Seq Length: 256.0
[2024-10-22 23:30:36,479][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-22 23:30:36,479][root][INFO] - Score: 87.88 [%]  |  Evaluation Time: 53.79 [s]
[2024-10-22 23:33:34,758][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-22 23:33:34,759][root][INFO] - Score: 87.88 [%]  |  Evaluation Time: 178.28 [s]
[2024-10-22 23:33:34,760][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-22 23:33:34,761][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 23:33:34,764][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 23:33:36,522][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 23:33:36,804][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 23:33:36,806][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 23:33:36,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 23:33:36,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 23:33:36,806][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 23:33:36,809][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 23:33:38,545][root][INFO] - 
[4/ 5 Epoch]
[2024-10-22 23:51:33,051][root][INFO] - Step: 8440/10550  |  Loss: 0.2351  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-22 23:52:27,736][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-22 23:52:27,736][root][INFO] - Score: 88.64 [%]  |  Evaluation Time: 54.68 [s]
[2024-10-22 23:54:13,625][root][INFO] - Step: 40000/73665  |  Loss: 0.5980  |  Score: 75.41 [%]  |  Seq Length: 256.0
[2024-10-22 23:55:25,787][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-22 23:55:25,788][root][INFO] - Score: 88.76 [%]  |  Evaluation Time: 178.05 [s]
[2024-10-22 23:55:25,789][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-22 23:55:25,790][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-22 23:55:25,792][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-22 23:55:27,611][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-22 23:55:27,899][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-22 23:55:27,901][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-22 23:55:27,901][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-22 23:55:27,901][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-22 23:55:27,902][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-22 23:55:27,905][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-22 23:55:29,689][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 00:08:43,519][root][INFO] - Step: 10000/10550  |  Loss: 0.1975  |  Score: 92.07 [%]  |  Seq Length: 256.0
[2024-10-23 00:13:22,750][root][INFO] - Step: 10550/10550  |  Loss: 0.1890  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-23 00:14:17,037][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 00:14:17,037][root][INFO] - Score: 88.93 [%]  |  Evaluation Time: 54.28 [s]
[2024-10-23 00:17:14,988][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 00:17:14,988][root][INFO] - Score: 88.85 [%]  |  Evaluation Time: 177.95 [s]
[2024-10-23 00:17:14,989][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 00:17:14,990][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 00:17:14,993][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 00:17:16,790][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 00:17:17,054][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 00:17:17,055][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 00:17:17,056][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 00:17:17,056][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 00:17:17,056][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 00:17:17,060][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 00:17:18,845][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 00:17:18,845][root][INFO] - - Epoch: 5
[2024-10-23 00:17:18,845][root][INFO] - - DEV score: 88.93 [%]
[2024-10-23 00:17:18,845][root][INFO] - - TEST score: 88.85 [%]
[2024-10-23 00:17:18,848][root][INFO] - Fine-tuning is done!
[2024-10-23 00:17:18,849][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 00:17:18,849][root][INFO] - - BEST LR: 0.01
[2024-10-23 00:17:18,849][root][INFO] - - DEV score: 89.14 [%]
[2024-10-23 00:17:18,849][root][INFO] - - TEST score: 88.88 [%]
[2024-10-23 00:17:25,305][root][INFO] - 

[2024-10-23 00:17:25,306][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 00:17:25,306][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs
[2024-10-23 00:17:25,306][root][INFO] - 

[2024-10-23 00:17:25,306][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 00:17:48,183][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,183][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,184][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,184][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,185][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,185][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,185][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,186][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,186][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,187][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,187][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,188][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,188][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,188][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,189][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,189][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,190][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,190][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,190][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,191][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,191][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,192][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,192][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 00:17:48,193][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 00:17:48,194][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 00:17:48,395][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 00:17:50,284][root][INFO] - 

[2024-10-23 00:17:50,284][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 00:17:50,284][root][INFO] - Data Preprocessing
[2024-10-23 00:17:50,284][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 00:17:50,284][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 00:17:50,284][root][INFO] - ㄴ data_remove                False

[2024-10-23 00:17:50,284][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 00:17:50,293][root][INFO] - vocab size              : 51200
[2024-10-23 00:17:50,293][root][INFO] - device                  : gpu
[2024-10-23 00:17:50,293][root][INFO] - random seed             : 2
[2024-10-23 00:17:50,293][root][INFO] - train data size         : 135040
[2024-10-23 00:17:50,293][root][INFO] - max epochs              : 5
[2024-10-23 00:17:50,294][root][INFO] - total steps             : 10550
[2024-10-23 00:17:50,294][root][INFO] - warmup steps            : 1055
[2024-10-23 00:17:50,294][root][INFO] - batch size              : 64
[2024-10-23 00:17:50,294][root][INFO] - accumulation steps      : 1
[2024-10-23 00:17:50,294][root][INFO] - optimizer               : adamwscale
[2024-10-23 00:17:50,294][root][INFO] - lr_scheduler            : cosine
[2024-10-23 00:17:50,294][root][INFO] - learning rate           : 0.01
[2024-10-23 00:17:50,294][root][INFO] - max length              : 256

[2024-10-23 00:17:50,294][root][INFO] - LoRA Configuration
[2024-10-23 00:17:50,294][root][INFO] - ㄴ r                    : 32
[2024-10-23 00:17:50,294][root][INFO] - ㄴ alpha                : 128
[2024-10-23 00:17:50,294][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 00:17:50,294][root][INFO] - 

[2024-10-23 00:17:50,295][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs
[2024-10-23 00:17:50,295][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-23 00:17:50,295][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-23 00:17:50,295][root][INFO] - * tb interval   : 10000

[2024-10-23 00:17:50,295][root][INFO] - 

[2024-10-23 00:17:50,295][root][INFO] - Start the Training !
[2024-10-23 00:17:50,298][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 00:30:41,665][root][INFO] - Step: 2110/10550  |  Loss: 0.3656  |  Score: 83.88 [%]  |  Seq Length: 256.0
[2024-10-23 00:31:15,517][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 00:31:15,517][root][INFO] - Score: 86.89 [%]  |  Evaluation Time: 33.85 [s]
[2024-10-23 00:31:29,864][root][INFO] - Step: 44199/73665  |  Loss: 0.5865  |  Score: 76.02 [%]  |  Seq Length: 256.0
[2024-10-23 00:31:40,127][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 00:31:40,127][root][INFO] - Score: 72.38 [%]  |  Evaluation Time: 10.26 [s]
[2024-10-23 00:32:00,196][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 00:32:00,196][root][INFO] - Score: 73.91 [%]  |  Evaluation Time: 20.07 [s]
[2024-10-23 00:32:00,197][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 00:32:00,198][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 00:32:00,200][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 00:32:01,947][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 00:32:02,200][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 00:32:02,201][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 00:32:02,202][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 00:32:02,202][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 00:32:02,202][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 00:32:02,205][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 00:32:03,849][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 00:33:07,427][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 00:33:07,427][root][INFO] - Score: 86.87 [%]  |  Evaluation Time: 111.91 [s]
[2024-10-23 00:33:07,428][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 00:33:07,429][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 00:33:08,261][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 00:33:08,286][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 00:33:08,286][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 00:33:08,286][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 00:33:08,287][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 00:33:08,287][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 00:33:08,288][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 00:33:08,873][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 00:45:59,460][root][INFO] - Step: 4220/10550  |  Loss: 0.2927  |  Score: 87.60 [%]  |  Seq Length: 256.0
[2024-10-23 00:46:33,324][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 00:46:33,324][root][INFO] - Score: 87.67 [%]  |  Evaluation Time: 33.86 [s]
[2024-10-23 00:48:25,220][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 00:48:25,221][root][INFO] - Score: 87.59 [%]  |  Evaluation Time: 111.89 [s]
[2024-10-23 00:48:25,222][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 00:48:25,222][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 00:48:26,659][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 00:48:26,700][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 00:48:26,701][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 00:48:26,701][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 00:48:26,701][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 00:48:26,701][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 00:48:26,702][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 00:48:28,032][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 01:01:20,014][root][INFO] - Step: 6330/10550  |  Loss: 0.2518  |  Score: 89.55 [%]  |  Seq Length: 256.0
[2024-10-23 01:01:53,987][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 01:01:53,987][root][INFO] - Score: 88.39 [%]  |  Evaluation Time: 33.97 [s]
[2024-10-23 01:03:46,113][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 01:03:46,113][root][INFO] - Score: 88.63 [%]  |  Evaluation Time: 112.12 [s]
[2024-10-23 01:03:46,115][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 01:03:46,115][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 01:03:47,664][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 01:03:47,695][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 01:03:47,696][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 01:03:47,696][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 01:03:47,696][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 01:03:47,696][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 01:03:47,698][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 01:03:49,022][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 01:16:41,780][root][INFO] - Step: 8440/10550  |  Loss: 0.2173  |  Score: 91.14 [%]  |  Seq Length: 256.0
[2024-10-23 01:17:15,738][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 01:17:15,739][root][INFO] - Score: 88.59 [%]  |  Evaluation Time: 33.95 [s]
[2024-10-23 01:19:07,815][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 01:19:07,815][root][INFO] - Score: 88.83 [%]  |  Evaluation Time: 112.07 [s]
[2024-10-23 01:19:07,817][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 01:19:07,817][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 01:19:09,356][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 01:19:09,402][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 01:19:09,402][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 01:19:09,403][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 01:19:09,403][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 01:19:09,403][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 01:19:09,404][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 01:19:10,718][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 01:23:43,696][root][INFO] - Step: 50000/73665  |  Loss: 0.5523  |  Score: 77.60 [%]  |  Seq Length: 256.0
[2024-10-23 01:28:42,342][root][INFO] - Step: 10000/10550  |  Loss: 0.1924  |  Score: 92.24 [%]  |  Seq Length: 256.0
[2024-10-23 01:32:03,534][root][INFO] - Step: 10550/10550  |  Loss: 0.1917  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-23 01:32:37,495][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 01:32:37,495][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 33.96 [s]
[2024-10-23 01:34:29,618][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 01:34:29,619][root][INFO] - Score: 88.94 [%]  |  Evaluation Time: 112.12 [s]
[2024-10-23 01:34:29,620][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 01:34:29,621][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 01:34:31,112][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 01:34:31,143][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 01:34:31,144][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 01:34:31,144][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 01:34:31,144][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 01:34:31,144][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 01:34:31,145][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 01:34:32,463][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 01:34:32,463][root][INFO] - - Epoch: 5
[2024-10-23 01:34:32,463][root][INFO] - - DEV score: 88.65 [%]
[2024-10-23 01:34:32,463][root][INFO] - - TEST score: 88.94 [%]
[2024-10-23 01:34:32,465][root][INFO] - Fine-tuning is done!
[2024-10-23 01:34:53,832][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,833][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,833][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,834][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,834][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,835][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,836][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,836][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,837][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,837][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,838][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,838][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,839][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,839][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,840][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,840][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,840][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,841][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,841][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,842][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,843][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,843][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,844][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 01:34:53,844][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 01:34:53,846][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 01:34:53,848][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 01:34:54,028][root][INFO] - 

[2024-10-23 01:34:54,028][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 01:34:54,028][root][INFO] - Data Preprocessing
[2024-10-23 01:34:54,028][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 01:34:54,028][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 01:34:54,029][root][INFO] - ㄴ data_remove                False

[2024-10-23 01:34:54,029][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 01:34:54,039][root][INFO] - vocab size              : 51200
[2024-10-23 01:34:54,039][root][INFO] - device                  : gpu
[2024-10-23 01:34:54,039][root][INFO] - random seed             : 2
[2024-10-23 01:34:54,039][root][INFO] - train data size         : 135040
[2024-10-23 01:34:54,039][root][INFO] - max epochs              : 5
[2024-10-23 01:34:54,039][root][INFO] - total steps             : 10550
[2024-10-23 01:34:54,039][root][INFO] - warmup steps            : 1055
[2024-10-23 01:34:54,039][root][INFO] - batch size              : 64
[2024-10-23 01:34:54,039][root][INFO] - accumulation steps      : 1
[2024-10-23 01:34:54,040][root][INFO] - optimizer               : adamwscale
[2024-10-23 01:34:54,040][root][INFO] - lr_scheduler            : cosine
[2024-10-23 01:34:54,040][root][INFO] - learning rate           : 0.02
[2024-10-23 01:34:54,040][root][INFO] - max length              : 256

[2024-10-23 01:34:54,040][root][INFO] - LoRA Configuration
[2024-10-23 01:34:54,040][root][INFO] - ㄴ r                    : 32
[2024-10-23 01:34:54,040][root][INFO] - ㄴ alpha                : 128
[2024-10-23 01:34:54,040][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 01:34:54,040][root][INFO] - 

[2024-10-23 01:34:54,040][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs
[2024-10-23 01:34:54,041][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-23 01:34:54,041][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-23 01:34:54,041][root][INFO] - * tb interval   : 10000

[2024-10-23 01:34:54,041][root][INFO] - 

[2024-10-23 01:34:54,041][root][INFO] - Start the Training !
[2024-10-23 01:34:54,043][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 01:47:46,054][root][INFO] - Step: 2110/10550  |  Loss: 0.3678  |  Score: 83.80 [%]  |  Seq Length: 256.0
[2024-10-23 01:48:19,997][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 01:48:19,997][root][INFO] - Score: 86.56 [%]  |  Evaluation Time: 33.94 [s]
[2024-10-23 01:50:12,070][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 01:50:12,070][root][INFO] - Score: 86.50 [%]  |  Evaluation Time: 112.07 [s]
[2024-10-23 01:50:12,072][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 01:50:12,072][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 01:50:13,587][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 01:50:13,631][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 01:50:13,632][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 01:50:13,632][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 01:50:13,632][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 01:50:13,632][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 01:50:13,633][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 01:50:15,052][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 02:03:06,862][root][INFO] - Step: 4220/10550  |  Loss: 0.3147  |  Score: 86.60 [%]  |  Seq Length: 256.0
[2024-10-23 02:03:40,796][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 02:03:40,796][root][INFO] - Score: 87.54 [%]  |  Evaluation Time: 33.93 [s]
[2024-10-23 02:05:32,911][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 02:05:32,911][root][INFO] - Score: 87.04 [%]  |  Evaluation Time: 112.11 [s]
[2024-10-23 02:05:32,912][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 02:05:32,913][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 02:05:34,487][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 02:05:34,519][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 02:05:34,519][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 02:05:34,519][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 02:05:34,519][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 02:05:34,520][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 02:05:34,521][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 02:05:35,962][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 02:18:28,936][root][INFO] - Step: 6330/10550  |  Loss: 0.2795  |  Score: 88.25 [%]  |  Seq Length: 256.0
[2024-10-23 02:19:02,938][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 02:19:02,938][root][INFO] - Score: 88.50 [%]  |  Evaluation Time: 34.00 [s]
[2024-10-23 02:20:55,033][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 02:20:55,033][root][INFO] - Score: 88.03 [%]  |  Evaluation Time: 112.09 [s]
[2024-10-23 02:20:55,034][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 02:20:55,034][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 02:20:56,541][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 02:20:56,585][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 02:20:56,586][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 02:20:56,586][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 02:20:56,586][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 02:20:56,586][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 02:20:56,587][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 02:20:57,983][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 02:33:51,287][root][INFO] - Step: 8440/10550  |  Loss: 0.2358  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-23 02:34:25,247][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 02:34:25,247][root][INFO] - Score: 88.90 [%]  |  Evaluation Time: 33.96 [s]
[2024-10-23 02:36:17,336][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 02:36:17,336][root][INFO] - Score: 88.69 [%]  |  Evaluation Time: 112.09 [s]
[2024-10-23 02:36:17,337][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 02:36:17,338][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 02:36:18,911][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 02:36:18,955][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 02:36:18,956][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 02:36:18,956][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 02:36:18,956][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 02:36:18,956][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 02:36:18,958][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 02:36:20,383][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 02:43:03,061][root][INFO] - Step: 58932/73665  |  Loss: 0.5429  |  Score: 78.01 [%]  |  Seq Length: 256.0
[2024-10-23 02:43:13,374][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 02:43:13,374][root][INFO] - Score: 74.13 [%]  |  Evaluation Time: 10.31 [s]
[2024-10-23 02:43:33,683][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 02:43:33,683][root][INFO] - Score: 76.49 [%]  |  Evaluation Time: 20.31 [s]
[2024-10-23 02:43:33,684][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 02:43:33,684][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 02:43:33,687][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 02:43:35,421][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 02:43:35,700][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 02:43:35,701][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 02:43:35,701][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 02:43:35,702][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 02:43:35,702][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 02:43:35,705][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 02:43:37,331][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 02:45:52,171][root][INFO] - Step: 10000/10550  |  Loss: 0.1934  |  Score: 92.19 [%]  |  Seq Length: 256.0
[2024-10-23 02:49:13,236][root][INFO] - Step: 10550/10550  |  Loss: 0.1928  |  Score: 92.14 [%]  |  Seq Length: 256.0
[2024-10-23 02:49:47,244][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 02:49:47,244][root][INFO] - Score: 89.11 [%]  |  Evaluation Time: 34.01 [s]
[2024-10-23 02:51:39,335][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 02:51:39,335][root][INFO] - Score: 88.93 [%]  |  Evaluation Time: 112.09 [s]
[2024-10-23 02:51:39,337][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 02:51:39,337][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 02:51:40,866][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 02:51:40,910][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 02:51:40,911][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 02:51:40,911][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 02:51:40,911][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 02:51:40,911][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 02:51:40,913][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 02:51:42,336][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 02:51:42,336][root][INFO] - - Epoch: 5
[2024-10-23 02:51:42,336][root][INFO] - - DEV score: 89.11 [%]
[2024-10-23 02:51:42,336][root][INFO] - - TEST score: 88.93 [%]
[2024-10-23 02:51:42,339][root][INFO] - Fine-tuning is done!
[2024-10-23 02:51:42,340][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 02:51:42,340][root][INFO] - - BEST LR: 0.02
[2024-10-23 02:51:42,340][root][INFO] - - DEV score: 89.11 [%]
[2024-10-23 02:51:42,340][root][INFO] - - TEST score: 88.93 [%]
[2024-10-23 02:51:48,577][root][INFO] - 

[2024-10-23 02:51:48,577][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 02:51:48,577][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs
[2024-10-23 02:51:48,577][root][INFO] - 

[2024-10-23 02:51:48,577][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 02:52:11,407][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,408][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,409][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,409][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,410][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,410][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,411][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,411][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,412][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,412][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,412][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,413][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,413][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,414][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,414][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,414][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,415][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,415][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,416][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,416][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,417][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,417][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,417][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 02:52:11,418][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 02:52:11,419][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 02:52:11,425][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 02:52:11,626][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 02:52:11,629][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 02:52:11,826][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 02:52:15,085][root][INFO] - 

[2024-10-23 02:52:15,085][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 02:52:15,085][root][INFO] - Data Preprocessing
[2024-10-23 02:52:15,085][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 02:52:15,086][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 02:52:15,086][root][INFO] - ㄴ data_remove                False

[2024-10-23 02:52:15,086][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 02:52:15,093][root][INFO] - vocab size              : 51200
[2024-10-23 02:52:15,094][root][INFO] - device                  : gpu
[2024-10-23 02:52:15,094][root][INFO] - random seed             : 2
[2024-10-23 02:52:15,094][root][INFO] - train data size         : 135040
[2024-10-23 02:52:15,094][root][INFO] - max epochs              : 5
[2024-10-23 02:52:15,094][root][INFO] - total steps             : 10550
[2024-10-23 02:52:15,094][root][INFO] - warmup steps            : 1055
[2024-10-23 02:52:15,094][root][INFO] - batch size              : 64
[2024-10-23 02:52:15,094][root][INFO] - accumulation steps      : 1
[2024-10-23 02:52:15,094][root][INFO] - optimizer               : adamwscale
[2024-10-23 02:52:15,094][root][INFO] - lr_scheduler            : cosine
[2024-10-23 02:52:15,095][root][INFO] - learning rate           : 0.01
[2024-10-23 02:52:15,095][root][INFO] - max length              : 256

[2024-10-23 02:52:15,095][root][INFO] - LoRA Configuration
[2024-10-23 02:52:15,095][root][INFO] - ㄴ r                    : 32
[2024-10-23 02:52:15,095][root][INFO] - ㄴ alpha                : 128
[2024-10-23 02:52:15,095][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 02:52:15,095][root][INFO] - KOMBO Configuration
[2024-10-23 02:52:15,095][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 02:52:15,095][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 02:52:15,095][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 02:52:15,095][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 02:52:15,096][root][INFO] - ㄴ do_combination       : True
[2024-10-23 02:52:15,096][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 02:52:15,096][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 02:52:15,096][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 02:52:15,096][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 02:52:15,096][root][INFO] - 

[2024-10-23 02:52:15,096][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs
[2024-10-23 02:52:15,096][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-23 02:52:15,096][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-23 02:52:15,096][root][INFO] - * tb interval   : 10000

[2024-10-23 02:52:15,097][root][INFO] - 

[2024-10-23 02:52:15,097][root][INFO] - Start the Training !
[2024-10-23 02:52:15,100][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 02:53:03,523][root][INFO] - Step: 60000/73665  |  Loss: 0.5096  |  Score: 79.70 [%]  |  Seq Length: 256.0
[2024-10-23 03:10:06,668][root][INFO] - Step: 2110/10550  |  Loss: 0.3663  |  Score: 83.68 [%]  |  Seq Length: 256.0
[2024-10-23 03:11:00,731][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 03:11:00,731][root][INFO] - Score: 86.41 [%]  |  Evaluation Time: 54.06 [s]
[2024-10-23 03:13:55,437][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 03:13:55,437][root][INFO] - Score: 86.31 [%]  |  Evaluation Time: 174.70 [s]
[2024-10-23 03:13:55,439][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 03:13:55,439][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 03:13:55,442][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 03:13:56,366][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 03:13:56,480][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 03:13:56,481][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 03:13:56,481][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 03:13:56,481][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 03:13:56,481][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 03:13:56,482][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 03:13:57,248][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 03:31:45,428][root][INFO] - Step: 4220/10550  |  Loss: 0.2922  |  Score: 87.54 [%]  |  Seq Length: 256.0
[2024-10-23 03:32:38,421][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 03:32:38,422][root][INFO] - Score: 88.19 [%]  |  Evaluation Time: 52.99 [s]
[2024-10-23 03:35:36,386][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 03:35:36,387][root][INFO] - Score: 88.10 [%]  |  Evaluation Time: 177.96 [s]
[2024-10-23 03:35:36,388][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 03:35:36,388][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 03:35:36,391][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 03:35:38,142][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 03:35:38,393][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 03:35:38,394][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 03:35:38,395][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 03:35:38,395][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 03:35:38,396][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 03:35:38,398][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 03:35:40,026][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 03:53:25,656][root][INFO] - Step: 6330/10550  |  Loss: 0.2515  |  Score: 89.60 [%]  |  Seq Length: 256.0
[2024-10-23 03:54:18,377][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 03:54:18,378][root][INFO] - Score: 88.78 [%]  |  Evaluation Time: 52.72 [s]
[2024-10-23 03:57:13,858][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 03:57:13,858][root][INFO] - Score: 88.60 [%]  |  Evaluation Time: 175.48 [s]
[2024-10-23 03:57:13,859][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 03:57:13,859][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 03:57:13,862][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 03:57:15,579][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 03:57:15,858][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 03:57:15,859][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 03:57:15,860][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 03:57:15,860][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 03:57:15,860][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 03:57:15,863][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 03:57:17,482][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 04:14:59,910][root][INFO] - Step: 8440/10550  |  Loss: 0.2156  |  Score: 91.19 [%]  |  Seq Length: 256.0
[2024-10-23 04:15:53,448][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 04:15:53,448][root][INFO] - Score: 89.02 [%]  |  Evaluation Time: 53.53 [s]
[2024-10-23 04:18:48,735][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 04:18:48,736][root][INFO] - Score: 88.70 [%]  |  Evaluation Time: 175.29 [s]
[2024-10-23 04:18:48,737][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 04:18:48,737][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 04:18:48,740][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 04:18:50,468][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 04:18:50,746][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 04:18:50,747][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 04:18:50,748][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 04:18:50,748][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 04:18:50,748][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 04:18:50,751][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 04:18:52,380][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 04:21:45,206][root][INFO] - Step: 70000/73665  |  Loss: 0.5066  |  Score: 79.73 [%]  |  Seq Length: 256.0
[2024-10-23 04:32:01,588][root][INFO] - Step: 10000/10550  |  Loss: 0.1922  |  Score: 92.30 [%]  |  Seq Length: 256.0
[2024-10-23 04:36:38,318][root][INFO] - Step: 10550/10550  |  Loss: 0.1885  |  Score: 92.39 [%]  |  Seq Length: 256.0
[2024-10-23 04:37:31,218][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 04:37:31,218][root][INFO] - Score: 89.04 [%]  |  Evaluation Time: 52.90 [s]
[2024-10-23 04:40:27,610][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 04:40:27,611][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 176.39 [s]
[2024-10-23 04:40:27,611][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 04:40:27,612][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 04:40:27,614][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 04:40:29,352][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 04:40:29,617][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 04:40:29,619][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 04:40:29,619][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 04:40:29,619][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 04:40:29,620][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 04:40:29,623][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 04:40:31,296][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 04:40:31,296][root][INFO] - - Epoch: 5
[2024-10-23 04:40:31,297][root][INFO] - - DEV score: 89.04 [%]
[2024-10-23 04:40:31,297][root][INFO] - - TEST score: 88.80 [%]
[2024-10-23 04:40:31,298][root][INFO] - Fine-tuning is done!
[2024-10-23 04:40:51,688][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,688][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,689][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,690][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,690][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,691][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,691][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,692][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,692][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,693][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,694][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,694][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,695][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,695][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,696][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,696][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,697][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,697][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,698][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,698][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,700][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,700][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,701][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 04:40:51,701][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 04:40:51,703][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 04:40:51,897][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 04:40:51,899][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 04:40:51,900][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 04:40:52,086][root][INFO] - 

[2024-10-23 04:40:52,086][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 04:40:52,087][root][INFO] - Data Preprocessing
[2024-10-23 04:40:52,087][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 04:40:52,087][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 04:40:52,087][root][INFO] - ㄴ data_remove                False

[2024-10-23 04:40:52,087][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 04:40:52,095][root][INFO] - vocab size              : 51200
[2024-10-23 04:40:52,095][root][INFO] - device                  : gpu
[2024-10-23 04:40:52,095][root][INFO] - random seed             : 2
[2024-10-23 04:40:52,095][root][INFO] - train data size         : 135040
[2024-10-23 04:40:52,095][root][INFO] - max epochs              : 5
[2024-10-23 04:40:52,095][root][INFO] - total steps             : 10550
[2024-10-23 04:40:52,096][root][INFO] - warmup steps            : 1055
[2024-10-23 04:40:52,096][root][INFO] - batch size              : 64
[2024-10-23 04:40:52,096][root][INFO] - accumulation steps      : 1
[2024-10-23 04:40:52,096][root][INFO] - optimizer               : adamwscale
[2024-10-23 04:40:52,096][root][INFO] - lr_scheduler            : cosine
[2024-10-23 04:40:52,096][root][INFO] - learning rate           : 0.02
[2024-10-23 04:40:52,096][root][INFO] - max length              : 256

[2024-10-23 04:40:52,096][root][INFO] - LoRA Configuration
[2024-10-23 04:40:52,096][root][INFO] - ㄴ r                    : 32
[2024-10-23 04:40:52,096][root][INFO] - ㄴ alpha                : 128
[2024-10-23 04:40:52,096][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 04:40:52,096][root][INFO] - KOMBO Configuration
[2024-10-23 04:40:52,097][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 04:40:52,097][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 04:40:52,097][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 04:40:52,097][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 04:40:52,097][root][INFO] - ㄴ do_combination       : True
[2024-10-23 04:40:52,097][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 04:40:52,097][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 04:40:52,097][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 04:40:52,097][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 04:40:52,097][root][INFO] - 

[2024-10-23 04:40:52,098][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs
[2024-10-23 04:40:52,098][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt
[2024-10-23 04:40:52,098][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/tb
[2024-10-23 04:40:52,098][root][INFO] - * tb interval   : 10000

[2024-10-23 04:40:52,098][root][INFO] - 

[2024-10-23 04:40:52,098][root][INFO] - Start the Training !
[2024-10-23 04:40:52,100][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 04:54:13,778][root][INFO] - Step: 73665/73665  |  Loss: 0.5088  |  Score: 79.63 [%]  |  Seq Length: 256.0
[2024-10-23 04:54:24,006][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 04:54:24,006][root][INFO] - Score: 74.30 [%]  |  Evaluation Time: 10.22 [s]
[2024-10-23 04:54:44,181][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 04:54:44,181][root][INFO] - Score: 76.30 [%]  |  Evaluation Time: 20.17 [s]
[2024-10-23 04:54:44,183][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 04:54:44,183][root][INFO] - - Epoch: 4
[2024-10-23 04:54:44,183][root][INFO] - - DEV score: 74.13 [%]
[2024-10-23 04:54:44,183][root][INFO] - - TEST score: 76.49 [%]
[2024-10-23 04:54:44,184][root][INFO] - Fine-tuning is done!
[2024-10-23 04:56:44,420][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,421][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,421][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,422][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,423][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,423][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,424][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,424][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,425][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,425][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,426][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,426][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,427][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,427][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,428][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,429][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,429][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,430][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,430][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,431][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,431][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,432][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,433][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 04:56:44,433][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 04:56:44,435][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-23 04:56:44,647][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 04:56:44,649][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-23 04:56:44,651][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 04:56:44,839][root][INFO] - 

[2024-10-23 04:56:44,839][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-23 04:56:44,839][root][INFO] - Data Preprocessing
[2024-10-23 04:56:44,839][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 04:56:44,839][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 04:56:44,839][root][INFO] - ㄴ data_remove                False

[2024-10-23 04:56:44,839][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 04:56:44,851][root][INFO] - vocab size              : 51200
[2024-10-23 04:56:44,852][root][INFO] - device                  : gpu
[2024-10-23 04:56:44,852][root][INFO] - random seed             : 2
[2024-10-23 04:56:44,852][root][INFO] - train data size         : 942912
[2024-10-23 04:56:44,852][root][INFO] - max epochs              : 5
[2024-10-23 04:56:44,852][root][INFO] - total steps             : 73665
[2024-10-23 04:56:44,852][root][INFO] - warmup steps            : 7366
[2024-10-23 04:56:44,852][root][INFO] - batch size              : 64
[2024-10-23 04:56:44,852][root][INFO] - accumulation steps      : 1
[2024-10-23 04:56:44,853][root][INFO] - optimizer               : adamwscale
[2024-10-23 04:56:44,853][root][INFO] - lr_scheduler            : cosine
[2024-10-23 04:56:44,853][root][INFO] - learning rate           : 0.005
[2024-10-23 04:56:44,853][root][INFO] - max length              : 256

[2024-10-23 04:56:44,853][root][INFO] - LoRA Configuration
[2024-10-23 04:56:44,853][root][INFO] - ㄴ r                    : 32
[2024-10-23 04:56:44,853][root][INFO] - ㄴ alpha                : 128
[2024-10-23 04:56:44,853][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 04:56:44,853][root][INFO] - KOMBO Configuration
[2024-10-23 04:56:44,853][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 04:56:44,853][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 04:56:44,853][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 04:56:44,854][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 04:56:44,854][root][INFO] - ㄴ do_combination       : True
[2024-10-23 04:56:44,854][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 04:56:44,854][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 04:56:44,854][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 04:56:44,854][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 04:56:44,854][root][INFO] - 

[2024-10-23 04:56:44,854][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs
[2024-10-23 04:56:44,854][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt
[2024-10-23 04:56:44,855][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/tb
[2024-10-23 04:56:44,855][root][INFO] - * tb interval   : 10000

[2024-10-23 04:56:44,855][root][INFO] - 

[2024-10-23 04:56:44,855][root][INFO] - Start the Training !
[2024-10-23 04:56:44,857][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 04:58:35,671][root][INFO] - Step: 2110/10550  |  Loss: 0.3669  |  Score: 83.89 [%]  |  Seq Length: 256.0
[2024-10-23 04:59:29,748][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 04:59:29,748][root][INFO] - Score: 86.36 [%]  |  Evaluation Time: 54.07 [s]
[2024-10-23 05:02:24,614][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 05:02:24,615][root][INFO] - Score: 86.21 [%]  |  Evaluation Time: 174.86 [s]
[2024-10-23 05:02:24,616][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 05:02:24,616][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 05:02:24,619][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 05:02:26,368][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 05:02:26,620][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 05:02:26,621][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 05:02:26,622][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 05:02:26,622][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 05:02:26,622][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 05:02:26,625][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 05:02:28,322][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 05:20:19,249][root][INFO] - Step: 4220/10550  |  Loss: 0.3147  |  Score: 86.49 [%]  |  Seq Length: 256.0
[2024-10-23 05:21:12,580][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 05:21:12,581][root][INFO] - Score: 87.52 [%]  |  Evaluation Time: 53.33 [s]
[2024-10-23 05:24:07,624][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 05:24:07,625][root][INFO] - Score: 87.31 [%]  |  Evaluation Time: 175.04 [s]
[2024-10-23 05:24:07,626][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 05:24:07,626][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 05:24:07,629][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 05:24:09,373][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 05:24:09,634][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 05:24:09,636][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 05:24:09,636][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 05:24:09,636][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 05:24:09,636][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 05:24:09,639][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 05:24:11,397][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 05:42:02,529][root][INFO] - Step: 6330/10550  |  Loss: 0.2806  |  Score: 88.10 [%]  |  Seq Length: 256.0
[2024-10-23 05:42:55,412][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 05:42:55,412][root][INFO] - Score: 88.19 [%]  |  Evaluation Time: 52.88 [s]
[2024-10-23 05:45:52,707][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 05:45:52,707][root][INFO] - Score: 88.02 [%]  |  Evaluation Time: 177.29 [s]
[2024-10-23 05:45:52,708][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 05:45:52,708][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 05:45:52,711][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 05:45:54,452][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 05:45:54,705][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 05:45:54,706][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 05:45:54,707][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 05:45:54,707][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 05:45:54,707][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 05:45:54,710][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 05:45:56,438][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 06:03:43,193][root][INFO] - Step: 8440/10550  |  Loss: 0.2368  |  Score: 90.22 [%]  |  Seq Length: 256.0
[2024-10-23 06:04:37,485][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 06:04:37,486][root][INFO] - Score: 88.73 [%]  |  Evaluation Time: 54.29 [s]
[2024-10-23 06:07:32,567][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 06:07:32,567][root][INFO] - Score: 88.55 [%]  |  Evaluation Time: 175.08 [s]
[2024-10-23 06:07:32,569][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 06:07:32,569][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 06:07:32,572][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 06:07:34,299][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 06:07:34,592][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 06:07:34,594][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 06:07:34,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 06:07:34,595][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 06:07:34,595][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 06:07:34,598][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 06:07:36,384][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 06:20:56,043][root][INFO] - Step: 10000/10550  |  Loss: 0.1952  |  Score: 92.20 [%]  |  Seq Length: 256.0
[2024-10-23 06:25:11,380][root][INFO] - Step: 10000/73665  |  Loss: 0.7557  |  Score: 66.89 [%]  |  Seq Length: 256.0
[2024-10-23 06:25:38,590][root][INFO] - Step: 10550/10550  |  Loss: 0.1934  |  Score: 92.23 [%]  |  Seq Length: 256.0
[2024-10-23 06:26:32,777][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 06:26:32,778][root][INFO] - Score: 88.97 [%]  |  Evaluation Time: 54.18 [s]
[2024-10-23 06:29:32,684][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 06:29:32,684][root][INFO] - Score: 88.70 [%]  |  Evaluation Time: 179.90 [s]
[2024-10-23 06:29:32,686][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 06:29:32,686][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 06:29:32,689][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 06:29:34,469][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 06:29:34,743][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 06:29:34,745][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 06:29:34,746][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 06:29:34,746][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 06:29:34,746][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 06:29:34,750][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 06:29:36,493][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 06:29:36,493][root][INFO] - - Epoch: 5
[2024-10-23 06:29:36,493][root][INFO] - - DEV score: 88.97 [%]
[2024-10-23 06:29:36,493][root][INFO] - - TEST score: 88.70 [%]
[2024-10-23 06:29:36,496][root][INFO] - Fine-tuning is done!
[2024-10-23 06:29:36,497][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 06:29:36,497][root][INFO] - - BEST LR: 0.01
[2024-10-23 06:29:36,497][root][INFO] - - DEV score: 89.04 [%]
[2024-10-23 06:29:36,497][root][INFO] - - TEST score: 88.80 [%]
[2024-10-23 06:29:43,125][root][INFO] - 

[2024-10-23 06:29:43,125][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 06:29:43,125][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs
[2024-10-23 06:29:43,125][root][INFO] - 

[2024-10-23 06:29:43,125][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 06:30:06,581][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,581][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,582][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,582][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,583][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,583][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,584][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,584][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,585][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,585][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,585][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,586][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,586][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,587][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,587][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,587][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,588][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,589][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,589][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,590][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,590][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,591][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,591][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 06:30:06,592][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 06:30:06,593][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 06:30:06,791][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 06:30:08,615][root][INFO] - 

[2024-10-23 06:30:08,615][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 06:30:08,615][root][INFO] - Data Preprocessing
[2024-10-23 06:30:08,615][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 06:30:08,615][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 06:30:08,615][root][INFO] - ㄴ data_remove                False

[2024-10-23 06:30:08,615][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 06:30:08,624][root][INFO] - vocab size              : 51200
[2024-10-23 06:30:08,624][root][INFO] - device                  : gpu
[2024-10-23 06:30:08,624][root][INFO] - random seed             : 3
[2024-10-23 06:30:08,624][root][INFO] - train data size         : 135040
[2024-10-23 06:30:08,624][root][INFO] - max epochs              : 5
[2024-10-23 06:30:08,624][root][INFO] - total steps             : 10550
[2024-10-23 06:30:08,624][root][INFO] - warmup steps            : 1055
[2024-10-23 06:30:08,624][root][INFO] - batch size              : 64
[2024-10-23 06:30:08,625][root][INFO] - accumulation steps      : 1
[2024-10-23 06:30:08,625][root][INFO] - optimizer               : adamwscale
[2024-10-23 06:30:08,625][root][INFO] - lr_scheduler            : cosine
[2024-10-23 06:30:08,625][root][INFO] - learning rate           : 0.01
[2024-10-23 06:30:08,625][root][INFO] - max length              : 256

[2024-10-23 06:30:08,625][root][INFO] - LoRA Configuration
[2024-10-23 06:30:08,625][root][INFO] - ㄴ r                    : 32
[2024-10-23 06:30:08,625][root][INFO] - ㄴ alpha                : 128
[2024-10-23 06:30:08,625][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 06:30:08,625][root][INFO] - 

[2024-10-23 06:30:08,625][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs
[2024-10-23 06:30:08,626][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-23 06:30:08,626][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-23 06:30:08,626][root][INFO] - * tb interval   : 10000

[2024-10-23 06:30:08,626][root][INFO] - 

[2024-10-23 06:30:08,626][root][INFO] - Start the Training !
[2024-10-23 06:30:08,629][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 06:43:04,391][root][INFO] - Step: 2110/10550  |  Loss: 0.3655  |  Score: 83.72 [%]  |  Seq Length: 256.0
[2024-10-23 06:43:38,414][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 06:43:38,414][root][INFO] - Score: 87.14 [%]  |  Evaluation Time: 34.02 [s]
[2024-10-23 06:45:30,805][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 06:45:30,805][root][INFO] - Score: 86.92 [%]  |  Evaluation Time: 112.39 [s]
[2024-10-23 06:45:30,807][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 06:45:30,807][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 06:45:31,652][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 06:45:31,677][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 06:45:31,678][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 06:45:31,678][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 06:45:31,678][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 06:45:31,678][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 06:45:31,679][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 06:45:32,363][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 06:58:27,444][root][INFO] - Step: 4220/10550  |  Loss: 0.2912  |  Score: 87.64 [%]  |  Seq Length: 256.0
[2024-10-23 06:59:01,422][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 06:59:01,422][root][INFO] - Score: 88.03 [%]  |  Evaluation Time: 33.97 [s]
[2024-10-23 07:00:53,841][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 07:00:53,841][root][INFO] - Score: 87.63 [%]  |  Evaluation Time: 112.42 [s]
[2024-10-23 07:00:53,843][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 07:00:53,843][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 07:00:55,345][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 07:00:55,386][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 07:00:55,387][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 07:00:55,387][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 07:00:55,387][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 07:00:55,387][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 07:00:55,388][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 07:00:56,905][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 07:07:23,859][root][INFO] - Step: 14733/73665  |  Loss: 0.6589  |  Score: 72.31 [%]  |  Seq Length: 256.0
[2024-10-23 07:07:34,607][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 07:07:34,608][root][INFO] - Score: 69.20 [%]  |  Evaluation Time: 10.74 [s]
[2024-10-23 07:07:55,481][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 07:07:55,481][root][INFO] - Score: 71.12 [%]  |  Evaluation Time: 20.87 [s]
[2024-10-23 07:07:55,482][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 07:07:55,483][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 07:07:55,486][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 07:07:57,237][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 07:07:57,522][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 07:07:57,524][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 07:07:57,524][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 07:07:57,524][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 07:07:57,525][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 07:07:57,528][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 07:07:59,248][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 07:13:50,001][root][INFO] - Step: 6330/10550  |  Loss: 0.2521  |  Score: 89.49 [%]  |  Seq Length: 256.0
[2024-10-23 07:14:23,963][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 07:14:23,963][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 33.96 [s]
[2024-10-23 07:16:16,241][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 07:16:16,242][root][INFO] - Score: 88.60 [%]  |  Evaluation Time: 112.28 [s]
[2024-10-23 07:16:16,243][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 07:16:16,243][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 07:16:17,788][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 07:16:17,863][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 07:16:17,864][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 07:16:17,864][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 07:16:17,864][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 07:16:17,864][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 07:16:17,865][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 07:16:19,283][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 07:29:11,364][root][INFO] - Step: 8440/10550  |  Loss: 0.2177  |  Score: 91.15 [%]  |  Seq Length: 256.0
[2024-10-23 07:29:45,318][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 07:29:45,318][root][INFO] - Score: 89.10 [%]  |  Evaluation Time: 33.95 [s]
[2024-10-23 07:31:37,775][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 07:31:37,776][root][INFO] - Score: 88.79 [%]  |  Evaluation Time: 112.46 [s]
[2024-10-23 07:31:37,777][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 07:31:37,777][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 07:31:39,298][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 07:31:39,346][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 07:31:39,347][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 07:31:39,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 07:31:39,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 07:31:39,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 07:31:39,348][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 07:31:40,783][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 07:41:12,194][root][INFO] - Step: 10000/10550  |  Loss: 0.1938  |  Score: 92.30 [%]  |  Seq Length: 256.0
[2024-10-23 07:44:33,423][root][INFO] - Step: 10550/10550  |  Loss: 0.1904  |  Score: 92.43 [%]  |  Seq Length: 256.0
[2024-10-23 07:45:07,432][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 07:45:07,432][root][INFO] - Score: 89.15 [%]  |  Evaluation Time: 34.01 [s]
[2024-10-23 07:46:59,726][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 07:46:59,726][root][INFO] - Score: 88.76 [%]  |  Evaluation Time: 112.29 [s]
[2024-10-23 07:46:59,728][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 07:46:59,728][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 07:47:01,315][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 07:47:01,346][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 07:47:01,347][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 07:47:01,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 07:47:01,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 07:47:01,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 07:47:01,348][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 07:47:02,749][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 07:47:02,749][root][INFO] - - Epoch: 5
[2024-10-23 07:47:02,749][root][INFO] - - DEV score: 89.15 [%]
[2024-10-23 07:47:02,749][root][INFO] - - TEST score: 88.76 [%]
[2024-10-23 07:47:02,751][root][INFO] - Fine-tuning is done!
[2024-10-23 07:47:24,293][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,294][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,295][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,296][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,297][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,297][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,298][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,298][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,299][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,299][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,300][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,300][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,301][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,301][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,302][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,302][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,303][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,303][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,304][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,304][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,305][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,305][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,306][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 07:47:24,306][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 07:47:24,308][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 07:47:24,310][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 07:47:24,506][root][INFO] - 

[2024-10-23 07:47:24,507][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 07:47:24,507][root][INFO] - Data Preprocessing
[2024-10-23 07:47:24,507][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 07:47:24,507][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 07:47:24,507][root][INFO] - ㄴ data_remove                False

[2024-10-23 07:47:24,507][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 07:47:24,517][root][INFO] - vocab size              : 51200
[2024-10-23 07:47:24,518][root][INFO] - device                  : gpu
[2024-10-23 07:47:24,518][root][INFO] - random seed             : 3
[2024-10-23 07:47:24,518][root][INFO] - train data size         : 135040
[2024-10-23 07:47:24,518][root][INFO] - max epochs              : 5
[2024-10-23 07:47:24,518][root][INFO] - total steps             : 10550
[2024-10-23 07:47:24,518][root][INFO] - warmup steps            : 1055
[2024-10-23 07:47:24,518][root][INFO] - batch size              : 64
[2024-10-23 07:47:24,519][root][INFO] - accumulation steps      : 1
[2024-10-23 07:47:24,519][root][INFO] - optimizer               : adamwscale
[2024-10-23 07:47:24,519][root][INFO] - lr_scheduler            : cosine
[2024-10-23 07:47:24,519][root][INFO] - learning rate           : 0.02
[2024-10-23 07:47:24,519][root][INFO] - max length              : 256

[2024-10-23 07:47:24,519][root][INFO] - LoRA Configuration
[2024-10-23 07:47:24,519][root][INFO] - ㄴ r                    : 32
[2024-10-23 07:47:24,519][root][INFO] - ㄴ alpha                : 128
[2024-10-23 07:47:24,520][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 07:47:24,520][root][INFO] - 

[2024-10-23 07:47:24,520][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs
[2024-10-23 07:47:24,520][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-23 07:47:24,520][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-23 07:47:24,520][root][INFO] - * tb interval   : 10000

[2024-10-23 07:47:24,520][root][INFO] - 

[2024-10-23 07:47:24,520][root][INFO] - Start the Training !
[2024-10-23 07:47:24,523][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 07:55:07,173][root][INFO] - Step: 20000/73665  |  Loss: 0.6263  |  Score: 74.08 [%]  |  Seq Length: 256.0
[2024-10-23 08:00:18,715][root][INFO] - Step: 2110/10550  |  Loss: 0.3665  |  Score: 83.77 [%]  |  Seq Length: 256.0
[2024-10-23 08:00:52,872][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 08:00:52,872][root][INFO] - Score: 86.44 [%]  |  Evaluation Time: 34.15 [s]
[2024-10-23 08:02:45,376][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 08:02:45,377][root][INFO] - Score: 86.27 [%]  |  Evaluation Time: 112.50 [s]
[2024-10-23 08:02:45,378][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 08:02:45,379][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 08:02:46,931][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 08:02:46,966][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 08:02:46,967][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 08:02:46,967][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 08:02:46,967][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 08:02:46,967][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 08:02:46,968][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 08:02:48,383][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 08:15:41,336][root][INFO] - Step: 4220/10550  |  Loss: 0.3128  |  Score: 86.66 [%]  |  Seq Length: 256.0
[2024-10-23 08:16:15,447][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 08:16:15,447][root][INFO] - Score: 87.42 [%]  |  Evaluation Time: 34.11 [s]
[2024-10-23 08:18:07,737][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 08:18:07,737][root][INFO] - Score: 87.27 [%]  |  Evaluation Time: 112.29 [s]
[2024-10-23 08:18:07,738][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 08:18:07,739][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 08:18:09,278][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 08:18:09,313][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 08:18:09,314][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 08:18:09,314][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 08:18:09,314][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 08:18:09,314][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 08:18:09,315][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 08:18:10,869][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 08:31:05,389][root][INFO] - Step: 6330/10550  |  Loss: 0.2804  |  Score: 88.26 [%]  |  Seq Length: 256.0
[2024-10-23 08:31:39,496][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 08:31:39,496][root][INFO] - Score: 88.27 [%]  |  Evaluation Time: 34.10 [s]
[2024-10-23 08:33:31,935][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 08:33:31,935][root][INFO] - Score: 88.17 [%]  |  Evaluation Time: 112.44 [s]
[2024-10-23 08:33:31,936][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 08:33:31,937][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 08:33:33,481][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 08:33:33,539][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 08:33:33,539][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 08:33:33,540][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 08:33:33,540][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 08:33:33,540][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 08:33:33,542][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 08:33:35,088][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 08:46:28,287][root][INFO] - Step: 8440/10550  |  Loss: 0.2360  |  Score: 90.29 [%]  |  Seq Length: 256.0
[2024-10-23 08:47:02,248][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 08:47:02,248][root][INFO] - Score: 88.97 [%]  |  Evaluation Time: 33.96 [s]
[2024-10-23 08:48:54,345][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 08:48:54,345][root][INFO] - Score: 88.70 [%]  |  Evaluation Time: 112.09 [s]
[2024-10-23 08:48:54,346][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 08:48:54,347][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 08:48:55,892][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 08:48:55,923][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 08:48:55,924][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 08:48:55,924][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 08:48:55,924][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 08:48:55,924][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 08:48:55,925][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 08:48:57,534][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 08:58:29,429][root][INFO] - Step: 10000/10550  |  Loss: 0.1965  |  Score: 92.20 [%]  |  Seq Length: 256.0
[2024-10-23 09:01:50,632][root][INFO] - Step: 10550/10550  |  Loss: 0.1922  |  Score: 92.30 [%]  |  Seq Length: 256.0
[2024-10-23 09:02:24,572][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 09:02:24,573][root][INFO] - Score: 88.97 [%]  |  Evaluation Time: 33.94 [s]
[2024-10-23 09:04:16,653][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 09:04:16,653][root][INFO] - Score: 88.72 [%]  |  Evaluation Time: 112.08 [s]
[2024-10-23 09:04:16,654][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 09:04:16,655][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 09:04:18,189][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:04:18,222][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:04:18,223][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:04:18,223][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:04:18,223][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:04:18,223][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:04:18,224][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:04:19,783][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 09:04:19,783][root][INFO] - - Epoch: 5
[2024-10-23 09:04:19,783][root][INFO] - - DEV score: 88.97 [%]
[2024-10-23 09:04:19,784][root][INFO] - - TEST score: 88.72 [%]
[2024-10-23 09:04:19,787][root][INFO] - Fine-tuning is done!
[2024-10-23 09:04:19,788][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 09:04:19,788][root][INFO] - - BEST LR: 0.01
[2024-10-23 09:04:19,788][root][INFO] - - DEV score: 89.15 [%]
[2024-10-23 09:04:19,788][root][INFO] - - TEST score: 88.76 [%]
[2024-10-23 09:04:25,720][root][INFO] - 

[2024-10-23 09:04:25,720][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 09:04:25,721][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs
[2024-10-23 09:04:25,721][root][INFO] - 

[2024-10-23 09:04:25,721][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 09:04:47,841][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,841][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,842][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,842][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,842][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,843][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,843][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,844][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,844][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,844][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,845][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,845][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,846][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,846][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,846][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,847][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,847][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,848][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,848][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,848][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,849][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,849][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,850][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 09:04:47,850][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 09:04:47,852][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 09:04:47,856][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 09:04:48,050][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 09:04:48,053][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 09:04:48,254][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 09:04:51,255][root][INFO] - 

[2024-10-23 09:04:51,256][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 09:04:51,256][root][INFO] - Data Preprocessing
[2024-10-23 09:04:51,256][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 09:04:51,256][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 09:04:51,256][root][INFO] - ㄴ data_remove                False

[2024-10-23 09:04:51,256][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 09:04:51,264][root][INFO] - vocab size              : 51200
[2024-10-23 09:04:51,264][root][INFO] - device                  : gpu
[2024-10-23 09:04:51,264][root][INFO] - random seed             : 3
[2024-10-23 09:04:51,264][root][INFO] - train data size         : 135040
[2024-10-23 09:04:51,264][root][INFO] - max epochs              : 5
[2024-10-23 09:04:51,264][root][INFO] - total steps             : 10550
[2024-10-23 09:04:51,264][root][INFO] - warmup steps            : 1055
[2024-10-23 09:04:51,264][root][INFO] - batch size              : 64
[2024-10-23 09:04:51,264][root][INFO] - accumulation steps      : 1
[2024-10-23 09:04:51,264][root][INFO] - optimizer               : adamwscale
[2024-10-23 09:04:51,264][root][INFO] - lr_scheduler            : cosine
[2024-10-23 09:04:51,265][root][INFO] - learning rate           : 0.01
[2024-10-23 09:04:51,265][root][INFO] - max length              : 256

[2024-10-23 09:04:51,265][root][INFO] - LoRA Configuration
[2024-10-23 09:04:51,265][root][INFO] - ㄴ r                    : 32
[2024-10-23 09:04:51,265][root][INFO] - ㄴ alpha                : 128
[2024-10-23 09:04:51,265][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 09:04:51,265][root][INFO] - KOMBO Configuration
[2024-10-23 09:04:51,265][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 09:04:51,265][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 09:04:51,265][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 09:04:51,265][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 09:04:51,266][root][INFO] - ㄴ do_combination       : True
[2024-10-23 09:04:51,266][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 09:04:51,266][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 09:04:51,266][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 09:04:51,266][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 09:04:51,266][root][INFO] - 

[2024-10-23 09:04:51,266][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs
[2024-10-23 09:04:51,266][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-23 09:04:51,266][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-23 09:04:51,266][root][INFO] - * tb interval   : 10000

[2024-10-23 09:04:51,266][root][INFO] - 

[2024-10-23 09:04:51,267][root][INFO] - Start the Training !
[2024-10-23 09:04:51,270][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 09:19:16,034][root][INFO] - Step: 29466/73665  |  Loss: 0.6071  |  Score: 75.01 [%]  |  Seq Length: 256.0
[2024-10-23 09:19:26,531][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 09:19:26,532][root][INFO] - Score: 73.26 [%]  |  Evaluation Time: 10.49 [s]
[2024-10-23 09:19:47,033][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 09:19:47,033][root][INFO] - Score: 74.59 [%]  |  Evaluation Time: 20.50 [s]
[2024-10-23 09:19:47,034][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 09:19:47,034][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 09:19:47,037][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:19:48,763][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:19:49,059][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:19:49,061][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:19:49,061][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:19:49,062][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:19:49,062][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:19:49,065][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:19:50,819][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 09:22:39,412][root][INFO] - Step: 2110/10550  |  Loss: 0.3672  |  Score: 83.67 [%]  |  Seq Length: 256.0
[2024-10-23 09:23:32,555][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 09:23:32,555][root][INFO] - Score: 87.20 [%]  |  Evaluation Time: 53.14 [s]
[2024-10-23 09:24:36,841][root][INFO] - Step: 30000/73665  |  Loss: 0.5778  |  Score: 76.45 [%]  |  Seq Length: 256.0
[2024-10-23 09:26:28,005][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 09:26:28,006][root][INFO] - Score: 87.02 [%]  |  Evaluation Time: 175.45 [s]
[2024-10-23 09:26:28,007][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 09:26:28,007][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 09:26:28,010][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:26:28,957][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:26:29,078][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:26:29,078][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:26:29,078][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:26:29,078][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:26:29,079][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:26:29,080][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:26:29,832][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 09:38:21,068][root][INFO] - 

[2024-10-23 09:38:21,069][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 09:38:21,069][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 09:38:21,069][root][INFO] - 

[2024-10-23 09:38:21,069][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 09:38:25,821][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,822][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,822][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,822][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,823][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,823][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,824][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,824][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,825][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,825][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,825][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,826][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,826][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,827][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,828][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,828][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,829][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,829][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,830][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,831][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,836][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,837][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,838][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 09:38:25,838][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 09:38:25,841][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 09:38:26,006][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 09:38:27,926][root][INFO] - 

[2024-10-23 09:38:27,927][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 09:38:27,927][root][INFO] - Data Preprocessing
[2024-10-23 09:38:27,927][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 09:38:27,927][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 09:38:27,927][root][INFO] - ㄴ data_remove                True

[2024-10-23 09:38:27,927][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 09:38:27,937][root][INFO] - vocab size              : 51200
[2024-10-23 09:38:27,937][root][INFO] - device                  : gpu
[2024-10-23 09:38:27,937][root][INFO] - random seed             : 1
[2024-10-23 09:38:27,937][root][INFO] - train data size         : 4096
[2024-10-23 09:38:27,938][root][INFO] - max epochs              : 15
[2024-10-23 09:38:27,938][root][INFO] - total steps             : 960
[2024-10-23 09:38:27,938][root][INFO] - warmup steps            : 96
[2024-10-23 09:38:27,938][root][INFO] - batch size              : 64
[2024-10-23 09:38:27,938][root][INFO] - accumulation steps      : 1
[2024-10-23 09:38:27,938][root][INFO] - optimizer               : adamwscale
[2024-10-23 09:38:27,938][root][INFO] - lr_scheduler            : cosine
[2024-10-23 09:38:27,938][root][INFO] - learning rate           : 0.01
[2024-10-23 09:38:27,938][root][INFO] - max length              : 256

[2024-10-23 09:38:27,938][root][INFO] - LoRA Configuration
[2024-10-23 09:38:27,938][root][INFO] - ㄴ r                    : 32
[2024-10-23 09:38:27,938][root][INFO] - ㄴ alpha                : 128
[2024-10-23 09:38:27,939][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 09:38:27,939][root][INFO] - 

[2024-10-23 09:38:27,939][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 09:38:27,939][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 09:38:27,939][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 09:38:27,939][root][INFO] - * tb interval   : 10000

[2024-10-23 09:38:27,939][root][INFO] - 

[2024-10-23 09:38:27,939][root][INFO] - Start the Training !
[2024-10-23 09:38:27,942][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 09:38:52,844][root][INFO] - Step: 64/960  |  Loss: 3.0314  |  Score: 23.98 [%]  |  Seq Length: 256.0
[2024-10-23 09:38:55,653][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 09:38:55,653][root][INFO] - Score: 70.60 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:38:58,395][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 09:38:58,396][root][INFO] - Score: 63.32 [%]  |  Evaluation Time: 2.74 [s]
[2024-10-23 09:38:58,397][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 09:38:58,397][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:39:00,007][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:39:00,049][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:39:00,050][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:39:00,050][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:39:00,050][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:39:00,050][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:39:00,051][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:39:01,509][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 09:39:25,260][root][INFO] - Step: 128/960  |  Loss: 1.3288  |  Score: 65.16 [%]  |  Seq Length: 256.0
[2024-10-23 09:39:28,047][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 09:39:28,047][root][INFO] - Score: 73.36 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:39:30,808][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 09:39:30,809][root][INFO] - Score: 69.33 [%]  |  Evaluation Time: 2.76 [s]
[2024-10-23 09:39:30,810][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 09:39:30,811][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:39:32,365][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:39:32,397][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:39:32,398][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:39:32,398][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:39:32,398][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:39:32,398][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:39:32,400][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:39:33,983][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 09:39:57,781][root][INFO] - Step: 192/960  |  Loss: 1.1536  |  Score: 69.98 [%]  |  Seq Length: 256.0
[2024-10-23 09:40:00,586][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 09:40:00,586][root][INFO] - Score: 77.16 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:40:03,338][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 09:40:03,338][root][INFO] - Score: 69.46 [%]  |  Evaluation Time: 2.75 [s]
[2024-10-23 09:40:03,339][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 09:40:03,340][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:40:04,882][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:40:04,937][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:40:04,938][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:40:04,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:40:04,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:40:04,938][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:40:04,939][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:40:06,338][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 09:40:30,231][root][INFO] - Step: 256/960  |  Loss: 0.9690  |  Score: 74.91 [%]  |  Seq Length: 256.0
[2024-10-23 09:40:33,053][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 09:40:33,054][root][INFO] - Score: 76.66 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 09:40:35,824][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 09:40:35,824][root][INFO] - Score: 71.30 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 09:40:35,825][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 09:40:35,825][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:40:37,347][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:40:37,376][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:40:37,376][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:40:37,376][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:40:37,376][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:40:37,376][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:40:37,377][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:40:38,791][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 09:41:02,675][root][INFO] - Step: 320/960  |  Loss: 0.8246  |  Score: 78.85 [%]  |  Seq Length: 256.0
[2024-10-23 09:41:05,467][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 09:41:05,467][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:41:08,269][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 09:41:08,269][root][INFO] - Score: 70.62 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:41:08,270][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 09:41:08,271][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:41:09,815][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:41:09,847][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:41:09,848][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:41:09,848][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:41:09,849][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:41:09,849][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:41:09,850][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:41:11,282][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 09:41:35,248][root][INFO] - Step: 384/960  |  Loss: 0.7300  |  Score: 80.47 [%]  |  Seq Length: 256.0
[2024-10-23 09:41:38,070][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 09:41:38,070][root][INFO] - Score: 76.14 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 09:41:40,836][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 09:41:40,836][root][INFO] - Score: 72.80 [%]  |  Evaluation Time: 2.76 [s]
[2024-10-23 09:41:40,839][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 09:42:04,737][root][INFO] - Step: 448/960  |  Loss: 0.6479  |  Score: 83.26 [%]  |  Seq Length: 256.0
[2024-10-23 09:42:07,548][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 09:42:07,549][root][INFO] - Score: 80.08 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 09:42:10,331][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 09:42:10,331][root][INFO] - Score: 72.44 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:42:10,332][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 09:42:10,332][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:42:11,840][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:42:11,883][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:42:11,883][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:42:11,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:42:11,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:42:11,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:42:11,885][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:42:13,294][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 09:42:37,218][root][INFO] - Step: 512/960  |  Loss: 0.5371  |  Score: 86.05 [%]  |  Seq Length: 256.0
[2024-10-23 09:42:40,034][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 09:42:40,035][root][INFO] - Score: 77.80 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 09:42:42,788][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 09:42:42,788][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 2.75 [s]
[2024-10-23 09:42:42,790][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 09:43:06,736][root][INFO] - Step: 576/960  |  Loss: 0.4860  |  Score: 86.71 [%]  |  Seq Length: 256.0
[2024-10-23 09:43:09,565][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 09:43:09,565][root][INFO] - Score: 76.41 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:43:12,331][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 09:43:12,332][root][INFO] - Score: 71.36 [%]  |  Evaluation Time: 2.76 [s]
[2024-10-23 09:43:12,333][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 09:43:36,293][root][INFO] - Step: 640/960  |  Loss: 0.4541  |  Score: 87.87 [%]  |  Seq Length: 256.0
[2024-10-23 09:43:39,079][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 09:43:39,079][root][INFO] - Score: 78.66 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:43:41,846][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 09:43:41,847][root][INFO] - Score: 72.27 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 09:43:41,849][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 09:44:05,759][root][INFO] - Step: 704/960  |  Loss: 0.4030  |  Score: 89.05 [%]  |  Seq Length: 256.0
[2024-10-23 09:44:08,542][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 09:44:08,543][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:44:11,323][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 09:44:11,323][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:44:11,325][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 09:44:24,098][root][INFO] - Step: 4220/10550  |  Loss: 0.2912  |  Score: 87.62 [%]  |  Seq Length: 256.0
[2024-10-23 09:44:35,236][root][INFO] - Step: 768/960  |  Loss: 0.3831  |  Score: 89.38 [%]  |  Seq Length: 256.0
[2024-10-23 09:44:38,035][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 09:44:38,035][root][INFO] - Score: 78.02 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:44:40,808][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 09:44:40,808][root][INFO] - Score: 72.02 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 09:44:40,810][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 09:45:04,759][root][INFO] - Step: 832/960  |  Loss: 0.3593  |  Score: 90.18 [%]  |  Seq Length: 256.0
[2024-10-23 09:45:07,602][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 09:45:07,602][root][INFO] - Score: 77.69 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 09:45:10,361][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 09:45:10,361][root][INFO] - Score: 71.76 [%]  |  Evaluation Time: 2.76 [s]
[2024-10-23 09:45:10,363][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 09:45:17,250][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 09:45:17,250][root][INFO] - Score: 88.24 [%]  |  Evaluation Time: 53.15 [s]
[2024-10-23 09:45:34,329][root][INFO] - Step: 896/960  |  Loss: 0.3505  |  Score: 90.25 [%]  |  Seq Length: 256.0
[2024-10-23 09:45:37,148][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 09:45:37,148][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 09:45:39,947][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 09:45:39,947][root][INFO] - Score: 71.83 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:45:39,949][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 09:46:03,911][root][INFO] - Step: 960/960  |  Loss: 0.3507  |  Score: 90.18 [%]  |  Seq Length: 256.0
[2024-10-23 09:46:06,734][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 09:46:06,734][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 09:46:09,541][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 09:46:09,541][root][INFO] - Score: 72.58 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:46:09,543][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 09:46:09,543][root][INFO] - - Epoch: 7
[2024-10-23 09:46:09,543][root][INFO] - - DEV score: 80.08 [%]
[2024-10-23 09:46:09,543][root][INFO] - - TEST score: 72.44 [%]
[2024-10-23 09:46:09,545][root][INFO] - Fine-tuning is done!
[2024-10-23 09:46:12,743][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,744][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,745][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,745][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,746][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,746][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,747][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,747][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,748][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,748][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,749][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,749][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,750][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,750][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,751][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,751][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,752][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,752][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,753][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,753][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,754][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,754][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,755][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 09:46:12,755][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 09:46:12,757][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 09:46:12,759][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 09:46:12,860][root][INFO] - 

[2024-10-23 09:46:12,861][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 09:46:12,861][root][INFO] - Data Preprocessing
[2024-10-23 09:46:12,861][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 09:46:12,861][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 09:46:12,861][root][INFO] - ㄴ data_remove                True

[2024-10-23 09:46:12,861][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 09:46:12,868][root][INFO] - vocab size              : 51200
[2024-10-23 09:46:12,868][root][INFO] - device                  : gpu
[2024-10-23 09:46:12,868][root][INFO] - random seed             : 1
[2024-10-23 09:46:12,869][root][INFO] - train data size         : 4096
[2024-10-23 09:46:12,869][root][INFO] - max epochs              : 15
[2024-10-23 09:46:12,869][root][INFO] - total steps             : 960
[2024-10-23 09:46:12,869][root][INFO] - warmup steps            : 96
[2024-10-23 09:46:12,869][root][INFO] - batch size              : 64
[2024-10-23 09:46:12,869][root][INFO] - accumulation steps      : 1
[2024-10-23 09:46:12,869][root][INFO] - optimizer               : adamwscale
[2024-10-23 09:46:12,869][root][INFO] - lr_scheduler            : cosine
[2024-10-23 09:46:12,869][root][INFO] - learning rate           : 0.02
[2024-10-23 09:46:12,869][root][INFO] - max length              : 256

[2024-10-23 09:46:12,869][root][INFO] - LoRA Configuration
[2024-10-23 09:46:12,869][root][INFO] - ㄴ r                    : 32
[2024-10-23 09:46:12,870][root][INFO] - ㄴ alpha                : 128
[2024-10-23 09:46:12,870][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 09:46:12,870][root][INFO] - 

[2024-10-23 09:46:12,870][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 09:46:12,870][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 09:46:12,870][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 09:46:12,870][root][INFO] - * tb interval   : 10000

[2024-10-23 09:46:12,870][root][INFO] - 

[2024-10-23 09:46:12,870][root][INFO] - Start the Training !
[2024-10-23 09:46:12,872][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 09:46:36,836][root][INFO] - Step: 64/960  |  Loss: 2.3749  |  Score: 39.01 [%]  |  Seq Length: 256.0
[2024-10-23 09:46:39,695][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 09:46:39,695][root][INFO] - Score: 72.94 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 09:46:42,498][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 09:46:42,499][root][INFO] - Score: 66.93 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:46:42,500][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 09:46:42,500][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:46:44,095][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:46:44,138][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:46:44,139][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:46:44,139][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:46:44,139][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:46:44,139][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:46:44,140][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:46:45,597][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 09:47:09,560][root][INFO] - Step: 128/960  |  Loss: 1.1878  |  Score: 69.16 [%]  |  Seq Length: 256.0
[2024-10-23 09:47:12,409][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 09:47:12,409][root][INFO] - Score: 72.83 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 09:47:15,197][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 09:47:15,198][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:47:15,198][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 09:47:15,199][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:47:16,741][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:47:16,773][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:47:16,773][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:47:16,774][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:47:16,774][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:47:16,774][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:47:16,775][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:47:18,222][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 09:47:42,156][root][INFO] - Step: 192/960  |  Loss: 1.0701  |  Score: 72.95 [%]  |  Seq Length: 256.0
[2024-10-23 09:47:44,995][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 09:47:44,995][root][INFO] - Score: 77.54 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 09:47:47,837][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 09:47:47,838][root][INFO] - Score: 69.72 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 09:47:47,839][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 09:47:47,839][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:47:49,434][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:47:49,587][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:47:49,587][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:47:49,588][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:47:49,588][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:47:49,588][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:47:49,589][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:47:51,047][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 09:48:14,503][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 09:48:14,504][root][INFO] - Score: 88.09 [%]  |  Evaluation Time: 177.25 [s]
[2024-10-23 09:48:14,505][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 09:48:14,505][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 09:48:14,508][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:48:15,017][root][INFO] - Step: 256/960  |  Loss: 0.8248  |  Score: 79.50 [%]  |  Seq Length: 256.0
[2024-10-23 09:48:16,237][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:48:16,441][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:48:16,443][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:48:16,443][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:48:16,444][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:48:16,444][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:48:16,447][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:48:17,932][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 09:48:17,932][root][INFO] - Score: 76.84 [%]  |  Evaluation Time: 2.91 [s]
[2024-10-23 09:48:18,124][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 09:48:20,873][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 09:48:20,873][root][INFO] - Score: 72.48 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 09:48:20,874][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 09:48:20,874][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:48:22,394][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:48:22,437][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:48:22,437][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:48:22,438][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:48:22,438][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:48:22,438][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:48:22,439][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:48:23,875][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 09:48:47,846][root][INFO] - Step: 320/960  |  Loss: 0.6808  |  Score: 82.61 [%]  |  Seq Length: 256.0
[2024-10-23 09:48:50,681][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 09:48:50,681][root][INFO] - Score: 78.01 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:48:53,460][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 09:48:53,461][root][INFO] - Score: 69.66 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:48:53,463][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 09:49:17,460][root][INFO] - Step: 384/960  |  Loss: 0.5404  |  Score: 85.80 [%]  |  Seq Length: 256.0
[2024-10-23 09:49:20,276][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 09:49:20,277][root][INFO] - Score: 74.87 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 09:49:23,066][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 09:49:23,066][root][INFO] - Score: 70.35 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:49:23,068][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 09:49:47,014][root][INFO] - Step: 448/960  |  Loss: 0.4922  |  Score: 87.97 [%]  |  Seq Length: 256.0
[2024-10-23 09:49:49,847][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 09:49:49,847][root][INFO] - Score: 79.70 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:49:52,645][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 09:49:52,645][root][INFO] - Score: 73.53 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:49:52,646][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 09:49:52,646][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:49:54,181][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:49:54,212][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:49:54,213][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:49:54,213][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:49:54,213][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:49:54,213][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:49:54,214][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:49:55,679][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 09:50:19,632][root][INFO] - Step: 512/960  |  Loss: 0.3796  |  Score: 90.13 [%]  |  Seq Length: 256.0
[2024-10-23 09:50:22,465][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 09:50:22,465][root][INFO] - Score: 78.80 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:50:25,257][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 09:50:25,257][root][INFO] - Score: 71.15 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:50:25,259][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 09:50:49,197][root][INFO] - Step: 576/960  |  Loss: 0.3075  |  Score: 91.59 [%]  |  Seq Length: 256.0
[2024-10-23 09:50:52,096][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 09:50:52,097][root][INFO] - Score: 77.14 [%]  |  Evaluation Time: 2.90 [s]
[2024-10-23 09:50:54,899][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 09:50:54,899][root][INFO] - Score: 70.13 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 09:50:54,901][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 09:51:18,860][root][INFO] - Step: 640/960  |  Loss: 0.2837  |  Score: 92.38 [%]  |  Seq Length: 256.0
[2024-10-23 09:51:21,697][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 09:51:21,697][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:51:24,482][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 09:51:24,482][root][INFO] - Score: 71.36 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 09:51:24,484][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 09:51:48,464][root][INFO] - Step: 704/960  |  Loss: 0.2486  |  Score: 93.34 [%]  |  Seq Length: 256.0
[2024-10-23 09:51:51,306][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 09:51:51,306][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 09:51:54,101][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 09:51:54,101][root][INFO] - Score: 71.31 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:51:54,103][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 09:52:18,104][root][INFO] - Step: 768/960  |  Loss: 0.2256  |  Score: 93.87 [%]  |  Seq Length: 256.0
[2024-10-23 09:52:20,952][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 09:52:20,952][root][INFO] - Score: 76.94 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 09:52:23,762][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 09:52:23,762][root][INFO] - Score: 71.08 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 09:52:23,764][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 09:52:47,711][root][INFO] - Step: 832/960  |  Loss: 0.2002  |  Score: 94.42 [%]  |  Seq Length: 256.0
[2024-10-23 09:52:50,543][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 09:52:50,543][root][INFO] - Score: 77.79 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:52:53,331][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 09:52:53,331][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:52:53,333][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 09:53:17,268][root][INFO] - Step: 896/960  |  Loss: 0.1934  |  Score: 94.63 [%]  |  Seq Length: 256.0
[2024-10-23 09:53:20,143][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 09:53:20,143][root][INFO] - Score: 78.32 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 09:53:22,938][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 09:53:22,938][root][INFO] - Score: 70.72 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 09:53:22,940][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 09:53:46,976][root][INFO] - Step: 960/960  |  Loss: 0.1886  |  Score: 94.67 [%]  |  Seq Length: 256.0
[2024-10-23 09:53:49,812][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 09:53:49,812][root][INFO] - Score: 78.75 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 09:53:52,623][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 09:53:52,623][root][INFO] - Score: 71.17 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 09:53:52,625][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 09:53:52,625][root][INFO] - - Epoch: 7
[2024-10-23 09:53:52,625][root][INFO] - - DEV score: 79.70 [%]
[2024-10-23 09:53:52,625][root][INFO] - - TEST score: 73.53 [%]
[2024-10-23 09:53:52,627][root][INFO] - Fine-tuning is done!
[2024-10-23 09:53:52,628][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 09:53:52,628][root][INFO] - - BEST LR: 0.02
[2024-10-23 09:53:52,629][root][INFO] - - DEV score: 79.70 [%]
[2024-10-23 09:53:52,629][root][INFO] - - TEST score: 73.53 [%]
[2024-10-23 09:53:58,928][root][INFO] - 

[2024-10-23 09:53:58,928][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 09:53:58,928][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 09:53:58,928][root][INFO] - 

[2024-10-23 09:53:58,928][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 09:54:03,429][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,430][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,430][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,431][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,431][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,432][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,432][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,432][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,433][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,433][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,434][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,434][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,434][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,435][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,435][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,436][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,436][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,436][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,437][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,437][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,438][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,438][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,439][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 09:54:03,439][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 09:54:03,441][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 09:54:03,444][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 09:54:03,646][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 09:54:03,648][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 09:54:03,822][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 09:54:06,955][root][INFO] - 

[2024-10-23 09:54:06,956][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 09:54:06,956][root][INFO] - Data Preprocessing
[2024-10-23 09:54:06,956][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 09:54:06,956][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 09:54:06,956][root][INFO] - ㄴ data_remove                True

[2024-10-23 09:54:06,956][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 09:54:06,965][root][INFO] - vocab size              : 51200
[2024-10-23 09:54:06,965][root][INFO] - device                  : gpu
[2024-10-23 09:54:06,965][root][INFO] - random seed             : 1
[2024-10-23 09:54:06,965][root][INFO] - train data size         : 4096
[2024-10-23 09:54:06,965][root][INFO] - max epochs              : 15
[2024-10-23 09:54:06,966][root][INFO] - total steps             : 960
[2024-10-23 09:54:06,966][root][INFO] - warmup steps            : 96
[2024-10-23 09:54:06,966][root][INFO] - batch size              : 64
[2024-10-23 09:54:06,966][root][INFO] - accumulation steps      : 1
[2024-10-23 09:54:06,966][root][INFO] - optimizer               : adamwscale
[2024-10-23 09:54:06,966][root][INFO] - lr_scheduler            : cosine
[2024-10-23 09:54:06,966][root][INFO] - learning rate           : 0.01
[2024-10-23 09:54:06,966][root][INFO] - max length              : 256

[2024-10-23 09:54:06,966][root][INFO] - LoRA Configuration
[2024-10-23 09:54:06,966][root][INFO] - ㄴ r                    : 32
[2024-10-23 09:54:06,966][root][INFO] - ㄴ alpha                : 128
[2024-10-23 09:54:06,966][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 09:54:06,967][root][INFO] - KOMBO Configuration
[2024-10-23 09:54:06,967][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 09:54:06,967][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 09:54:06,967][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 09:54:06,967][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 09:54:06,967][root][INFO] - ㄴ do_combination       : True
[2024-10-23 09:54:06,967][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 09:54:06,967][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 09:54:06,967][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 09:54:06,967][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 09:54:06,968][root][INFO] - 

[2024-10-23 09:54:06,968][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 09:54:06,968][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 09:54:06,968][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 09:54:06,968][root][INFO] - * tb interval   : 10000

[2024-10-23 09:54:06,968][root][INFO] - 

[2024-10-23 09:54:06,968][root][INFO] - Start the Training !
[2024-10-23 09:54:06,971][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 09:54:41,101][root][INFO] - Step: 64/960  |  Loss: 2.9233  |  Score: 22.16 [%]  |  Seq Length: 256.0
[2024-10-23 09:54:45,591][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 09:54:45,591][root][INFO] - Score: 68.07 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 09:54:49,960][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 09:54:49,960][root][INFO] - Score: 63.44 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-23 09:54:49,961][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 09:54:49,962][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:54:49,965][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:54:50,856][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:54:50,971][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:54:50,972][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:54:50,972][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:54:50,972][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:54:50,972][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:54:50,973][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:54:51,730][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 09:55:25,464][root][INFO] - Step: 128/960  |  Loss: 1.4008  |  Score: 63.96 [%]  |  Seq Length: 256.0
[2024-10-23 09:55:29,996][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 09:55:29,996][root][INFO] - Score: 77.48 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 09:55:34,350][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 09:55:34,350][root][INFO] - Score: 65.77 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-23 09:55:34,351][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 09:55:34,352][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:55:34,354][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:55:36,043][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:55:36,252][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:55:36,254][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:55:36,254][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:55:36,254][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:55:36,255][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:55:36,258][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:55:37,842][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 09:56:11,591][root][INFO] - Step: 192/960  |  Loss: 1.1831  |  Score: 69.52 [%]  |  Seq Length: 256.0
[2024-10-23 09:56:16,097][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 09:56:16,098][root][INFO] - Score: 77.40 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 09:56:20,472][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 09:56:20,472][root][INFO] - Score: 70.89 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-23 09:56:20,473][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 09:56:20,473][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:56:20,476][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:56:22,156][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:56:22,424][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:56:22,425][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:56:22,426][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:56:22,426][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:56:22,426][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:56:22,429][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:56:24,014][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 09:56:57,903][root][INFO] - Step: 256/960  |  Loss: 0.9662  |  Score: 75.04 [%]  |  Seq Length: 256.0
[2024-10-23 09:57:02,408][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 09:57:02,408][root][INFO] - Score: 79.07 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 09:57:06,751][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 09:57:06,751][root][INFO] - Score: 71.01 [%]  |  Evaluation Time: 4.34 [s]
[2024-10-23 09:57:06,752][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 09:57:06,752][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 09:57:06,755][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 09:57:08,434][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 09:57:08,705][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 09:57:08,707][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 09:57:08,707][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 09:57:08,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 09:57:08,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 09:57:08,711][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 09:57:10,313][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 09:57:44,079][root][INFO] - Step: 320/960  |  Loss: 0.8088  |  Score: 78.14 [%]  |  Seq Length: 256.0
[2024-10-23 09:57:48,578][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 09:57:48,578][root][INFO] - Score: 70.48 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 09:57:52,935][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 09:57:52,935][root][INFO] - Score: 71.90 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 09:57:52,937][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 09:58:26,731][root][INFO] - Step: 384/960  |  Loss: 0.7642  |  Score: 81.30 [%]  |  Seq Length: 256.0
[2024-10-23 09:58:31,220][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 09:58:31,220][root][INFO] - Score: 77.88 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 09:58:35,570][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 09:58:35,570][root][INFO] - Score: 69.08 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-23 09:58:35,573][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 09:59:09,436][root][INFO] - Step: 448/960  |  Loss: 0.6461  |  Score: 83.01 [%]  |  Seq Length: 256.0
[2024-10-23 09:59:13,967][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 09:59:13,967][root][INFO] - Score: 77.68 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 09:59:18,315][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 09:59:18,316][root][INFO] - Score: 71.73 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-23 09:59:18,318][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 09:59:52,230][root][INFO] - Step: 512/960  |  Loss: 0.5875  |  Score: 84.69 [%]  |  Seq Length: 256.0
[2024-10-23 09:59:56,721][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 09:59:56,721][root][INFO] - Score: 80.04 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 10:00:01,066][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:00:01,066][root][INFO] - Score: 72.28 [%]  |  Evaluation Time: 4.34 [s]
[2024-10-23 10:00:01,067][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 10:00:01,067][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:00:01,070][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:00:02,591][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:00:02,856][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:00:02,858][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:00:02,858][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:00:02,858][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:00:02,859][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:00:02,862][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:00:04,457][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:00:38,179][root][INFO] - Step: 576/960  |  Loss: 0.5194  |  Score: 86.69 [%]  |  Seq Length: 256.0
[2024-10-23 10:00:42,712][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:00:42,712][root][INFO] - Score: 75.35 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 10:00:47,038][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:00:47,038][root][INFO] - Score: 72.13 [%]  |  Evaluation Time: 4.32 [s]
[2024-10-23 10:00:47,040][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:01:20,718][root][INFO] - Step: 640/960  |  Loss: 0.4707  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-23 10:01:25,203][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:01:25,203][root][INFO] - Score: 79.54 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-23 10:01:29,573][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:01:29,573][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-23 10:01:29,575][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 10:02:03,261][root][INFO] - Step: 704/960  |  Loss: 0.4232  |  Score: 88.66 [%]  |  Seq Length: 256.0
[2024-10-23 10:02:07,765][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 10:02:07,766][root][INFO] - Score: 78.36 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 10:02:12,172][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 10:02:12,172][root][INFO] - Score: 71.47 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 10:02:12,174][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 10:02:45,986][root][INFO] - Step: 768/960  |  Loss: 0.3824  |  Score: 89.41 [%]  |  Seq Length: 256.0
[2024-10-23 10:02:50,501][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 10:02:50,501][root][INFO] - Score: 78.85 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:02:54,863][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 10:02:54,863][root][INFO] - Score: 72.85 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:02:54,866][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 10:03:28,722][root][INFO] - Step: 832/960  |  Loss: 0.3726  |  Score: 89.76 [%]  |  Seq Length: 256.0
[2024-10-23 10:03:33,266][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 10:03:33,266][root][INFO] - Score: 78.77 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:03:37,656][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 10:03:37,657][root][INFO] - Score: 71.72 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:03:37,659][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 10:04:11,401][root][INFO] - Step: 896/960  |  Loss: 0.3583  |  Score: 90.18 [%]  |  Seq Length: 256.0
[2024-10-23 10:04:15,952][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 10:04:15,952][root][INFO] - Score: 79.40 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 10:04:20,349][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 10:04:20,349][root][INFO] - Score: 72.55 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 10:04:20,351][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 10:04:54,275][root][INFO] - Step: 960/960  |  Loss: 0.3494  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-23 10:04:58,926][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 10:04:58,926][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-23 10:05:03,326][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 10:05:03,326][root][INFO] - Score: 71.80 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 10:05:03,327][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:05:03,327][root][INFO] - - Epoch: 8
[2024-10-23 10:05:03,327][root][INFO] - - DEV score: 80.04 [%]
[2024-10-23 10:05:03,327][root][INFO] - - TEST score: 72.28 [%]
[2024-10-23 10:05:03,328][root][INFO] - Fine-tuning is done!
[2024-10-23 10:05:06,482][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,483][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,483][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,484][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,484][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,485][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,485][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,486][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,486][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,487][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,488][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,488][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,489][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,489][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,490][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,490][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,491][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,491][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,492][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,492][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,493][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,493][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,494][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:05:06,495][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:05:06,496][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 10:05:06,706][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 10:05:06,709][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 10:05:06,710][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:05:06,877][root][INFO] - 

[2024-10-23 10:05:06,877][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 10:05:06,878][root][INFO] - Data Preprocessing
[2024-10-23 10:05:06,878][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 10:05:06,878][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:05:06,878][root][INFO] - ㄴ data_remove                True

[2024-10-23 10:05:06,878][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:05:06,885][root][INFO] - vocab size              : 51200
[2024-10-23 10:05:06,885][root][INFO] - device                  : gpu
[2024-10-23 10:05:06,885][root][INFO] - random seed             : 1
[2024-10-23 10:05:06,885][root][INFO] - train data size         : 4096
[2024-10-23 10:05:06,885][root][INFO] - max epochs              : 15
[2024-10-23 10:05:06,885][root][INFO] - total steps             : 960
[2024-10-23 10:05:06,885][root][INFO] - warmup steps            : 96
[2024-10-23 10:05:06,885][root][INFO] - batch size              : 64
[2024-10-23 10:05:06,886][root][INFO] - accumulation steps      : 1
[2024-10-23 10:05:06,886][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:05:06,886][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:05:06,886][root][INFO] - learning rate           : 0.02
[2024-10-23 10:05:06,886][root][INFO] - max length              : 256

[2024-10-23 10:05:06,886][root][INFO] - LoRA Configuration
[2024-10-23 10:05:06,886][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:05:06,886][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:05:06,886][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:05:06,886][root][INFO] - KOMBO Configuration
[2024-10-23 10:05:06,886][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 10:05:06,886][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 10:05:06,887][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 10:05:06,887][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 10:05:06,887][root][INFO] - ㄴ do_combination       : True
[2024-10-23 10:05:06,887][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 10:05:06,887][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 10:05:06,887][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 10:05:06,887][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 10:05:06,887][root][INFO] - 

[2024-10-23 10:05:06,887][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 10:05:06,888][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 10:05:06,888][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 10:05:06,888][root][INFO] - * tb interval   : 10000

[2024-10-23 10:05:06,888][root][INFO] - 

[2024-10-23 10:05:06,888][root][INFO] - Start the Training !
[2024-10-23 10:05:06,890][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 10:05:40,859][root][INFO] - Step: 64/960  |  Loss: 2.3798  |  Score: 36.19 [%]  |  Seq Length: 256.0
[2024-10-23 10:05:45,602][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 10:05:45,602][root][INFO] - Score: 71.64 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 10:05:50,059][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 10:05:50,059][root][INFO] - Score: 66.66 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-23 10:05:50,060][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 10:05:50,061][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:05:50,063][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:05:51,783][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:05:52,070][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:05:52,071][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:05:52,071][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:05:52,072][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:05:52,072][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:05:52,075][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:05:53,723][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 10:06:13,005][root][INFO] - Step: 6330/10550  |  Loss: 0.2516  |  Score: 89.60 [%]  |  Seq Length: 256.0
[2024-10-23 10:06:27,784][root][INFO] - Step: 128/960  |  Loss: 1.2698  |  Score: 67.88 [%]  |  Seq Length: 256.0
[2024-10-23 10:06:32,385][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 10:06:32,385][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-23 10:06:36,831][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 10:06:36,831][root][INFO] - Score: 67.21 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-23 10:06:36,833][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 10:06:36,833][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:06:36,836][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:06:38,373][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:06:38,625][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:06:38,627][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:06:38,627][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:06:38,628][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:06:38,628][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:06:38,631][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:06:40,284][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 10:07:06,539][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:07:06,539][root][INFO] - Score: 88.46 [%]  |  Evaluation Time: 53.53 [s]
[2024-10-23 10:07:14,372][root][INFO] - Step: 192/960  |  Loss: 1.0092  |  Score: 73.50 [%]  |  Seq Length: 256.0
[2024-10-23 10:07:18,982][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:07:18,982][root][INFO] - Score: 78.32 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-23 10:07:23,432][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:07:23,432][root][INFO] - Score: 71.77 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-23 10:07:23,433][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:07:23,434][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:07:23,436][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:07:25,151][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:07:25,439][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:07:25,441][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:07:25,441][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:07:25,441][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:07:25,442][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:07:25,445][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:07:27,081][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 10:08:01,046][root][INFO] - Step: 256/960  |  Loss: 0.8496  |  Score: 79.04 [%]  |  Seq Length: 256.0
[2024-10-23 10:08:05,615][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:08:05,615][root][INFO] - Score: 78.89 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 10:08:10,065][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:08:10,065][root][INFO] - Score: 71.27 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-23 10:08:10,066][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 10:08:10,067][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:08:10,069][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:08:11,784][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:08:12,076][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:08:12,078][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:08:12,078][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:08:12,078][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:08:12,079][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:08:12,081][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:08:13,778][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 10:08:47,506][root][INFO] - Step: 320/960  |  Loss: 0.6949  |  Score: 81.90 [%]  |  Seq Length: 256.0
[2024-10-23 10:08:52,004][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:08:52,004][root][INFO] - Score: 72.76 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 10:08:56,387][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:08:56,387][root][INFO] - Score: 71.51 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 10:08:56,389][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 10:09:30,239][root][INFO] - Step: 384/960  |  Loss: 0.5617  |  Score: 85.42 [%]  |  Seq Length: 256.0
[2024-10-23 10:09:34,810][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 10:09:34,810][root][INFO] - Score: 76.67 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 10:09:39,272][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 10:09:39,272][root][INFO] - Score: 69.87 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-23 10:09:39,274][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 10:10:04,099][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:10:04,100][root][INFO] - Score: 88.48 [%]  |  Evaluation Time: 177.56 [s]
[2024-10-23 10:10:04,101][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:10:04,102][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:10:04,106][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:10:05,868][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:10:06,158][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:10:06,160][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:10:06,160][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:10:06,161][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:10:06,161][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:10:06,164][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:10:07,820][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 10:10:13,168][root][INFO] - Step: 448/960  |  Loss: 0.4708  |  Score: 87.77 [%]  |  Seq Length: 256.0
[2024-10-23 10:10:17,736][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 10:10:17,736][root][INFO] - Score: 78.32 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-23 10:10:22,149][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 10:10:22,149][root][INFO] - Score: 71.89 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-23 10:10:22,150][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 10:10:22,151][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:10:22,153][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:10:23,869][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:10:24,156][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:10:24,158][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:10:24,158][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:10:24,158][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:10:24,159][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:10:24,162][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:10:25,784][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 10:10:59,623][root][INFO] - Step: 512/960  |  Loss: 0.3930  |  Score: 89.39 [%]  |  Seq Length: 256.0
[2024-10-23 10:11:04,196][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 10:11:04,196][root][INFO] - Score: 79.15 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 10:11:08,597][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:11:08,597][root][INFO] - Score: 71.42 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 10:11:08,598][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 10:11:08,598][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:11:08,601][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:11:10,307][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:11:10,607][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:11:10,607][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:11:10,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:11:10,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:11:10,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:11:10,609][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:11:12,334][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:11:46,166][root][INFO] - Step: 576/960  |  Loss: 0.3414  |  Score: 90.89 [%]  |  Seq Length: 256.0
[2024-10-23 10:11:50,758][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:11:50,758][root][INFO] - Score: 76.96 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-23 10:11:55,192][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:11:55,192][root][INFO] - Score: 71.25 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-23 10:11:55,195][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:12:28,986][root][INFO] - Step: 640/960  |  Loss: 0.2971  |  Score: 91.80 [%]  |  Seq Length: 256.0
[2024-10-23 10:12:33,530][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:12:33,530][root][INFO] - Score: 80.67 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:12:37,974][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:12:37,974][root][INFO] - Score: 70.30 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-23 10:12:37,975][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-23 10:12:37,976][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:12:37,978][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:12:39,686][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:12:39,969][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:12:39,970][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:12:39,971][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:12:39,971][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:12:39,972][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:12:39,974][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:12:41,620][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 10:13:15,435][root][INFO] - Step: 704/960  |  Loss: 0.2630  |  Score: 92.93 [%]  |  Seq Length: 256.0
[2024-10-23 10:13:19,983][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 10:13:19,983][root][INFO] - Score: 79.51 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:13:24,360][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 10:13:24,360][root][INFO] - Score: 71.52 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-23 10:13:24,361][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-23 10:13:24,361][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:13:24,364][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:13:26,086][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:13:26,386][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:13:26,387][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:13:26,387][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:13:26,387][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:13:26,388][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:13:26,390][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:13:28,039][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 10:14:01,832][root][INFO] - Step: 768/960  |  Loss: 0.2307  |  Score: 93.81 [%]  |  Seq Length: 256.0
[2024-10-23 10:14:06,374][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 10:14:06,374][root][INFO] - Score: 80.17 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:14:10,871][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 10:14:10,871][root][INFO] - Score: 72.41 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 10:14:10,872][root][INFO] - 
Save new Best Score (Epoch: 12)
[2024-10-23 10:14:10,872][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:14:10,875][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:14:12,510][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:14:12,766][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:14:12,768][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:14:12,768][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:14:12,768][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:14:12,769][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:14:12,771][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:14:14,465][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 10:14:48,535][root][INFO] - Step: 832/960  |  Loss: 0.2010  |  Score: 94.47 [%]  |  Seq Length: 256.0
[2024-10-23 10:14:53,115][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 10:14:53,115][root][INFO] - Score: 80.17 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-23 10:14:57,543][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 10:14:57,543][root][INFO] - Score: 71.66 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-23 10:14:57,545][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 10:15:31,597][root][INFO] - Step: 896/960  |  Loss: 0.1971  |  Score: 94.48 [%]  |  Seq Length: 256.0
[2024-10-23 10:15:36,161][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 10:15:36,162][root][INFO] - Score: 80.66 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-23 10:15:40,596][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 10:15:40,596][root][INFO] - Score: 72.18 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-23 10:15:40,596][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-23 10:15:40,597][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 10:15:40,600][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:15:42,325][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:15:42,614][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:15:42,615][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:15:42,615][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:15:42,616][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:15:42,616][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:15:42,619][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:15:44,261][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 10:16:18,369][root][INFO] - Step: 960/960  |  Loss: 0.1924  |  Score: 94.52 [%]  |  Seq Length: 256.0
[2024-10-23 10:16:22,882][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 10:16:22,882][root][INFO] - Score: 79.47 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:16:27,308][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 10:16:27,308][root][INFO] - Score: 71.90 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 10:16:27,309][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:16:27,309][root][INFO] - - Epoch: 14
[2024-10-23 10:16:27,309][root][INFO] - - DEV score: 80.66 [%]
[2024-10-23 10:16:27,309][root][INFO] - - TEST score: 72.18 [%]
[2024-10-23 10:16:27,310][root][INFO] - Fine-tuning is done!
[2024-10-23 10:16:27,311][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 10:16:27,311][root][INFO] - - BEST LR: 0.02
[2024-10-23 10:16:27,311][root][INFO] - - DEV score: 80.66 [%]
[2024-10-23 10:16:27,311][root][INFO] - - TEST score: 72.18 [%]
[2024-10-23 10:16:33,671][root][INFO] - 

[2024-10-23 10:16:33,671][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 10:16:33,671][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 10:16:33,671][root][INFO] - 

[2024-10-23 10:16:33,672][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 10:16:38,246][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,246][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,247][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,248][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,249][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,249][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,250][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,251][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,251][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,252][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,253][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,253][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,254][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,255][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,256][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,256][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,257][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,258][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,258][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,259][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,264][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,264][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,265][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:16:38,265][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:16:38,267][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 10:16:38,440][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:16:40,373][root][INFO] - 

[2024-10-23 10:16:40,373][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 10:16:40,373][root][INFO] - Data Preprocessing
[2024-10-23 10:16:40,374][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 10:16:40,374][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:16:40,374][root][INFO] - ㄴ data_remove                True

[2024-10-23 10:16:40,374][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:16:40,389][root][INFO] - vocab size              : 51200
[2024-10-23 10:16:40,389][root][INFO] - device                  : gpu
[2024-10-23 10:16:40,389][root][INFO] - random seed             : 2
[2024-10-23 10:16:40,390][root][INFO] - train data size         : 4096
[2024-10-23 10:16:40,390][root][INFO] - max epochs              : 15
[2024-10-23 10:16:40,390][root][INFO] - total steps             : 960
[2024-10-23 10:16:40,390][root][INFO] - warmup steps            : 96
[2024-10-23 10:16:40,390][root][INFO] - batch size              : 64
[2024-10-23 10:16:40,390][root][INFO] - accumulation steps      : 1
[2024-10-23 10:16:40,390][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:16:40,391][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:16:40,391][root][INFO] - learning rate           : 0.01
[2024-10-23 10:16:40,391][root][INFO] - max length              : 256

[2024-10-23 10:16:40,391][root][INFO] - LoRA Configuration
[2024-10-23 10:16:40,391][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:16:40,392][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:16:40,392][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:16:40,392][root][INFO] - 

[2024-10-23 10:16:40,392][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 10:16:40,392][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 10:16:40,392][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 10:16:40,393][root][INFO] - * tb interval   : 10000

[2024-10-23 10:16:40,393][root][INFO] - 

[2024-10-23 10:16:40,393][root][INFO] - Start the Training !
[2024-10-23 10:16:40,397][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 10:17:05,398][root][INFO] - Step: 64/960  |  Loss: 2.3515  |  Score: 31.31 [%]  |  Seq Length: 256.0
[2024-10-23 10:17:08,255][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 10:17:08,255][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 10:17:11,059][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 10:17:11,059][root][INFO] - Score: 65.17 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:17:11,061][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 10:17:11,061][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:17:11,903][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:17:11,931][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:17:11,932][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:17:11,932][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:17:11,932][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:17:11,932][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:17:11,933][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:17:12,634][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 10:17:36,557][root][INFO] - Step: 128/960  |  Loss: 1.3413  |  Score: 64.84 [%]  |  Seq Length: 256.0
[2024-10-23 10:17:39,365][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 10:17:39,365][root][INFO] - Score: 75.39 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:17:42,143][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 10:17:42,143][root][INFO] - Score: 67.23 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 10:17:42,144][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 10:17:42,144][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:17:43,645][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:17:43,755][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:17:43,756][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:17:43,756][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:17:43,756][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:17:43,756][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:17:43,757][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:17:45,174][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 10:18:09,333][root][INFO] - Step: 192/960  |  Loss: 1.0895  |  Score: 71.90 [%]  |  Seq Length: 256.0
[2024-10-23 10:18:12,171][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:18:12,171][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:18:14,968][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:18:14,968][root][INFO] - Score: 68.63 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 10:18:14,970][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:18:14,970][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:18:16,507][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:18:16,561][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:18:16,561][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:18:16,562][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:18:16,562][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:18:16,562][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:18:16,563][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:18:17,981][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 10:18:41,959][root][INFO] - Step: 256/960  |  Loss: 0.9454  |  Score: 75.36 [%]  |  Seq Length: 256.0
[2024-10-23 10:18:44,807][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:18:44,808][root][INFO] - Score: 77.85 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 10:18:47,618][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:18:47,618][root][INFO] - Score: 70.28 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:18:47,619][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 10:18:47,620][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:18:49,185][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:18:49,228][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:18:49,229][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:18:49,229][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:18:49,229][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:18:49,229][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:18:49,230][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:18:50,675][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 10:19:14,667][root][INFO] - Step: 320/960  |  Loss: 0.7914  |  Score: 78.93 [%]  |  Seq Length: 256.0
[2024-10-23 10:19:17,480][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:19:17,480][root][INFO] - Score: 78.11 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:19:20,251][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:19:20,251][root][INFO] - Score: 70.15 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 10:19:20,252][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 10:19:20,253][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:19:21,783][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:19:21,820][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:19:21,821][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:19:21,821][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:19:21,821][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:19:21,821][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:19:21,822][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:19:23,266][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 10:19:47,255][root][INFO] - Step: 384/960  |  Loss: 0.6937  |  Score: 81.79 [%]  |  Seq Length: 256.0
[2024-10-23 10:19:50,135][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 10:19:50,135][root][INFO] - Score: 78.59 [%]  |  Evaluation Time: 2.88 [s]
[2024-10-23 10:19:52,913][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 10:19:52,914][root][INFO] - Score: 70.15 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 10:19:52,915][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 10:19:52,916][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:19:54,443][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:19:54,473][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:19:54,474][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:19:54,474][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:19:54,474][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:19:54,474][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:19:54,475][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:19:55,897][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 10:20:19,902][root][INFO] - Step: 448/960  |  Loss: 0.6377  |  Score: 83.83 [%]  |  Seq Length: 256.0
[2024-10-23 10:20:22,724][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 10:20:22,724][root][INFO] - Score: 78.57 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:20:25,504][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 10:20:25,504][root][INFO] - Score: 70.29 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 10:20:25,505][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 10:20:25,506][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:20:27,081][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:20:27,150][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:20:27,151][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:20:27,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:20:27,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:20:27,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:20:27,153][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:20:28,593][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 10:20:52,666][root][INFO] - Step: 512/960  |  Loss: 0.5596  |  Score: 85.92 [%]  |  Seq Length: 256.0
[2024-10-23 10:20:55,487][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 10:20:55,487][root][INFO] - Score: 79.28 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:20:58,288][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:20:58,289][root][INFO] - Score: 73.00 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:20:58,290][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 10:20:58,291][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:20:59,845][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:20:59,875][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:20:59,876][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:20:59,876][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:20:59,876][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:20:59,876][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:20:59,877][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:21:01,338][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:21:25,426][root][INFO] - Step: 576/960  |  Loss: 0.4945  |  Score: 86.81 [%]  |  Seq Length: 256.0
[2024-10-23 10:21:28,298][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:21:28,299][root][INFO] - Score: 78.67 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 10:21:31,120][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:21:31,120][root][INFO] - Score: 72.22 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:21:31,123][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:21:55,175][root][INFO] - Step: 640/960  |  Loss: 0.4659  |  Score: 87.88 [%]  |  Seq Length: 256.0
[2024-10-23 10:21:58,061][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:21:58,062][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 2.88 [s]
[2024-10-23 10:22:00,877][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:22:00,877][root][INFO] - Score: 72.36 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:22:00,879][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 10:22:24,884][root][INFO] - Step: 704/960  |  Loss: 0.4098  |  Score: 89.14 [%]  |  Seq Length: 256.0
[2024-10-23 10:22:27,715][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 10:22:27,715][root][INFO] - Score: 76.83 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:22:30,546][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 10:22:30,546][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:22:30,549][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 10:22:54,583][root][INFO] - Step: 768/960  |  Loss: 0.3819  |  Score: 89.69 [%]  |  Seq Length: 256.0
[2024-10-23 10:22:57,419][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 10:22:57,420][root][INFO] - Score: 78.03 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:23:00,247][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 10:23:00,247][root][INFO] - Score: 70.78 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:23:00,249][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 10:23:24,285][root][INFO] - Step: 832/960  |  Loss: 0.3641  |  Score: 89.99 [%]  |  Seq Length: 256.0
[2024-10-23 10:23:27,128][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 10:23:27,128][root][INFO] - Score: 78.87 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 10:23:29,926][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 10:23:29,926][root][INFO] - Score: 72.16 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:23:29,928][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 10:23:53,896][root][INFO] - Step: 896/960  |  Loss: 0.3521  |  Score: 90.44 [%]  |  Seq Length: 256.0
[2024-10-23 10:23:56,723][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 10:23:56,723][root][INFO] - Score: 78.90 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:23:59,528][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 10:23:59,529][root][INFO] - Score: 71.39 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:23:59,531][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 10:24:23,581][root][INFO] - Step: 960/960  |  Loss: 0.3379  |  Score: 90.74 [%]  |  Seq Length: 256.0
[2024-10-23 10:24:26,417][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 10:24:26,417][root][INFO] - Score: 79.09 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:24:29,226][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 10:24:29,226][root][INFO] - Score: 71.51 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:24:29,227][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:24:29,227][root][INFO] - - Epoch: 8
[2024-10-23 10:24:29,227][root][INFO] - - DEV score: 79.28 [%]
[2024-10-23 10:24:29,227][root][INFO] - - TEST score: 73.00 [%]
[2024-10-23 10:24:29,228][root][INFO] - Fine-tuning is done!
[2024-10-23 10:24:32,324][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,325][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,326][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,326][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,327][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,327][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,328][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,328][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,329][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,329][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,330][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,330][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,331][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,332][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,332][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,333][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,333][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,334][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,334][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,335][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,336][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,336][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,337][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:24:32,337][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:24:32,339][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 10:24:32,341][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:24:32,491][root][INFO] - 

[2024-10-23 10:24:32,491][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 10:24:32,491][root][INFO] - Data Preprocessing
[2024-10-23 10:24:32,491][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 10:24:32,491][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:24:32,491][root][INFO] - ㄴ data_remove                True

[2024-10-23 10:24:32,491][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:24:32,498][root][INFO] - vocab size              : 51200
[2024-10-23 10:24:32,499][root][INFO] - device                  : gpu
[2024-10-23 10:24:32,499][root][INFO] - random seed             : 2
[2024-10-23 10:24:32,499][root][INFO] - train data size         : 4096
[2024-10-23 10:24:32,499][root][INFO] - max epochs              : 15
[2024-10-23 10:24:32,499][root][INFO] - total steps             : 960
[2024-10-23 10:24:32,499][root][INFO] - warmup steps            : 96
[2024-10-23 10:24:32,499][root][INFO] - batch size              : 64
[2024-10-23 10:24:32,499][root][INFO] - accumulation steps      : 1
[2024-10-23 10:24:32,499][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:24:32,499][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:24:32,499][root][INFO] - learning rate           : 0.02
[2024-10-23 10:24:32,500][root][INFO] - max length              : 256

[2024-10-23 10:24:32,500][root][INFO] - LoRA Configuration
[2024-10-23 10:24:32,500][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:24:32,500][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:24:32,500][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:24:32,500][root][INFO] - 

[2024-10-23 10:24:32,500][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 10:24:32,500][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 10:24:32,500][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 10:24:32,500][root][INFO] - * tb interval   : 10000

[2024-10-23 10:24:32,500][root][INFO] - 

[2024-10-23 10:24:32,500][root][INFO] - Start the Training !
[2024-10-23 10:24:32,502][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 10:24:56,553][root][INFO] - Step: 64/960  |  Loss: 1.9965  |  Score: 43.60 [%]  |  Seq Length: 256.0
[2024-10-23 10:24:59,424][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 10:24:59,424][root][INFO] - Score: 72.10 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 10:25:02,247][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 10:25:02,248][root][INFO] - Score: 66.22 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:25:02,249][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 10:25:02,250][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:25:03,828][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:25:03,872][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:25:03,872][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:25:03,873][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:25:03,873][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:25:03,873][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:25:03,874][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:25:05,317][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 10:25:29,380][root][INFO] - Step: 128/960  |  Loss: 1.2407  |  Score: 67.74 [%]  |  Seq Length: 256.0
[2024-10-23 10:25:32,235][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 10:25:32,235][root][INFO] - Score: 76.14 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 10:25:35,023][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 10:25:35,023][root][INFO] - Score: 69.30 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 10:25:35,024][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 10:25:35,025][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:25:36,609][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:25:36,667][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:25:36,667][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:25:36,668][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:25:36,668][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:25:36,668][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:25:36,669][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:25:38,172][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 10:26:02,214][root][INFO] - Step: 192/960  |  Loss: 1.0004  |  Score: 75.74 [%]  |  Seq Length: 256.0
[2024-10-23 10:26:05,087][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:26:05,088][root][INFO] - Score: 78.76 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 10:26:07,943][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:26:07,943][root][INFO] - Score: 70.83 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 10:26:07,944][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:26:07,944][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:26:09,482][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:26:09,516][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:26:09,516][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:26:09,517][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:26:09,517][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:26:09,517][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:26:09,518][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:26:10,964][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 10:26:35,083][root][INFO] - Step: 256/960  |  Loss: 0.7720  |  Score: 79.91 [%]  |  Seq Length: 256.0
[2024-10-23 10:26:37,957][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:26:37,957][root][INFO] - Score: 76.61 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 10:26:40,790][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:26:40,791][root][INFO] - Score: 70.32 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:26:40,793][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 10:27:04,800][root][INFO] - Step: 320/960  |  Loss: 0.6715  |  Score: 83.21 [%]  |  Seq Length: 256.0
[2024-10-23 10:27:07,668][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:27:07,668][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 10:27:10,508][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:27:10,508][root][INFO] - Score: 69.44 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 10:27:10,511][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 10:27:34,589][root][INFO] - Step: 384/960  |  Loss: 0.5421  |  Score: 86.32 [%]  |  Seq Length: 256.0
[2024-10-23 10:27:37,474][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 10:27:37,474][root][INFO] - Score: 77.86 [%]  |  Evaluation Time: 2.88 [s]
[2024-10-23 10:27:40,312][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 10:27:40,313][root][INFO] - Score: 69.08 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 10:27:40,315][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 10:28:03,652][root][INFO] - Step: 8440/10550  |  Loss: 0.2158  |  Score: 91.24 [%]  |  Seq Length: 256.0
[2024-10-23 10:28:04,401][root][INFO] - Step: 448/960  |  Loss: 0.4388  |  Score: 88.86 [%]  |  Seq Length: 256.0
[2024-10-23 10:28:07,266][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 10:28:07,266][root][INFO] - Score: 77.98 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 10:28:10,129][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 10:28:10,130][root][INFO] - Score: 68.02 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 10:28:10,132][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 10:28:34,205][root][INFO] - Step: 512/960  |  Loss: 0.3560  |  Score: 90.52 [%]  |  Seq Length: 256.0
[2024-10-23 10:28:37,068][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 10:28:37,068][root][INFO] - Score: 78.17 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 10:28:39,870][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:28:39,870][root][INFO] - Score: 71.30 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:28:39,872][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:28:57,682][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:28:57,682][root][INFO] - Score: 88.98 [%]  |  Evaluation Time: 54.03 [s]
[2024-10-23 10:29:03,955][root][INFO] - Step: 576/960  |  Loss: 0.3264  |  Score: 91.31 [%]  |  Seq Length: 256.0
[2024-10-23 10:29:06,816][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:29:06,816][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 10:29:09,624][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:29:09,624][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:29:09,627][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:29:33,711][root][INFO] - Step: 640/960  |  Loss: 0.2713  |  Score: 92.52 [%]  |  Seq Length: 256.0
[2024-10-23 10:29:36,595][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:29:36,595][root][INFO] - Score: 78.79 [%]  |  Evaluation Time: 2.88 [s]
[2024-10-23 10:29:39,445][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:29:39,445][root][INFO] - Score: 69.94 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 10:29:39,447][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 10:30:03,545][root][INFO] - Step: 704/960  |  Loss: 0.2340  |  Score: 93.63 [%]  |  Seq Length: 256.0
[2024-10-23 10:30:06,444][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 10:30:06,445][root][INFO] - Score: 76.57 [%]  |  Evaluation Time: 2.90 [s]
[2024-10-23 10:30:09,302][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 10:30:09,303][root][INFO] - Score: 69.68 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 10:30:09,306][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 10:30:33,370][root][INFO] - Step: 768/960  |  Loss: 0.2097  |  Score: 94.33 [%]  |  Seq Length: 256.0
[2024-10-23 10:30:36,261][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 10:30:36,261][root][INFO] - Score: 78.49 [%]  |  Evaluation Time: 2.89 [s]
[2024-10-23 10:30:39,132][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 10:30:39,133][root][INFO] - Score: 69.72 [%]  |  Evaluation Time: 2.87 [s]
[2024-10-23 10:30:39,136][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 10:31:03,298][root][INFO] - Step: 832/960  |  Loss: 0.1921  |  Score: 94.74 [%]  |  Seq Length: 256.0
[2024-10-23 10:31:06,251][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 10:31:06,252][root][INFO] - Score: 78.37 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 10:31:09,093][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 10:31:09,093][root][INFO] - Score: 70.58 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 10:31:09,096][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 10:31:33,204][root][INFO] - Step: 896/960  |  Loss: 0.1831  |  Score: 95.00 [%]  |  Seq Length: 256.0
[2024-10-23 10:31:36,090][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 10:31:36,091][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 2.88 [s]
[2024-10-23 10:31:38,907][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 10:31:38,908][root][INFO] - Score: 69.90 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:31:38,910][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 10:31:56,408][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:31:56,409][root][INFO] - Score: 88.93 [%]  |  Evaluation Time: 178.72 [s]
[2024-10-23 10:31:56,410][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 10:31:56,410][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:31:56,413][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:31:58,215][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:31:58,530][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:31:58,531][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:31:58,531][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:31:58,532][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:31:58,532][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:31:58,535][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:32:00,275][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 10:32:02,999][root][INFO] - Step: 960/960  |  Loss: 0.1741  |  Score: 95.16 [%]  |  Seq Length: 256.0
[2024-10-23 10:32:05,879][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 10:32:05,879][root][INFO] - Score: 78.76 [%]  |  Evaluation Time: 2.88 [s]
[2024-10-23 10:32:08,712][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 10:32:08,712][root][INFO] - Score: 70.09 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 10:32:08,713][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:32:08,713][root][INFO] - - Epoch: 3
[2024-10-23 10:32:08,713][root][INFO] - - DEV score: 78.76 [%]
[2024-10-23 10:32:08,713][root][INFO] - - TEST score: 70.83 [%]
[2024-10-23 10:32:08,715][root][INFO] - Fine-tuning is done!
[2024-10-23 10:32:08,716][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 10:32:08,716][root][INFO] - - BEST LR: 0.01
[2024-10-23 10:32:08,716][root][INFO] - - DEV score: 79.28 [%]
[2024-10-23 10:32:08,716][root][INFO] - - TEST score: 73.00 [%]
[2024-10-23 10:32:14,812][root][INFO] - 

[2024-10-23 10:32:14,812][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 10:32:14,812][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 10:32:14,812][root][INFO] - 

[2024-10-23 10:32:14,812][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 10:32:19,263][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,264][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,264][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,265][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,265][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,266][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,266][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,267][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,267][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,268][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,268][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,269][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,269][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,270][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,271][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,271][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,272][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,273][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,274][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,274][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,275][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,276][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,277][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:32:19,277][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:32:19,280][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 10:32:19,286][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 10:32:19,532][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 10:32:19,535][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 10:32:19,701][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:32:22,913][root][INFO] - 

[2024-10-23 10:32:22,913][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 10:32:22,914][root][INFO] - Data Preprocessing
[2024-10-23 10:32:22,914][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 10:32:22,914][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:32:22,914][root][INFO] - ㄴ data_remove                True

[2024-10-23 10:32:22,914][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:32:22,923][root][INFO] - vocab size              : 51200
[2024-10-23 10:32:22,923][root][INFO] - device                  : gpu
[2024-10-23 10:32:22,923][root][INFO] - random seed             : 2
[2024-10-23 10:32:22,924][root][INFO] - train data size         : 4096
[2024-10-23 10:32:22,924][root][INFO] - max epochs              : 15
[2024-10-23 10:32:22,924][root][INFO] - total steps             : 960
[2024-10-23 10:32:22,924][root][INFO] - warmup steps            : 96
[2024-10-23 10:32:22,924][root][INFO] - batch size              : 64
[2024-10-23 10:32:22,924][root][INFO] - accumulation steps      : 1
[2024-10-23 10:32:22,924][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:32:22,924][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:32:22,924][root][INFO] - learning rate           : 0.01
[2024-10-23 10:32:22,924][root][INFO] - max length              : 256

[2024-10-23 10:32:22,924][root][INFO] - LoRA Configuration
[2024-10-23 10:32:22,924][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:32:22,924][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:32:22,925][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:32:22,925][root][INFO] - KOMBO Configuration
[2024-10-23 10:32:22,925][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 10:32:22,925][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 10:32:22,925][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 10:32:22,925][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 10:32:22,925][root][INFO] - ㄴ do_combination       : True
[2024-10-23 10:32:22,925][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 10:32:22,925][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 10:32:22,926][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 10:32:22,926][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 10:32:22,926][root][INFO] - 

[2024-10-23 10:32:22,926][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 10:32:22,926][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 10:32:22,926][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 10:32:22,926][root][INFO] - * tb interval   : 10000

[2024-10-23 10:32:22,926][root][INFO] - 

[2024-10-23 10:32:22,926][root][INFO] - Start the Training !
[2024-10-23 10:32:22,929][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 10:32:57,233][root][INFO] - Step: 64/960  |  Loss: 2.2237  |  Score: 33.11 [%]  |  Seq Length: 256.0
[2024-10-23 10:33:01,803][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 10:33:01,803][root][INFO] - Score: 71.81 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 10:33:06,161][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 10:33:06,161][root][INFO] - Score: 63.23 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:33:06,162][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 10:33:06,163][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:33:06,166][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:33:07,035][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:33:07,162][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:33:07,162][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:33:07,162][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:33:07,162][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:33:07,162][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:33:07,163][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:33:07,922][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 10:33:41,713][root][INFO] - Step: 128/960  |  Loss: 1.4064  |  Score: 66.12 [%]  |  Seq Length: 256.0
[2024-10-23 10:33:46,244][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 10:33:46,244][root][INFO] - Score: 77.78 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 10:33:50,656][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 10:33:50,657][root][INFO] - Score: 65.22 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-23 10:33:50,658][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 10:33:50,658][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:33:50,661][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:33:52,340][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:33:52,543][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:33:52,544][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:33:52,544][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:33:52,545][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:33:52,545][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:33:52,547][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:33:54,145][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 10:34:28,055][root][INFO] - Step: 192/960  |  Loss: 1.1373  |  Score: 70.12 [%]  |  Seq Length: 256.0
[2024-10-23 10:34:32,600][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:34:32,601][root][INFO] - Score: 77.99 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:34:37,009][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:34:37,009][root][INFO] - Score: 69.04 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-23 10:34:37,010][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:34:37,011][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:34:37,013][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:34:38,726][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:34:38,929][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:34:38,930][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:34:38,930][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:34:38,931][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:34:38,931][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:34:38,934][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:34:40,539][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 10:35:14,101][root][INFO] - Step: 256/960  |  Loss: 0.9479  |  Score: 74.68 [%]  |  Seq Length: 256.0
[2024-10-23 10:35:18,655][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:35:18,656][root][INFO] - Score: 75.81 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 10:35:23,028][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:35:23,028][root][INFO] - Score: 69.55 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-23 10:35:23,030][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 10:35:56,955][root][INFO] - Step: 320/960  |  Loss: 0.8157  |  Score: 79.85 [%]  |  Seq Length: 256.0
[2024-10-23 10:36:01,501][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:36:01,501][root][INFO] - Score: 77.15 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:36:05,890][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:36:05,891][root][INFO] - Score: 69.50 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:36:05,893][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 10:36:39,869][root][INFO] - Step: 384/960  |  Loss: 0.7166  |  Score: 81.19 [%]  |  Seq Length: 256.0
[2024-10-23 10:36:44,390][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 10:36:44,390][root][INFO] - Score: 80.16 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-23 10:36:48,774][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 10:36:48,774][root][INFO] - Score: 72.50 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 10:36:48,776][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 10:36:48,776][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:36:48,779][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:36:50,480][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:36:50,757][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:36:50,759][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:36:50,759][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:36:50,759][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:36:50,760][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:36:50,763][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:36:52,387][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 10:37:26,220][root][INFO] - Step: 448/960  |  Loss: 0.6156  |  Score: 83.51 [%]  |  Seq Length: 256.0
[2024-10-23 10:37:30,723][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 10:37:30,723][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 10:37:35,059][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 10:37:35,059][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.33 [s]
[2024-10-23 10:37:35,061][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 10:38:08,973][root][INFO] - Step: 512/960  |  Loss: 0.5431  |  Score: 85.72 [%]  |  Seq Length: 256.0
[2024-10-23 10:38:13,538][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 10:38:13,538][root][INFO] - Score: 79.86 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-23 10:38:18,035][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:38:18,035][root][INFO] - Score: 71.94 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 10:38:18,037][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:38:52,095][root][INFO] - Step: 576/960  |  Loss: 0.4786  |  Score: 87.41 [%]  |  Seq Length: 256.0
[2024-10-23 10:38:56,682][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:38:56,683][root][INFO] - Score: 78.77 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-23 10:39:01,060][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:39:01,060][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 10:39:01,062][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:39:34,986][root][INFO] - Step: 640/960  |  Loss: 0.4426  |  Score: 88.20 [%]  |  Seq Length: 256.0
[2024-10-23 10:39:39,531][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:39:39,531][root][INFO] - Score: 77.53 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:39:43,883][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:39:43,883][root][INFO] - Score: 71.99 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-23 10:39:43,885][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 10:40:17,833][root][INFO] - Step: 704/960  |  Loss: 0.3986  |  Score: 89.04 [%]  |  Seq Length: 256.0
[2024-10-23 10:40:22,377][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 10:40:22,377][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:40:26,780][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 10:40:26,780][root][INFO] - Score: 70.68 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 10:40:26,782][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 10:41:00,699][root][INFO] - Step: 768/960  |  Loss: 0.3704  |  Score: 89.78 [%]  |  Seq Length: 256.0
[2024-10-23 10:41:05,215][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 10:41:05,215][root][INFO] - Score: 76.12 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:41:09,605][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 10:41:09,605][root][INFO] - Score: 69.80 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:41:09,607][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 10:41:43,624][root][INFO] - Step: 832/960  |  Loss: 0.3558  |  Score: 90.36 [%]  |  Seq Length: 256.0
[2024-10-23 10:41:48,174][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 10:41:48,174][root][INFO] - Score: 76.57 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 10:41:52,591][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 10:41:52,591][root][INFO] - Score: 71.12 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 10:41:52,593][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 10:42:26,644][root][INFO] - Step: 896/960  |  Loss: 0.3491  |  Score: 90.24 [%]  |  Seq Length: 256.0
[2024-10-23 10:42:31,183][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 10:42:31,183][root][INFO] - Score: 80.17 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:42:35,564][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 10:42:35,565][root][INFO] - Score: 70.91 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 10:42:35,567][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 10:43:09,562][root][INFO] - Step: 960/960  |  Loss: 0.3450  |  Score: 90.40 [%]  |  Seq Length: 256.0
[2024-10-23 10:43:14,104][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 10:43:14,104][root][INFO] - Score: 73.83 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 10:43:18,470][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 10:43:18,471][root][INFO] - Score: 71.01 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:43:18,471][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:43:18,471][root][INFO] - - Epoch: 6
[2024-10-23 10:43:18,471][root][INFO] - - DEV score: 80.16 [%]
[2024-10-23 10:43:18,472][root][INFO] - - TEST score: 72.50 [%]
[2024-10-23 10:43:18,472][root][INFO] - Fine-tuning is done!
[2024-10-23 10:43:21,836][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,836][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,837][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,838][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,838][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,839][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,839][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,840][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,840][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,841][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,842][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,842][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,842][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,843][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,843][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,844][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,844][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,845][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,845][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,846][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,847][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,847][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,848][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:43:21,848][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:43:21,850][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 10:43:22,058][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 10:43:22,061][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 10:43:22,062][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:43:22,244][root][INFO] - 

[2024-10-23 10:43:22,244][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 10:43:22,244][root][INFO] - Data Preprocessing
[2024-10-23 10:43:22,244][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 10:43:22,244][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:43:22,244][root][INFO] - ㄴ data_remove                True

[2024-10-23 10:43:22,244][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:43:22,251][root][INFO] - vocab size              : 51200
[2024-10-23 10:43:22,251][root][INFO] - device                  : gpu
[2024-10-23 10:43:22,251][root][INFO] - random seed             : 2
[2024-10-23 10:43:22,252][root][INFO] - train data size         : 4096
[2024-10-23 10:43:22,252][root][INFO] - max epochs              : 15
[2024-10-23 10:43:22,252][root][INFO] - total steps             : 960
[2024-10-23 10:43:22,252][root][INFO] - warmup steps            : 96
[2024-10-23 10:43:22,252][root][INFO] - batch size              : 64
[2024-10-23 10:43:22,252][root][INFO] - accumulation steps      : 1
[2024-10-23 10:43:22,252][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:43:22,252][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:43:22,252][root][INFO] - learning rate           : 0.02
[2024-10-23 10:43:22,252][root][INFO] - max length              : 256

[2024-10-23 10:43:22,252][root][INFO] - LoRA Configuration
[2024-10-23 10:43:22,252][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:43:22,252][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:43:22,253][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:43:22,253][root][INFO] - KOMBO Configuration
[2024-10-23 10:43:22,253][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 10:43:22,253][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 10:43:22,253][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 10:43:22,253][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 10:43:22,253][root][INFO] - ㄴ do_combination       : True
[2024-10-23 10:43:22,253][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 10:43:22,253][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 10:43:22,253][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 10:43:22,254][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 10:43:22,254][root][INFO] - 

[2024-10-23 10:43:22,254][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 10:43:22,254][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 10:43:22,254][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 10:43:22,254][root][INFO] - * tb interval   : 10000

[2024-10-23 10:43:22,254][root][INFO] - 

[2024-10-23 10:43:22,254][root][INFO] - Start the Training !
[2024-10-23 10:43:22,256][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 10:43:56,314][root][INFO] - Step: 64/960  |  Loss: 1.9990  |  Score: 42.85 [%]  |  Seq Length: 256.0
[2024-10-23 10:44:00,839][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 10:44:00,839][root][INFO] - Score: 73.55 [%]  |  Evaluation Time: 4.52 [s]
[2024-10-23 10:44:05,203][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 10:44:05,203][root][INFO] - Score: 66.05 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:44:05,204][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 10:44:05,204][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:44:05,207][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:44:06,933][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:44:07,192][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:44:07,193][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:44:07,193][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:44:07,193][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:44:07,194][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:44:07,197][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:44:08,838][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 10:44:42,377][root][INFO] - Step: 128/960  |  Loss: 1.2533  |  Score: 68.63 [%]  |  Seq Length: 256.0
[2024-10-23 10:44:46,933][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 10:44:46,934][root][INFO] - Score: 78.75 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 10:44:51,355][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 10:44:51,355][root][INFO] - Score: 70.11 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 10:44:51,355][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 10:44:51,356][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:44:51,358][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:44:53,073][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:44:53,346][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:44:53,347][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:44:53,347][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:44:53,348][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:44:53,348][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:44:53,350][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:44:54,992][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 10:45:11,095][root][INFO] - Step: 10000/10550  |  Loss: 0.1914  |  Score: 92.37 [%]  |  Seq Length: 256.0
[2024-10-23 10:45:28,996][root][INFO] - Step: 192/960  |  Loss: 1.0632  |  Score: 73.58 [%]  |  Seq Length: 256.0
[2024-10-23 10:45:33,553][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:45:33,554][root][INFO] - Score: 78.27 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 10:45:37,943][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:45:37,943][root][INFO] - Score: 70.81 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:45:37,944][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:45:37,945][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:45:37,947][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:45:39,643][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:45:39,920][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:45:39,922][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:45:39,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:45:39,923][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:45:39,923][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:45:39,925][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:45:41,578][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 10:46:15,594][root][INFO] - Step: 256/960  |  Loss: 0.8320  |  Score: 78.77 [%]  |  Seq Length: 256.0
[2024-10-23 10:46:20,124][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:46:20,124][root][INFO] - Score: 76.99 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 10:46:24,518][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:46:24,518][root][INFO] - Score: 70.23 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:46:24,520][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 10:46:58,323][root][INFO] - Step: 320/960  |  Loss: 0.6828  |  Score: 83.73 [%]  |  Seq Length: 256.0
[2024-10-23 10:47:02,824][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:47:02,825][root][INFO] - Score: 77.94 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 10:47:07,176][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:47:07,176][root][INFO] - Score: 70.49 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-23 10:47:07,178][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 10:47:40,977][root][INFO] - Step: 384/960  |  Loss: 0.5517  |  Score: 86.10 [%]  |  Seq Length: 256.0
[2024-10-23 10:47:45,462][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 10:47:45,462][root][INFO] - Score: 80.20 [%]  |  Evaluation Time: 4.48 [s]
[2024-10-23 10:47:49,811][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 10:47:49,811][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 4.35 [s]
[2024-10-23 10:47:49,812][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 10:47:49,812][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:47:49,815][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:47:51,506][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:47:51,780][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:47:51,781][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:47:51,782][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:47:51,782][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:47:51,782][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:47:51,785][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:47:53,392][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 10:48:27,065][root][INFO] - Step: 448/960  |  Loss: 0.4488  |  Score: 88.24 [%]  |  Seq Length: 256.0
[2024-10-23 10:48:31,571][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 10:48:31,571][root][INFO] - Score: 78.58 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 10:48:35,999][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 10:48:35,999][root][INFO] - Score: 69.74 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-23 10:48:36,001][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 10:49:09,059][root][INFO] - Step: 512/960  |  Loss: 0.3899  |  Score: 90.59 [%]  |  Seq Length: 256.0
[2024-10-23 10:49:13,576][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 10:49:13,577][root][INFO] - Score: 80.37 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:49:17,934][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:49:17,934][root][INFO] - Score: 71.37 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:49:17,935][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 10:49:17,935][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 10:49:17,938][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 10:49:19,607][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:49:19,920][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:49:19,921][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:49:19,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:49:19,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:49:19,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:49:19,925][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:49:21,530][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:49:51,168][root][INFO] - Step: 10550/10550  |  Loss: 0.1927  |  Score: 92.22 [%]  |  Seq Length: 256.0
[2024-10-23 10:49:55,331][root][INFO] - Step: 576/960  |  Loss: 0.3181  |  Score: 91.95 [%]  |  Seq Length: 256.0
[2024-10-23 10:49:59,823][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:49:59,823][root][INFO] - Score: 79.05 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 10:50:04,171][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:50:04,171][root][INFO] - Score: 69.52 [%]  |  Evaluation Time: 4.34 [s]
[2024-10-23 10:50:04,173][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:50:37,973][root][INFO] - Step: 640/960  |  Loss: 0.2638  |  Score: 92.81 [%]  |  Seq Length: 256.0
[2024-10-23 10:50:42,485][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:50:42,485][root][INFO] - Score: 77.55 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:50:45,537][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:50:45,537][root][INFO] - Score: 88.93 [%]  |  Evaluation Time: 54.36 [s]
[2024-10-23 10:50:46,879][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:50:46,879][root][INFO] - Score: 71.75 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:50:46,881][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 10:51:20,913][root][INFO] - Step: 704/960  |  Loss: 0.2301  |  Score: 93.87 [%]  |  Seq Length: 256.0
[2024-10-23 10:51:25,428][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 10:51:25,429][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:51:29,815][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 10:51:29,815][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 10:51:29,817][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 10:52:03,589][root][INFO] - Step: 768/960  |  Loss: 0.2086  |  Score: 94.23 [%]  |  Seq Length: 256.0
[2024-10-23 10:52:08,150][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 10:52:08,150][root][INFO] - Score: 76.45 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-23 10:52:12,541][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 10:52:12,541][root][INFO] - Score: 70.36 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 10:52:12,543][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 10:52:46,556][root][INFO] - Step: 832/960  |  Loss: 0.2007  |  Score: 94.32 [%]  |  Seq Length: 256.0
[2024-10-23 10:52:51,072][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 10:52:51,072][root][INFO] - Score: 78.00 [%]  |  Evaluation Time: 4.51 [s]
[2024-10-23 10:52:55,447][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 10:52:55,447][root][INFO] - Score: 71.37 [%]  |  Evaluation Time: 4.37 [s]
[2024-10-23 10:52:55,449][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 10:53:29,327][root][INFO] - Step: 896/960  |  Loss: 0.1816  |  Score: 94.90 [%]  |  Seq Length: 256.0
[2024-10-23 10:53:33,834][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 10:53:33,834][root][INFO] - Score: 80.96 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 10:53:38,197][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 10:53:38,197][root][INFO] - Score: 70.61 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:53:38,200][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 10:53:46,208][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:53:46,208][root][INFO] - Score: 88.97 [%]  |  Evaluation Time: 180.67 [s]
[2024-10-23 10:53:46,210][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:53:46,210][root][INFO] - - Epoch: 4
[2024-10-23 10:53:46,210][root][INFO] - - DEV score: 88.98 [%]
[2024-10-23 10:53:46,210][root][INFO] - - TEST score: 88.93 [%]
[2024-10-23 10:53:46,211][root][INFO] - Fine-tuning is done!
[2024-10-23 10:54:01,723][root][INFO] - Step: 40000/73665  |  Loss: 0.5719  |  Score: 76.69 [%]  |  Seq Length: 256.0
[2024-10-23 10:54:09,378][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,379][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,380][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,380][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,381][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,381][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,382][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,382][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,383][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,383][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,384][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,384][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,385][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,386][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,387][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,388][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,389][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,390][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,392][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,392][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,393][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,394][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,395][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:09,395][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:09,397][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 10:54:09,623][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 10:54:09,626][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 10:54:09,627][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:54:09,988][root][INFO] - 

[2024-10-23 10:54:09,988][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 10:54:09,988][root][INFO] - Data Preprocessing
[2024-10-23 10:54:09,988][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 10:54:09,988][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:54:09,988][root][INFO] - ㄴ data_remove                False

[2024-10-23 10:54:09,988][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:54:09,999][root][INFO] - vocab size              : 51200
[2024-10-23 10:54:09,999][root][INFO] - device                  : gpu
[2024-10-23 10:54:09,999][root][INFO] - random seed             : 3
[2024-10-23 10:54:09,999][root][INFO] - train data size         : 135040
[2024-10-23 10:54:09,999][root][INFO] - max epochs              : 5
[2024-10-23 10:54:09,999][root][INFO] - total steps             : 10550
[2024-10-23 10:54:09,999][root][INFO] - warmup steps            : 1055
[2024-10-23 10:54:09,999][root][INFO] - batch size              : 64
[2024-10-23 10:54:09,999][root][INFO] - accumulation steps      : 1
[2024-10-23 10:54:10,000][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:54:10,000][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:54:10,000][root][INFO] - learning rate           : 0.02
[2024-10-23 10:54:10,000][root][INFO] - max length              : 256

[2024-10-23 10:54:10,000][root][INFO] - LoRA Configuration
[2024-10-23 10:54:10,000][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:54:10,000][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:54:10,000][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:54:10,000][root][INFO] - KOMBO Configuration
[2024-10-23 10:54:10,000][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 10:54:10,000][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 10:54:10,001][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 10:54:10,001][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 10:54:10,001][root][INFO] - ㄴ do_combination       : True
[2024-10-23 10:54:10,001][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 10:54:10,001][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 10:54:10,001][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 10:54:10,001][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 10:54:10,001][root][INFO] - 

[2024-10-23 10:54:10,001][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs
[2024-10-23 10:54:10,001][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt
[2024-10-23 10:54:10,002][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/tb
[2024-10-23 10:54:10,002][root][INFO] - * tb interval   : 10000

[2024-10-23 10:54:10,002][root][INFO] - 

[2024-10-23 10:54:10,002][root][INFO] - Start the Training !
[2024-10-23 10:54:10,004][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 10:54:11,955][root][INFO] - Step: 960/960  |  Loss: 0.1811  |  Score: 94.80 [%]  |  Seq Length: 256.0
[2024-10-23 10:54:16,506][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 10:54:16,506][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 10:54:20,871][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 10:54:20,871][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 10:54:20,872][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 10:54:20,872][root][INFO] - - Epoch: 8
[2024-10-23 10:54:20,872][root][INFO] - - DEV score: 80.37 [%]
[2024-10-23 10:54:20,872][root][INFO] - - TEST score: 71.37 [%]
[2024-10-23 10:54:20,873][root][INFO] - Fine-tuning is done!
[2024-10-23 10:54:20,873][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 10:54:20,873][root][INFO] - - BEST LR: 0.01
[2024-10-23 10:54:20,873][root][INFO] - - DEV score: 80.16 [%]
[2024-10-23 10:54:20,874][root][INFO] - - TEST score: 72.50 [%]
[2024-10-23 10:54:27,043][root][INFO] - 

[2024-10-23 10:54:27,043][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 10:54:27,043][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs
[2024-10-23 10:54:27,043][root][INFO] - 

[2024-10-23 10:54:27,043][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 10:54:31,438][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,439][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,439][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,440][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,440][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,441][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,441][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,442][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,442][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,443][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,443][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,444][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,444][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,445][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,445][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,446][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,446][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,447][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,447][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,448][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,453][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,454][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,454][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 10:54:31,455][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 10:54:31,457][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 10:54:31,631][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 10:54:33,567][root][INFO] - 

[2024-10-23 10:54:33,568][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 10:54:33,568][root][INFO] - Data Preprocessing
[2024-10-23 10:54:33,568][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 10:54:33,568][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 10:54:33,568][root][INFO] - ㄴ data_remove                True

[2024-10-23 10:54:33,568][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 10:54:33,578][root][INFO] - vocab size              : 51200
[2024-10-23 10:54:33,578][root][INFO] - device                  : gpu
[2024-10-23 10:54:33,579][root][INFO] - random seed             : 3
[2024-10-23 10:54:33,579][root][INFO] - train data size         : 4096
[2024-10-23 10:54:33,579][root][INFO] - max epochs              : 15
[2024-10-23 10:54:33,579][root][INFO] - total steps             : 960
[2024-10-23 10:54:33,579][root][INFO] - warmup steps            : 96
[2024-10-23 10:54:33,579][root][INFO] - batch size              : 64
[2024-10-23 10:54:33,579][root][INFO] - accumulation steps      : 1
[2024-10-23 10:54:33,579][root][INFO] - optimizer               : adamwscale
[2024-10-23 10:54:33,579][root][INFO] - lr_scheduler            : cosine
[2024-10-23 10:54:33,579][root][INFO] - learning rate           : 0.01
[2024-10-23 10:54:33,579][root][INFO] - max length              : 256

[2024-10-23 10:54:33,580][root][INFO] - LoRA Configuration
[2024-10-23 10:54:33,580][root][INFO] - ㄴ r                    : 32
[2024-10-23 10:54:33,580][root][INFO] - ㄴ alpha                : 128
[2024-10-23 10:54:33,580][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 10:54:33,580][root][INFO] - 

[2024-10-23 10:54:33,580][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs
[2024-10-23 10:54:33,580][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 10:54:33,580][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 10:54:33,580][root][INFO] - * tb interval   : 10000

[2024-10-23 10:54:33,580][root][INFO] - 

[2024-10-23 10:54:33,580][root][INFO] - Start the Training !
[2024-10-23 10:54:33,583][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 10:54:58,536][root][INFO] - Step: 64/960  |  Loss: 2.8229  |  Score: 23.58 [%]  |  Seq Length: 256.0
[2024-10-23 10:55:01,339][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 10:55:01,340][root][INFO] - Score: 67.37 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:55:04,093][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 10:55:04,093][root][INFO] - Score: 61.49 [%]  |  Evaluation Time: 2.75 [s]
[2024-10-23 10:55:04,094][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 10:55:04,095][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:55:04,917][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:55:04,942][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:55:04,942][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:55:04,942][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:55:04,942][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:55:04,942][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:55:04,943][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:55:05,624][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 10:55:29,489][root][INFO] - Step: 128/960  |  Loss: 1.3587  |  Score: 63.96 [%]  |  Seq Length: 256.0
[2024-10-23 10:55:32,280][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 10:55:32,280][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 10:55:35,055][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 10:55:35,056][root][INFO] - Score: 66.68 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 10:55:35,057][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 10:55:35,057][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:55:36,575][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:55:36,975][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:55:36,976][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:55:36,976][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:55:36,976][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:55:36,976][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:55:36,977][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:55:38,594][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 10:56:02,485][root][INFO] - Step: 192/960  |  Loss: 1.1017  |  Score: 70.68 [%]  |  Seq Length: 256.0
[2024-10-23 10:56:05,298][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 10:56:05,298][root][INFO] - Score: 75.08 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:56:08,047][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 10:56:08,048][root][INFO] - Score: 68.50 [%]  |  Evaluation Time: 2.75 [s]
[2024-10-23 10:56:08,048][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 10:56:08,048][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:56:09,545][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:56:09,607][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:56:09,608][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:56:09,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:56:09,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:56:09,608][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:56:09,609][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:56:11,010][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 10:56:34,901][root][INFO] - Step: 256/960  |  Loss: 0.9618  |  Score: 75.13 [%]  |  Seq Length: 256.0
[2024-10-23 10:56:37,704][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 10:56:37,704][root][INFO] - Score: 76.86 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 10:56:40,475][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 10:56:40,476][root][INFO] - Score: 69.34 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 10:56:40,477][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 10:56:40,477][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:56:42,005][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:56:42,036][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:56:42,036][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:56:42,036][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:56:42,036][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:56:42,036][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:56:42,037][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:56:43,411][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 10:57:07,395][root][INFO] - Step: 320/960  |  Loss: 0.8282  |  Score: 77.75 [%]  |  Seq Length: 256.0
[2024-10-23 10:57:10,210][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 10:57:10,210][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:57:13,017][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 10:57:13,017][root][INFO] - Score: 72.29 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:57:13,018][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 10:57:13,019][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:57:14,515][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:57:14,558][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:57:14,558][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:57:14,558][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:57:14,558][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:57:14,558][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:57:14,560][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:57:15,930][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 10:57:39,850][root][INFO] - Step: 384/960  |  Loss: 0.7038  |  Score: 81.03 [%]  |  Seq Length: 256.0
[2024-10-23 10:57:42,693][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 10:57:42,693][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 10:57:45,481][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 10:57:45,482][root][INFO] - Score: 71.67 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 10:57:45,484][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 10:58:09,391][root][INFO] - Step: 448/960  |  Loss: 0.6171  |  Score: 83.83 [%]  |  Seq Length: 256.0
[2024-10-23 10:58:12,209][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 10:58:12,210][root][INFO] - Score: 78.71 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 10:58:15,004][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 10:58:15,004][root][INFO] - Score: 71.71 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 10:58:15,006][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 10:58:38,935][root][INFO] - Step: 512/960  |  Loss: 0.5619  |  Score: 85.12 [%]  |  Seq Length: 256.0
[2024-10-23 10:58:41,747][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 10:58:41,747][root][INFO] - Score: 78.46 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:58:44,522][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 10:58:44,522][root][INFO] - Score: 72.06 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 10:58:44,524][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 10:59:08,463][root][INFO] - Step: 576/960  |  Loss: 0.5001  |  Score: 86.32 [%]  |  Seq Length: 256.0
[2024-10-23 10:59:11,271][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 10:59:11,271][root][INFO] - Score: 78.77 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:59:14,066][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 10:59:14,066][root][INFO] - Score: 72.67 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 10:59:14,067][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-23 10:59:14,067][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 10:59:15,566][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 10:59:15,606][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 10:59:15,607][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 10:59:15,607][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 10:59:15,607][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 10:59:15,607][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 10:59:15,608][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 10:59:16,994][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 10:59:40,949][root][INFO] - Step: 640/960  |  Loss: 0.4397  |  Score: 87.86 [%]  |  Seq Length: 256.0
[2024-10-23 10:59:43,762][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 10:59:43,763][root][INFO] - Score: 79.27 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 10:59:46,524][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 10:59:46,525][root][INFO] - Score: 71.81 [%]  |  Evaluation Time: 2.76 [s]
[2024-10-23 10:59:46,526][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 11:00:10,457][root][INFO] - Step: 704/960  |  Loss: 0.4001  |  Score: 88.82 [%]  |  Seq Length: 256.0
[2024-10-23 11:00:13,292][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 11:00:13,292][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:00:16,098][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 11:00:16,098][root][INFO] - Score: 71.63 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 11:00:16,100][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 11:00:40,034][root][INFO] - Step: 768/960  |  Loss: 0.3761  |  Score: 89.28 [%]  |  Seq Length: 256.0
[2024-10-23 11:00:42,894][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 11:00:42,894][root][INFO] - Score: 75.85 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 11:00:45,667][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 11:00:45,667][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 2.77 [s]
[2024-10-23 11:00:45,669][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 11:01:09,616][root][INFO] - Step: 832/960  |  Loss: 0.3663  |  Score: 90.08 [%]  |  Seq Length: 256.0
[2024-10-23 11:01:12,428][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 11:01:12,428][root][INFO] - Score: 78.36 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 11:01:15,206][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 11:01:15,206][root][INFO] - Score: 71.47 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 11:01:15,208][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 11:01:39,136][root][INFO] - Step: 896/960  |  Loss: 0.3446  |  Score: 90.24 [%]  |  Seq Length: 256.0
[2024-10-23 11:01:41,977][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 11:01:41,977][root][INFO] - Score: 78.34 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 11:01:44,772][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 11:01:44,772][root][INFO] - Score: 72.26 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 11:01:44,774][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 11:02:08,699][root][INFO] - Step: 960/960  |  Loss: 0.3468  |  Score: 90.39 [%]  |  Seq Length: 256.0
[2024-10-23 11:02:11,512][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 11:02:11,512][root][INFO] - Score: 79.11 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 11:02:14,297][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 11:02:14,297][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 11:02:14,298][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 11:02:14,298][root][INFO] - - Epoch: 9
[2024-10-23 11:02:14,298][root][INFO] - - DEV score: 78.77 [%]
[2024-10-23 11:02:14,298][root][INFO] - - TEST score: 72.67 [%]
[2024-10-23 11:02:14,299][root][INFO] - Fine-tuning is done!
[2024-10-23 11:02:17,755][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,756][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,757][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,757][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,758][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,758][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,759][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,759][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,760][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,760][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,761][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,761][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,762][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,762][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,763][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,764][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,764][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,765][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,765][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,766][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,766][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,767][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,768][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 11:02:17,768][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 11:02:17,770][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 11:02:17,772][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 11:02:17,921][root][INFO] - 

[2024-10-23 11:02:17,921][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 11:02:17,921][root][INFO] - Data Preprocessing
[2024-10-23 11:02:17,921][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 11:02:17,921][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 11:02:17,921][root][INFO] - ㄴ data_remove                True

[2024-10-23 11:02:17,922][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 11:02:17,928][root][INFO] - vocab size              : 51200
[2024-10-23 11:02:17,928][root][INFO] - device                  : gpu
[2024-10-23 11:02:17,928][root][INFO] - random seed             : 3
[2024-10-23 11:02:17,929][root][INFO] - train data size         : 4096
[2024-10-23 11:02:17,929][root][INFO] - max epochs              : 15
[2024-10-23 11:02:17,929][root][INFO] - total steps             : 960
[2024-10-23 11:02:17,929][root][INFO] - warmup steps            : 96
[2024-10-23 11:02:17,929][root][INFO] - batch size              : 64
[2024-10-23 11:02:17,929][root][INFO] - accumulation steps      : 1
[2024-10-23 11:02:17,929][root][INFO] - optimizer               : adamwscale
[2024-10-23 11:02:17,929][root][INFO] - lr_scheduler            : cosine
[2024-10-23 11:02:17,929][root][INFO] - learning rate           : 0.02
[2024-10-23 11:02:17,929][root][INFO] - max length              : 256

[2024-10-23 11:02:17,929][root][INFO] - LoRA Configuration
[2024-10-23 11:02:17,930][root][INFO] - ㄴ r                    : 32
[2024-10-23 11:02:17,930][root][INFO] - ㄴ alpha                : 128
[2024-10-23 11:02:17,930][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 11:02:17,930][root][INFO] - 

[2024-10-23 11:02:17,930][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs
[2024-10-23 11:02:17,930][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 11:02:17,930][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 11:02:17,930][root][INFO] - * tb interval   : 10000

[2024-10-23 11:02:17,930][root][INFO] - 

[2024-10-23 11:02:17,930][root][INFO] - Start the Training !
[2024-10-23 11:02:17,932][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 11:02:41,885][root][INFO] - Step: 64/960  |  Loss: 2.3648  |  Score: 35.73 [%]  |  Seq Length: 256.0
[2024-10-23 11:02:44,746][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 11:02:44,747][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 11:02:47,530][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 11:02:47,530][root][INFO] - Score: 64.79 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 11:02:47,531][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 11:02:47,532][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:02:49,044][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:02:49,099][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:02:49,100][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:02:49,100][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:02:49,100][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:02:49,100][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:02:49,101][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:02:50,541][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 11:03:14,482][root][INFO] - Step: 128/960  |  Loss: 1.2742  |  Score: 68.37 [%]  |  Seq Length: 256.0
[2024-10-23 11:03:17,320][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 11:03:17,320][root][INFO] - Score: 75.22 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 11:03:20,139][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 11:03:20,139][root][INFO] - Score: 67.68 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 11:03:20,140][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 11:03:20,141][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:03:21,617][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:03:21,660][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:03:21,660][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:03:21,660][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:03:21,660][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:03:21,661][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:03:21,661][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:03:23,086][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 11:03:47,049][root][INFO] - Step: 192/960  |  Loss: 0.9922  |  Score: 73.58 [%]  |  Seq Length: 256.0
[2024-10-23 11:03:49,916][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 11:03:49,916][root][INFO] - Score: 75.64 [%]  |  Evaluation Time: 2.86 [s]
[2024-10-23 11:03:52,724][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 11:03:52,725][root][INFO] - Score: 69.04 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 11:03:52,726][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 11:03:52,726][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:03:54,233][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:03:54,283][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:03:54,284][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:03:54,284][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:03:54,284][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:03:54,284][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:03:54,285][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:03:55,682][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 11:04:19,647][root][INFO] - Step: 256/960  |  Loss: 0.8362  |  Score: 79.40 [%]  |  Seq Length: 256.0
[2024-10-23 11:04:22,495][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 11:04:22,495][root][INFO] - Score: 77.79 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 11:04:25,298][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 11:04:25,299][root][INFO] - Score: 71.21 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 11:04:25,300][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 11:04:25,300][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:04:26,858][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:04:26,902][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:04:26,903][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:04:26,903][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:04:26,903][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:04:26,903][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:04:26,904][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:04:28,298][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 11:04:52,227][root][INFO] - Step: 320/960  |  Loss: 0.6793  |  Score: 82.61 [%]  |  Seq Length: 256.0
[2024-10-23 11:04:55,047][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 11:04:55,048][root][INFO] - Score: 76.79 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 11:04:57,847][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 11:04:57,847][root][INFO] - Score: 70.48 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 11:04:57,849][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 11:05:21,786][root][INFO] - Step: 384/960  |  Loss: 0.5490  |  Score: 86.24 [%]  |  Seq Length: 256.0
[2024-10-23 11:05:24,621][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 11:05:24,621][root][INFO] - Score: 71.55 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:05:27,408][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 11:05:27,408][root][INFO] - Score: 72.02 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 11:05:27,410][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 11:05:51,408][root][INFO] - Step: 448/960  |  Loss: 0.4546  |  Score: 88.31 [%]  |  Seq Length: 256.0
[2024-10-23 11:05:54,238][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 11:05:54,239][root][INFO] - Score: 78.67 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:05:57,039][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 11:05:57,039][root][INFO] - Score: 71.86 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 11:05:57,040][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 11:05:57,040][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:05:58,556][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:05:58,602][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:05:58,603][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:05:58,604][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:05:58,604][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:05:58,604][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:05:58,606][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:06:00,044][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 11:06:24,011][root][INFO] - Step: 512/960  |  Loss: 0.3610  |  Score: 90.16 [%]  |  Seq Length: 256.0
[2024-10-23 11:06:26,843][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 11:06:26,843][root][INFO] - Score: 78.94 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:06:29,640][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 11:06:29,641][root][INFO] - Score: 71.39 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 11:06:29,643][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 11:06:53,638][root][INFO] - Step: 576/960  |  Loss: 0.3076  |  Score: 91.60 [%]  |  Seq Length: 256.0
[2024-10-23 11:06:56,477][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 11:06:56,477][root][INFO] - Score: 79.15 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 11:06:59,276][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 11:06:59,276][root][INFO] - Score: 72.86 [%]  |  Evaluation Time: 2.80 [s]
[2024-10-23 11:06:59,277][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-23 11:06:59,277][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:07:00,783][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:07:00,814][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:07:00,815][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:07:00,815][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:07:00,815][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:07:00,815][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:07:00,816][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:07:02,255][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 11:07:26,224][root][INFO] - Step: 640/960  |  Loss: 0.2694  |  Score: 92.89 [%]  |  Seq Length: 256.0
[2024-10-23 11:07:29,060][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 11:07:29,060][root][INFO] - Score: 78.38 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:07:31,842][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 11:07:31,842][root][INFO] - Score: 72.30 [%]  |  Evaluation Time: 2.78 [s]
[2024-10-23 11:07:31,844][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 11:07:55,822][root][INFO] - Step: 704/960  |  Loss: 0.2303  |  Score: 93.84 [%]  |  Seq Length: 256.0
[2024-10-23 11:07:58,679][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 11:07:58,679][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 11:08:01,485][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 11:08:01,486][root][INFO] - Score: 72.17 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 11:08:01,488][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 11:08:25,474][root][INFO] - Step: 768/960  |  Loss: 0.1991  |  Score: 94.22 [%]  |  Seq Length: 256.0
[2024-10-23 11:08:28,312][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 11:08:28,312][root][INFO] - Score: 75.86 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:08:31,139][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 11:08:31,140][root][INFO] - Score: 70.56 [%]  |  Evaluation Time: 2.83 [s]
[2024-10-23 11:08:31,142][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 11:08:55,084][root][INFO] - Step: 832/960  |  Loss: 0.1909  |  Score: 94.75 [%]  |  Seq Length: 256.0
[2024-10-23 11:08:57,937][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 11:08:57,937][root][INFO] - Score: 79.93 [%]  |  Evaluation Time: 2.85 [s]
[2024-10-23 11:09:00,751][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 11:09:00,751][root][INFO] - Score: 71.48 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 11:09:00,753][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 11:09:24,714][root][INFO] - Step: 896/960  |  Loss: 0.1795  |  Score: 94.96 [%]  |  Seq Length: 256.0
[2024-10-23 11:09:27,541][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 11:09:27,541][root][INFO] - Score: 79.59 [%]  |  Evaluation Time: 2.82 [s]
[2024-10-23 11:09:30,354][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 11:09:30,354][root][INFO] - Score: 72.28 [%]  |  Evaluation Time: 2.81 [s]
[2024-10-23 11:09:30,356][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 11:09:54,339][root][INFO] - Step: 960/960  |  Loss: 0.1737  |  Score: 95.04 [%]  |  Seq Length: 256.0
[2024-10-23 11:09:57,179][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 11:09:57,179][root][INFO] - Score: 79.76 [%]  |  Evaluation Time: 2.84 [s]
[2024-10-23 11:09:59,966][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 11:09:59,967][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 2.79 [s]
[2024-10-23 11:09:59,968][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 11:09:59,968][root][INFO] - - Epoch: 9
[2024-10-23 11:09:59,968][root][INFO] - - DEV score: 79.15 [%]
[2024-10-23 11:09:59,968][root][INFO] - - TEST score: 72.86 [%]
[2024-10-23 11:09:59,969][root][INFO] - Fine-tuning is done!
[2024-10-23 11:09:59,969][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 11:09:59,969][root][INFO] - - BEST LR: 0.02
[2024-10-23 11:09:59,970][root][INFO] - - DEV score: 79.15 [%]
[2024-10-23 11:09:59,970][root][INFO] - - TEST score: 72.86 [%]
[2024-10-23 11:10:05,942][root][INFO] - 

[2024-10-23 11:10:05,942][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 11:10:05,942][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs
[2024-10-23 11:10:05,942][root][INFO] - 

[2024-10-23 11:10:05,942][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 11:10:10,509][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,509][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,510][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,510][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,511][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,511][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,512][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,512][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,513][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,513][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,513][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,514][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,514][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,515][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,515][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,516][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,516][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,517][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,518][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,518][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,519][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,520][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,520][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 11:10:10,521][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 11:10:10,523][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 11:10:10,528][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 11:10:10,732][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 11:10:10,734][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 11:10:10,902][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 11:10:14,177][root][INFO] - 

[2024-10-23 11:10:14,178][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 11:10:14,178][root][INFO] - Data Preprocessing
[2024-10-23 11:10:14,178][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 11:10:14,178][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 11:10:14,178][root][INFO] - ㄴ data_remove                True

[2024-10-23 11:10:14,178][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 11:10:14,186][root][INFO] - vocab size              : 51200
[2024-10-23 11:10:14,186][root][INFO] - device                  : gpu
[2024-10-23 11:10:14,186][root][INFO] - random seed             : 3
[2024-10-23 11:10:14,187][root][INFO] - train data size         : 4096
[2024-10-23 11:10:14,187][root][INFO] - max epochs              : 15
[2024-10-23 11:10:14,187][root][INFO] - total steps             : 960
[2024-10-23 11:10:14,187][root][INFO] - warmup steps            : 96
[2024-10-23 11:10:14,187][root][INFO] - batch size              : 64
[2024-10-23 11:10:14,187][root][INFO] - accumulation steps      : 1
[2024-10-23 11:10:14,187][root][INFO] - optimizer               : adamwscale
[2024-10-23 11:10:14,187][root][INFO] - lr_scheduler            : cosine
[2024-10-23 11:10:14,187][root][INFO] - learning rate           : 0.01
[2024-10-23 11:10:14,187][root][INFO] - max length              : 256

[2024-10-23 11:10:14,187][root][INFO] - LoRA Configuration
[2024-10-23 11:10:14,188][root][INFO] - ㄴ r                    : 32
[2024-10-23 11:10:14,188][root][INFO] - ㄴ alpha                : 128
[2024-10-23 11:10:14,188][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 11:10:14,188][root][INFO] - KOMBO Configuration
[2024-10-23 11:10:14,188][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 11:10:14,188][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 11:10:14,188][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 11:10:14,188][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 11:10:14,188][root][INFO] - ㄴ do_combination       : True
[2024-10-23 11:10:14,189][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 11:10:14,189][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 11:10:14,189][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 11:10:14,189][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 11:10:14,189][root][INFO] - 

[2024-10-23 11:10:14,189][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs
[2024-10-23 11:10:14,189][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 11:10:14,189][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 11:10:14,189][root][INFO] - * tb interval   : 10000

[2024-10-23 11:10:14,189][root][INFO] - 

[2024-10-23 11:10:14,189][root][INFO] - Start the Training !
[2024-10-23 11:10:14,193][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 11:10:48,557][root][INFO] - Step: 64/960  |  Loss: 2.8311  |  Score: 22.22 [%]  |  Seq Length: 256.0
[2024-10-23 11:10:53,093][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 11:10:53,093][root][INFO] - Score: 70.10 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 11:10:57,479][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 11:10:57,479][root][INFO] - Score: 61.44 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 11:10:57,479][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 11:10:57,480][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:10:57,483][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:10:58,362][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:10:58,477][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:10:58,478][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:10:58,478][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:10:58,478][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:10:58,478][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:10:58,479][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:10:59,237][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 11:11:32,543][root][INFO] - Step: 128/960  |  Loss: 1.3643  |  Score: 63.99 [%]  |  Seq Length: 256.0
[2024-10-23 11:11:37,080][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 11:11:37,080][root][INFO] - Score: 74.20 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 11:11:41,468][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 11:11:41,469][root][INFO] - Score: 67.02 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 11:11:41,470][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 11:11:41,470][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:11:41,473][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:11:43,148][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:11:43,364][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:11:43,365][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:11:43,365][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:11:43,366][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:11:43,366][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:11:43,368][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:11:44,953][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 11:12:06,952][root][INFO] - Step: 2110/10550  |  Loss: 0.3679  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-23 11:12:18,890][root][INFO] - Step: 192/960  |  Loss: 1.0814  |  Score: 71.45 [%]  |  Seq Length: 256.0
[2024-10-23 11:12:23,461][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 11:12:23,462][root][INFO] - Score: 72.81 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 11:12:27,912][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 11:12:27,912][root][INFO] - Score: 70.86 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-23 11:12:27,913][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 11:12:27,914][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:12:27,916][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:12:29,612][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:12:29,868][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:12:29,870][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:12:29,870][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:12:29,870][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:12:29,870][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:12:29,874][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:12:31,468][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 11:13:00,834][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 11:13:00,834][root][INFO] - Score: 86.78 [%]  |  Evaluation Time: 53.88 [s]
[2024-10-23 11:13:04,956][root][INFO] - Step: 256/960  |  Loss: 0.9486  |  Score: 75.86 [%]  |  Seq Length: 256.0
[2024-10-23 11:13:09,577][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 11:13:09,577][root][INFO] - Score: 75.72 [%]  |  Evaluation Time: 4.62 [s]
[2024-10-23 11:13:13,966][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 11:13:13,966][root][INFO] - Score: 70.80 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 11:13:13,967][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 11:13:13,967][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:13:13,970][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:13:15,675][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:13:15,942][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:13:15,944][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:13:15,944][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:13:15,944][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:13:15,944][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:13:15,948][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:13:17,561][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 11:13:51,520][root][INFO] - Step: 320/960  |  Loss: 0.8685  |  Score: 78.24 [%]  |  Seq Length: 256.0
[2024-10-23 11:13:56,149][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 11:13:56,150][root][INFO] - Score: 78.53 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 11:14:00,613][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 11:14:00,613][root][INFO] - Score: 71.56 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-23 11:14:00,614][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 11:14:00,615][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:14:00,617][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:14:02,136][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:14:02,402][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:14:02,404][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:14:02,404][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:14:02,405][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:14:02,405][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:14:02,408][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:14:03,988][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 11:14:37,493][root][INFO] - Step: 384/960  |  Loss: 0.7159  |  Score: 81.75 [%]  |  Seq Length: 256.0
[2024-10-23 11:14:42,097][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 11:14:42,097][root][INFO] - Score: 76.58 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-23 11:14:46,486][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 11:14:46,486][root][INFO] - Score: 70.56 [%]  |  Evaluation Time: 4.39 [s]
[2024-10-23 11:14:46,489][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 11:15:20,408][root][INFO] - Step: 448/960  |  Loss: 0.6419  |  Score: 83.61 [%]  |  Seq Length: 256.0
[2024-10-23 11:15:24,972][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 11:15:24,973][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-23 11:15:29,416][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 11:15:29,416][root][INFO] - Score: 72.21 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-23 11:15:29,418][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 11:15:58,536][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 11:15:58,536][root][INFO] - Score: 86.51 [%]  |  Evaluation Time: 177.70 [s]
[2024-10-23 11:15:58,538][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 11:15:58,538][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:15:58,543][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:16:00,326][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:16:00,472][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:16:00,473][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:16:00,473][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:16:00,473][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:16:00,473][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:16:00,475][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:16:02,104][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 11:16:03,341][root][INFO] - Step: 512/960  |  Loss: 0.5937  |  Score: 85.25 [%]  |  Seq Length: 256.0
[2024-10-23 11:16:07,888][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 11:16:07,889][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 11:16:12,255][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 11:16:12,256][root][INFO] - Score: 70.89 [%]  |  Evaluation Time: 4.36 [s]
[2024-10-23 11:16:12,258][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 11:16:46,027][root][INFO] - Step: 576/960  |  Loss: 0.5111  |  Score: 85.80 [%]  |  Seq Length: 256.0
[2024-10-23 11:16:50,556][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 11:16:50,556][root][INFO] - Score: 74.13 [%]  |  Evaluation Time: 4.53 [s]
[2024-10-23 11:16:54,964][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 11:16:54,964][root][INFO] - Score: 69.54 [%]  |  Evaluation Time: 4.41 [s]
[2024-10-23 11:16:54,966][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 11:17:28,942][root][INFO] - Step: 640/960  |  Loss: 0.4490  |  Score: 87.43 [%]  |  Seq Length: 256.0
[2024-10-23 11:17:33,510][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 11:17:33,510][root][INFO] - Score: 75.24 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 11:17:37,933][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 11:17:37,934][root][INFO] - Score: 70.24 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 11:17:37,936][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 11:18:11,806][root][INFO] - Step: 704/960  |  Loss: 0.4210  |  Score: 88.59 [%]  |  Seq Length: 256.0
[2024-10-23 11:18:16,373][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 11:18:16,373][root][INFO] - Score: 76.38 [%]  |  Evaluation Time: 4.56 [s]
[2024-10-23 11:18:20,778][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 11:18:20,779][root][INFO] - Score: 71.74 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 11:18:20,781][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 11:18:54,705][root][INFO] - Step: 768/960  |  Loss: 0.3907  |  Score: 89.55 [%]  |  Seq Length: 256.0
[2024-10-23 11:18:59,382][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 11:18:59,382][root][INFO] - Score: 77.68 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 11:19:03,828][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 11:19:03,828][root][INFO] - Score: 71.48 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-23 11:19:03,830][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 11:19:37,664][root][INFO] - Step: 832/960  |  Loss: 0.3597  |  Score: 90.09 [%]  |  Seq Length: 256.0
[2024-10-23 11:19:42,220][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 11:19:42,221][root][INFO] - Score: 77.22 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 11:19:46,627][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 11:19:46,627][root][INFO] - Score: 71.33 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 11:19:46,629][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 11:20:20,202][root][INFO] - Step: 896/960  |  Loss: 0.3515  |  Score: 90.30 [%]  |  Seq Length: 256.0
[2024-10-23 11:20:24,753][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 11:20:24,753][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 11:20:29,215][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 11:20:29,215][root][INFO] - Score: 71.74 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-23 11:20:29,217][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-23 11:20:29,217][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:20:29,220][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:20:30,908][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:20:31,199][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:20:31,200][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:20:31,200][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:20:31,201][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:20:31,201][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:20:31,204][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:20:32,821][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 11:21:06,022][root][INFO] - Step: 960/960  |  Loss: 0.3540  |  Score: 90.05 [%]  |  Seq Length: 256.0
[2024-10-23 11:21:10,570][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 11:21:10,570][root][INFO] - Score: 78.24 [%]  |  Evaluation Time: 4.54 [s]
[2024-10-23 11:21:14,972][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 11:21:14,972][root][INFO] - Score: 71.55 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 11:21:14,973][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 11:21:14,973][root][INFO] - - Epoch: 14
[2024-10-23 11:21:14,973][root][INFO] - - DEV score: 78.60 [%]
[2024-10-23 11:21:14,974][root][INFO] - - TEST score: 71.74 [%]
[2024-10-23 11:21:14,974][root][INFO] - Fine-tuning is done!
[2024-10-23 11:21:18,120][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,121][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,122][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,123][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,123][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,124][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,125][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,126][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,126][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,127][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,128][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,129][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,129][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,130][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,131][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,132][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,132][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,133][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,134][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,134][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,135][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,136][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,136][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 11:21:18,137][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 11:21:18,140][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 11:21:18,378][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 11:21:18,380][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 11:21:18,381][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 11:21:18,547][root][INFO] - 

[2024-10-23 11:21:18,547][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 11:21:18,547][root][INFO] - Data Preprocessing
[2024-10-23 11:21:18,547][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 11:21:18,548][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 11:21:18,548][root][INFO] - ㄴ data_remove                True

[2024-10-23 11:21:18,548][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 11:21:18,555][root][INFO] - vocab size              : 51200
[2024-10-23 11:21:18,555][root][INFO] - device                  : gpu
[2024-10-23 11:21:18,555][root][INFO] - random seed             : 3
[2024-10-23 11:21:18,555][root][INFO] - train data size         : 4096
[2024-10-23 11:21:18,555][root][INFO] - max epochs              : 15
[2024-10-23 11:21:18,555][root][INFO] - total steps             : 960
[2024-10-23 11:21:18,555][root][INFO] - warmup steps            : 96
[2024-10-23 11:21:18,555][root][INFO] - batch size              : 64
[2024-10-23 11:21:18,555][root][INFO] - accumulation steps      : 1
[2024-10-23 11:21:18,555][root][INFO] - optimizer               : adamwscale
[2024-10-23 11:21:18,556][root][INFO] - lr_scheduler            : cosine
[2024-10-23 11:21:18,556][root][INFO] - learning rate           : 0.02
[2024-10-23 11:21:18,556][root][INFO] - max length              : 256

[2024-10-23 11:21:18,556][root][INFO] - LoRA Configuration
[2024-10-23 11:21:18,556][root][INFO] - ㄴ r                    : 32
[2024-10-23 11:21:18,556][root][INFO] - ㄴ alpha                : 128
[2024-10-23 11:21:18,556][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 11:21:18,556][root][INFO] - KOMBO Configuration
[2024-10-23 11:21:18,556][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 11:21:18,556][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 11:21:18,556][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 11:21:18,557][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 11:21:18,557][root][INFO] - ㄴ do_combination       : True
[2024-10-23 11:21:18,557][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 11:21:18,557][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 11:21:18,557][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 11:21:18,557][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 11:21:18,557][root][INFO] - 

[2024-10-23 11:21:18,557][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs
[2024-10-23 11:21:18,557][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 11:21:18,557][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 11:21:18,558][root][INFO] - * tb interval   : 10000

[2024-10-23 11:21:18,558][root][INFO] - 

[2024-10-23 11:21:18,558][root][INFO] - Start the Training !
[2024-10-23 11:21:18,560][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 11:21:52,637][root][INFO] - Step: 64/960  |  Loss: 2.3133  |  Score: 36.43 [%]  |  Seq Length: 256.0
[2024-10-23 11:21:57,273][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 11:21:57,274][root][INFO] - Score: 74.36 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 11:22:01,741][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 11:22:01,741][root][INFO] - Score: 64.19 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-23 11:22:01,742][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 11:22:01,743][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:22:01,745][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:22:03,463][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:22:03,751][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:22:03,752][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:22:03,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:22:03,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:22:03,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:22:03,756][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:22:05,355][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 11:22:39,357][root][INFO] - Step: 128/960  |  Loss: 1.2505  |  Score: 67.80 [%]  |  Seq Length: 256.0
[2024-10-23 11:22:43,932][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 11:22:43,932][root][INFO] - Score: 76.69 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 11:22:48,359][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 11:22:48,359][root][INFO] - Score: 68.31 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 11:22:48,360][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 11:22:48,361][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:22:48,363][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:22:50,060][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:22:50,358][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:22:50,359][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:22:50,359][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:22:50,360][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:22:50,360][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:22:50,363][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:22:51,999][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 11:23:25,956][root][INFO] - Step: 192/960  |  Loss: 1.0202  |  Score: 74.33 [%]  |  Seq Length: 256.0
[2024-10-23 11:23:30,537][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 11:23:30,538][root][INFO] - Score: 73.71 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-23 11:23:34,997][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 11:23:34,997][root][INFO] - Score: 73.04 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-23 11:23:34,998][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 11:23:34,999][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:23:35,002][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:23:36,704][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:23:36,975][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:23:36,979][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:23:36,980][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:23:36,980][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:23:36,981][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:23:36,983][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:23:38,646][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 11:24:12,575][root][INFO] - Step: 256/960  |  Loss: 0.8023  |  Score: 79.68 [%]  |  Seq Length: 256.0
[2024-10-23 11:24:17,128][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 11:24:17,128][root][INFO] - Score: 75.82 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 11:24:21,570][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 11:24:21,570][root][INFO] - Score: 73.20 [%]  |  Evaluation Time: 4.44 [s]
[2024-10-23 11:24:21,571][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 11:24:21,571][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:24:21,574][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:24:23,276][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:24:23,561][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:24:23,562][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:24:23,562][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:24:23,562][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:24:23,563][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:24:23,566][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:24:25,217][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 11:24:59,174][root][INFO] - Step: 320/960  |  Loss: 0.6999  |  Score: 82.97 [%]  |  Seq Length: 256.0
[2024-10-23 11:25:03,837][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 11:25:03,837][root][INFO] - Score: 77.99 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 11:25:08,291][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 11:25:08,292][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-23 11:25:08,293][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 11:25:08,293][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:25:08,296][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:25:09,767][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:25:10,075][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:25:10,076][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:25:10,077][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:25:10,077][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:25:10,078][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:25:10,080][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:25:11,764][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 11:25:45,740][root][INFO] - Step: 384/960  |  Loss: 0.5251  |  Score: 86.17 [%]  |  Seq Length: 256.0
[2024-10-23 11:25:50,380][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 11:25:50,381][root][INFO] - Score: 79.01 [%]  |  Evaluation Time: 4.64 [s]
[2024-10-23 11:25:54,880][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 11:25:54,881][root][INFO] - Score: 71.02 [%]  |  Evaluation Time: 4.50 [s]
[2024-10-23 11:25:54,881][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 11:25:54,882][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:25:54,884][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:25:56,567][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:25:56,859][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:25:56,890][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:25:56,890][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:25:56,891][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:25:56,891][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:25:56,894][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:25:58,548][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 11:26:32,504][root][INFO] - Step: 448/960  |  Loss: 0.4597  |  Score: 88.17 [%]  |  Seq Length: 256.0
[2024-10-23 11:26:37,107][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 11:26:37,107][root][INFO] - Score: 77.82 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-23 11:26:41,560][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 11:26:41,560][root][INFO] - Score: 73.15 [%]  |  Evaluation Time: 4.45 [s]
[2024-10-23 11:26:41,561][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 11:26:41,562][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:26:41,564][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:26:43,267][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:26:43,577][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:26:43,578][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:26:43,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:26:43,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:26:43,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:26:43,582][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:26:45,258][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 11:27:19,180][root][INFO] - Step: 512/960  |  Loss: 0.3584  |  Score: 90.50 [%]  |  Seq Length: 256.0
[2024-10-23 11:27:23,768][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 11:27:23,768][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 4.58 [s]
[2024-10-23 11:27:28,169][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 11:27:28,170][root][INFO] - Score: 70.11 [%]  |  Evaluation Time: 4.40 [s]
[2024-10-23 11:27:28,172][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 11:28:02,170][root][INFO] - Step: 576/960  |  Loss: 0.3288  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-23 11:28:06,785][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 11:28:06,785][root][INFO] - Score: 75.01 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-23 11:28:11,249][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 11:28:11,249][root][INFO] - Score: 69.72 [%]  |  Evaluation Time: 4.46 [s]
[2024-10-23 11:28:11,251][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 11:28:45,205][root][INFO] - Step: 640/960  |  Loss: 0.2613  |  Score: 92.70 [%]  |  Seq Length: 256.0
[2024-10-23 11:28:49,777][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 11:28:49,777][root][INFO] - Score: 77.71 [%]  |  Evaluation Time: 4.57 [s]
[2024-10-23 11:28:54,197][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 11:28:54,197][root][INFO] - Score: 71.20 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 11:28:54,199][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 11:29:28,284][root][INFO] - Step: 704/960  |  Loss: 0.2449  |  Score: 93.31 [%]  |  Seq Length: 256.0
[2024-10-23 11:29:32,833][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 11:29:32,833][root][INFO] - Score: 76.21 [%]  |  Evaluation Time: 4.55 [s]
[2024-10-23 11:29:37,265][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 11:29:37,266][root][INFO] - Score: 71.68 [%]  |  Evaluation Time: 4.43 [s]
[2024-10-23 11:29:37,268][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 11:30:11,130][root][INFO] - Step: 768/960  |  Loss: 0.2104  |  Score: 94.31 [%]  |  Seq Length: 256.0
[2024-10-23 11:30:15,725][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 11:30:15,725][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-23 11:30:20,109][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 11:30:20,109][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 4.38 [s]
[2024-10-23 11:30:20,111][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 11:30:54,021][root][INFO] - Step: 832/960  |  Loss: 0.1949  |  Score: 94.66 [%]  |  Seq Length: 256.0
[2024-10-23 11:30:58,627][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 11:30:58,628][root][INFO] - Score: 77.87 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-23 11:31:03,050][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 11:31:03,050][root][INFO] - Score: 71.88 [%]  |  Evaluation Time: 4.42 [s]
[2024-10-23 11:31:03,052][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 11:31:35,340][root][INFO] - Step: 44199/73665  |  Loss: 0.5651  |  Score: 77.05 [%]  |  Seq Length: 256.0
[2024-10-23 11:31:37,147][root][INFO] - Step: 896/960  |  Loss: 0.1780  |  Score: 95.03 [%]  |  Seq Length: 256.0
[2024-10-23 11:31:41,755][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 11:31:41,755][root][INFO] - Score: 79.33 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-23 11:31:45,854][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 11:31:45,854][root][INFO] - Score: 73.28 [%]  |  Evaluation Time: 10.51 [s]
[2024-10-23 11:31:46,245][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 11:31:46,245][root][INFO] - Score: 71.67 [%]  |  Evaluation Time: 4.49 [s]
[2024-10-23 11:31:46,246][root][INFO] - 
Save new Best Score (Epoch: 14)
[2024-10-23 11:31:46,246][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:31:46,249][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:31:48,033][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:31:48,331][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:31:48,332][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:31:48,333][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:31:48,334][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:31:48,334][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:31:48,337][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:31:50,030][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 11:32:06,487][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 11:32:06,487][root][INFO] - Score: 75.32 [%]  |  Evaluation Time: 20.63 [s]
[2024-10-23 11:32:06,488][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 11:32:06,488][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 11:32:06,491][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:32:08,259][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:32:08,577][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:32:08,578][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:32:08,578][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:32:08,578][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:32:08,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:32:08,581][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:32:10,421][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 11:32:23,021][root][INFO] - Step: 960/960  |  Loss: 0.1763  |  Score: 94.87 [%]  |  Seq Length: 256.0
[2024-10-23 11:32:27,655][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 11:32:27,655][root][INFO] - Score: 77.67 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 11:32:32,125][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 11:32:32,125][root][INFO] - Score: 71.99 [%]  |  Evaluation Time: 4.47 [s]
[2024-10-23 11:32:32,126][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 11:32:32,126][root][INFO] - - Epoch: 14
[2024-10-23 11:32:32,126][root][INFO] - - DEV score: 79.33 [%]
[2024-10-23 11:32:32,126][root][INFO] - - TEST score: 71.67 [%]
[2024-10-23 11:32:32,127][root][INFO] - Fine-tuning is done!
[2024-10-23 11:32:32,127][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 11:32:32,128][root][INFO] - - BEST LR: 0.02
[2024-10-23 11:32:32,128][root][INFO] - - DEV score: 79.33 [%]
[2024-10-23 11:32:32,128][root][INFO] - - TEST score: 71.67 [%]
[2024-10-23 11:33:59,064][root][INFO] - Step: 4220/10550  |  Loss: 0.3131  |  Score: 86.58 [%]  |  Seq Length: 256.0
[2024-10-23 11:34:52,644][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 11:34:52,644][root][INFO] - Score: 86.98 [%]  |  Evaluation Time: 53.58 [s]
[2024-10-23 11:37:49,008][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 11:37:49,008][root][INFO] - Score: 87.23 [%]  |  Evaluation Time: 176.36 [s]
[2024-10-23 11:37:49,009][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 11:37:49,010][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:37:49,013][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:37:50,715][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:37:51,027][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:37:51,028][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:37:51,028][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:37:51,029][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:37:51,029][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:37:51,032][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:37:52,657][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 11:55:45,479][root][INFO] - Step: 6330/10550  |  Loss: 0.2796  |  Score: 88.07 [%]  |  Seq Length: 256.0
[2024-10-23 11:56:38,620][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 11:56:38,620][root][INFO] - Score: 88.05 [%]  |  Evaluation Time: 53.14 [s]
[2024-10-23 11:59:34,848][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 11:59:34,849][root][INFO] - Score: 87.96 [%]  |  Evaluation Time: 176.23 [s]
[2024-10-23 11:59:34,850][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 11:59:34,850][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 11:59:34,853][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 11:59:36,584][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 11:59:36,869][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 11:59:36,871][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 11:59:36,871][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 11:59:36,871][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 11:59:36,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 11:59:36,875][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 11:59:38,510][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 12:17:30,579][root][INFO] - Step: 8440/10550  |  Loss: 0.2354  |  Score: 90.32 [%]  |  Seq Length: 256.0
[2024-10-23 12:18:23,946][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 12:18:23,946][root][INFO] - Score: 88.76 [%]  |  Evaluation Time: 53.36 [s]
[2024-10-23 12:21:20,846][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 12:21:20,846][root][INFO] - Score: 88.69 [%]  |  Evaluation Time: 176.90 [s]
[2024-10-23 12:21:20,847][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 12:21:20,848][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 12:21:20,850][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 12:21:22,562][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 12:21:22,846][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 12:21:22,847][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 12:21:22,848][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 12:21:22,848][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 12:21:22,848][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 12:21:22,851][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 12:21:24,484][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 12:23:45,881][root][INFO] - Step: 50000/73665  |  Loss: 0.5393  |  Score: 78.25 [%]  |  Seq Length: 256.0
[2024-10-23 12:34:38,031][root][INFO] - Step: 10000/10550  |  Loss: 0.1950  |  Score: 92.09 [%]  |  Seq Length: 256.0
[2024-10-23 12:39:17,686][root][INFO] - Step: 10550/10550  |  Loss: 0.1935  |  Score: 92.38 [%]  |  Seq Length: 256.0
[2024-10-23 12:40:11,581][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 12:40:11,581][root][INFO] - Score: 88.86 [%]  |  Evaluation Time: 53.89 [s]
[2024-10-23 12:43:08,791][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 12:43:08,791][root][INFO] - Score: 88.89 [%]  |  Evaluation Time: 177.21 [s]
[2024-10-23 12:43:08,793][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 12:43:08,793][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 12:43:08,796][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 12:43:10,493][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 12:43:10,797][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 12:43:10,799][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 12:43:10,803][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 12:43:10,803][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 12:43:10,803][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 12:43:10,806][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_en_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 12:43:12,453][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 12:43:12,453][root][INFO] - - Epoch: 5
[2024-10-23 12:43:12,453][root][INFO] - - DEV score: 88.86 [%]
[2024-10-23 12:43:12,454][root][INFO] - - TEST score: 88.89 [%]
[2024-10-23 12:43:12,456][root][INFO] - Fine-tuning is done!
[2024-10-23 12:43:12,456][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 12:43:12,456][root][INFO] - - BEST LR: 0.01
[2024-10-23 12:43:12,457][root][INFO] - - DEV score: 88.98 [%]
[2024-10-23 12:43:12,457][root][INFO] - - TEST score: 88.93 [%]
[2024-10-23 13:42:54,542][root][INFO] - Step: 58932/73665  |  Loss: 0.5375  |  Score: 78.24 [%]  |  Seq Length: 256.0
[2024-10-23 13:43:04,797][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 13:43:04,798][root][INFO] - Score: 74.53 [%]  |  Evaluation Time: 10.25 [s]
[2024-10-23 13:43:24,791][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 13:43:24,791][root][INFO] - Score: 76.11 [%]  |  Evaluation Time: 19.99 [s]
[2024-10-23 13:43:24,792][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 13:43:24,792][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 13:43:24,795][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 13:43:26,491][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 13:43:26,784][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 13:43:26,786][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 13:43:26,786][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 13:43:26,786][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 13:43:26,787][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 13:43:26,790][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 13:43:28,524][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 13:52:55,164][root][INFO] - Step: 60000/73665  |  Loss: 0.5187  |  Score: 79.26 [%]  |  Seq Length: 256.0
[2024-10-23 14:22:05,888][root][INFO] - 

[2024-10-23 14:22:05,888][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 14:22:05,888][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:22:05,888][root][INFO] - 

[2024-10-23 14:22:05,888][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 14:22:28,896][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,897][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,897][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,897][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,898][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,898][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,899][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,899][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,900][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,900][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,900][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,901][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,901][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,902][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,902][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,902][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,903][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,903][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,904][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,904][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,905][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,905][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,905][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 14:22:28,906][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 14:22:28,907][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 14:22:29,092][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 14:22:30,954][root][INFO] - 

[2024-10-23 14:22:30,954][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 14:22:30,954][root][INFO] - Data Preprocessing
[2024-10-23 14:22:30,954][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 14:22:30,954][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 14:22:30,954][root][INFO] - ㄴ data_remove                True

[2024-10-23 14:22:30,955][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 14:22:30,962][root][INFO] - vocab size              : 51200
[2024-10-23 14:22:30,962][root][INFO] - device                  : gpu
[2024-10-23 14:22:30,962][root][INFO] - random seed             : 1
[2024-10-23 14:22:30,962][root][INFO] - train data size         : 109504
[2024-10-23 14:22:30,963][root][INFO] - max epochs              : 5
[2024-10-23 14:22:30,963][root][INFO] - total steps             : 8555
[2024-10-23 14:22:30,963][root][INFO] - warmup steps            : 856
[2024-10-23 14:22:30,963][root][INFO] - batch size              : 64
[2024-10-23 14:22:30,963][root][INFO] - accumulation steps      : 1
[2024-10-23 14:22:30,963][root][INFO] - optimizer               : adamwscale
[2024-10-23 14:22:30,963][root][INFO] - lr_scheduler            : cosine
[2024-10-23 14:22:30,963][root][INFO] - learning rate           : 0.01
[2024-10-23 14:22:30,963][root][INFO] - max length              : 256

[2024-10-23 14:22:30,963][root][INFO] - LoRA Configuration
[2024-10-23 14:22:30,963][root][INFO] - ㄴ r                    : 32
[2024-10-23 14:22:30,963][root][INFO] - ㄴ alpha                : 128
[2024-10-23 14:22:30,964][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 14:22:30,964][root][INFO] - 

[2024-10-23 14:22:30,964][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:22:30,964][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 14:22:30,964][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 14:22:30,964][root][INFO] - * tb interval   : 10000

[2024-10-23 14:22:30,964][root][INFO] - 

[2024-10-23 14:22:30,964][root][INFO] - Start the Training !
[2024-10-23 14:22:30,967][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 14:24:44,811][root][INFO] - 

[2024-10-23 14:24:44,811][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 14:24:44,811][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:24:44,812][root][INFO] - 

[2024-10-23 14:24:44,812][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 14:24:49,377][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,378][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,378][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,378][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,379][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,379][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,380][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,380][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,381][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,381][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,382][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,382][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,383][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,383][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,384][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,384][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,385][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,385][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,386][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,386][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,390][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,391][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,391][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 14:24:49,392][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 14:24:49,393][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 14:24:49,568][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 14:24:51,481][root][INFO] - 

[2024-10-23 14:24:51,481][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 14:24:51,481][root][INFO] - Data Preprocessing
[2024-10-23 14:24:51,481][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 14:24:51,481][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 14:24:51,481][root][INFO] - ㄴ data_remove                True

[2024-10-23 14:24:51,481][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 14:24:51,489][root][INFO] - vocab size              : 51200
[2024-10-23 14:24:51,489][root][INFO] - device                  : gpu
[2024-10-23 14:24:51,489][root][INFO] - random seed             : 1
[2024-10-23 14:24:51,489][root][INFO] - train data size         : 4416
[2024-10-23 14:24:51,489][root][INFO] - max epochs              : 15
[2024-10-23 14:24:51,489][root][INFO] - total steps             : 1035
[2024-10-23 14:24:51,489][root][INFO] - warmup steps            : 104
[2024-10-23 14:24:51,489][root][INFO] - batch size              : 64
[2024-10-23 14:24:51,489][root][INFO] - accumulation steps      : 1
[2024-10-23 14:24:51,490][root][INFO] - optimizer               : adamwscale
[2024-10-23 14:24:51,490][root][INFO] - lr_scheduler            : cosine
[2024-10-23 14:24:51,490][root][INFO] - learning rate           : 0.01
[2024-10-23 14:24:51,490][root][INFO] - max length              : 256

[2024-10-23 14:24:51,490][root][INFO] - LoRA Configuration
[2024-10-23 14:24:51,490][root][INFO] - ㄴ r                    : 32
[2024-10-23 14:24:51,490][root][INFO] - ㄴ alpha                : 128
[2024-10-23 14:24:51,490][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 14:24:51,490][root][INFO] - 

[2024-10-23 14:24:51,490][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:24:51,490][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 14:24:51,490][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 14:24:51,491][root][INFO] - * tb interval   : 10000

[2024-10-23 14:24:51,491][root][INFO] - 

[2024-10-23 14:24:51,491][root][INFO] - Start the Training !
[2024-10-23 14:24:51,493][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 14:25:17,946][root][INFO] - Step: 69/1035  |  Loss: 2.7287  |  Score: 28.93 [%]  |  Seq Length: 256.0
[2024-10-23 14:25:20,984][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 14:25:20,984][root][INFO] - Score: 74.55 [%]  |  Evaluation Time: 3.03 [s]
[2024-10-23 14:25:23,927][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 14:25:23,927][root][INFO] - Score: 65.63 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 14:25:23,929][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 14:25:23,929][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:25:24,725][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:25:24,764][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:25:24,764][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:25:24,765][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:25:24,765][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:25:24,765][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:25:24,766][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:25:25,409][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 14:25:50,944][root][INFO] - Step: 138/1035  |  Loss: 1.3340  |  Score: 64.65 [%]  |  Seq Length: 256.0
[2024-10-23 14:25:53,991][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 14:25:53,991][root][INFO] - Score: 77.46 [%]  |  Evaluation Time: 3.04 [s]
[2024-10-23 14:25:56,919][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 14:25:56,920][root][INFO] - Score: 68.58 [%]  |  Evaluation Time: 2.93 [s]
[2024-10-23 14:25:56,921][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 14:25:56,921][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:25:58,399][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:25:58,445][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:25:58,446][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:25:58,446][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:25:58,446][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:25:58,446][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:25:58,448][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:25:59,824][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 14:26:25,479][root][INFO] - Step: 207/1035  |  Loss: 1.1218  |  Score: 69.75 [%]  |  Seq Length: 256.0
[2024-10-23 14:26:28,548][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 14:26:28,548][root][INFO] - Score: 77.28 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 14:26:31,458][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 14:26:31,458][root][INFO] - Score: 67.16 [%]  |  Evaluation Time: 2.91 [s]
[2024-10-23 14:26:31,461][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 14:26:57,134][root][INFO] - Step: 276/1035  |  Loss: 0.9555  |  Score: 74.83 [%]  |  Seq Length: 256.0
[2024-10-23 14:27:00,191][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 14:27:00,192][root][INFO] - Score: 78.45 [%]  |  Evaluation Time: 3.05 [s]
[2024-10-23 14:27:03,144][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 14:27:03,144][root][INFO] - Score: 69.96 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 14:27:03,146][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 14:27:03,146][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:27:04,636][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:27:04,683][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:27:04,683][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:27:04,683][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:27:04,684][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:27:04,684][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:27:04,685][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:27:06,079][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 14:27:31,788][root][INFO] - Step: 345/1035  |  Loss: 0.8765  |  Score: 76.65 [%]  |  Seq Length: 256.0
[2024-10-23 14:27:34,870][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 14:27:34,870][root][INFO] - Score: 78.92 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:27:37,833][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 14:27:37,834][root][INFO] - Score: 72.80 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 14:27:37,835][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 14:27:37,835][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:27:39,320][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:27:39,367][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:27:39,367][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:27:39,367][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:27:39,368][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:27:39,368][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:27:39,369][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:27:40,764][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 14:28:06,481][root][INFO] - Step: 414/1035  |  Loss: 0.7824  |  Score: 79.79 [%]  |  Seq Length: 256.0
[2024-10-23 14:28:09,565][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 14:28:09,566][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:28:12,507][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 14:28:12,507][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 14:28:12,509][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 14:28:38,247][root][INFO] - Step: 483/1035  |  Loss: 0.6602  |  Score: 82.65 [%]  |  Seq Length: 256.0
[2024-10-23 14:28:41,321][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 14:28:41,321][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 14:28:44,243][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 14:28:44,243][root][INFO] - Score: 71.80 [%]  |  Evaluation Time: 2.92 [s]
[2024-10-23 14:28:44,245][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 14:29:09,990][root][INFO] - Step: 552/1035  |  Loss: 0.5768  |  Score: 83.99 [%]  |  Seq Length: 256.0
[2024-10-23 14:29:13,069][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 14:29:13,069][root][INFO] - Score: 77.61 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:29:16,008][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 14:29:16,009][root][INFO] - Score: 71.94 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 14:29:16,011][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 14:29:41,942][root][INFO] - Step: 621/1035  |  Loss: 0.5143  |  Score: 85.79 [%]  |  Seq Length: 256.0
[2024-10-23 14:29:45,026][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 14:29:45,026][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:29:47,988][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 14:29:47,988][root][INFO] - Score: 72.26 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 14:29:47,990][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 14:30:13,779][root][INFO] - Step: 690/1035  |  Loss: 0.4565  |  Score: 87.55 [%]  |  Seq Length: 256.0
[2024-10-23 14:30:16,870][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 14:30:16,870][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 14:30:19,879][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 14:30:19,879][root][INFO] - Score: 72.51 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 14:30:19,881][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 14:30:45,699][root][INFO] - Step: 759/1035  |  Loss: 0.4261  |  Score: 88.37 [%]  |  Seq Length: 256.0
[2024-10-23 14:30:48,779][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 14:30:48,779][root][INFO] - Score: 78.25 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:30:51,852][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 14:30:51,853][root][INFO] - Score: 72.58 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 14:30:51,855][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 14:31:17,739][root][INFO] - Step: 828/1035  |  Loss: 0.3867  |  Score: 89.02 [%]  |  Seq Length: 256.0
[2024-10-23 14:31:20,822][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 14:31:20,823][root][INFO] - Score: 79.52 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:31:23,790][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 14:31:23,791][root][INFO] - Score: 72.45 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 14:31:23,792][root][INFO] - 
Save new Best Score (Epoch: 12)
[2024-10-23 14:31:23,792][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:31:25,412][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:31:25,444][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:31:25,444][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:31:25,444][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:31:25,445][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:31:25,445][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:31:25,446][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:31:26,878][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 14:31:52,746][root][INFO] - Step: 897/1035  |  Loss: 0.3906  |  Score: 88.65 [%]  |  Seq Length: 256.0
[2024-10-23 14:31:55,844][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 14:31:55,845][root][INFO] - Score: 78.90 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 14:31:58,827][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 14:31:58,827][root][INFO] - Score: 72.80 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 14:31:58,830][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 14:32:24,725][root][INFO] - Step: 966/1035  |  Loss: 0.3804  |  Score: 88.68 [%]  |  Seq Length: 256.0
[2024-10-23 14:32:27,801][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 14:32:27,801][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 14:32:30,778][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 14:32:30,778][root][INFO] - Score: 72.81 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 14:32:30,781][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 14:32:56,629][root][INFO] - Step: 1035/1035  |  Loss: 0.3585  |  Score: 89.51 [%]  |  Seq Length: 256.0
[2024-10-23 14:32:57,230][root][INFO] - Step: 1711/8555  |  Loss: 0.3670  |  Score: 83.82 [%]  |  Seq Length: 256.0
[2024-10-23 14:32:59,711][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 14:32:59,711][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:33:02,713][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 14:33:02,713][root][INFO] - Score: 73.01 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 14:33:02,714][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 14:33:02,714][root][INFO] - - Epoch: 12
[2024-10-23 14:33:02,714][root][INFO] - - DEV score: 79.52 [%]
[2024-10-23 14:33:02,714][root][INFO] - - TEST score: 72.45 [%]
[2024-10-23 14:33:02,715][root][INFO] - Fine-tuning is done!
[2024-10-23 14:33:05,929][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,929][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,930][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,931][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,932][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,932][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,933][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,933][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,934][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,935][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,935][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,936][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,937][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,937][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,938][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,938][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,939][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,939][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,940][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,941][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,941][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,942][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,943][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 14:33:05,943][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 14:33:05,946][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 14:33:05,947][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 14:33:06,101][root][INFO] - 

[2024-10-23 14:33:06,101][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 14:33:06,101][root][INFO] - Data Preprocessing
[2024-10-23 14:33:06,101][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 14:33:06,101][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 14:33:06,101][root][INFO] - ㄴ data_remove                True

[2024-10-23 14:33:06,102][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 14:33:06,109][root][INFO] - vocab size              : 51200
[2024-10-23 14:33:06,110][root][INFO] - device                  : gpu
[2024-10-23 14:33:06,110][root][INFO] - random seed             : 1
[2024-10-23 14:33:06,110][root][INFO] - train data size         : 4416
[2024-10-23 14:33:06,110][root][INFO] - max epochs              : 15
[2024-10-23 14:33:06,110][root][INFO] - total steps             : 1035
[2024-10-23 14:33:06,110][root][INFO] - warmup steps            : 104
[2024-10-23 14:33:06,110][root][INFO] - batch size              : 64
[2024-10-23 14:33:06,110][root][INFO] - accumulation steps      : 1
[2024-10-23 14:33:06,110][root][INFO] - optimizer               : adamwscale
[2024-10-23 14:33:06,111][root][INFO] - lr_scheduler            : cosine
[2024-10-23 14:33:06,111][root][INFO] - learning rate           : 0.02
[2024-10-23 14:33:06,111][root][INFO] - max length              : 256

[2024-10-23 14:33:06,111][root][INFO] - LoRA Configuration
[2024-10-23 14:33:06,111][root][INFO] - ㄴ r                    : 32
[2024-10-23 14:33:06,111][root][INFO] - ㄴ alpha                : 128
[2024-10-23 14:33:06,111][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 14:33:06,111][root][INFO] - 

[2024-10-23 14:33:06,111][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:33:06,111][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 14:33:06,112][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 14:33:06,112][root][INFO] - * tb interval   : 10000

[2024-10-23 14:33:06,112][root][INFO] - 

[2024-10-23 14:33:06,112][root][INFO] - Start the Training !
[2024-10-23 14:33:06,114][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 14:33:24,826][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 14:33:24,826][root][INFO] - Score: 86.58 [%]  |  Evaluation Time: 27.59 [s]
[2024-10-23 14:33:32,046][root][INFO] - Step: 69/1035  |  Loss: 2.2971  |  Score: 40.15 [%]  |  Seq Length: 256.0
[2024-10-23 14:33:35,190][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 14:33:35,190][root][INFO] - Score: 75.75 [%]  |  Evaluation Time: 3.14 [s]
[2024-10-23 14:33:38,204][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 14:33:38,205][root][INFO] - Score: 67.40 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 14:33:38,206][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 14:33:38,207][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:33:39,815][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:33:39,862][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:33:39,862][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:33:39,862][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:33:39,862][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:33:39,862][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:33:39,864][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:33:41,318][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 14:34:07,216][root][INFO] - Step: 138/1035  |  Loss: 1.2154  |  Score: 67.23 [%]  |  Seq Length: 256.0
[2024-10-23 14:34:10,361][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 14:34:10,362][root][INFO] - Score: 77.80 [%]  |  Evaluation Time: 3.14 [s]
[2024-10-23 14:34:13,357][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 14:34:13,358][root][INFO] - Score: 70.68 [%]  |  Evaluation Time: 2.99 [s]
[2024-10-23 14:34:13,359][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 14:34:13,360][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:34:15,050][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:34:15,085][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:34:15,086][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:34:15,086][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:34:15,086][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:34:15,086][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:34:15,088][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:34:16,552][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 14:34:42,522][root][INFO] - Step: 207/1035  |  Loss: 1.0335  |  Score: 73.26 [%]  |  Seq Length: 256.0
[2024-10-23 14:34:45,622][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 14:34:45,622][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 14:34:48,681][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 14:34:48,681][root][INFO] - Score: 68.60 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 14:34:48,684][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 14:34:55,614][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 14:34:55,614][root][INFO] - Score: 86.82 [%]  |  Evaluation Time: 90.79 [s]
[2024-10-23 14:34:55,616][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 14:34:55,616][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:34:56,451][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:34:56,476][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:34:56,477][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:34:56,477][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:34:56,477][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:34:56,477][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:34:56,478][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:34:57,161][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 14:35:14,534][root][INFO] - Step: 276/1035  |  Loss: 0.8075  |  Score: 78.58 [%]  |  Seq Length: 256.0
[2024-10-23 14:35:17,660][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 14:35:17,661][root][INFO] - Score: 78.26 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 14:35:20,677][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 14:35:20,677][root][INFO] - Score: 69.64 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 14:35:20,679][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 14:35:46,553][root][INFO] - Step: 345/1035  |  Loss: 0.7246  |  Score: 81.48 [%]  |  Seq Length: 256.0
[2024-10-23 14:35:49,681][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 14:35:49,681][root][INFO] - Score: 78.38 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 14:35:52,702][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 14:35:52,702][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 14:35:52,703][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 14:35:52,704][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:35:54,223][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:35:54,255][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:35:54,256][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:35:54,256][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:35:54,256][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:35:54,256][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:35:54,257][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:35:55,679][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 14:36:21,490][root][INFO] - Step: 414/1035  |  Loss: 0.5690  |  Score: 84.74 [%]  |  Seq Length: 256.0
[2024-10-23 14:36:24,627][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 14:36:24,628][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 3.13 [s]
[2024-10-23 14:36:27,599][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 14:36:27,599][root][INFO] - Score: 70.39 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 14:36:27,601][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 14:36:53,492][root][INFO] - Step: 483/1035  |  Loss: 0.4739  |  Score: 87.81 [%]  |  Seq Length: 256.0
[2024-10-23 14:36:56,603][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 14:36:56,603][root][INFO] - Score: 77.67 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 14:36:59,553][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 14:36:59,553][root][INFO] - Score: 71.52 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 14:36:59,556][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 14:37:25,389][root][INFO] - Step: 552/1035  |  Loss: 0.3735  |  Score: 89.23 [%]  |  Seq Length: 256.0
[2024-10-23 14:37:28,516][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 14:37:28,516][root][INFO] - Score: 77.32 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 14:37:31,497][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 14:37:31,497][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 14:37:31,499][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 14:37:57,514][root][INFO] - Step: 621/1035  |  Loss: 0.3311  |  Score: 91.09 [%]  |  Seq Length: 256.0
[2024-10-23 14:38:00,578][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 14:38:00,578][root][INFO] - Score: 77.44 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 14:38:03,549][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 14:38:03,549][root][INFO] - Score: 71.15 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 14:38:03,551][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 14:38:29,472][root][INFO] - Step: 690/1035  |  Loss: 0.2809  |  Score: 92.42 [%]  |  Seq Length: 256.0
[2024-10-23 14:38:32,646][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 14:38:32,647][root][INFO] - Score: 77.74 [%]  |  Evaluation Time: 3.17 [s]
[2024-10-23 14:38:35,693][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 14:38:35,694][root][INFO] - Score: 71.63 [%]  |  Evaluation Time: 3.04 [s]
[2024-10-23 14:38:35,696][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 14:39:01,641][root][INFO] - Step: 759/1035  |  Loss: 0.2414  |  Score: 93.37 [%]  |  Seq Length: 256.0
[2024-10-23 14:39:04,727][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 14:39:04,728][root][INFO] - Score: 78.30 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:39:07,704][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 14:39:07,704][root][INFO] - Score: 71.77 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 14:39:07,705][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-23 14:39:07,705][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:39:09,394][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:39:09,428][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:39:09,429][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:39:09,429][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:39:09,429][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:39:09,429][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:39:09,431][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:39:10,848][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 14:39:36,696][root][INFO] - Step: 828/1035  |  Loss: 0.2118  |  Score: 93.98 [%]  |  Seq Length: 256.0
[2024-10-23 14:39:39,791][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 14:39:39,791][root][INFO] - Score: 79.66 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 14:39:42,752][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 14:39:42,752][root][INFO] - Score: 71.30 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 14:39:42,753][root][INFO] - 
Save new Best Score (Epoch: 12)
[2024-10-23 14:39:42,753][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:39:44,403][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:39:44,436][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:39:44,437][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:39:44,437][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:39:44,437][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:39:44,437][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:39:44,438][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:39:45,818][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 14:40:11,636][root][INFO] - Step: 897/1035  |  Loss: 0.2033  |  Score: 94.18 [%]  |  Seq Length: 256.0
[2024-10-23 14:40:14,710][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 14:40:14,711][root][INFO] - Score: 78.83 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 14:40:17,665][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 14:40:17,665][root][INFO] - Score: 71.59 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 14:40:17,667][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 14:40:43,486][root][INFO] - Step: 966/1035  |  Loss: 0.1932  |  Score: 94.18 [%]  |  Seq Length: 256.0
[2024-10-23 14:40:46,566][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 14:40:46,567][root][INFO] - Score: 78.88 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 14:40:49,529][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 14:40:49,529][root][INFO] - Score: 72.07 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 14:40:49,531][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 14:41:15,386][root][INFO] - Step: 1035/1035  |  Loss: 0.1828  |  Score: 94.77 [%]  |  Seq Length: 256.0
[2024-10-23 14:41:18,515][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 14:41:18,516][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 3.13 [s]
[2024-10-23 14:41:21,513][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 14:41:21,513][root][INFO] - Score: 72.43 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 14:41:21,514][root][INFO] - 
Save new Best Score (Epoch: 15)
[2024-10-23 14:41:21,514][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:41:23,110][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:41:23,144][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:41:23,145][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:41:23,145][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:41:23,145][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:41:23,145][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:41:23,146][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:41:24,546][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 14:41:24,546][root][INFO] - - Epoch: 15
[2024-10-23 14:41:24,547][root][INFO] - - DEV score: 78.63 [%]
[2024-10-23 14:41:24,547][root][INFO] - - TEST score: 72.43 [%]
[2024-10-23 14:41:24,549][root][INFO] - Fine-tuning is done!
[2024-10-23 14:41:24,550][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 14:41:24,550][root][INFO] - - BEST LR: 0.01
[2024-10-23 14:41:24,550][root][INFO] - - DEV score: 79.52 [%]
[2024-10-23 14:41:24,550][root][INFO] - - TEST score: 72.45 [%]
[2024-10-23 14:41:30,258][root][INFO] - 

[2024-10-23 14:41:30,259][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 14:41:30,259][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:41:30,259][root][INFO] - 

[2024-10-23 14:41:30,260][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 14:41:34,729][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,729][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,730][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,730][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,731][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,731][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,732][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,732][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,733][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,733][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,734][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,734][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,735][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,735][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,736][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,736][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,737][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,737][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,738][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,738][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,739][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,739][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,740][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 14:41:34,740][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 14:41:34,742][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 14:41:34,746][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 14:41:34,954][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 14:41:34,956][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 14:41:35,118][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 14:41:38,429][root][INFO] - 

[2024-10-23 14:41:38,429][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 14:41:38,429][root][INFO] - Data Preprocessing
[2024-10-23 14:41:38,430][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 14:41:38,430][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 14:41:38,430][root][INFO] - ㄴ data_remove                True

[2024-10-23 14:41:38,430][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 14:41:38,438][root][INFO] - vocab size              : 51200
[2024-10-23 14:41:38,438][root][INFO] - device                  : gpu
[2024-10-23 14:41:38,438][root][INFO] - random seed             : 1
[2024-10-23 14:41:38,438][root][INFO] - train data size         : 4416
[2024-10-23 14:41:38,438][root][INFO] - max epochs              : 15
[2024-10-23 14:41:38,438][root][INFO] - total steps             : 1035
[2024-10-23 14:41:38,438][root][INFO] - warmup steps            : 104
[2024-10-23 14:41:38,438][root][INFO] - batch size              : 64
[2024-10-23 14:41:38,439][root][INFO] - accumulation steps      : 1
[2024-10-23 14:41:38,439][root][INFO] - optimizer               : adamwscale
[2024-10-23 14:41:38,439][root][INFO] - lr_scheduler            : cosine
[2024-10-23 14:41:38,439][root][INFO] - learning rate           : 0.01
[2024-10-23 14:41:38,439][root][INFO] - max length              : 256

[2024-10-23 14:41:38,439][root][INFO] - LoRA Configuration
[2024-10-23 14:41:38,439][root][INFO] - ㄴ r                    : 32
[2024-10-23 14:41:38,439][root][INFO] - ㄴ alpha                : 128
[2024-10-23 14:41:38,439][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 14:41:38,439][root][INFO] - KOMBO Configuration
[2024-10-23 14:41:38,439][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 14:41:38,440][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 14:41:38,440][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 14:41:38,440][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 14:41:38,440][root][INFO] - ㄴ do_combination       : True
[2024-10-23 14:41:38,440][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 14:41:38,440][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 14:41:38,440][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 14:41:38,440][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 14:41:38,440][root][INFO] - 

[2024-10-23 14:41:38,440][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:41:38,441][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 14:41:38,441][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 14:41:38,441][root][INFO] - * tb interval   : 10000

[2024-10-23 14:41:38,441][root][INFO] - 

[2024-10-23 14:41:38,441][root][INFO] - Start the Training !
[2024-10-23 14:41:38,444][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 14:42:15,382][root][INFO] - Step: 69/1035  |  Loss: 2.7234  |  Score: 29.43 [%]  |  Seq Length: 256.0
[2024-10-23 14:42:20,270][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 14:42:20,270][root][INFO] - Score: 72.46 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-23 14:42:24,877][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 14:42:24,877][root][INFO] - Score: 64.38 [%]  |  Evaluation Time: 4.60 [s]
[2024-10-23 14:42:24,878][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 14:42:24,878][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:42:24,881][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:42:25,803][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:42:25,922][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:42:25,922][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:42:25,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:42:25,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:42:25,922][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:42:25,923][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:42:26,702][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 14:43:03,525][root][INFO] - Step: 138/1035  |  Loss: 1.3457  |  Score: 63.45 [%]  |  Seq Length: 256.0
[2024-10-23 14:43:08,497][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 14:43:08,497][root][INFO] - Score: 76.74 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-23 14:43:13,167][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 14:43:13,167][root][INFO] - Score: 70.49 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 14:43:13,168][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 14:43:13,168][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:43:13,171][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:43:15,073][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:43:15,370][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:43:15,372][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:43:15,372][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:43:15,372][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:43:15,373][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:43:15,375][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:43:17,126][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 14:43:53,735][root][INFO] - Step: 207/1035  |  Loss: 1.0661  |  Score: 70.77 [%]  |  Seq Length: 256.0
[2024-10-23 14:43:58,662][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 14:43:58,662][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 4.92 [s]
[2024-10-23 14:44:03,357][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 14:44:03,357][root][INFO] - Score: 71.32 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-23 14:44:03,358][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 14:44:03,359][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:44:03,362][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:44:05,368][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:44:05,582][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:44:05,583][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:44:05,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:44:05,584][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:44:05,585][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:44:05,587][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:44:07,312][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 14:44:43,256][root][INFO] - Step: 276/1035  |  Loss: 0.9634  |  Score: 74.33 [%]  |  Seq Length: 256.0
[2024-10-23 14:44:48,208][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 14:44:48,208][root][INFO] - Score: 78.23 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 14:44:52,875][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 14:44:52,876][root][INFO] - Score: 71.66 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 14:44:52,877][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 14:44:52,877][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:44:52,880][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:44:54,879][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:44:55,152][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:44:55,154][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:44:55,155][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:44:55,155][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:44:55,155][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:44:55,158][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:44:56,878][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 14:45:23,682][root][INFO] - Step: 3422/8555  |  Loss: 0.2919  |  Score: 87.74 [%]  |  Seq Length: 256.0
[2024-10-23 14:45:33,868][root][INFO] - Step: 345/1035  |  Loss: 0.8175  |  Score: 77.35 [%]  |  Seq Length: 256.0
[2024-10-23 14:45:38,915][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 14:45:38,915][root][INFO] - Score: 77.74 [%]  |  Evaluation Time: 5.04 [s]
[2024-10-23 14:45:43,569][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 14:45:43,570][root][INFO] - Score: 70.69 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-23 14:45:43,572][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 14:45:51,243][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 14:45:51,243][root][INFO] - Score: 88.08 [%]  |  Evaluation Time: 27.56 [s]
[2024-10-23 14:46:20,410][root][INFO] - Step: 414/1035  |  Loss: 0.7553  |  Score: 80.64 [%]  |  Seq Length: 256.0
[2024-10-23 14:46:25,370][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 14:46:25,370][root][INFO] - Score: 77.72 [%]  |  Evaluation Time: 4.96 [s]
[2024-10-23 14:46:30,037][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 14:46:30,037][root][INFO] - Score: 71.82 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 14:46:30,039][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 14:47:06,868][root][INFO] - Step: 483/1035  |  Loss: 0.6330  |  Score: 82.86 [%]  |  Seq Length: 256.0
[2024-10-23 14:47:11,890][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 14:47:11,890][root][INFO] - Score: 79.46 [%]  |  Evaluation Time: 5.02 [s]
[2024-10-23 14:47:16,617][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 14:47:16,617][root][INFO] - Score: 71.77 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-23 14:47:16,618][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 14:47:16,619][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:47:16,622][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:47:18,619][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:47:18,883][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:47:18,884][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:47:18,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:47:18,884][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:47:18,885][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:47:18,887][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:47:20,579][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 14:47:21,997][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 14:47:21,997][root][INFO] - Score: 88.06 [%]  |  Evaluation Time: 90.75 [s]
[2024-10-23 14:47:21,999][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 14:47:21,999][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:47:23,775][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:47:23,814][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:47:23,815][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:47:23,815][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:47:23,816][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:47:23,816][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:47:23,817][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:47:25,222][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 14:47:57,229][root][INFO] - Step: 552/1035  |  Loss: 0.6096  |  Score: 83.90 [%]  |  Seq Length: 256.0
[2024-10-23 14:48:02,173][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 14:48:02,173][root][INFO] - Score: 78.33 [%]  |  Evaluation Time: 4.94 [s]
[2024-10-23 14:48:06,866][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 14:48:06,866][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-23 14:48:06,868][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 14:48:43,575][root][INFO] - Step: 621/1035  |  Loss: 0.5196  |  Score: 85.89 [%]  |  Seq Length: 256.0
[2024-10-23 14:48:48,500][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 14:48:48,500][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 4.92 [s]
[2024-10-23 14:48:53,158][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 14:48:53,158][root][INFO] - Score: 71.13 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 14:48:53,160][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 14:49:29,786][root][INFO] - Step: 690/1035  |  Loss: 0.4447  |  Score: 87.73 [%]  |  Seq Length: 256.0
[2024-10-23 14:49:34,780][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 14:49:34,780][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 4.99 [s]
[2024-10-23 14:49:39,513][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 14:49:39,513][root][INFO] - Score: 71.76 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-23 14:49:39,515][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 14:50:16,258][root][INFO] - Step: 759/1035  |  Loss: 0.4269  |  Score: 88.51 [%]  |  Seq Length: 256.0
[2024-10-23 14:50:21,197][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 14:50:21,197][root][INFO] - Score: 78.54 [%]  |  Evaluation Time: 4.94 [s]
[2024-10-23 14:50:25,834][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 14:50:25,834][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 14:50:25,836][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 14:51:02,514][root][INFO] - Step: 828/1035  |  Loss: 0.3975  |  Score: 89.15 [%]  |  Seq Length: 256.0
[2024-10-23 14:51:07,465][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 14:51:07,465][root][INFO] - Score: 78.75 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 14:51:12,124][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 14:51:12,124][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 14:51:12,127][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 14:51:48,980][root][INFO] - Step: 897/1035  |  Loss: 0.3705  |  Score: 89.39 [%]  |  Seq Length: 256.0
[2024-10-23 14:51:53,886][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 14:51:53,886][root][INFO] - Score: 78.29 [%]  |  Evaluation Time: 4.90 [s]
[2024-10-23 14:51:58,535][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 14:51:58,535][root][INFO] - Score: 72.32 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-23 14:51:58,537][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 14:52:35,094][root][INFO] - Step: 966/1035  |  Loss: 0.3545  |  Score: 89.90 [%]  |  Seq Length: 256.0
[2024-10-23 14:52:40,026][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 14:52:40,026][root][INFO] - Score: 77.40 [%]  |  Evaluation Time: 4.93 [s]
[2024-10-23 14:52:44,640][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 14:52:44,640][root][INFO] - Score: 71.29 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-23 14:52:44,642][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 14:53:21,396][root][INFO] - Step: 1035/1035  |  Loss: 0.3739  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-23 14:53:26,376][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 14:53:26,376][root][INFO] - Score: 78.85 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-23 14:53:30,965][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 14:53:30,965][root][INFO] - Score: 71.92 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-23 14:53:30,966][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 14:53:30,966][root][INFO] - - Epoch: 7
[2024-10-23 14:53:30,966][root][INFO] - - DEV score: 79.46 [%]
[2024-10-23 14:53:30,966][root][INFO] - - TEST score: 71.77 [%]
[2024-10-23 14:53:30,967][root][INFO] - Fine-tuning is done!
[2024-10-23 14:53:34,485][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,486][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,487][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,487][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,488][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,489][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,489][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,490][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,490][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,491][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,491][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,492][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,492][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,493][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,493][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,494][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,494][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,495][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,495][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,496][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,496][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,497][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,497][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 14:53:34,498][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 14:53:34,500][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 14:53:34,721][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 14:53:34,724][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 14:53:34,725][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 14:53:34,901][root][INFO] - 

[2024-10-23 14:53:34,901][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 14:53:34,901][root][INFO] - Data Preprocessing
[2024-10-23 14:53:34,902][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 14:53:34,902][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 14:53:34,902][root][INFO] - ㄴ data_remove                True

[2024-10-23 14:53:34,902][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 14:53:34,910][root][INFO] - vocab size              : 51200
[2024-10-23 14:53:34,910][root][INFO] - device                  : gpu
[2024-10-23 14:53:34,910][root][INFO] - random seed             : 1
[2024-10-23 14:53:34,910][root][INFO] - train data size         : 4416
[2024-10-23 14:53:34,911][root][INFO] - max epochs              : 15
[2024-10-23 14:53:34,911][root][INFO] - total steps             : 1035
[2024-10-23 14:53:34,911][root][INFO] - warmup steps            : 104
[2024-10-23 14:53:34,911][root][INFO] - batch size              : 64
[2024-10-23 14:53:34,911][root][INFO] - accumulation steps      : 1
[2024-10-23 14:53:34,911][root][INFO] - optimizer               : adamwscale
[2024-10-23 14:53:34,911][root][INFO] - lr_scheduler            : cosine
[2024-10-23 14:53:34,911][root][INFO] - learning rate           : 0.02
[2024-10-23 14:53:34,911][root][INFO] - max length              : 256

[2024-10-23 14:53:34,911][root][INFO] - LoRA Configuration
[2024-10-23 14:53:34,911][root][INFO] - ㄴ r                    : 32
[2024-10-23 14:53:34,911][root][INFO] - ㄴ alpha                : 128
[2024-10-23 14:53:34,912][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 14:53:34,912][root][INFO] - KOMBO Configuration
[2024-10-23 14:53:34,912][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 14:53:34,912][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 14:53:34,912][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 14:53:34,912][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 14:53:34,912][root][INFO] - ㄴ do_combination       : True
[2024-10-23 14:53:34,912][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 14:53:34,912][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 14:53:34,912][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 14:53:34,913][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 14:53:34,913][root][INFO] - 

[2024-10-23 14:53:34,913][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs
[2024-10-23 14:53:34,913][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 14:53:34,913][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 14:53:34,913][root][INFO] - * tb interval   : 10000

[2024-10-23 14:53:34,913][root][INFO] - 

[2024-10-23 14:53:34,913][root][INFO] - Start the Training !
[2024-10-23 14:53:34,915][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 14:54:11,905][root][INFO] - Step: 69/1035  |  Loss: 2.2800  |  Score: 39.34 [%]  |  Seq Length: 256.0
[2024-10-23 14:54:16,917][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 14:54:16,918][root][INFO] - Score: 73.81 [%]  |  Evaluation Time: 5.01 [s]
[2024-10-23 14:54:21,632][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 14:54:21,632][root][INFO] - Score: 66.85 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-23 14:54:21,633][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 14:54:21,633][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:54:21,636][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:54:23,520][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:54:23,808][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:54:23,809][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:54:23,809][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:54:23,810][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:54:23,810][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:54:23,813][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:54:25,507][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 14:55:02,537][root][INFO] - Step: 138/1035  |  Loss: 1.2247  |  Score: 66.57 [%]  |  Seq Length: 256.0
[2024-10-23 14:55:07,621][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 14:55:07,621][root][INFO] - Score: 77.95 [%]  |  Evaluation Time: 5.08 [s]
[2024-10-23 14:55:12,545][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 14:55:12,545][root][INFO] - Score: 71.43 [%]  |  Evaluation Time: 4.92 [s]
[2024-10-23 14:55:12,546][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 14:55:12,547][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:55:12,550][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:55:14,446][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:55:14,692][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:55:14,693][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:55:14,694][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:55:14,694][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:55:14,695][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:55:14,697][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:55:16,490][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 14:55:53,519][root][INFO] - Step: 207/1035  |  Loss: 1.0115  |  Score: 73.37 [%]  |  Seq Length: 256.0
[2024-10-23 14:55:58,639][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 14:55:58,639][root][INFO] - Score: 78.26 [%]  |  Evaluation Time: 5.12 [s]
[2024-10-23 14:56:03,500][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 14:56:03,500][root][INFO] - Score: 70.19 [%]  |  Evaluation Time: 4.86 [s]
[2024-10-23 14:56:03,503][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 14:56:40,628][root][INFO] - Step: 276/1035  |  Loss: 0.8914  |  Score: 78.12 [%]  |  Seq Length: 256.0
[2024-10-23 14:56:45,755][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 14:56:45,755][root][INFO] - Score: 77.90 [%]  |  Evaluation Time: 5.12 [s]
[2024-10-23 14:56:50,607][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 14:56:50,607][root][INFO] - Score: 69.28 [%]  |  Evaluation Time: 4.85 [s]
[2024-10-23 14:56:50,609][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 14:57:27,633][root][INFO] - Step: 345/1035  |  Loss: 0.6918  |  Score: 81.09 [%]  |  Seq Length: 256.0
[2024-10-23 14:57:32,771][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 14:57:32,771][root][INFO] - Score: 76.52 [%]  |  Evaluation Time: 5.13 [s]
[2024-10-23 14:57:37,496][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 14:57:37,496][root][INFO] - Score: 69.39 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-23 14:57:37,499][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 14:57:52,540][root][INFO] - Step: 5133/8555  |  Loss: 0.2507  |  Score: 89.64 [%]  |  Seq Length: 256.0
[2024-10-23 14:58:14,590][root][INFO] - Step: 414/1035  |  Loss: 0.6008  |  Score: 84.85 [%]  |  Seq Length: 256.0
[2024-10-23 14:58:19,680][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 14:58:19,680][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 5.09 [s]
[2024-10-23 14:58:20,086][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 14:58:20,086][root][INFO] - Score: 88.43 [%]  |  Evaluation Time: 27.54 [s]
[2024-10-23 14:58:24,494][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 14:58:24,494][root][INFO] - Score: 70.59 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-23 14:58:24,497][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 14:59:01,531][root][INFO] - Step: 483/1035  |  Loss: 0.4529  |  Score: 87.38 [%]  |  Seq Length: 256.0
[2024-10-23 14:59:06,584][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 14:59:06,585][root][INFO] - Score: 78.80 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-23 14:59:11,403][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 14:59:11,403][root][INFO] - Score: 71.22 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-23 14:59:11,406][root][INFO] - 
Save new Best Score (Epoch: 7)
[2024-10-23 14:59:11,407][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:59:11,412][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 14:59:13,216][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:59:13,492][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:59:13,494][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:59:13,495][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:59:13,495][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:59:13,496][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:59:13,499][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:59:15,162][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 14:59:50,748][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 14:59:50,749][root][INFO] - Score: 88.31 [%]  |  Evaluation Time: 90.66 [s]
[2024-10-23 14:59:50,750][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 14:59:50,750][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 14:59:52,049][root][INFO] - Step: 552/1035  |  Loss: 0.3733  |  Score: 89.39 [%]  |  Seq Length: 256.0
[2024-10-23 14:59:52,349][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 14:59:52,381][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 14:59:52,381][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 14:59:52,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 14:59:52,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 14:59:52,382][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 14:59:52,383][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 14:59:53,795][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 14:59:57,160][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 14:59:57,160][root][INFO] - Score: 77.83 [%]  |  Evaluation Time: 5.11 [s]
[2024-10-23 15:00:01,952][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:00:01,952][root][INFO] - Score: 70.25 [%]  |  Evaluation Time: 4.79 [s]
[2024-10-23 15:00:01,955][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:00:38,908][root][INFO] - Step: 621/1035  |  Loss: 0.3175  |  Score: 91.47 [%]  |  Seq Length: 256.0
[2024-10-23 15:00:44,125][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:00:44,125][root][INFO] - Score: 77.68 [%]  |  Evaluation Time: 5.21 [s]
[2024-10-23 15:00:48,889][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:00:48,889][root][INFO] - Score: 69.70 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-23 15:00:48,892][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 15:01:25,851][root][INFO] - Step: 690/1035  |  Loss: 0.2637  |  Score: 92.48 [%]  |  Seq Length: 256.0
[2024-10-23 15:01:31,024][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 15:01:31,024][root][INFO] - Score: 78.00 [%]  |  Evaluation Time: 5.17 [s]
[2024-10-23 15:01:35,903][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 15:01:35,903][root][INFO] - Score: 69.66 [%]  |  Evaluation Time: 4.88 [s]
[2024-10-23 15:01:35,905][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 15:02:12,917][root][INFO] - Step: 759/1035  |  Loss: 0.2376  |  Score: 93.37 [%]  |  Seq Length: 256.0
[2024-10-23 15:02:17,953][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 15:02:17,953][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 5.03 [s]
[2024-10-23 15:02:22,901][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 15:02:22,902][root][INFO] - Score: 70.49 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:02:22,904][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 15:02:59,817][root][INFO] - Step: 828/1035  |  Loss: 0.2266  |  Score: 93.81 [%]  |  Seq Length: 256.0
[2024-10-23 15:03:04,986][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 15:03:04,986][root][INFO] - Score: 78.68 [%]  |  Evaluation Time: 5.17 [s]
[2024-10-23 15:03:09,772][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 15:03:09,772][root][INFO] - Score: 69.82 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-23 15:03:09,774][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 15:03:46,756][root][INFO] - Step: 897/1035  |  Loss: 0.2004  |  Score: 94.31 [%]  |  Seq Length: 256.0
[2024-10-23 15:03:51,869][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 15:03:51,869][root][INFO] - Score: 78.21 [%]  |  Evaluation Time: 5.11 [s]
[2024-10-23 15:03:56,632][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 15:03:56,633][root][INFO] - Score: 70.46 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-23 15:03:56,635][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 15:04:33,589][root][INFO] - Step: 966/1035  |  Loss: 0.1811  |  Score: 94.88 [%]  |  Seq Length: 256.0
[2024-10-23 15:04:38,671][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 15:04:38,671][root][INFO] - Score: 77.31 [%]  |  Evaluation Time: 5.08 [s]
[2024-10-23 15:04:43,535][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 15:04:43,535][root][INFO] - Score: 69.35 [%]  |  Evaluation Time: 4.86 [s]
[2024-10-23 15:04:43,538][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 15:05:20,615][root][INFO] - Step: 1035/1035  |  Loss: 0.1912  |  Score: 94.62 [%]  |  Seq Length: 256.0
[2024-10-23 15:05:25,701][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 15:05:25,702][root][INFO] - Score: 79.08 [%]  |  Evaluation Time: 5.08 [s]
[2024-10-23 15:05:30,553][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 15:05:30,554][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.85 [s]
[2024-10-23 15:05:30,555][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:05:30,555][root][INFO] - - Epoch: 7
[2024-10-23 15:05:30,555][root][INFO] - - DEV score: 78.80 [%]
[2024-10-23 15:05:30,555][root][INFO] - - TEST score: 71.22 [%]
[2024-10-23 15:05:30,556][root][INFO] - Fine-tuning is done!
[2024-10-23 15:05:30,557][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 15:05:30,557][root][INFO] - - BEST LR: 0.01
[2024-10-23 15:05:30,557][root][INFO] - - DEV score: 79.46 [%]
[2024-10-23 15:05:30,557][root][INFO] - - TEST score: 71.77 [%]
[2024-10-23 15:05:37,095][root][INFO] - 

[2024-10-23 15:05:37,096][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 15:05:37,096][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-23 15:05:37,096][root][INFO] - 

[2024-10-23 15:05:37,097][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 15:05:42,329][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,330][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,330][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,331][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,331][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,331][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,332][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,332][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,333][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,333][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,334][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,334][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,335][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,335][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,336][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,336][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,336][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,337][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,337][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,338][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,342][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,343][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,343][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:05:42,343][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:05:42,345][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 15:05:42,521][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:05:44,570][root][INFO] - 

[2024-10-23 15:05:44,570][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 15:05:44,570][root][INFO] - Data Preprocessing
[2024-10-23 15:05:44,570][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 15:05:44,571][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:05:44,571][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:05:44,571][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:05:44,579][root][INFO] - vocab size              : 51200
[2024-10-23 15:05:44,580][root][INFO] - device                  : gpu
[2024-10-23 15:05:44,580][root][INFO] - random seed             : 2
[2024-10-23 15:05:44,580][root][INFO] - train data size         : 4416
[2024-10-23 15:05:44,580][root][INFO] - max epochs              : 15
[2024-10-23 15:05:44,580][root][INFO] - total steps             : 1035
[2024-10-23 15:05:44,580][root][INFO] - warmup steps            : 104
[2024-10-23 15:05:44,580][root][INFO] - batch size              : 64
[2024-10-23 15:05:44,580][root][INFO] - accumulation steps      : 1
[2024-10-23 15:05:44,580][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:05:44,580][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:05:44,580][root][INFO] - learning rate           : 0.01
[2024-10-23 15:05:44,581][root][INFO] - max length              : 256

[2024-10-23 15:05:44,581][root][INFO] - LoRA Configuration
[2024-10-23 15:05:44,581][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:05:44,581][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:05:44,581][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:05:44,581][root][INFO] - 

[2024-10-23 15:05:44,581][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-23 15:05:44,581][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 15:05:44,581][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 15:05:44,581][root][INFO] - * tb interval   : 10000

[2024-10-23 15:05:44,581][root][INFO] - 

[2024-10-23 15:05:44,581][root][INFO] - Start the Training !
[2024-10-23 15:05:44,584][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 15:06:11,539][root][INFO] - Step: 69/1035  |  Loss: 2.2426  |  Score: 31.49 [%]  |  Seq Length: 256.0
[2024-10-23 15:06:14,606][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:06:14,606][root][INFO] - Score: 73.13 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 15:06:17,560][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:06:17,560][root][INFO] - Score: 65.03 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 15:06:17,561][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:06:17,562][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:06:18,564][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:06:18,588][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:06:18,588][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:06:18,589][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:06:18,589][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:06:18,589][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:06:18,590][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:06:19,331][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 15:06:45,185][root][INFO] - Step: 138/1035  |  Loss: 1.3149  |  Score: 64.83 [%]  |  Seq Length: 256.0
[2024-10-23 15:06:48,283][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:06:48,283][root][INFO] - Score: 76.01 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:06:51,265][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:06:51,265][root][INFO] - Score: 67.22 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:06:51,266][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:06:51,266][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:06:53,062][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:06:53,095][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:06:53,096][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:06:53,096][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:06:53,096][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:06:53,096][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:06:53,097][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:06:54,603][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 15:07:20,443][root][INFO] - Step: 207/1035  |  Loss: 1.0892  |  Score: 71.17 [%]  |  Seq Length: 256.0
[2024-10-23 15:07:23,553][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 15:07:23,554][root][INFO] - Score: 78.08 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:07:26,531][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 15:07:26,531][root][INFO] - Score: 69.41 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:07:26,532][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 15:07:26,532][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:07:28,274][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:07:28,305][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:07:28,306][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:07:28,306][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:07:28,306][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:07:28,306][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:07:28,307][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:07:29,820][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 15:07:55,659][root][INFO] - Step: 276/1035  |  Loss: 0.9436  |  Score: 75.32 [%]  |  Seq Length: 256.0
[2024-10-23 15:07:58,756][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:07:58,757][root][INFO] - Score: 76.22 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:08:01,731][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:08:01,731][root][INFO] - Score: 69.03 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:08:01,733][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 15:08:27,588][root][INFO] - Step: 345/1035  |  Loss: 0.8032  |  Score: 77.78 [%]  |  Seq Length: 256.0
[2024-10-23 15:08:30,690][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:08:30,690][root][INFO] - Score: 77.21 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:08:33,648][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:08:33,648][root][INFO] - Score: 70.15 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 15:08:33,650][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 15:08:59,509][root][INFO] - Step: 414/1035  |  Loss: 0.7027  |  Score: 81.07 [%]  |  Seq Length: 256.0
[2024-10-23 15:09:02,603][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 15:09:02,603][root][INFO] - Score: 79.74 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:09:05,611][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 15:09:05,611][root][INFO] - Score: 71.61 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 15:09:05,612][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 15:09:05,613][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:09:07,329][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:09:07,360][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:09:07,361][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:09:07,361][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:09:07,361][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:09:07,361][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:09:07,362][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:09:08,793][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 15:09:34,713][root][INFO] - Step: 483/1035  |  Loss: 0.6301  |  Score: 83.33 [%]  |  Seq Length: 256.0
[2024-10-23 15:09:37,821][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 15:09:37,821][root][INFO] - Score: 79.65 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:09:40,843][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 15:09:40,843][root][INFO] - Score: 70.10 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 15:09:40,846][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 15:10:06,784][root][INFO] - Step: 552/1035  |  Loss: 0.5646  |  Score: 85.34 [%]  |  Seq Length: 256.0
[2024-10-23 15:10:09,887][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 15:10:09,888][root][INFO] - Score: 78.63 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:10:12,875][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:10:12,876][root][INFO] - Score: 72.03 [%]  |  Evaluation Time: 2.99 [s]
[2024-10-23 15:10:12,878][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:10:20,805][root][INFO] - Step: 6844/8555  |  Loss: 0.2157  |  Score: 91.36 [%]  |  Seq Length: 256.0
[2024-10-23 15:10:38,799][root][INFO] - Step: 621/1035  |  Loss: 0.4767  |  Score: 86.87 [%]  |  Seq Length: 256.0
[2024-10-23 15:10:41,912][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:10:41,913][root][INFO] - Score: 78.74 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:10:44,881][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:10:44,881][root][INFO] - Score: 71.01 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:10:44,883][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 15:10:48,374][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:10:48,374][root][INFO] - Score: 88.74 [%]  |  Evaluation Time: 27.57 [s]
[2024-10-23 15:11:10,817][root][INFO] - Step: 690/1035  |  Loss: 0.4329  |  Score: 88.21 [%]  |  Seq Length: 256.0
[2024-10-23 15:11:13,943][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 15:11:13,943][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 15:11:16,930][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 15:11:16,930][root][INFO] - Score: 70.40 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:11:16,932][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 15:11:43,002][root][INFO] - Step: 759/1035  |  Loss: 0.4191  |  Score: 88.76 [%]  |  Seq Length: 256.0
[2024-10-23 15:11:46,107][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 15:11:46,107][root][INFO] - Score: 78.06 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:11:49,096][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 15:11:49,096][root][INFO] - Score: 71.34 [%]  |  Evaluation Time: 2.99 [s]
[2024-10-23 15:11:49,098][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 15:12:14,977][root][INFO] - Step: 828/1035  |  Loss: 0.3870  |  Score: 89.36 [%]  |  Seq Length: 256.0
[2024-10-23 15:12:18,073][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 15:12:18,074][root][INFO] - Score: 77.77 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:12:19,219][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:12:19,220][root][INFO] - Score: 88.70 [%]  |  Evaluation Time: 90.84 [s]
[2024-10-23 15:12:19,221][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 15:12:19,221][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 15:12:20,951][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:12:20,983][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:12:20,984][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:12:20,984][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:12:20,984][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:12:20,984][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:12:20,985][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:12:21,048][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 15:12:21,078][root][INFO] - Score: 71.15 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:12:21,081][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 15:12:22,480][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 15:12:47,008][root][INFO] - Step: 897/1035  |  Loss: 0.3490  |  Score: 90.01 [%]  |  Seq Length: 256.0
[2024-10-23 15:12:50,103][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 15:12:50,104][root][INFO] - Score: 77.37 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:12:53,056][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 15:12:53,057][root][INFO] - Score: 70.89 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 15:12:53,059][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 15:13:18,965][root][INFO] - Step: 966/1035  |  Loss: 0.3511  |  Score: 90.53 [%]  |  Seq Length: 256.0
[2024-10-23 15:13:22,084][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 15:13:22,084][root][INFO] - Score: 77.47 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 15:13:25,047][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 15:13:25,047][root][INFO] - Score: 71.51 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 15:13:25,049][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 15:13:51,012][root][INFO] - Step: 1035/1035  |  Loss: 0.3426  |  Score: 90.05 [%]  |  Seq Length: 256.0
[2024-10-23 15:13:54,091][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 15:13:54,092][root][INFO] - Score: 77.74 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 15:13:57,063][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 15:13:57,063][root][INFO] - Score: 71.65 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:13:57,064][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:13:57,064][root][INFO] - - Epoch: 6
[2024-10-23 15:13:57,064][root][INFO] - - DEV score: 79.74 [%]
[2024-10-23 15:13:57,064][root][INFO] - - TEST score: 71.61 [%]
[2024-10-23 15:13:57,065][root][INFO] - Fine-tuning is done!
[2024-10-23 15:14:00,249][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,249][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,250][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,250][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,251][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,251][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,252][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,253][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,253][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,254][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,254][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,255][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,255][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,256][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,256][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,257][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,258][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,258][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,259][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,259][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,261][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,261][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,262][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:14:00,262][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:14:00,264][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 15:14:00,266][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:14:00,431][root][INFO] - 

[2024-10-23 15:14:00,431][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 15:14:00,431][root][INFO] - Data Preprocessing
[2024-10-23 15:14:00,431][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 15:14:00,432][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:14:00,432][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:14:00,432][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:14:00,439][root][INFO] - vocab size              : 51200
[2024-10-23 15:14:00,439][root][INFO] - device                  : gpu
[2024-10-23 15:14:00,439][root][INFO] - random seed             : 2
[2024-10-23 15:14:00,439][root][INFO] - train data size         : 4416
[2024-10-23 15:14:00,439][root][INFO] - max epochs              : 15
[2024-10-23 15:14:00,439][root][INFO] - total steps             : 1035
[2024-10-23 15:14:00,439][root][INFO] - warmup steps            : 104
[2024-10-23 15:14:00,439][root][INFO] - batch size              : 64
[2024-10-23 15:14:00,440][root][INFO] - accumulation steps      : 1
[2024-10-23 15:14:00,440][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:14:00,440][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:14:00,440][root][INFO] - learning rate           : 0.02
[2024-10-23 15:14:00,440][root][INFO] - max length              : 256

[2024-10-23 15:14:00,440][root][INFO] - LoRA Configuration
[2024-10-23 15:14:00,440][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:14:00,440][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:14:00,440][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:14:00,440][root][INFO] - 

[2024-10-23 15:14:00,440][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-23 15:14:00,440][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 15:14:00,441][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 15:14:00,441][root][INFO] - * tb interval   : 10000

[2024-10-23 15:14:00,441][root][INFO] - 

[2024-10-23 15:14:00,441][root][INFO] - Start the Training !
[2024-10-23 15:14:00,443][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 15:14:26,336][root][INFO] - Step: 69/1035  |  Loss: 2.0285  |  Score: 42.09 [%]  |  Seq Length: 256.0
[2024-10-23 15:14:29,458][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:14:29,458][root][INFO] - Score: 72.99 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 15:14:32,439][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:14:32,439][root][INFO] - Score: 66.82 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:14:32,440][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:14:32,441][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:14:34,182][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:14:34,212][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:14:34,212][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:14:34,212][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:14:34,212][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:14:34,212][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:14:34,213][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:14:35,663][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 15:15:01,719][root][INFO] - Step: 138/1035  |  Loss: 1.2442  |  Score: 67.39 [%]  |  Seq Length: 256.0
[2024-10-23 15:15:04,821][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:15:04,821][root][INFO] - Score: 76.31 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:15:07,824][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:15:07,825][root][INFO] - Score: 64.97 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 15:15:07,826][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:15:07,826][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:15:09,583][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:15:09,627][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:15:09,628][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:15:09,628][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:15:09,628][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:15:09,629][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:15:09,630][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:15:11,062][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 15:15:37,119][root][INFO] - Step: 207/1035  |  Loss: 1.0246  |  Score: 74.88 [%]  |  Seq Length: 256.0
[2024-10-23 15:15:40,251][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 15:15:40,251][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 3.13 [s]
[2024-10-23 15:15:43,238][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 15:15:43,238][root][INFO] - Score: 70.40 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:15:43,239][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 15:15:43,240][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:15:44,889][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:15:44,930][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:15:44,931][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:15:44,931][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:15:44,931][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:15:44,932][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:15:44,933][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:15:46,378][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 15:16:12,392][root][INFO] - Step: 276/1035  |  Loss: 0.7974  |  Score: 79.34 [%]  |  Seq Length: 256.0
[2024-10-23 15:16:15,513][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:16:15,513][root][INFO] - Score: 76.12 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 15:16:18,539][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:16:18,539][root][INFO] - Score: 70.40 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 15:16:18,542][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 15:16:44,584][root][INFO] - Step: 345/1035  |  Loss: 0.6460  |  Score: 82.21 [%]  |  Seq Length: 256.0
[2024-10-23 15:16:47,743][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:16:47,743][root][INFO] - Score: 76.93 [%]  |  Evaluation Time: 3.16 [s]
[2024-10-23 15:16:50,755][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:16:50,756][root][INFO] - Score: 69.54 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 15:16:50,758][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 15:17:16,882][root][INFO] - Step: 414/1035  |  Loss: 0.5076  |  Score: 86.11 [%]  |  Seq Length: 256.0
[2024-10-23 15:17:20,025][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 15:17:20,025][root][INFO] - Score: 77.92 [%]  |  Evaluation Time: 3.14 [s]
[2024-10-23 15:17:23,032][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 15:17:23,033][root][INFO] - Score: 70.43 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 15:17:23,035][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 15:17:49,092][root][INFO] - Step: 483/1035  |  Loss: 0.4455  |  Score: 88.47 [%]  |  Seq Length: 256.0
[2024-10-23 15:17:52,231][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 15:17:52,231][root][INFO] - Score: 78.61 [%]  |  Evaluation Time: 3.14 [s]
[2024-10-23 15:17:55,239][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 15:17:55,239][root][INFO] - Score: 69.35 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 15:17:55,242][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 15:18:21,294][root][INFO] - Step: 552/1035  |  Loss: 0.3666  |  Score: 90.25 [%]  |  Seq Length: 256.0
[2024-10-23 15:18:24,411][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 15:18:24,411][root][INFO] - Score: 77.62 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:18:27,429][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:18:27,429][root][INFO] - Score: 70.53 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 15:18:27,432][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:18:53,405][root][INFO] - Step: 621/1035  |  Loss: 0.3033  |  Score: 91.92 [%]  |  Seq Length: 256.0
[2024-10-23 15:18:56,516][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:18:56,517][root][INFO] - Score: 78.72 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:18:59,516][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:18:59,517][root][INFO] - Score: 70.40 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 15:18:59,518][root][INFO] - 
Save new Best Score (Epoch: 9)
[2024-10-23 15:18:59,519][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:19:01,087][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:19:01,130][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:19:01,131][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:19:01,131][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:19:01,131][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:19:01,131][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:19:01,132][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:19:02,548][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 15:19:28,494][root][INFO] - Step: 690/1035  |  Loss: 0.2632  |  Score: 92.74 [%]  |  Seq Length: 256.0
[2024-10-23 15:19:31,597][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 15:19:31,597][root][INFO] - Score: 77.09 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:19:34,611][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 15:19:34,612][root][INFO] - Score: 68.52 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 15:19:34,617][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 15:20:00,625][root][INFO] - Step: 759/1035  |  Loss: 0.2369  |  Score: 93.57 [%]  |  Seq Length: 256.0
[2024-10-23 15:20:03,779][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 15:20:03,779][root][INFO] - Score: 78.28 [%]  |  Evaluation Time: 3.15 [s]
[2024-10-23 15:20:06,782][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 15:20:06,783][root][INFO] - Score: 69.98 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 15:20:06,785][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 15:20:32,725][root][INFO] - Step: 828/1035  |  Loss: 0.2180  |  Score: 93.83 [%]  |  Seq Length: 256.0
[2024-10-23 15:20:35,866][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 15:20:35,866][root][INFO] - Score: 78.20 [%]  |  Evaluation Time: 3.14 [s]
[2024-10-23 15:20:38,887][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 15:20:38,888][root][INFO] - Score: 69.62 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 15:20:38,890][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 15:21:04,855][root][INFO] - Step: 897/1035  |  Loss: 0.1882  |  Score: 94.60 [%]  |  Seq Length: 256.0
[2024-10-23 15:21:07,964][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 15:21:07,964][root][INFO] - Score: 77.27 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:21:10,961][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 15:21:10,962][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 2.99 [s]
[2024-10-23 15:21:10,964][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 15:21:36,965][root][INFO] - Step: 966/1035  |  Loss: 0.1835  |  Score: 94.83 [%]  |  Seq Length: 256.0
[2024-10-23 15:21:40,094][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 15:21:40,094][root][INFO] - Score: 77.94 [%]  |  Evaluation Time: 3.13 [s]
[2024-10-23 15:21:43,118][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 15:21:43,118][root][INFO] - Score: 69.74 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 15:21:43,121][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 15:22:05,662][root][INFO] - Step: 70000/73665  |  Loss: 0.5186  |  Score: 79.15 [%]  |  Seq Length: 256.0
[2024-10-23 15:22:09,086][root][INFO] - Step: 1035/1035  |  Loss: 0.1749  |  Score: 94.73 [%]  |  Seq Length: 256.0
[2024-10-23 15:22:12,207][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 15:22:12,207][root][INFO] - Score: 78.13 [%]  |  Evaluation Time: 3.12 [s]
[2024-10-23 15:22:15,206][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 15:22:15,206][root][INFO] - Score: 70.00 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 15:22:15,207][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:22:15,207][root][INFO] - - Epoch: 9
[2024-10-23 15:22:15,207][root][INFO] - - DEV score: 78.72 [%]
[2024-10-23 15:22:15,207][root][INFO] - - TEST score: 70.40 [%]
[2024-10-23 15:22:15,209][root][INFO] - Fine-tuning is done!
[2024-10-23 15:22:15,210][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 15:22:15,210][root][INFO] - - BEST LR: 0.01
[2024-10-23 15:22:15,210][root][INFO] - - DEV score: 79.74 [%]
[2024-10-23 15:22:15,210][root][INFO] - - TEST score: 71.61 [%]
[2024-10-23 15:22:21,688][root][INFO] - 

[2024-10-23 15:22:21,688][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 15:22:21,688][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-23 15:22:21,688][root][INFO] - 

[2024-10-23 15:22:21,688][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 15:22:26,361][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,362][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,362][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,363][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,363][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,364][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,364][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,365][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,365][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,366][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,367][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,367][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,368][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,368][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,369][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,369][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,370][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,370][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,371][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,371][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,372][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,373][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,373][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:22:26,374][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:22:26,375][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 15:22:26,379][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 15:22:26,598][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 15:22:26,601][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 15:22:26,781][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:22:30,310][root][INFO] - 

[2024-10-23 15:22:30,310][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 15:22:30,310][root][INFO] - Data Preprocessing
[2024-10-23 15:22:30,311][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 15:22:30,311][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:22:30,311][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:22:30,311][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:22:30,321][root][INFO] - vocab size              : 51200
[2024-10-23 15:22:30,321][root][INFO] - device                  : gpu
[2024-10-23 15:22:30,321][root][INFO] - random seed             : 2
[2024-10-23 15:22:30,321][root][INFO] - train data size         : 4416
[2024-10-23 15:22:30,321][root][INFO] - max epochs              : 15
[2024-10-23 15:22:30,321][root][INFO] - total steps             : 1035
[2024-10-23 15:22:30,321][root][INFO] - warmup steps            : 104
[2024-10-23 15:22:30,321][root][INFO] - batch size              : 64
[2024-10-23 15:22:30,321][root][INFO] - accumulation steps      : 1
[2024-10-23 15:22:30,322][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:22:30,322][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:22:30,322][root][INFO] - learning rate           : 0.01
[2024-10-23 15:22:30,322][root][INFO] - max length              : 256

[2024-10-23 15:22:30,322][root][INFO] - LoRA Configuration
[2024-10-23 15:22:30,322][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:22:30,322][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:22:30,322][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:22:30,322][root][INFO] - KOMBO Configuration
[2024-10-23 15:22:30,322][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 15:22:30,323][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 15:22:30,323][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 15:22:30,323][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 15:22:30,323][root][INFO] - ㄴ do_combination       : True
[2024-10-23 15:22:30,323][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 15:22:30,323][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 15:22:30,323][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 15:22:30,323][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 15:22:30,323][root][INFO] - 

[2024-10-23 15:22:30,324][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-23 15:22:30,324][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 15:22:30,324][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 15:22:30,324][root][INFO] - * tb interval   : 10000

[2024-10-23 15:22:30,324][root][INFO] - 

[2024-10-23 15:22:30,324][root][INFO] - Start the Training !
[2024-10-23 15:22:30,327][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 15:22:50,281][root][INFO] - Step: 8555/8555  |  Loss: 0.1926  |  Score: 92.36 [%]  |  Seq Length: 256.0
[2024-10-23 15:23:07,519][root][INFO] - Step: 69/1035  |  Loss: 2.2343  |  Score: 33.98 [%]  |  Seq Length: 256.0
[2024-10-23 15:23:12,533][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:23:12,533][root][INFO] - Score: 71.39 [%]  |  Evaluation Time: 5.01 [s]
[2024-10-23 15:23:17,220][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:23:17,220][root][INFO] - Score: 64.23 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-23 15:23:17,222][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:23:17,222][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:23:17,227][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:23:17,958][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:23:17,958][root][INFO] - Score: 89.04 [%]  |  Evaluation Time: 27.67 [s]
[2024-10-23 15:23:18,129][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:23:18,261][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:23:18,261][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:23:18,261][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:23:18,261][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:23:18,262][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:23:18,263][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:23:19,075][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 15:23:55,784][root][INFO] - Step: 138/1035  |  Loss: 1.2964  |  Score: 65.52 [%]  |  Seq Length: 256.0
[2024-10-23 15:24:00,765][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:24:00,766][root][INFO] - Score: 76.40 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-23 15:24:05,492][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:24:05,492][root][INFO] - Score: 68.10 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-23 15:24:05,493][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:24:05,494][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:24:05,497][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:24:07,243][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:24:07,499][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:24:07,522][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:24:07,523][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:24:07,523][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:24:07,523][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:24:07,527][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:24:09,235][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 15:24:45,991][root][INFO] - Step: 207/1035  |  Loss: 1.0796  |  Score: 70.34 [%]  |  Seq Length: 256.0
[2024-10-23 15:24:48,814][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:24:48,815][root][INFO] - Score: 88.74 [%]  |  Evaluation Time: 90.85 [s]
[2024-10-23 15:24:48,816][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 15:24:48,816][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 15:24:50,340][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:24:50,378][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:24:50,379][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:24:50,379][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:24:50,379][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:24:50,379][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:24:50,380][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:24:50,925][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 15:24:50,926][root][INFO] - Score: 77.36 [%]  |  Evaluation Time: 4.93 [s]
[2024-10-23 15:24:51,831][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:24:51,831][root][INFO] - - Epoch: 5
[2024-10-23 15:24:51,831][root][INFO] - - DEV score: 89.04 [%]
[2024-10-23 15:24:51,831][root][INFO] - - TEST score: 88.74 [%]
[2024-10-23 15:24:51,833][root][INFO] - Fine-tuning is done!
[2024-10-23 15:24:55,658][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 15:24:55,659][root][INFO] - Score: 68.88 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-23 15:24:55,660][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 15:24:55,660][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:24:55,663][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:24:57,357][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:24:57,664][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:24:57,665][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:24:57,665][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:24:57,665][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:24:57,666][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:24:57,669][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:24:59,326][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 15:25:09,360][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,360][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,361][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,361][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,362][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,362][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,363][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,363][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,364][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,364][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,365][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,365][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,366][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,366][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,367][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,367][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,368][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,368][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,369][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,369][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,370][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,370][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,371][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:25:09,371][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:25:09,373][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 15:25:09,375][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:25:09,547][root][INFO] - 

[2024-10-23 15:25:09,547][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 15:25:09,547][root][INFO] - Data Preprocessing
[2024-10-23 15:25:09,547][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 15:25:09,547][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:25:09,547][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:25:09,548][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:25:09,555][root][INFO] - vocab size              : 51200
[2024-10-23 15:25:09,555][root][INFO] - device                  : gpu
[2024-10-23 15:25:09,555][root][INFO] - random seed             : 1
[2024-10-23 15:25:09,555][root][INFO] - train data size         : 109504
[2024-10-23 15:25:09,556][root][INFO] - max epochs              : 5
[2024-10-23 15:25:09,556][root][INFO] - total steps             : 8555
[2024-10-23 15:25:09,556][root][INFO] - warmup steps            : 856
[2024-10-23 15:25:09,556][root][INFO] - batch size              : 64
[2024-10-23 15:25:09,556][root][INFO] - accumulation steps      : 1
[2024-10-23 15:25:09,556][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:25:09,556][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:25:09,556][root][INFO] - learning rate           : 0.02
[2024-10-23 15:25:09,556][root][INFO] - max length              : 256

[2024-10-23 15:25:09,556][root][INFO] - LoRA Configuration
[2024-10-23 15:25:09,556][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:25:09,556][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:25:09,557][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:25:09,557][root][INFO] - 

[2024-10-23 15:25:09,557][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 15:25:09,557][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 15:25:09,557][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 15:25:09,557][root][INFO] - * tb interval   : 10000

[2024-10-23 15:25:09,557][root][INFO] - 

[2024-10-23 15:25:09,557][root][INFO] - Start the Training !
[2024-10-23 15:25:09,559][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 15:25:35,939][root][INFO] - Step: 276/1035  |  Loss: 0.9099  |  Score: 75.44 [%]  |  Seq Length: 256.0
[2024-10-23 15:25:40,844][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:25:40,845][root][INFO] - Score: 79.17 [%]  |  Evaluation Time: 4.90 [s]
[2024-10-23 15:25:45,440][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:25:45,441][root][INFO] - Score: 71.22 [%]  |  Evaluation Time: 4.59 [s]
[2024-10-23 15:25:45,442][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 15:25:45,442][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:25:45,445][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:25:47,147][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:25:47,453][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:25:47,454][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:25:47,455][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:25:47,455][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:25:47,455][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:25:47,458][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:25:49,152][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 15:26:25,815][root][INFO] - Step: 345/1035  |  Loss: 0.8433  |  Score: 78.77 [%]  |  Seq Length: 256.0
[2024-10-23 15:26:30,732][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:26:30,732][root][INFO] - Score: 77.55 [%]  |  Evaluation Time: 4.91 [s]
[2024-10-23 15:26:35,397][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:26:35,397][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 15:26:35,400][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 15:27:12,075][root][INFO] - Step: 414/1035  |  Loss: 0.6869  |  Score: 80.73 [%]  |  Seq Length: 256.0
[2024-10-23 15:27:17,029][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 15:27:17,029][root][INFO] - Score: 79.19 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:27:21,682][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 15:27:21,682][root][INFO] - Score: 72.09 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-23 15:27:21,683][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 15:27:21,684][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:27:21,686][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:27:23,408][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:27:23,694][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:27:23,695][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:27:23,695][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:27:23,695][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:27:23,696][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:27:23,699][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:27:25,379][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 15:28:02,068][root][INFO] - Step: 483/1035  |  Loss: 0.6537  |  Score: 83.42 [%]  |  Seq Length: 256.0
[2024-10-23 15:28:07,041][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 15:28:07,041][root][INFO] - Score: 78.14 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-23 15:28:11,722][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 15:28:11,723][root][INFO] - Score: 71.55 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-23 15:28:11,725][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 15:28:48,653][root][INFO] - Step: 552/1035  |  Loss: 0.5833  |  Score: 84.99 [%]  |  Seq Length: 256.0
[2024-10-23 15:28:53,604][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 15:28:53,604][root][INFO] - Score: 79.78 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:28:58,276][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:28:58,276][root][INFO] - Score: 71.10 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 15:28:58,278][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:29:35,146][root][INFO] - Step: 621/1035  |  Loss: 0.4828  |  Score: 86.45 [%]  |  Seq Length: 256.0
[2024-10-23 15:29:40,091][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:29:40,091][root][INFO] - Score: 78.12 [%]  |  Evaluation Time: 4.94 [s]
[2024-10-23 15:29:44,747][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:29:44,748][root][INFO] - Score: 72.20 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-23 15:29:44,750][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 15:30:21,574][root][INFO] - Step: 690/1035  |  Loss: 0.4385  |  Score: 88.27 [%]  |  Seq Length: 256.0
[2024-10-23 15:30:26,506][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 15:30:26,506][root][INFO] - Score: 77.90 [%]  |  Evaluation Time: 4.93 [s]
[2024-10-23 15:30:31,140][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 15:30:31,140][root][INFO] - Score: 71.95 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 15:30:31,142][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 15:31:07,824][root][INFO] - Step: 759/1035  |  Loss: 0.4118  |  Score: 88.68 [%]  |  Seq Length: 256.0
[2024-10-23 15:31:12,744][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 15:31:12,744][root][INFO] - Score: 78.05 [%]  |  Evaluation Time: 4.92 [s]
[2024-10-23 15:31:17,379][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 15:31:17,379][root][INFO] - Score: 70.96 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 15:31:17,382][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 15:31:54,183][root][INFO] - Step: 828/1035  |  Loss: 0.3862  |  Score: 89.19 [%]  |  Seq Length: 256.0
[2024-10-23 15:31:59,221][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 15:31:59,222][root][INFO] - Score: 78.65 [%]  |  Evaluation Time: 5.04 [s]
[2024-10-23 15:32:03,857][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 15:32:03,858][root][INFO] - Score: 71.57 [%]  |  Evaluation Time: 4.63 [s]
[2024-10-23 15:32:03,861][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 15:32:40,751][root][INFO] - Step: 897/1035  |  Loss: 0.3516  |  Score: 90.15 [%]  |  Seq Length: 256.0
[2024-10-23 15:32:45,703][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 15:32:45,703][root][INFO] - Score: 79.24 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:32:50,388][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 15:32:50,388][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-23 15:32:50,391][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 15:33:27,231][root][INFO] - Step: 966/1035  |  Loss: 0.3555  |  Score: 90.05 [%]  |  Seq Length: 256.0
[2024-10-23 15:33:32,188][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 15:33:32,188][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:33:36,882][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 15:33:36,882][root][INFO] - Score: 72.22 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-23 15:33:36,885][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 15:34:13,595][root][INFO] - Step: 1035/1035  |  Loss: 0.3324  |  Score: 90.52 [%]  |  Seq Length: 256.0
[2024-10-23 15:34:18,547][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 15:34:18,548][root][INFO] - Score: 78.78 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:34:23,303][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 15:34:23,304][root][INFO] - Score: 72.23 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-23 15:34:23,305][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:34:23,305][root][INFO] - - Epoch: 6
[2024-10-23 15:34:23,305][root][INFO] - - DEV score: 79.19 [%]
[2024-10-23 15:34:23,305][root][INFO] - - TEST score: 72.09 [%]
[2024-10-23 15:34:23,306][root][INFO] - Fine-tuning is done!
[2024-10-23 15:34:26,491][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,492][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,492][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,493][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,494][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,494][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,495][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,495][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,496][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,496][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,497][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,497][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,498][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,499][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,499][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,500][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,500][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,501][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,501][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,502][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,503][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,503][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,504][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:34:26,504][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:34:26,506][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 15:34:26,717][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 15:34:26,720][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 15:34:26,721][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:34:26,887][root][INFO] - 

[2024-10-23 15:34:26,887][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 15:34:26,887][root][INFO] - Data Preprocessing
[2024-10-23 15:34:26,887][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 15:34:26,887][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:34:26,888][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:34:26,888][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:34:26,894][root][INFO] - vocab size              : 51200
[2024-10-23 15:34:26,895][root][INFO] - device                  : gpu
[2024-10-23 15:34:26,895][root][INFO] - random seed             : 2
[2024-10-23 15:34:26,895][root][INFO] - train data size         : 4416
[2024-10-23 15:34:26,895][root][INFO] - max epochs              : 15
[2024-10-23 15:34:26,895][root][INFO] - total steps             : 1035
[2024-10-23 15:34:26,895][root][INFO] - warmup steps            : 104
[2024-10-23 15:34:26,895][root][INFO] - batch size              : 64
[2024-10-23 15:34:26,895][root][INFO] - accumulation steps      : 1
[2024-10-23 15:34:26,895][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:34:26,895][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:34:26,896][root][INFO] - learning rate           : 0.02
[2024-10-23 15:34:26,896][root][INFO] - max length              : 256

[2024-10-23 15:34:26,896][root][INFO] - LoRA Configuration
[2024-10-23 15:34:26,896][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:34:26,896][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:34:26,896][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:34:26,896][root][INFO] - KOMBO Configuration
[2024-10-23 15:34:26,896][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 15:34:26,896][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 15:34:26,896][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 15:34:26,896][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 15:34:26,897][root][INFO] - ㄴ do_combination       : True
[2024-10-23 15:34:26,897][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 15:34:26,897][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 15:34:26,897][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 15:34:26,897][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 15:34:26,897][root][INFO] - 

[2024-10-23 15:34:26,897][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs
[2024-10-23 15:34:26,897][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 15:34:26,897][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 15:34:26,897][root][INFO] - * tb interval   : 10000

[2024-10-23 15:34:26,897][root][INFO] - 

[2024-10-23 15:34:26,898][root][INFO] - Start the Training !
[2024-10-23 15:34:26,900][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 15:35:03,569][root][INFO] - Step: 69/1035  |  Loss: 1.9943  |  Score: 43.46 [%]  |  Seq Length: 256.0
[2024-10-23 15:35:08,604][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:35:08,604][root][INFO] - Score: 74.58 [%]  |  Evaluation Time: 5.03 [s]
[2024-10-23 15:35:13,324][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:35:13,324][root][INFO] - Score: 67.09 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-23 15:35:13,325][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:35:13,326][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:35:13,329][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:35:14,945][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:35:15,250][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:35:15,251][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:35:15,252][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:35:15,252][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:35:15,252][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:35:15,255][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:35:16,914][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 15:35:37,112][root][INFO] - Step: 1711/8555  |  Loss: 0.3667  |  Score: 83.79 [%]  |  Seq Length: 256.0
[2024-10-23 15:35:52,660][root][INFO] - Step: 138/1035  |  Loss: 1.2441  |  Score: 67.59 [%]  |  Seq Length: 256.0
[2024-10-23 15:35:57,664][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:35:57,664][root][INFO] - Score: 77.36 [%]  |  Evaluation Time: 5.00 [s]
[2024-10-23 15:36:02,339][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:36:02,339][root][INFO] - Score: 68.29 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 15:36:02,340][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:36:02,341][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:36:02,343][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:36:04,052][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:36:04,350][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:36:04,351][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:36:04,352][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:36:04,352][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:36:04,352][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:36:04,355][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:36:04,811][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:36:04,812][root][INFO] - Score: 86.41 [%]  |  Evaluation Time: 27.70 [s]
[2024-10-23 15:36:06,016][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 15:36:42,830][root][INFO] - Step: 207/1035  |  Loss: 1.0568  |  Score: 72.57 [%]  |  Seq Length: 256.0
[2024-10-23 15:36:47,784][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 15:36:47,784][root][INFO] - Score: 76.92 [%]  |  Evaluation Time: 4.95 [s]
[2024-10-23 15:36:52,456][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 15:36:52,456][root][INFO] - Score: 69.77 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 15:36:52,457][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 15:36:52,457][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:36:52,460][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:36:54,197][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:36:54,495][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:36:54,496][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:36:54,496][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:36:54,496][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:36:54,496][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:36:54,497][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:36:56,173][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 15:37:33,025][root][INFO] - Step: 276/1035  |  Loss: 0.7927  |  Score: 79.02 [%]  |  Seq Length: 256.0
[2024-10-23 15:37:35,773][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:37:35,773][root][INFO] - Score: 86.30 [%]  |  Evaluation Time: 90.96 [s]
[2024-10-23 15:37:35,775][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:37:35,775][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 15:37:37,445][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:37:37,479][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:37:37,479][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:37:37,480][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:37:37,480][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:37:37,480][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:37:37,481][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:37:38,018][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:37:38,018][root][INFO] - Score: 78.79 [%]  |  Evaluation Time: 4.99 [s]
[2024-10-23 15:37:38,863][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 15:37:42,694][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:37:42,694][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 15:37:42,695][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 15:37:42,696][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:37:42,698][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:37:44,415][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:37:44,702][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:37:44,704][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:37:44,704][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:37:44,704][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:37:44,704][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:37:44,707][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:37:46,368][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 15:38:23,070][root][INFO] - Step: 345/1035  |  Loss: 0.6667  |  Score: 83.15 [%]  |  Seq Length: 256.0
[2024-10-23 15:38:27,968][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:38:27,968][root][INFO] - Score: 77.49 [%]  |  Evaluation Time: 4.90 [s]
[2024-10-23 15:38:32,583][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:38:32,583][root][INFO] - Score: 70.79 [%]  |  Evaluation Time: 4.61 [s]
[2024-10-23 15:38:32,585][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 15:39:09,447][root][INFO] - Step: 414/1035  |  Loss: 0.5284  |  Score: 85.76 [%]  |  Seq Length: 256.0
[2024-10-23 15:39:14,468][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 15:39:14,468][root][INFO] - Score: 78.08 [%]  |  Evaluation Time: 5.02 [s]
[2024-10-23 15:39:19,124][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 15:39:19,124][root][INFO] - Score: 70.69 [%]  |  Evaluation Time: 4.65 [s]
[2024-10-23 15:39:19,126][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 15:39:56,087][root][INFO] - Step: 483/1035  |  Loss: 0.4649  |  Score: 88.39 [%]  |  Seq Length: 256.0
[2024-10-23 15:40:01,169][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 15:40:01,170][root][INFO] - Score: 76.81 [%]  |  Evaluation Time: 5.08 [s]
[2024-10-23 15:40:05,879][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 15:40:05,879][root][INFO] - Score: 69.48 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-23 15:40:05,882][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 15:40:42,791][root][INFO] - Step: 552/1035  |  Loss: 0.3836  |  Score: 89.69 [%]  |  Seq Length: 256.0
[2024-10-23 15:40:47,791][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 15:40:47,791][root][INFO] - Score: 78.54 [%]  |  Evaluation Time: 5.00 [s]
[2024-10-23 15:40:52,510][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:40:52,510][root][INFO] - Score: 69.83 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-23 15:40:52,512][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:41:29,335][root][INFO] - Step: 621/1035  |  Loss: 0.3026  |  Score: 91.75 [%]  |  Seq Length: 256.0
[2024-10-23 15:41:34,316][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:41:34,316][root][INFO] - Score: 77.70 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-23 15:41:39,067][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:41:39,067][root][INFO] - Score: 70.59 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-23 15:41:39,070][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 15:42:16,035][root][INFO] - Step: 690/1035  |  Loss: 0.2722  |  Score: 92.58 [%]  |  Seq Length: 256.0
[2024-10-23 15:42:21,059][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 15:42:21,059][root][INFO] - Score: 77.89 [%]  |  Evaluation Time: 5.02 [s]
[2024-10-23 15:42:25,797][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 15:42:25,797][root][INFO] - Score: 69.54 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 15:42:25,800][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 15:43:02,751][root][INFO] - Step: 759/1035  |  Loss: 0.2286  |  Score: 93.64 [%]  |  Seq Length: 256.0
[2024-10-23 15:43:07,781][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 15:43:07,781][root][INFO] - Score: 78.31 [%]  |  Evaluation Time: 5.03 [s]
[2024-10-23 15:43:12,554][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 15:43:12,554][root][INFO] - Score: 70.42 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-23 15:43:12,557][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 15:43:49,568][root][INFO] - Step: 828/1035  |  Loss: 0.2122  |  Score: 93.89 [%]  |  Seq Length: 256.0
[2024-10-23 15:43:54,587][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 15:43:54,588][root][INFO] - Score: 78.49 [%]  |  Evaluation Time: 5.02 [s]
[2024-10-23 15:43:59,283][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 15:43:59,284][root][INFO] - Score: 69.63 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-23 15:43:59,285][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 15:44:36,127][root][INFO] - Step: 897/1035  |  Loss: 0.1909  |  Score: 94.64 [%]  |  Seq Length: 256.0
[2024-10-23 15:44:41,188][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 15:44:41,188][root][INFO] - Score: 79.36 [%]  |  Evaluation Time: 5.06 [s]
[2024-10-23 15:44:45,893][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 15:44:45,894][root][INFO] - Score: 69.85 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-23 15:44:45,896][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 15:45:22,788][root][INFO] - Step: 966/1035  |  Loss: 0.1915  |  Score: 94.57 [%]  |  Seq Length: 256.0
[2024-10-23 15:45:27,773][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 15:45:27,774][root][INFO] - Score: 78.42 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-23 15:45:32,477][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 15:45:32,477][root][INFO] - Score: 70.87 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-23 15:45:32,479][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 15:46:09,397][root][INFO] - Step: 1035/1035  |  Loss: 0.1713  |  Score: 94.93 [%]  |  Seq Length: 256.0
[2024-10-23 15:46:14,411][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 15:46:14,411][root][INFO] - Score: 79.22 [%]  |  Evaluation Time: 5.01 [s]
[2024-10-23 15:46:19,114][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 15:46:19,115][root][INFO] - Score: 70.45 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-23 15:46:19,116][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:46:19,116][root][INFO] - - Epoch: 4
[2024-10-23 15:46:19,116][root][INFO] - - DEV score: 78.79 [%]
[2024-10-23 15:46:19,116][root][INFO] - - TEST score: 71.11 [%]
[2024-10-23 15:46:19,117][root][INFO] - Fine-tuning is done!
[2024-10-23 15:46:19,118][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 15:46:19,118][root][INFO] - - BEST LR: 0.01
[2024-10-23 15:46:19,118][root][INFO] - - DEV score: 79.19 [%]
[2024-10-23 15:46:19,118][root][INFO] - - TEST score: 72.09 [%]
[2024-10-23 15:46:25,496][root][INFO] - 

[2024-10-23 15:46:25,496][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 15:46:25,496][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs
[2024-10-23 15:46:25,496][root][INFO] - 

[2024-10-23 15:46:25,496][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 15:46:30,051][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,052][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,053][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,053][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,054][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,054][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,055][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,055][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,056][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,056][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,057][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,057][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,058][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,058][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,059][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,059][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,060][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,060][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,061][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,061][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,068][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,069][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,069][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:46:30,070][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:46:30,072][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 15:46:30,243][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:46:32,456][root][INFO] - 

[2024-10-23 15:46:32,456][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 15:46:32,457][root][INFO] - Data Preprocessing
[2024-10-23 15:46:32,457][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 15:46:32,457][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:46:32,457][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:46:32,457][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:46:32,467][root][INFO] - vocab size              : 51200
[2024-10-23 15:46:32,468][root][INFO] - device                  : gpu
[2024-10-23 15:46:32,468][root][INFO] - random seed             : 3
[2024-10-23 15:46:32,468][root][INFO] - train data size         : 4416
[2024-10-23 15:46:32,468][root][INFO] - max epochs              : 15
[2024-10-23 15:46:32,468][root][INFO] - total steps             : 1035
[2024-10-23 15:46:32,468][root][INFO] - warmup steps            : 104
[2024-10-23 15:46:32,468][root][INFO] - batch size              : 64
[2024-10-23 15:46:32,468][root][INFO] - accumulation steps      : 1
[2024-10-23 15:46:32,468][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:46:32,468][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:46:32,469][root][INFO] - learning rate           : 0.01
[2024-10-23 15:46:32,469][root][INFO] - max length              : 256

[2024-10-23 15:46:32,469][root][INFO] - LoRA Configuration
[2024-10-23 15:46:32,469][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:46:32,469][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:46:32,469][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:46:32,469][root][INFO] - 

[2024-10-23 15:46:32,469][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs
[2024-10-23 15:46:32,469][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 15:46:32,469][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 15:46:32,469][root][INFO] - * tb interval   : 10000

[2024-10-23 15:46:32,470][root][INFO] - 

[2024-10-23 15:46:32,470][root][INFO] - Start the Training !
[2024-10-23 15:46:32,472][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 15:46:59,490][root][INFO] - Step: 69/1035  |  Loss: 2.6863  |  Score: 26.23 [%]  |  Seq Length: 256.0
[2024-10-23 15:47:02,513][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:47:02,513][root][INFO] - Score: 71.33 [%]  |  Evaluation Time: 3.02 [s]
[2024-10-23 15:47:05,403][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:47:05,403][root][INFO] - Score: 61.24 [%]  |  Evaluation Time: 2.89 [s]
[2024-10-23 15:47:05,404][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:47:05,405][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:47:06,261][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:47:06,287][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:47:06,287][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:47:06,287][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:47:06,288][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:47:06,288][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:47:06,289][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:47:06,968][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 15:47:32,820][root][INFO] - Step: 138/1035  |  Loss: 1.3546  |  Score: 64.95 [%]  |  Seq Length: 256.0
[2024-10-23 15:47:35,865][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:47:35,865][root][INFO] - Score: 74.66 [%]  |  Evaluation Time: 3.04 [s]
[2024-10-23 15:47:38,774][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:47:38,775][root][INFO] - Score: 66.64 [%]  |  Evaluation Time: 2.91 [s]
[2024-10-23 15:47:38,776][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:47:38,776][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:47:40,400][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:47:40,449][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:47:40,450][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:47:40,450][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:47:40,450][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:47:40,450][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:47:40,451][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:47:41,906][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 15:48:07,504][root][INFO] - Step: 3422/8555  |  Loss: 0.3106  |  Score: 86.75 [%]  |  Seq Length: 256.0
[2024-10-23 15:48:07,811][root][INFO] - Step: 207/1035  |  Loss: 1.1067  |  Score: 69.91 [%]  |  Seq Length: 256.0
[2024-10-23 15:48:10,894][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 15:48:10,894][root][INFO] - Score: 76.74 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 15:48:13,834][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 15:48:13,834][root][INFO] - Score: 70.96 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 15:48:13,836][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 15:48:13,836][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:48:15,353][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:48:15,395][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:48:15,396][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:48:15,396][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:48:15,396][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:48:15,396][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:48:15,397][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:48:16,870][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 15:48:35,313][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:48:35,313][root][INFO] - Score: 86.53 [%]  |  Evaluation Time: 27.81 [s]
[2024-10-23 15:48:42,759][root][INFO] - Step: 276/1035  |  Loss: 0.9287  |  Score: 74.38 [%]  |  Seq Length: 256.0
[2024-10-23 15:48:45,801][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:48:45,801][root][INFO] - Score: 77.56 [%]  |  Evaluation Time: 3.04 [s]
[2024-10-23 15:48:48,767][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:48:48,767][root][INFO] - Score: 73.08 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 15:48:48,768][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 15:48:48,769][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:48:50,454][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:48:50,504][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:48:50,505][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:48:50,505][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:48:50,505][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:48:50,506][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:48:50,507][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:48:51,964][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 15:49:17,872][root][INFO] - Step: 345/1035  |  Loss: 0.8280  |  Score: 78.07 [%]  |  Seq Length: 256.0
[2024-10-23 15:49:20,946][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:49:20,946][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 15:49:23,918][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:49:23,918][root][INFO] - Score: 71.46 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:49:23,921][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 15:49:49,733][root][INFO] - Step: 414/1035  |  Loss: 0.7144  |  Score: 80.98 [%]  |  Seq Length: 256.0
[2024-10-23 15:49:52,797][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 15:49:52,798][root][INFO] - Score: 79.16 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 15:49:55,727][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 15:49:55,727][root][INFO] - Score: 71.60 [%]  |  Evaluation Time: 2.93 [s]
[2024-10-23 15:49:55,728][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 15:49:55,729][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:49:57,268][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:49:57,300][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:49:57,300][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:49:57,301][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:49:57,301][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:49:57,301][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:49:57,302][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:49:58,723][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 15:50:06,389][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:50:06,389][root][INFO] - Score: 86.49 [%]  |  Evaluation Time: 91.07 [s]
[2024-10-23 15:50:06,391][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:50:06,391][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 15:50:07,935][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:50:07,972][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:50:07,973][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:50:07,973][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:50:07,973][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:50:07,973][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:50:07,974][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:50:09,511][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 15:50:24,587][root][INFO] - Step: 483/1035  |  Loss: 0.6042  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-23 15:50:27,692][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 15:50:27,692][root][INFO] - Score: 77.42 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:50:30,637][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 15:50:30,638][root][INFO] - Score: 70.51 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 15:50:30,640][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 15:50:56,500][root][INFO] - Step: 552/1035  |  Loss: 0.5572  |  Score: 84.79 [%]  |  Seq Length: 256.0
[2024-10-23 15:50:59,616][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 15:50:59,616][root][INFO] - Score: 79.34 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:51:02,548][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:51:02,548][root][INFO] - Score: 71.81 [%]  |  Evaluation Time: 2.93 [s]
[2024-10-23 15:51:02,549][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 15:51:02,550][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:51:04,070][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:51:04,111][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:51:04,112][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:51:04,112][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:51:04,112][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:51:04,112][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:51:04,113][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:51:05,558][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:51:31,405][root][INFO] - Step: 621/1035  |  Loss: 0.4983  |  Score: 86.18 [%]  |  Seq Length: 256.0
[2024-10-23 15:51:34,455][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:51:34,455][root][INFO] - Score: 78.54 [%]  |  Evaluation Time: 3.05 [s]
[2024-10-23 15:51:37,398][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:51:37,398][root][INFO] - Score: 71.14 [%]  |  Evaluation Time: 2.94 [s]
[2024-10-23 15:51:37,401][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 15:52:03,285][root][INFO] - Step: 690/1035  |  Loss: 0.4670  |  Score: 87.37 [%]  |  Seq Length: 256.0
[2024-10-23 15:52:06,344][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 15:52:06,344][root][INFO] - Score: 78.47 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 15:52:09,263][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 15:52:09,263][root][INFO] - Score: 71.07 [%]  |  Evaluation Time: 2.92 [s]
[2024-10-23 15:52:09,265][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 15:52:35,098][root][INFO] - Step: 759/1035  |  Loss: 0.4012  |  Score: 88.70 [%]  |  Seq Length: 256.0
[2024-10-23 15:52:38,160][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 15:52:38,160][root][INFO] - Score: 78.97 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 15:52:41,090][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 15:52:41,090][root][INFO] - Score: 70.84 [%]  |  Evaluation Time: 2.93 [s]
[2024-10-23 15:52:41,093][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 15:53:06,968][root][INFO] - Step: 828/1035  |  Loss: 0.3819  |  Score: 89.01 [%]  |  Seq Length: 256.0
[2024-10-23 15:53:10,019][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 15:53:10,019][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 3.05 [s]
[2024-10-23 15:53:12,947][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 15:53:12,947][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 2.93 [s]
[2024-10-23 15:53:12,952][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 15:53:38,815][root][INFO] - Step: 897/1035  |  Loss: 0.3629  |  Score: 89.54 [%]  |  Seq Length: 256.0
[2024-10-23 15:53:41,892][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 15:53:41,893][root][INFO] - Score: 78.38 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 15:53:44,842][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 15:53:44,842][root][INFO] - Score: 71.40 [%]  |  Evaluation Time: 2.95 [s]
[2024-10-23 15:53:44,844][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 15:54:10,690][root][INFO] - Step: 966/1035  |  Loss: 0.3613  |  Score: 89.61 [%]  |  Seq Length: 256.0
[2024-10-23 15:54:13,760][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 15:54:13,761][root][INFO] - Score: 77.96 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 15:54:16,769][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 15:54:16,770][root][INFO] - Score: 71.32 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 15:54:16,772][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 15:54:42,631][root][INFO] - Step: 1035/1035  |  Loss: 0.3520  |  Score: 89.66 [%]  |  Seq Length: 256.0
[2024-10-23 15:54:45,705][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 15:54:45,705][root][INFO] - Score: 78.60 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 15:54:48,757][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 15:54:48,757][root][INFO] - Score: 71.17 [%]  |  Evaluation Time: 3.05 [s]
[2024-10-23 15:54:48,758][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:54:48,758][root][INFO] - - Epoch: 8
[2024-10-23 15:54:48,758][root][INFO] - - DEV score: 79.34 [%]
[2024-10-23 15:54:48,758][root][INFO] - - TEST score: 71.81 [%]
[2024-10-23 15:54:48,759][root][INFO] - Fine-tuning is done!
[2024-10-23 15:54:52,017][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,017][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,018][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,018][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,019][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,020][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,020][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,020][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,021][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,021][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,022][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,022][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,023][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,023][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,024][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,024][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,025][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,025][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,026][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,026][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,027][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,027][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,028][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:54:52,028][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:54:52,030][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 15:54:52,032][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:54:52,188][root][INFO] - 

[2024-10-23 15:54:52,188][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 15:54:52,188][root][INFO] - Data Preprocessing
[2024-10-23 15:54:52,188][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 15:54:52,188][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:54:52,189][root][INFO] - ㄴ data_remove                True

[2024-10-23 15:54:52,189][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:54:52,197][root][INFO] - vocab size              : 51200
[2024-10-23 15:54:52,197][root][INFO] - device                  : gpu
[2024-10-23 15:54:52,197][root][INFO] - random seed             : 3
[2024-10-23 15:54:52,197][root][INFO] - train data size         : 4416
[2024-10-23 15:54:52,197][root][INFO] - max epochs              : 15
[2024-10-23 15:54:52,197][root][INFO] - total steps             : 1035
[2024-10-23 15:54:52,197][root][INFO] - warmup steps            : 104
[2024-10-23 15:54:52,197][root][INFO] - batch size              : 64
[2024-10-23 15:54:52,198][root][INFO] - accumulation steps      : 1
[2024-10-23 15:54:52,198][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:54:52,198][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:54:52,198][root][INFO] - learning rate           : 0.02
[2024-10-23 15:54:52,198][root][INFO] - max length              : 256

[2024-10-23 15:54:52,198][root][INFO] - LoRA Configuration
[2024-10-23 15:54:52,198][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:54:52,198][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:54:52,198][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:54:52,198][root][INFO] - 

[2024-10-23 15:54:52,199][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs
[2024-10-23 15:54:52,199][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 15:54:52,199][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 15:54:52,199][root][INFO] - * tb interval   : 10000

[2024-10-23 15:54:52,199][root][INFO] - 

[2024-10-23 15:54:52,199][root][INFO] - Start the Training !
[2024-10-23 15:54:52,201][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 15:54:55,016][root][INFO] - Step: 73665/73665  |  Loss: 0.5207  |  Score: 79.04 [%]  |  Seq Length: 256.0
[2024-10-23 15:55:05,705][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:55:05,705][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 10.69 [s]
[2024-10-23 15:55:18,233][root][INFO] - Step: 69/1035  |  Loss: 2.3430  |  Score: 36.09 [%]  |  Seq Length: 256.0
[2024-10-23 15:55:21,322][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 15:55:21,323][root][INFO] - Score: 73.45 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:55:24,290][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 15:55:24,290][root][INFO] - Score: 64.98 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:55:24,292][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 15:55:24,292][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:55:25,855][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:55:25,901][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:55:25,902][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:55:25,902][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:55:25,902][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:55:25,902][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:55:25,904][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:55:26,393][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:55:26,394][root][INFO] - Score: 76.13 [%]  |  Evaluation Time: 20.69 [s]
[2024-10-23 15:55:26,395][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 15:55:26,395][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 15:55:26,398][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 15:55:27,589][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 15:55:28,418][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:55:28,718][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:55:28,719][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:55:28,720][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:55:28,720][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:55:28,720][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:55:28,723][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:55:30,529][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 15:55:30,530][root][INFO] - - Epoch: 5
[2024-10-23 15:55:30,530][root][INFO] - - DEV score: 74.51 [%]
[2024-10-23 15:55:30,530][root][INFO] - - TEST score: 76.13 [%]
[2024-10-23 15:55:30,532][root][INFO] - Fine-tuning is done!
[2024-10-23 15:55:30,532][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 15:55:30,533][root][INFO] - - BEST LR: 0.005
[2024-10-23 15:55:30,533][root][INFO] - - DEV score: 74.51 [%]
[2024-10-23 15:55:30,533][root][INFO] - - TEST score: 76.13 [%]
[2024-10-23 15:55:37,548][root][INFO] - 

[2024-10-23 15:55:37,548][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 15:55:37,548][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-23 15:55:37,548][root][INFO] - 

[2024-10-23 15:55:37,548][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 3, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': False, 'task_name': 'KorNLI'}, 'optim': {'name': 'adamwscale', 'base_lr': 0.0001, 'base_lrs': '1e-02 5e-03', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 15:55:53,504][root][INFO] - Step: 138/1035  |  Loss: 1.2675  |  Score: 68.05 [%]  |  Seq Length: 256.0
[2024-10-23 15:55:56,588][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 15:55:56,588][root][INFO] - Score: 74.67 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 15:55:59,555][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 15:55:59,555][root][INFO] - Score: 65.90 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 15:55:59,556][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 15:55:59,557][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:56:01,128][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:56:01,172][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:56:01,173][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:56:01,173][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:56:01,173][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:56:01,173][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:56:01,175][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:56:02,631][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 15:56:28,547][root][INFO] - Step: 207/1035  |  Loss: 1.0486  |  Score: 72.18 [%]  |  Seq Length: 256.0
[2024-10-23 15:56:31,663][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 15:56:31,663][root][INFO] - Score: 76.14 [%]  |  Evaluation Time: 3.11 [s]
[2024-10-23 15:56:34,630][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 15:56:34,631][root][INFO] - Score: 71.19 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:56:34,632][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 15:56:34,632][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:56:36,180][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:56:36,211][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:56:36,212][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:56:36,212][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:56:36,212][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:56:36,212][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:56:36,214][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:56:37,654][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 15:57:03,508][root][INFO] - Step: 276/1035  |  Loss: 0.8149  |  Score: 77.83 [%]  |  Seq Length: 256.0
[2024-10-23 15:57:06,591][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 15:57:06,591][root][INFO] - Score: 76.55 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 15:57:09,564][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 15:57:09,564][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 15:57:09,566][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 15:57:09,566][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:57:11,177][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:57:11,210][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:57:11,211][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:57:11,211][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:57:11,211][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:57:11,211][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:57:11,213][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:57:12,809][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 15:57:38,661][root][INFO] - Step: 345/1035  |  Loss: 0.6587  |  Score: 82.11 [%]  |  Seq Length: 256.0
[2024-10-23 15:57:41,723][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 15:57:41,723][root][INFO] - Score: 76.64 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 15:57:44,723][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 15:57:44,724][root][INFO] - Score: 68.63 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 15:57:44,726][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 15:57:48,557][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,558][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,558][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,559][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,559][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,560][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,561][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,561][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,562][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,562][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,563][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,563][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,564][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,564][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,565][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,565][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,566][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,566][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,567][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,567][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,568][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,568][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,569][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 15:57:48,569][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 15:57:48,571][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-23 15:57:48,577][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 15:57:48,781][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 15:57:48,783][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-23 15:57:49,029][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 15:57:52,594][root][INFO] - 

[2024-10-23 15:57:52,595][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-23 15:57:52,595][root][INFO] - Data Preprocessing
[2024-10-23 15:57:52,595][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 15:57:52,595][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 15:57:52,595][root][INFO] - ㄴ data_remove                False

[2024-10-23 15:57:52,595][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 15:57:52,603][root][INFO] - vocab size              : 51200
[2024-10-23 15:57:52,603][root][INFO] - device                  : gpu
[2024-10-23 15:57:52,603][root][INFO] - random seed             : 3
[2024-10-23 15:57:52,603][root][INFO] - train data size         : 942912
[2024-10-23 15:57:52,603][root][INFO] - max epochs              : 5
[2024-10-23 15:57:52,603][root][INFO] - total steps             : 73665
[2024-10-23 15:57:52,603][root][INFO] - warmup steps            : 7366
[2024-10-23 15:57:52,603][root][INFO] - batch size              : 64
[2024-10-23 15:57:52,603][root][INFO] - accumulation steps      : 1
[2024-10-23 15:57:52,604][root][INFO] - optimizer               : adamwscale
[2024-10-23 15:57:52,604][root][INFO] - lr_scheduler            : cosine
[2024-10-23 15:57:52,604][root][INFO] - learning rate           : 0.01
[2024-10-23 15:57:52,604][root][INFO] - max length              : 256

[2024-10-23 15:57:52,604][root][INFO] - LoRA Configuration
[2024-10-23 15:57:52,604][root][INFO] - ㄴ r                    : 32
[2024-10-23 15:57:52,604][root][INFO] - ㄴ alpha                : 128
[2024-10-23 15:57:52,604][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 15:57:52,604][root][INFO] - KOMBO Configuration
[2024-10-23 15:57:52,604][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 15:57:52,604][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 15:57:52,605][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 15:57:52,605][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 15:57:52,605][root][INFO] - ㄴ do_combination       : True
[2024-10-23 15:57:52,605][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 15:57:52,605][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 15:57:52,605][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 15:57:52,605][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 15:57:52,605][root][INFO] - 

[2024-10-23 15:57:52,605][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-23 15:57:52,606][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-23 15:57:52,606][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb
[2024-10-23 15:57:52,606][root][INFO] - * tb interval   : 10000

[2024-10-23 15:57:52,606][root][INFO] - 

[2024-10-23 15:57:52,606][root][INFO] - Start the Training !
[2024-10-23 15:57:52,609][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 15:58:10,590][root][INFO] - Step: 414/1035  |  Loss: 0.5365  |  Score: 85.39 [%]  |  Seq Length: 256.0
[2024-10-23 15:58:13,691][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 15:58:13,691][root][INFO] - Score: 78.14 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 15:58:16,692][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 15:58:16,692][root][INFO] - Score: 70.07 [%]  |  Evaluation Time: 3.00 [s]
[2024-10-23 15:58:16,694][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 15:58:16,695][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:58:18,297][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:58:18,329][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:58:18,329][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:58:18,330][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:58:18,330][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:58:18,330][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:58:18,331][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:58:19,899][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 15:58:45,797][root][INFO] - Step: 483/1035  |  Loss: 0.4335  |  Score: 88.47 [%]  |  Seq Length: 256.0
[2024-10-23 15:58:48,894][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 15:58:48,895][root][INFO] - Score: 75.57 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 15:58:51,861][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 15:58:51,861][root][INFO] - Score: 69.87 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 15:58:51,864][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 15:59:17,770][root][INFO] - Step: 552/1035  |  Loss: 0.3841  |  Score: 89.44 [%]  |  Seq Length: 256.0
[2024-10-23 15:59:20,837][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 15:59:20,837][root][INFO] - Score: 79.43 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 15:59:23,816][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 15:59:23,816][root][INFO] - Score: 71.16 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:59:23,818][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 15:59:23,819][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 15:59:25,426][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 15:59:25,478][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 15:59:25,479][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 15:59:25,479][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 15:59:25,479][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 15:59:25,479][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 15:59:25,480][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 15:59:27,065][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 15:59:52,969][root][INFO] - Step: 621/1035  |  Loss: 0.3227  |  Score: 91.01 [%]  |  Seq Length: 256.0
[2024-10-23 15:59:56,026][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 15:59:56,026][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 3.05 [s]
[2024-10-23 15:59:59,011][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 15:59:59,011][root][INFO] - Score: 69.96 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 15:59:59,014][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 16:00:24,913][root][INFO] - Step: 690/1035  |  Loss: 0.2845  |  Score: 92.43 [%]  |  Seq Length: 256.0
[2024-10-23 16:00:27,988][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 16:00:27,988][root][INFO] - Score: 78.43 [%]  |  Evaluation Time: 3.07 [s]
[2024-10-23 16:00:30,960][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 16:00:30,960][root][INFO] - Score: 70.90 [%]  |  Evaluation Time: 2.97 [s]
[2024-10-23 16:00:30,963][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 16:00:38,722][root][INFO] - Step: 5133/8555  |  Loss: 0.2735  |  Score: 88.66 [%]  |  Seq Length: 256.0
[2024-10-23 16:00:56,933][root][INFO] - Step: 759/1035  |  Loss: 0.2410  |  Score: 93.32 [%]  |  Seq Length: 256.0
[2024-10-23 16:01:00,041][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 16:01:00,041][root][INFO] - Score: 79.41 [%]  |  Evaluation Time: 3.10 [s]
[2024-10-23 16:01:03,028][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 16:01:03,028][root][INFO] - Score: 70.20 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 16:01:03,031][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 16:01:06,511][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 16:01:06,511][root][INFO] - Score: 87.67 [%]  |  Evaluation Time: 27.79 [s]
[2024-10-23 16:01:28,904][root][INFO] - Step: 828/1035  |  Loss: 0.2189  |  Score: 93.93 [%]  |  Seq Length: 256.0
[2024-10-23 16:01:31,962][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 16:01:31,962][root][INFO] - Score: 77.91 [%]  |  Evaluation Time: 3.06 [s]
[2024-10-23 16:01:34,928][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 16:01:34,929][root][INFO] - Score: 70.65 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 16:01:34,931][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 16:02:00,851][root][INFO] - Step: 897/1035  |  Loss: 0.2003  |  Score: 94.09 [%]  |  Seq Length: 256.0
[2024-10-23 16:02:03,947][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 16:02:03,947][root][INFO] - Score: 78.81 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 16:02:06,926][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 16:02:06,927][root][INFO] - Score: 71.11 [%]  |  Evaluation Time: 2.98 [s]
[2024-10-23 16:02:06,929][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 16:02:32,817][root][INFO] - Step: 966/1035  |  Loss: 0.1951  |  Score: 94.31 [%]  |  Seq Length: 256.0
[2024-10-23 16:02:35,905][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 16:02:35,905][root][INFO] - Score: 78.38 [%]  |  Evaluation Time: 3.08 [s]
[2024-10-23 16:02:37,543][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 16:02:37,543][root][INFO] - Score: 87.53 [%]  |  Evaluation Time: 91.03 [s]
[2024-10-23 16:02:37,544][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 16:02:37,545][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 16:02:38,868][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 16:02:38,868][root][INFO] - Score: 70.33 [%]  |  Evaluation Time: 2.96 [s]
[2024-10-23 16:02:38,870][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 16:02:39,096][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:02:39,131][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:02:39,131][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:02:39,131][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:02:39,131][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:02:39,132][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:02:39,133][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:02:40,570][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 16:03:04,827][root][INFO] - Step: 1035/1035  |  Loss: 0.1847  |  Score: 94.56 [%]  |  Seq Length: 256.0
[2024-10-23 16:03:07,921][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 16:03:07,921][root][INFO] - Score: 79.06 [%]  |  Evaluation Time: 3.09 [s]
[2024-10-23 16:03:10,929][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 16:03:10,929][root][INFO] - Score: 70.73 [%]  |  Evaluation Time: 3.01 [s]
[2024-10-23 16:03:10,930][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 16:03:10,930][root][INFO] - - Epoch: 8
[2024-10-23 16:03:10,930][root][INFO] - - DEV score: 79.43 [%]
[2024-10-23 16:03:10,930][root][INFO] - - TEST score: 71.16 [%]
[2024-10-23 16:03:10,932][root][INFO] - Fine-tuning is done!
[2024-10-23 16:03:10,932][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 16:03:10,932][root][INFO] - - BEST LR: 0.01
[2024-10-23 16:03:10,932][root][INFO] - - DEV score: 79.34 [%]
[2024-10-23 16:03:10,932][root][INFO] - - TEST score: 71.81 [%]
[2024-10-23 16:03:17,269][root][INFO] - 

[2024-10-23 16:03:17,269][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 16:03:17,269][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs
[2024-10-23 16:03:17,269][root][INFO] - 

[2024-10-23 16:03:17,269][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 1, 'remain_lang': 'ko_en_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'KorSTS'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 15, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 16:03:21,789][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,790][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,790][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,791][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,791][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,792][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,792][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,792][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,793][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,793][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,794][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,794][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,794][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,795][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,795][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,796][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,796][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,796][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,797][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,797][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,798][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,798][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,799][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 16:03:21,799][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 16:03:21,801][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 16:03:21,804][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 16:03:22,007][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 16:03:22,009][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 16:03:22,196][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 16:03:25,643][root][INFO] - 

[2024-10-23 16:03:25,644][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 16:03:25,644][root][INFO] - Data Preprocessing
[2024-10-23 16:03:25,644][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 16:03:25,644][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 16:03:25,644][root][INFO] - ㄴ data_remove                True

[2024-10-23 16:03:25,644][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 16:03:25,652][root][INFO] - vocab size              : 51200
[2024-10-23 16:03:25,652][root][INFO] - device                  : gpu
[2024-10-23 16:03:25,652][root][INFO] - random seed             : 3
[2024-10-23 16:03:25,652][root][INFO] - train data size         : 4416
[2024-10-23 16:03:25,652][root][INFO] - max epochs              : 15
[2024-10-23 16:03:25,652][root][INFO] - total steps             : 1035
[2024-10-23 16:03:25,652][root][INFO] - warmup steps            : 104
[2024-10-23 16:03:25,652][root][INFO] - batch size              : 64
[2024-10-23 16:03:25,652][root][INFO] - accumulation steps      : 1
[2024-10-23 16:03:25,652][root][INFO] - optimizer               : adamwscale
[2024-10-23 16:03:25,653][root][INFO] - lr_scheduler            : cosine
[2024-10-23 16:03:25,653][root][INFO] - learning rate           : 0.01
[2024-10-23 16:03:25,653][root][INFO] - max length              : 256

[2024-10-23 16:03:25,653][root][INFO] - LoRA Configuration
[2024-10-23 16:03:25,653][root][INFO] - ㄴ r                    : 32
[2024-10-23 16:03:25,653][root][INFO] - ㄴ alpha                : 128
[2024-10-23 16:03:25,653][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 16:03:25,653][root][INFO] - KOMBO Configuration
[2024-10-23 16:03:25,653][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 16:03:25,653][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 16:03:25,653][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 16:03:25,654][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 16:03:25,654][root][INFO] - ㄴ do_combination       : True
[2024-10-23 16:03:25,654][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 16:03:25,654][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 16:03:25,654][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 16:03:25,654][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 16:03:25,654][root][INFO] - 

[2024-10-23 16:03:25,654][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs
[2024-10-23 16:03:25,654][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 16:03:25,654][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 16:03:25,655][root][INFO] - * tb interval   : 10000

[2024-10-23 16:03:25,655][root][INFO] - 

[2024-10-23 16:03:25,655][root][INFO] - Start the Training !
[2024-10-23 16:03:25,658][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 16:04:03,250][root][INFO] - Step: 69/1035  |  Loss: 2.5276  |  Score: 29.85 [%]  |  Seq Length: 256.0
[2024-10-23 16:04:08,403][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 16:04:08,403][root][INFO] - Score: 68.46 [%]  |  Evaluation Time: 5.15 [s]
[2024-10-23 16:04:13,212][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 16:04:13,212][root][INFO] - Score: 62.37 [%]  |  Evaluation Time: 4.81 [s]
[2024-10-23 16:04:13,213][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 16:04:13,214][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:04:13,220][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:04:14,461][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:04:14,578][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:04:14,579][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:04:14,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:04:14,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:04:14,579][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:04:14,581][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:04:15,446][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 16:04:52,035][root][INFO] - Step: 138/1035  |  Loss: 1.3505  |  Score: 63.94 [%]  |  Seq Length: 256.0
[2024-10-23 16:04:57,032][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 16:04:57,032][root][INFO] - Score: 75.37 [%]  |  Evaluation Time: 4.99 [s]
[2024-10-23 16:05:01,701][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 16:05:01,701][root][INFO] - Score: 68.80 [%]  |  Evaluation Time: 4.67 [s]
[2024-10-23 16:05:01,703][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 16:05:01,703][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:05:01,706][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:05:03,451][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:05:03,593][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:05:03,594][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:05:03,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:05:03,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:05:03,594][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:05:03,596][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:05:05,264][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 16:05:42,033][root][INFO] - Step: 207/1035  |  Loss: 1.0864  |  Score: 70.05 [%]  |  Seq Length: 256.0
[2024-10-23 16:05:47,007][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 16:05:47,007][root][INFO] - Score: 77.04 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-23 16:05:51,740][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 16:05:51,741][root][INFO] - Score: 68.87 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-23 16:05:51,742][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 16:05:51,742][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:05:51,745][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:05:53,481][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:05:53,697][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:05:53,699][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:05:53,699][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:05:53,699][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:05:53,700][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:05:53,703][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:05:55,339][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 16:06:32,361][root][INFO] - Step: 276/1035  |  Loss: 0.9104  |  Score: 75.42 [%]  |  Seq Length: 256.0
[2024-10-23 16:06:37,435][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 16:06:37,435][root][INFO] - Score: 76.99 [%]  |  Evaluation Time: 5.07 [s]
[2024-10-23 16:06:42,151][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 16:06:42,151][root][INFO] - Score: 70.41 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-23 16:06:42,152][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 16:06:42,153][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:06:42,155][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:06:43,894][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:06:44,105][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:06:44,106][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:06:44,106][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:06:44,106][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:06:44,107][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:06:44,109][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:06:45,777][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 16:07:22,506][root][INFO] - Step: 345/1035  |  Loss: 0.8420  |  Score: 77.83 [%]  |  Seq Length: 256.0
[2024-10-23 16:07:27,487][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 16:07:27,488][root][INFO] - Score: 77.06 [%]  |  Evaluation Time: 4.98 [s]
[2024-10-23 16:07:32,203][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 16:07:32,203][root][INFO] - Score: 70.88 [%]  |  Evaluation Time: 4.71 [s]
[2024-10-23 16:07:32,204][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 16:07:32,205][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:07:32,208][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:07:33,912][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:07:34,175][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:07:34,176][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:07:34,177][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:07:34,177][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:07:34,178][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:07:34,180][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:07:35,844][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 16:08:12,905][root][INFO] - Step: 414/1035  |  Loss: 0.7149  |  Score: 80.23 [%]  |  Seq Length: 256.0
[2024-10-23 16:08:17,894][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 16:08:17,894][root][INFO] - Score: 78.14 [%]  |  Evaluation Time: 4.99 [s]
[2024-10-23 16:08:22,648][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 16:08:22,648][root][INFO] - Score: 70.71 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-23 16:08:22,650][root][INFO] - 
Save new Best Score (Epoch: 6)
[2024-10-23 16:08:22,651][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:08:22,657][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:08:24,490][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:08:24,751][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:08:24,752][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:08:24,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:08:24,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:08:24,753][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:08:24,756][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:08:26,394][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 16:09:03,168][root][INFO] - Step: 483/1035  |  Loss: 0.6148  |  Score: 82.92 [%]  |  Seq Length: 256.0
[2024-10-23 16:09:08,186][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 16:09:08,187][root][INFO] - Score: 75.92 [%]  |  Evaluation Time: 5.01 [s]
[2024-10-23 16:09:12,853][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 16:09:12,853][root][INFO] - Score: 69.07 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 16:09:12,855][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 16:09:49,700][root][INFO] - Step: 552/1035  |  Loss: 0.5539  |  Score: 84.81 [%]  |  Seq Length: 256.0
[2024-10-23 16:09:54,753][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 16:09:54,753][root][INFO] - Score: 78.10 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-23 16:09:59,495][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 16:09:59,496][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 16:09:59,497][root][INFO] - 
Save new Best Score (Epoch: 8)
[2024-10-23 16:09:59,497][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:09:59,500][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:10:01,312][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:10:01,454][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:10:01,454][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:10:01,455][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:10:01,455][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:10:01,455][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:10:01,456][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:10:03,133][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 16:10:39,788][root][INFO] - Step: 621/1035  |  Loss: 0.4859  |  Score: 86.74 [%]  |  Seq Length: 256.0
[2024-10-23 16:10:44,824][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 16:10:44,824][root][INFO] - Score: 77.66 [%]  |  Evaluation Time: 5.03 [s]
[2024-10-23 16:10:49,510][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 16:10:49,510][root][INFO] - Score: 68.94 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-23 16:10:49,513][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 16:11:26,522][root][INFO] - Step: 690/1035  |  Loss: 0.4322  |  Score: 87.69 [%]  |  Seq Length: 256.0
[2024-10-23 16:11:31,590][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 16:11:31,590][root][INFO] - Score: 78.71 [%]  |  Evaluation Time: 5.07 [s]
[2024-10-23 16:11:36,345][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 16:11:36,345][root][INFO] - Score: 71.45 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-23 16:11:36,346][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-23 16:11:36,346][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:11:36,349][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:11:38,130][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:11:38,391][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:11:38,393][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:11:38,393][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:11:38,393][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:11:38,394][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:11:38,397][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:11:40,037][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 16:12:17,035][root][INFO] - Step: 759/1035  |  Loss: 0.3962  |  Score: 88.84 [%]  |  Seq Length: 256.0
[2024-10-23 16:12:22,107][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 16:12:22,107][root][INFO] - Score: 78.04 [%]  |  Evaluation Time: 5.07 [s]
[2024-10-23 16:12:26,873][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 16:12:26,873][root][INFO] - Score: 71.37 [%]  |  Evaluation Time: 4.76 [s]
[2024-10-23 16:12:26,876][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 16:13:03,795][root][INFO] - Step: 828/1035  |  Loss: 0.3893  |  Score: 89.10 [%]  |  Seq Length: 256.0
[2024-10-23 16:13:08,858][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 16:13:08,858][root][INFO] - Score: 77.50 [%]  |  Evaluation Time: 5.06 [s]
[2024-10-23 16:13:09,854][root][INFO] - Step: 6844/8555  |  Loss: 0.2275  |  Score: 90.72 [%]  |  Seq Length: 256.0
[2024-10-23 16:13:13,638][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 16:13:13,638][root][INFO] - Score: 71.04 [%]  |  Evaluation Time: 4.78 [s]
[2024-10-23 16:13:13,641][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 16:13:37,611][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 16:13:37,612][root][INFO] - Score: 88.71 [%]  |  Evaluation Time: 27.75 [s]
[2024-10-23 16:13:50,627][root][INFO] - Step: 897/1035  |  Loss: 0.3563  |  Score: 90.02 [%]  |  Seq Length: 256.0
[2024-10-23 16:13:55,658][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 16:13:55,658][root][INFO] - Score: 76.79 [%]  |  Evaluation Time: 5.03 [s]
[2024-10-23 16:14:00,398][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 16:14:00,398][root][INFO] - Score: 70.44 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 16:14:00,400][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 16:14:37,356][root][INFO] - Step: 966/1035  |  Loss: 0.3376  |  Score: 90.28 [%]  |  Seq Length: 256.0
[2024-10-23 16:14:42,410][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 16:14:42,411][root][INFO] - Score: 77.45 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-23 16:14:47,183][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 16:14:47,184][root][INFO] - Score: 71.23 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-23 16:14:47,187][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 16:15:08,602][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 16:15:08,602][root][INFO] - Score: 88.40 [%]  |  Evaluation Time: 90.99 [s]
[2024-10-23 16:15:08,603][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 16:15:08,604][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 16:15:10,312][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:15:10,345][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:15:10,346][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:15:10,346][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:15:10,346][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:15:10,346][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:15:10,347][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:15:11,755][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 16:15:23,898][root][INFO] - Step: 1035/1035  |  Loss: 0.3463  |  Score: 90.21 [%]  |  Seq Length: 256.0
[2024-10-23 16:15:28,868][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 16:15:28,868][root][INFO] - Score: 77.60 [%]  |  Evaluation Time: 4.97 [s]
[2024-10-23 16:15:33,525][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 16:15:33,526][root][INFO] - Score: 71.30 [%]  |  Evaluation Time: 4.66 [s]
[2024-10-23 16:15:33,527][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 16:15:33,527][root][INFO] - - Epoch: 10
[2024-10-23 16:15:33,527][root][INFO] - - DEV score: 78.71 [%]
[2024-10-23 16:15:33,527][root][INFO] - - TEST score: 71.45 [%]
[2024-10-23 16:15:33,528][root][INFO] - Fine-tuning is done!
[2024-10-23 16:15:36,890][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,891][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,892][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,892][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,893][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,893][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,894][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,894][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,895][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,895][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,896][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,896][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,896][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,897][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,898][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,898][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,899][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,899][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,899][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,900][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,900][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,901][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,901][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 16:15:36,902][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 16:15:36,903][root][INFO] - Trainable params: 1769472 || all params: 126934272 || trainable: 1.39 %
[2024-10-23 16:15:37,108][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 16:15:37,110][root][INFO] - Trainable params: 17845248 || all params: 143010048 || trainable: 12.48 %
[2024-10-23 16:15:37,111][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 16:15:37,282][root][INFO] - 

[2024-10-23 16:15:37,282][root][INFO] - ========== Fine-tuning on KorSTS ==========
[2024-10-23 16:15:37,282][root][INFO] - Data Preprocessing
[2024-10-23 16:15:37,282][root][INFO] - ㄴ remain_lang                ko_en_punc
[2024-10-23 16:15:37,282][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 16:15:37,282][root][INFO] - ㄴ data_remove                True

[2024-10-23 16:15:37,282][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 16:15:37,289][root][INFO] - vocab size              : 51200
[2024-10-23 16:15:37,289][root][INFO] - device                  : gpu
[2024-10-23 16:15:37,289][root][INFO] - random seed             : 3
[2024-10-23 16:15:37,290][root][INFO] - train data size         : 4416
[2024-10-23 16:15:37,290][root][INFO] - max epochs              : 15
[2024-10-23 16:15:37,290][root][INFO] - total steps             : 1035
[2024-10-23 16:15:37,290][root][INFO] - warmup steps            : 104
[2024-10-23 16:15:37,290][root][INFO] - batch size              : 64
[2024-10-23 16:15:37,290][root][INFO] - accumulation steps      : 1
[2024-10-23 16:15:37,290][root][INFO] - optimizer               : adamwscale
[2024-10-23 16:15:37,290][root][INFO] - lr_scheduler            : cosine
[2024-10-23 16:15:37,290][root][INFO] - learning rate           : 0.02
[2024-10-23 16:15:37,290][root][INFO] - max length              : 256

[2024-10-23 16:15:37,290][root][INFO] - LoRA Configuration
[2024-10-23 16:15:37,291][root][INFO] - ㄴ r                    : 32
[2024-10-23 16:15:37,291][root][INFO] - ㄴ alpha                : 128
[2024-10-23 16:15:37,291][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 16:15:37,291][root][INFO] - KOMBO Configuration
[2024-10-23 16:15:37,291][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 16:15:37,291][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 16:15:37,291][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 16:15:37,291][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 16:15:37,291][root][INFO] - ㄴ do_combination       : True
[2024-10-23 16:15:37,291][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 16:15:37,292][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 16:15:37,292][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 16:15:37,292][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 16:15:37,292][root][INFO] - 

[2024-10-23 16:15:37,292][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs
[2024-10-23 16:15:37,292][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-23 16:15:37,292][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/tb
[2024-10-23 16:15:37,292][root][INFO] - * tb interval   : 10000

[2024-10-23 16:15:37,292][root][INFO] - 

[2024-10-23 16:15:37,292][root][INFO] - Start the Training !
[2024-10-23 16:15:37,294][root][INFO] - 
[1/ 15 Epoch]
[2024-10-23 16:16:14,182][root][INFO] - Step: 69/1035  |  Loss: 2.1499  |  Score: 40.69 [%]  |  Seq Length: 256.0
[2024-10-23 16:16:19,297][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 16:16:19,297][root][INFO] - Score: 74.07 [%]  |  Evaluation Time: 5.11 [s]
[2024-10-23 16:16:24,066][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 16:16:24,066][root][INFO] - Score: 66.33 [%]  |  Evaluation Time: 4.77 [s]
[2024-10-23 16:16:24,067][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 16:16:24,068][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:16:24,070][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:16:25,846][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:16:26,006][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:16:26,006][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:16:26,006][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:16:26,006][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:16:26,007][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:16:26,008][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:16:27,639][root][INFO] - 
[2/ 15 Epoch]
[2024-10-23 16:17:04,514][root][INFO] - Step: 138/1035  |  Loss: 1.2128  |  Score: 67.62 [%]  |  Seq Length: 256.0
[2024-10-23 16:17:09,553][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 16:17:09,553][root][INFO] - Score: 76.16 [%]  |  Evaluation Time: 5.04 [s]
[2024-10-23 16:17:14,293][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 16:17:14,293][root][INFO] - Score: 69.60 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 16:17:14,294][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 16:17:14,295][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:17:14,297][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:17:16,101][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:17:16,372][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:17:16,374][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:17:16,374][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:17:16,374][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:17:16,375][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:17:16,378][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:17:18,028][root][INFO] - 
[3/ 15 Epoch]
[2024-10-23 16:17:54,900][root][INFO] - Step: 207/1035  |  Loss: 1.0121  |  Score: 74.04 [%]  |  Seq Length: 256.0
[2024-10-23 16:17:59,892][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 16:17:59,892][root][INFO] - Score: 75.52 [%]  |  Evaluation Time: 4.99 [s]
[2024-10-23 16:18:04,578][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 16:18:04,578][root][INFO] - Score: 68.94 [%]  |  Evaluation Time: 4.68 [s]
[2024-10-23 16:18:04,580][root][INFO] - 
[4/ 15 Epoch]
[2024-10-23 16:18:41,413][root][INFO] - Step: 276/1035  |  Loss: 0.8378  |  Score: 78.86 [%]  |  Seq Length: 256.0
[2024-10-23 16:18:46,493][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 16:18:46,493][root][INFO] - Score: 78.33 [%]  |  Evaluation Time: 5.08 [s]
[2024-10-23 16:18:51,248][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 16:18:51,249][root][INFO] - Score: 69.77 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-23 16:18:51,250][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 16:18:51,250][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:18:51,253][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:18:53,004][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:18:53,279][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:18:53,281][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:18:53,281][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:18:53,281][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:18:53,281][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:18:53,285][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:18:54,943][root][INFO] - 
[5/ 15 Epoch]
[2024-10-23 16:19:32,019][root][INFO] - Step: 345/1035  |  Loss: 0.6900  |  Score: 82.36 [%]  |  Seq Length: 256.0
[2024-10-23 16:19:37,060][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 16:19:37,060][root][INFO] - Score: 76.76 [%]  |  Evaluation Time: 5.04 [s]
[2024-10-23 16:19:41,799][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 16:19:41,800][root][INFO] - Score: 69.90 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 16:19:41,802][root][INFO] - 
[6/ 15 Epoch]
[2024-10-23 16:20:18,634][root][INFO] - Step: 414/1035  |  Loss: 0.5556  |  Score: 84.96 [%]  |  Seq Length: 256.0
[2024-10-23 16:20:23,676][root][INFO] - ########################  DEV REPORT #EP6  ########################
[2024-10-23 16:20:23,676][root][INFO] - Score: 77.02 [%]  |  Evaluation Time: 5.04 [s]
[2024-10-23 16:20:28,403][root][INFO] - ########################  TEST REPORT #EP6  ########################
[2024-10-23 16:20:28,404][root][INFO] - Score: 69.27 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-23 16:20:28,406][root][INFO] - 
[7/ 15 Epoch]
[2024-10-23 16:21:05,222][root][INFO] - Step: 483/1035  |  Loss: 0.4356  |  Score: 87.74 [%]  |  Seq Length: 256.0
[2024-10-23 16:21:10,287][root][INFO] - ########################  DEV REPORT #EP7  ########################
[2024-10-23 16:21:10,287][root][INFO] - Score: 77.27 [%]  |  Evaluation Time: 5.06 [s]
[2024-10-23 16:21:15,033][root][INFO] - ########################  TEST REPORT #EP7  ########################
[2024-10-23 16:21:15,033][root][INFO] - Score: 70.06 [%]  |  Evaluation Time: 4.74 [s]
[2024-10-23 16:21:15,036][root][INFO] - 
[8/ 15 Epoch]
[2024-10-23 16:21:51,687][root][INFO] - Step: 552/1035  |  Loss: 0.3558  |  Score: 90.00 [%]  |  Seq Length: 256.0
[2024-10-23 16:21:56,726][root][INFO] - ########################  DEV REPORT #EP8  ########################
[2024-10-23 16:21:56,727][root][INFO] - Score: 77.15 [%]  |  Evaluation Time: 5.04 [s]
[2024-10-23 16:22:01,550][root][INFO] - ########################  TEST REPORT #EP8  ########################
[2024-10-23 16:22:01,550][root][INFO] - Score: 70.36 [%]  |  Evaluation Time: 4.82 [s]
[2024-10-23 16:22:01,553][root][INFO] - 
[9/ 15 Epoch]
[2024-10-23 16:22:38,423][root][INFO] - Step: 621/1035  |  Loss: 0.3147  |  Score: 91.54 [%]  |  Seq Length: 256.0
[2024-10-23 16:22:43,477][root][INFO] - ########################  DEV REPORT #EP9  ########################
[2024-10-23 16:22:43,477][root][INFO] - Score: 77.33 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-23 16:22:48,202][root][INFO] - ########################  TEST REPORT #EP9  ########################
[2024-10-23 16:22:48,203][root][INFO] - Score: 68.11 [%]  |  Evaluation Time: 4.72 [s]
[2024-10-23 16:22:48,205][root][INFO] - 
[10/ 15 Epoch]
[2024-10-23 16:23:25,096][root][INFO] - Step: 690/1035  |  Loss: 0.2747  |  Score: 92.46 [%]  |  Seq Length: 256.0
[2024-10-23 16:23:30,115][root][INFO] - ########################  DEV REPORT #EP10  ########################
[2024-10-23 16:23:30,115][root][INFO] - Score: 77.64 [%]  |  Evaluation Time: 5.02 [s]
[2024-10-23 16:23:34,806][root][INFO] - ########################  TEST REPORT #EP10  ########################
[2024-10-23 16:23:34,807][root][INFO] - Score: 70.69 [%]  |  Evaluation Time: 4.69 [s]
[2024-10-23 16:23:34,808][root][INFO] - 
Save new Best Score (Epoch: 10)
[2024-10-23 16:23:34,809][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:23:34,811][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:23:36,543][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:23:36,817][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:23:36,818][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:23:36,818][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:23:36,819][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:23:36,819][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:23:36,822][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:23:38,484][root][INFO] - 
[11/ 15 Epoch]
[2024-10-23 16:24:15,354][root][INFO] - Step: 759/1035  |  Loss: 0.2485  |  Score: 93.43 [%]  |  Seq Length: 256.0
[2024-10-23 16:24:20,375][root][INFO] - ########################  DEV REPORT #EP11  ########################
[2024-10-23 16:24:20,375][root][INFO] - Score: 77.77 [%]  |  Evaluation Time: 5.02 [s]
[2024-10-23 16:24:25,073][root][INFO] - ########################  TEST REPORT #EP11  ########################
[2024-10-23 16:24:25,074][root][INFO] - Score: 70.64 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-23 16:24:25,075][root][INFO] - 
Save new Best Score (Epoch: 11)
[2024-10-23 16:24:25,075][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 16:24:25,078][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:24:26,805][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:24:27,078][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:24:27,079][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:24:27,079][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:24:27,080][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:24:27,080][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:24:27,082][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorSTS/ko_en_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:24:28,718][root][INFO] - 
[12/ 15 Epoch]
[2024-10-23 16:25:05,665][root][INFO] - Step: 828/1035  |  Loss: 0.2140  |  Score: 93.94 [%]  |  Seq Length: 256.0
[2024-10-23 16:25:10,718][root][INFO] - ########################  DEV REPORT #EP12  ########################
[2024-10-23 16:25:10,719][root][INFO] - Score: 77.23 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-23 16:25:15,522][root][INFO] - ########################  TEST REPORT #EP12  ########################
[2024-10-23 16:25:15,522][root][INFO] - Score: 69.69 [%]  |  Evaluation Time: 4.80 [s]
[2024-10-23 16:25:15,525][root][INFO] - 
[13/ 15 Epoch]
[2024-10-23 16:25:40,884][root][INFO] - Step: 8555/8555  |  Loss: 0.1876  |  Score: 92.53 [%]  |  Seq Length: 256.0
[2024-10-23 16:25:52,447][root][INFO] - Step: 897/1035  |  Loss: 0.2011  |  Score: 94.36 [%]  |  Seq Length: 256.0
[2024-10-23 16:25:57,502][root][INFO] - ########################  DEV REPORT #EP13  ########################
[2024-10-23 16:25:57,503][root][INFO] - Score: 76.59 [%]  |  Evaluation Time: 5.05 [s]
[2024-10-23 16:26:02,210][root][INFO] - ########################  TEST REPORT #EP13  ########################
[2024-10-23 16:26:02,210][root][INFO] - Score: 69.80 [%]  |  Evaluation Time: 4.70 [s]
[2024-10-23 16:26:02,212][root][INFO] - 
[14/ 15 Epoch]
[2024-10-23 16:26:08,587][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 16:26:08,588][root][INFO] - Score: 89.04 [%]  |  Evaluation Time: 27.70 [s]
[2024-10-23 16:26:39,114][root][INFO] - Step: 966/1035  |  Loss: 0.1802  |  Score: 94.82 [%]  |  Seq Length: 256.0
[2024-10-23 16:26:44,203][root][INFO] - ########################  DEV REPORT #EP14  ########################
[2024-10-23 16:26:44,204][root][INFO] - Score: 76.84 [%]  |  Evaluation Time: 5.09 [s]
[2024-10-23 16:26:48,952][root][INFO] - ########################  TEST REPORT #EP14  ########################
[2024-10-23 16:26:48,952][root][INFO] - Score: 70.14 [%]  |  Evaluation Time: 4.75 [s]
[2024-10-23 16:26:48,955][root][INFO] - 
[15/ 15 Epoch]
[2024-10-23 16:27:25,992][root][INFO] - Step: 1035/1035  |  Loss: 0.1826  |  Score: 94.83 [%]  |  Seq Length: 256.0
[2024-10-23 16:27:31,097][root][INFO] - ########################  DEV REPORT #EP15  ########################
[2024-10-23 16:27:31,097][root][INFO] - Score: 77.41 [%]  |  Evaluation Time: 5.10 [s]
[2024-10-23 16:27:35,829][root][INFO] - ########################  TEST REPORT #EP15  ########################
[2024-10-23 16:27:35,829][root][INFO] - Score: 70.74 [%]  |  Evaluation Time: 4.73 [s]
[2024-10-23 16:27:35,831][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 16:27:35,831][root][INFO] - - Epoch: 11
[2024-10-23 16:27:35,831][root][INFO] - - DEV score: 77.77 [%]
[2024-10-23 16:27:35,831][root][INFO] - - TEST score: 70.64 [%]
[2024-10-23 16:27:35,833][root][INFO] - Fine-tuning is done!
[2024-10-23 16:27:35,834][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 16:27:35,834][root][INFO] - - BEST LR: 0.01
[2024-10-23 16:27:35,834][root][INFO] - - DEV score: 78.71 [%]
[2024-10-23 16:27:35,834][root][INFO] - - TEST score: 71.45 [%]
[2024-10-23 16:27:39,607][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 16:27:39,607][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 91.02 [s]
[2024-10-23 16:27:39,608][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 16:27:39,609][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 16:27:41,154][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:27:41,188][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:27:41,188][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:27:41,189][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:27:41,189][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:27:41,189][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:27:41,190][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:27:42,733][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 16:27:42,733][root][INFO] - - Epoch: 5
[2024-10-23 16:27:42,734][root][INFO] - - DEV score: 89.04 [%]
[2024-10-23 16:27:42,734][root][INFO] - - TEST score: 88.62 [%]
[2024-10-23 16:27:42,737][root][INFO] - Fine-tuning is done!
[2024-10-23 16:27:42,738][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 16:27:42,738][root][INFO] - - BEST LR: 0.01
[2024-10-23 16:27:42,738][root][INFO] - - DEV score: 89.04 [%]
[2024-10-23 16:27:42,739][root][INFO] - - TEST score: 88.74 [%]
[2024-10-23 16:27:49,192][root][INFO] - 

[2024-10-23 16:27:49,192][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 16:27:49,192][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 16:27:49,192][root][INFO] - 

[2024-10-23 16:27:49,193][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 1, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 16:28:08,549][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,550][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,550][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,551][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,551][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,552][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,552][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,553][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,553][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,553][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,554][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,554][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,555][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,559][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,559][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,560][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,560][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,561][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,561][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,561][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,562][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,562][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,563][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 16:28:08,563][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 16:28:08,565][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 16:28:08,569][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 16:28:08,774][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 16:28:08,776][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 16:28:08,974][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 16:28:12,330][root][INFO] - 

[2024-10-23 16:28:12,331][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 16:28:12,331][root][INFO] - Data Preprocessing
[2024-10-23 16:28:12,331][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 16:28:12,331][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 16:28:12,331][root][INFO] - ㄴ data_remove                True

[2024-10-23 16:28:12,331][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 16:28:12,339][root][INFO] - vocab size              : 51200
[2024-10-23 16:28:12,339][root][INFO] - device                  : gpu
[2024-10-23 16:28:12,339][root][INFO] - random seed             : 1
[2024-10-23 16:28:12,340][root][INFO] - train data size         : 109504
[2024-10-23 16:28:12,340][root][INFO] - max epochs              : 5
[2024-10-23 16:28:12,340][root][INFO] - total steps             : 8555
[2024-10-23 16:28:12,340][root][INFO] - warmup steps            : 856
[2024-10-23 16:28:12,340][root][INFO] - batch size              : 64
[2024-10-23 16:28:12,340][root][INFO] - accumulation steps      : 1
[2024-10-23 16:28:12,340][root][INFO] - optimizer               : adamwscale
[2024-10-23 16:28:12,340][root][INFO] - lr_scheduler            : cosine
[2024-10-23 16:28:12,340][root][INFO] - learning rate           : 0.01
[2024-10-23 16:28:12,340][root][INFO] - max length              : 256

[2024-10-23 16:28:12,340][root][INFO] - LoRA Configuration
[2024-10-23 16:28:12,340][root][INFO] - ㄴ r                    : 32
[2024-10-23 16:28:12,341][root][INFO] - ㄴ alpha                : 128
[2024-10-23 16:28:12,341][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 16:28:12,341][root][INFO] - KOMBO Configuration
[2024-10-23 16:28:12,341][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 16:28:12,341][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 16:28:12,341][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 16:28:12,341][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 16:28:12,341][root][INFO] - ㄴ do_combination       : True
[2024-10-23 16:28:12,341][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 16:28:12,341][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 16:28:12,342][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 16:28:12,342][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 16:28:12,342][root][INFO] - 

[2024-10-23 16:28:12,342][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 16:28:12,342][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 16:28:12,342][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 16:28:12,342][root][INFO] - * tb interval   : 10000

[2024-10-23 16:28:12,342][root][INFO] - 

[2024-10-23 16:28:12,342][root][INFO] - Start the Training !
[2024-10-23 16:28:12,345][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 16:42:38,870][root][INFO] - Step: 1711/8555  |  Loss: 0.3691  |  Score: 83.54 [%]  |  Seq Length: 256.0
[2024-10-23 16:43:22,374][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 16:43:22,374][root][INFO] - Score: 86.76 [%]  |  Evaluation Time: 43.50 [s]
[2024-10-23 16:45:44,490][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 16:45:44,491][root][INFO] - Score: 86.52 [%]  |  Evaluation Time: 142.11 [s]
[2024-10-23 16:45:44,492][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 16:45:44,493][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 16:45:44,496][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 16:45:45,647][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 16:45:45,762][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 16:45:45,763][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 16:45:45,763][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 16:45:45,763][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 16:45:45,763][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 16:45:45,764][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 16:45:46,529][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 17:00:12,770][root][INFO] - Step: 3422/8555  |  Loss: 0.2923  |  Score: 87.64 [%]  |  Seq Length: 256.0
[2024-10-23 17:00:56,005][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 17:00:56,005][root][INFO] - Score: 87.05 [%]  |  Evaluation Time: 43.23 [s]
[2024-10-23 17:03:17,674][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 17:03:17,674][root][INFO] - Score: 87.13 [%]  |  Evaluation Time: 141.67 [s]
[2024-10-23 17:03:17,677][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 17:03:17,678][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 17:03:17,686][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 17:03:19,525][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 17:03:19,781][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 17:03:19,783][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 17:03:19,783][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 17:03:19,784][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 17:03:19,784][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 17:03:19,787][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 17:03:21,396][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 17:17:43,376][root][INFO] - Step: 5133/8555  |  Loss: 0.2529  |  Score: 89.54 [%]  |  Seq Length: 256.0
[2024-10-23 17:18:26,560][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 17:18:26,560][root][INFO] - Score: 88.54 [%]  |  Evaluation Time: 43.18 [s]
[2024-10-23 17:20:47,664][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 17:20:47,665][root][INFO] - Score: 88.29 [%]  |  Evaluation Time: 141.10 [s]
[2024-10-23 17:20:47,666][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 17:20:47,666][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 17:20:47,669][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 17:20:49,496][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 17:20:49,788][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 17:20:49,790][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 17:20:49,790][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 17:20:49,791][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 17:20:49,791][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 17:20:49,794][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 17:20:51,397][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 17:27:45,518][root][INFO] - Step: 10000/73665  |  Loss: 0.7371  |  Score: 67.91 [%]  |  Seq Length: 256.0
[2024-10-23 17:35:12,521][root][INFO] - Step: 6844/8555  |  Loss: 0.2163  |  Score: 91.30 [%]  |  Seq Length: 256.0
[2024-10-23 17:35:55,984][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 17:35:55,984][root][INFO] - Score: 88.79 [%]  |  Evaluation Time: 43.46 [s]
[2024-10-23 17:38:18,006][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 17:38:18,006][root][INFO] - Score: 88.59 [%]  |  Evaluation Time: 142.02 [s]
[2024-10-23 17:38:18,008][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 17:38:18,008][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 17:38:18,011][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 17:38:20,658][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 17:38:20,958][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 17:38:20,960][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 17:38:20,960][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 17:38:20,961][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 17:38:20,962][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 17:38:20,966][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 17:38:22,633][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 17:52:47,749][root][INFO] - Step: 8555/8555  |  Loss: 0.1903  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-23 17:53:31,486][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 17:53:31,486][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 43.73 [s]
[2024-10-23 17:55:54,037][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 17:55:54,037][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 142.55 [s]
[2024-10-23 17:55:54,038][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 17:55:54,038][root][INFO] - - Epoch: 4
[2024-10-23 17:55:54,039][root][INFO] - - DEV score: 88.79 [%]
[2024-10-23 17:55:54,039][root][INFO] - - TEST score: 88.59 [%]
[2024-10-23 17:55:54,039][root][INFO] - Fine-tuning is done!
[2024-10-23 17:56:11,016][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,017][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,018][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,018][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,019][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,020][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,021][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,021][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,022][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,022][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,023][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,023][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,024][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,024][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,025][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,026][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,027][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,028][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,029][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,030][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,031][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,032][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,032][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 17:56:11,033][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 17:56:11,035][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 17:56:11,262][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 17:56:11,264][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 17:56:11,265][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 17:56:11,458][root][INFO] - 

[2024-10-23 17:56:11,458][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 17:56:11,458][root][INFO] - Data Preprocessing
[2024-10-23 17:56:11,458][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 17:56:11,459][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 17:56:11,459][root][INFO] - ㄴ data_remove                True

[2024-10-23 17:56:11,459][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 17:56:11,467][root][INFO] - vocab size              : 51200
[2024-10-23 17:56:11,468][root][INFO] - device                  : gpu
[2024-10-23 17:56:11,468][root][INFO] - random seed             : 1
[2024-10-23 17:56:11,468][root][INFO] - train data size         : 109504
[2024-10-23 17:56:11,468][root][INFO] - max epochs              : 5
[2024-10-23 17:56:11,468][root][INFO] - total steps             : 8555
[2024-10-23 17:56:11,468][root][INFO] - warmup steps            : 856
[2024-10-23 17:56:11,468][root][INFO] - batch size              : 64
[2024-10-23 17:56:11,468][root][INFO] - accumulation steps      : 1
[2024-10-23 17:56:11,468][root][INFO] - optimizer               : adamwscale
[2024-10-23 17:56:11,468][root][INFO] - lr_scheduler            : cosine
[2024-10-23 17:56:11,468][root][INFO] - learning rate           : 0.02
[2024-10-23 17:56:11,469][root][INFO] - max length              : 256

[2024-10-23 17:56:11,469][root][INFO] - LoRA Configuration
[2024-10-23 17:56:11,469][root][INFO] - ㄴ r                    : 32
[2024-10-23 17:56:11,469][root][INFO] - ㄴ alpha                : 128
[2024-10-23 17:56:11,469][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 17:56:11,469][root][INFO] - KOMBO Configuration
[2024-10-23 17:56:11,469][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 17:56:11,469][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 17:56:11,469][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 17:56:11,469][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 17:56:11,469][root][INFO] - ㄴ do_combination       : True
[2024-10-23 17:56:11,470][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 17:56:11,470][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 17:56:11,470][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 17:56:11,470][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 17:56:11,470][root][INFO] - 

[2024-10-23 17:56:11,470][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs
[2024-10-23 17:56:11,470][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt
[2024-10-23 17:56:11,470][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/tb
[2024-10-23 17:56:11,470][root][INFO] - * tb interval   : 10000

[2024-10-23 17:56:11,470][root][INFO] - 

[2024-10-23 17:56:11,470][root][INFO] - Start the Training !
[2024-10-23 17:56:11,473][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 18:10:22,629][root][INFO] - Step: 14733/73665  |  Loss: 0.6621  |  Score: 72.24 [%]  |  Seq Length: 256.0
[2024-10-23 18:10:33,265][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 18:10:33,265][root][INFO] - Score: 71.84 [%]  |  Evaluation Time: 10.63 [s]
[2024-10-23 18:10:44,679][root][INFO] - Step: 1711/8555  |  Loss: 0.3680  |  Score: 83.71 [%]  |  Seq Length: 256.0
[2024-10-23 18:10:53,856][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 18:10:53,856][root][INFO] - Score: 72.30 [%]  |  Evaluation Time: 20.59 [s]
[2024-10-23 18:10:53,857][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 18:10:53,858][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 18:10:53,861][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 18:10:55,029][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 18:10:55,150][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 18:10:55,151][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 18:10:55,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 18:10:55,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 18:10:55,151][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 18:10:55,152][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 18:10:56,063][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 18:11:28,294][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 18:11:28,294][root][INFO] - Score: 86.75 [%]  |  Evaluation Time: 43.61 [s]
[2024-10-23 18:13:50,346][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 18:13:50,347][root][INFO] - Score: 86.55 [%]  |  Evaluation Time: 142.05 [s]
[2024-10-23 18:13:50,348][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 18:13:50,348][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 18:13:50,351][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 18:13:52,300][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 18:13:52,598][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 18:13:52,599][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 18:13:52,599][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 18:13:52,600][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 18:13:52,600][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 18:13:52,603][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 18:13:54,223][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 18:28:20,578][root][INFO] - Step: 3422/8555  |  Loss: 0.3110  |  Score: 86.72 [%]  |  Seq Length: 256.0
[2024-10-23 18:29:03,611][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 18:29:03,611][root][INFO] - Score: 87.16 [%]  |  Evaluation Time: 43.03 [s]
[2024-10-23 18:31:25,366][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 18:31:25,366][root][INFO] - Score: 87.09 [%]  |  Evaluation Time: 141.75 [s]
[2024-10-23 18:31:25,367][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 18:31:25,368][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 18:31:25,370][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 18:31:27,279][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 18:31:27,565][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 18:31:27,566][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 18:31:27,567][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 18:31:27,567][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 18:31:27,568][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 18:31:27,570][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 18:31:29,183][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 18:46:02,727][root][INFO] - Step: 5133/8555  |  Loss: 0.2744  |  Score: 88.56 [%]  |  Seq Length: 256.0
[2024-10-23 18:46:45,650][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 18:46:45,650][root][INFO] - Score: 87.94 [%]  |  Evaluation Time: 42.92 [s]
[2024-10-23 18:49:07,418][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 18:49:07,419][root][INFO] - Score: 87.81 [%]  |  Evaluation Time: 141.77 [s]
[2024-10-23 18:49:07,420][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 18:49:07,420][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 18:49:07,423][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 18:49:09,301][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 18:49:09,612][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 18:49:09,613][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 18:49:09,614][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 18:49:09,614][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 18:49:09,614][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 18:49:09,617][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 18:49:11,279][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 18:58:19,708][root][INFO] - Step: 20000/73665  |  Loss: 0.6366  |  Score: 73.53 [%]  |  Seq Length: 256.0
[2024-10-23 19:03:34,964][root][INFO] - Step: 6844/8555  |  Loss: 0.2258  |  Score: 90.82 [%]  |  Seq Length: 256.0
[2024-10-23 19:04:17,873][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 19:04:17,874][root][INFO] - Score: 88.52 [%]  |  Evaluation Time: 42.91 [s]
[2024-10-23 19:06:38,866][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 19:06:38,866][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 140.99 [s]
[2024-10-23 19:06:38,868][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 19:06:38,868][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best
[2024-10-23 19:06:38,871][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 19:06:40,750][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 19:06:41,042][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 19:06:41,043][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 19:06:41,043][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 19:06:41,044][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 19:06:41,044][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 19:06:41,047][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_1rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 19:06:42,688][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 19:21:05,469][root][INFO] - Step: 8555/8555  |  Loss: 0.1853  |  Score: 92.60 [%]  |  Seq Length: 256.0
[2024-10-23 19:21:48,819][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 19:21:48,820][root][INFO] - Score: 88.24 [%]  |  Evaluation Time: 43.35 [s]
[2024-10-23 19:24:09,541][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 19:24:09,541][root][INFO] - Score: 88.56 [%]  |  Evaluation Time: 140.72 [s]
[2024-10-23 19:24:09,542][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 19:24:09,542][root][INFO] - - Epoch: 4
[2024-10-23 19:24:09,542][root][INFO] - - DEV score: 88.52 [%]
[2024-10-23 19:24:09,542][root][INFO] - - TEST score: 88.45 [%]
[2024-10-23 19:24:09,543][root][INFO] - Fine-tuning is done!
[2024-10-23 19:24:09,544][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 19:24:09,544][root][INFO] - - BEST LR: 0.01
[2024-10-23 19:24:09,544][root][INFO] - - DEV score: 88.79 [%]
[2024-10-23 19:24:09,544][root][INFO] - - TEST score: 88.59 [%]
[2024-10-23 19:24:15,751][root][INFO] - 

[2024-10-23 19:24:15,751][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 19:24:15,751][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 19:24:15,751][root][INFO] - 

[2024-10-23 19:24:15,751][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 19:24:34,025][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,026][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,026][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,027][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,027][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,027][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,028][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,028][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,029][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,029][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,030][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,030][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,030][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,031][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,031][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,032][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,032][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,033][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,033][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,033][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,034][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,034][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,035][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 19:24:34,035][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 19:24:34,037][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 19:24:34,233][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 19:24:36,118][root][INFO] - 

[2024-10-23 19:24:36,118][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 19:24:36,118][root][INFO] - Data Preprocessing
[2024-10-23 19:24:36,118][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 19:24:36,118][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 19:24:36,118][root][INFO] - ㄴ data_remove                True

[2024-10-23 19:24:36,118][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 19:24:36,127][root][INFO] - vocab size              : 51200
[2024-10-23 19:24:36,127][root][INFO] - device                  : gpu
[2024-10-23 19:24:36,127][root][INFO] - random seed             : 2
[2024-10-23 19:24:36,127][root][INFO] - train data size         : 109504
[2024-10-23 19:24:36,128][root][INFO] - max epochs              : 5
[2024-10-23 19:24:36,128][root][INFO] - total steps             : 8555
[2024-10-23 19:24:36,128][root][INFO] - warmup steps            : 856
[2024-10-23 19:24:36,128][root][INFO] - batch size              : 64
[2024-10-23 19:24:36,128][root][INFO] - accumulation steps      : 1
[2024-10-23 19:24:36,128][root][INFO] - optimizer               : adamwscale
[2024-10-23 19:24:36,128][root][INFO] - lr_scheduler            : cosine
[2024-10-23 19:24:36,128][root][INFO] - learning rate           : 0.01
[2024-10-23 19:24:36,128][root][INFO] - max length              : 256

[2024-10-23 19:24:36,128][root][INFO] - LoRA Configuration
[2024-10-23 19:24:36,128][root][INFO] - ㄴ r                    : 32
[2024-10-23 19:24:36,128][root][INFO] - ㄴ alpha                : 128
[2024-10-23 19:24:36,129][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 19:24:36,129][root][INFO] - 

[2024-10-23 19:24:36,129][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 19:24:36,129][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 19:24:36,129][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 19:24:36,129][root][INFO] - * tb interval   : 10000

[2024-10-23 19:24:36,129][root][INFO] - 

[2024-10-23 19:24:36,129][root][INFO] - Start the Training !
[2024-10-23 19:24:36,132][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 19:35:03,106][root][INFO] - Step: 1711/8555  |  Loss: 0.3671  |  Score: 83.77 [%]  |  Seq Length: 256.0
[2024-10-23 19:35:30,727][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 19:35:30,727][root][INFO] - Score: 84.99 [%]  |  Evaluation Time: 27.62 [s]
[2024-10-23 19:37:01,510][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 19:37:01,510][root][INFO] - Score: 85.25 [%]  |  Evaluation Time: 90.78 [s]
[2024-10-23 19:37:01,511][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 19:37:01,512][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 19:37:02,353][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 19:37:02,380][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 19:37:02,380][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 19:37:02,380][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 19:37:02,380][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 19:37:02,380][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 19:37:02,381][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 19:37:03,062][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 19:47:30,268][root][INFO] - Step: 3422/8555  |  Loss: 0.2928  |  Score: 87.67 [%]  |  Seq Length: 256.0
[2024-10-23 19:47:57,907][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 19:47:57,908][root][INFO] - Score: 88.01 [%]  |  Evaluation Time: 27.64 [s]
[2024-10-23 19:49:28,791][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 19:49:28,791][root][INFO] - Score: 87.69 [%]  |  Evaluation Time: 90.88 [s]
[2024-10-23 19:49:28,792][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 19:49:28,793][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 19:49:30,310][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 19:49:30,340][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 19:49:30,341][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 19:49:30,341][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 19:49:30,341][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 19:49:30,341][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 19:49:30,342][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 19:49:31,731][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 19:59:58,135][root][INFO] - Step: 5133/8555  |  Loss: 0.2517  |  Score: 89.56 [%]  |  Seq Length: 256.0
[2024-10-23 20:00:25,794][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 20:00:25,794][root][INFO] - Score: 88.51 [%]  |  Evaluation Time: 27.66 [s]
[2024-10-23 20:01:56,628][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 20:01:56,629][root][INFO] - Score: 88.39 [%]  |  Evaluation Time: 90.83 [s]
[2024-10-23 20:01:56,630][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 20:01:56,630][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 20:01:58,190][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 20:01:58,221][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 20:01:58,222][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 20:01:58,222][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 20:01:58,222][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 20:01:58,222][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 20:01:58,223][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 20:01:59,702][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 20:12:26,147][root][INFO] - Step: 6844/8555  |  Loss: 0.2150  |  Score: 91.26 [%]  |  Seq Length: 256.0
[2024-10-23 20:12:53,808][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 20:12:53,808][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 27.66 [s]
[2024-10-23 20:14:24,759][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 20:14:24,760][root][INFO] - Score: 88.47 [%]  |  Evaluation Time: 90.95 [s]
[2024-10-23 20:14:24,761][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 20:14:24,761][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 20:14:26,310][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 20:14:26,356][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 20:14:26,357][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 20:14:26,358][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 20:14:26,358][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 20:14:26,358][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 20:14:26,360][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 20:14:27,853][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 20:22:52,852][root][INFO] - Step: 29466/73665  |  Loss: 0.6313  |  Score: 73.79 [%]  |  Seq Length: 256.0
[2024-10-23 20:23:03,282][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 20:23:03,282][root][INFO] - Score: 71.32 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-23 20:23:23,651][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 20:23:23,651][root][INFO] - Score: 72.75 [%]  |  Evaluation Time: 20.37 [s]
[2024-10-23 20:23:23,653][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 20:24:55,131][root][INFO] - Step: 8555/8555  |  Loss: 0.1899  |  Score: 92.44 [%]  |  Seq Length: 256.0
[2024-10-23 20:25:22,905][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 20:25:22,906][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 27.77 [s]
[2024-10-23 20:26:53,738][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 20:26:53,739][root][INFO] - Score: 88.55 [%]  |  Evaluation Time: 90.83 [s]
[2024-10-23 20:26:53,740][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 20:26:53,740][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 20:26:55,264][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 20:26:55,294][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 20:26:55,295][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 20:26:55,295][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 20:26:55,295][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 20:26:55,295][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 20:26:55,296][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 20:26:56,833][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 20:26:56,833][root][INFO] - - Epoch: 5
[2024-10-23 20:26:56,834][root][INFO] - - DEV score: 88.62 [%]
[2024-10-23 20:26:56,834][root][INFO] - - TEST score: 88.55 [%]
[2024-10-23 20:26:56,835][root][INFO] - Fine-tuning is done!
[2024-10-23 20:27:14,103][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,104][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,104][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,105][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,105][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,106][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,106][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,107][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,107][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,108][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,108][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,109][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,109][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,110][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,110][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,111][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,111][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,112][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,112][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,113][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,114][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,114][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,115][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 20:27:14,115][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 20:27:14,117][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 20:27:14,119][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 20:27:14,378][root][INFO] - 

[2024-10-23 20:27:14,379][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 20:27:14,379][root][INFO] - Data Preprocessing
[2024-10-23 20:27:14,379][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 20:27:14,379][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 20:27:14,379][root][INFO] - ㄴ data_remove                True

[2024-10-23 20:27:14,379][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 20:27:14,387][root][INFO] - vocab size              : 51200
[2024-10-23 20:27:14,387][root][INFO] - device                  : gpu
[2024-10-23 20:27:14,387][root][INFO] - random seed             : 2
[2024-10-23 20:27:14,388][root][INFO] - train data size         : 109504
[2024-10-23 20:27:14,388][root][INFO] - max epochs              : 5
[2024-10-23 20:27:14,388][root][INFO] - total steps             : 8555
[2024-10-23 20:27:14,388][root][INFO] - warmup steps            : 856
[2024-10-23 20:27:14,388][root][INFO] - batch size              : 64
[2024-10-23 20:27:14,388][root][INFO] - accumulation steps      : 1
[2024-10-23 20:27:14,388][root][INFO] - optimizer               : adamwscale
[2024-10-23 20:27:14,388][root][INFO] - lr_scheduler            : cosine
[2024-10-23 20:27:14,388][root][INFO] - learning rate           : 0.02
[2024-10-23 20:27:14,388][root][INFO] - max length              : 256

[2024-10-23 20:27:14,388][root][INFO] - LoRA Configuration
[2024-10-23 20:27:14,389][root][INFO] - ㄴ r                    : 32
[2024-10-23 20:27:14,389][root][INFO] - ㄴ alpha                : 128
[2024-10-23 20:27:14,389][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 20:27:14,389][root][INFO] - 

[2024-10-23 20:27:14,389][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 20:27:14,389][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 20:27:14,389][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 20:27:14,389][root][INFO] - * tb interval   : 10000

[2024-10-23 20:27:14,389][root][INFO] - 

[2024-10-23 20:27:14,389][root][INFO] - Start the Training !
[2024-10-23 20:27:14,391][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 20:28:09,769][root][INFO] - Step: 30000/73665  |  Loss: 0.6058  |  Score: 75.06 [%]  |  Seq Length: 256.0
[2024-10-23 20:37:41,199][root][INFO] - Step: 1711/8555  |  Loss: 0.3665  |  Score: 83.95 [%]  |  Seq Length: 256.0
[2024-10-23 20:38:08,977][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 20:38:08,977][root][INFO] - Score: 84.06 [%]  |  Evaluation Time: 27.78 [s]
[2024-10-23 20:39:39,885][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 20:39:39,886][root][INFO] - Score: 84.03 [%]  |  Evaluation Time: 90.90 [s]
[2024-10-23 20:39:39,886][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 20:39:39,887][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 20:39:41,408][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 20:39:41,456][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 20:39:41,457][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 20:39:41,457][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 20:39:41,457][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 20:39:41,457][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 20:39:41,458][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 20:39:42,996][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 20:50:10,053][root][INFO] - Step: 3422/8555  |  Loss: 0.3120  |  Score: 86.77 [%]  |  Seq Length: 256.0
[2024-10-23 20:50:37,752][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 20:50:37,752][root][INFO] - Score: 88.00 [%]  |  Evaluation Time: 27.70 [s]
[2024-10-23 20:52:08,733][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 20:52:08,734][root][INFO] - Score: 87.57 [%]  |  Evaluation Time: 90.98 [s]
[2024-10-23 20:52:08,736][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 20:52:08,737][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 20:52:10,389][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 20:52:10,420][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 20:52:10,421][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 20:52:10,421][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 20:52:10,421][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 20:52:10,421][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 20:52:10,422][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 20:52:11,981][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 21:02:39,328][root][INFO] - Step: 5133/8555  |  Loss: 0.2728  |  Score: 88.63 [%]  |  Seq Length: 256.0
[2024-10-23 21:03:07,072][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 21:03:07,072][root][INFO] - Score: 88.51 [%]  |  Evaluation Time: 27.74 [s]
[2024-10-23 21:04:37,886][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 21:04:37,886][root][INFO] - Score: 88.13 [%]  |  Evaluation Time: 90.81 [s]
[2024-10-23 21:04:37,888][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 21:04:37,888][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 21:04:39,429][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 21:04:39,460][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 21:04:39,460][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 21:04:39,461][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 21:04:39,461][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 21:04:39,461][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 21:04:39,462][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 21:04:41,024][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 21:15:09,098][root][INFO] - Step: 6844/8555  |  Loss: 0.2254  |  Score: 90.93 [%]  |  Seq Length: 256.0
[2024-10-23 21:15:36,826][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 21:15:36,827][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 27.72 [s]
[2024-10-23 21:17:07,669][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 21:17:07,669][root][INFO] - Score: 88.43 [%]  |  Evaluation Time: 90.84 [s]
[2024-10-23 21:17:07,671][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 21:17:07,671][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 21:17:09,294][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 21:17:09,325][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 21:17:09,325][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 21:17:09,326][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 21:17:09,326][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 21:17:09,326][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 21:17:09,327][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 21:17:10,882][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 21:27:38,825][root][INFO] - Step: 8555/8555  |  Loss: 0.1851  |  Score: 92.74 [%]  |  Seq Length: 256.0
[2024-10-23 21:28:06,534][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 21:28:06,535][root][INFO] - Score: 88.88 [%]  |  Evaluation Time: 27.71 [s]
[2024-10-23 21:29:37,412][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 21:29:37,412][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 90.88 [s]
[2024-10-23 21:29:37,414][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 21:29:37,414][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 21:29:39,042][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 21:29:39,076][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 21:29:39,077][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 21:29:39,077][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 21:29:39,077][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 21:29:39,078][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 21:29:39,079][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 21:29:40,637][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 21:29:40,637][root][INFO] - - Epoch: 5
[2024-10-23 21:29:40,637][root][INFO] - - DEV score: 88.88 [%]
[2024-10-23 21:29:40,637][root][INFO] - - TEST score: 88.57 [%]
[2024-10-23 21:29:40,642][root][INFO] - Fine-tuning is done!
[2024-10-23 21:29:40,643][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-23 21:29:40,643][root][INFO] - - BEST LR: 0.02
[2024-10-23 21:29:40,643][root][INFO] - - DEV score: 88.88 [%]
[2024-10-23 21:29:40,643][root][INFO] - - TEST score: 88.57 [%]
[2024-10-23 21:29:46,572][root][INFO] - 

[2024-10-23 21:29:46,572][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-23 21:29:46,572][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 21:29:46,572][root][INFO] - 

[2024-10-23 21:29:46,572][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 2, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-23 21:30:04,859][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,860][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,860][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,861][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,861][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,862][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,862][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,863][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,863][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,863][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,864][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,864][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,865][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,865][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,865][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,866][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,866][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,867][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,867][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,867][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,868][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,868][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,869][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 21:30:04,869][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 21:30:04,871][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 21:30:04,875][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-23 21:30:05,078][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 21:30:05,080][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 21:30:05,282][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 21:30:08,468][root][INFO] - 

[2024-10-23 21:30:08,468][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 21:30:08,468][root][INFO] - Data Preprocessing
[2024-10-23 21:30:08,468][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 21:30:08,469][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 21:30:08,469][root][INFO] - ㄴ data_remove                True

[2024-10-23 21:30:08,469][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 21:30:08,476][root][INFO] - vocab size              : 51200
[2024-10-23 21:30:08,476][root][INFO] - device                  : gpu
[2024-10-23 21:30:08,476][root][INFO] - random seed             : 2
[2024-10-23 21:30:08,477][root][INFO] - train data size         : 109504
[2024-10-23 21:30:08,477][root][INFO] - max epochs              : 5
[2024-10-23 21:30:08,477][root][INFO] - total steps             : 8555
[2024-10-23 21:30:08,477][root][INFO] - warmup steps            : 856
[2024-10-23 21:30:08,477][root][INFO] - batch size              : 64
[2024-10-23 21:30:08,477][root][INFO] - accumulation steps      : 1
[2024-10-23 21:30:08,477][root][INFO] - optimizer               : adamwscale
[2024-10-23 21:30:08,477][root][INFO] - lr_scheduler            : cosine
[2024-10-23 21:30:08,477][root][INFO] - learning rate           : 0.01
[2024-10-23 21:30:08,477][root][INFO] - max length              : 256

[2024-10-23 21:30:08,477][root][INFO] - LoRA Configuration
[2024-10-23 21:30:08,477][root][INFO] - ㄴ r                    : 32
[2024-10-23 21:30:08,478][root][INFO] - ㄴ alpha                : 128
[2024-10-23 21:30:08,478][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 21:30:08,478][root][INFO] - KOMBO Configuration
[2024-10-23 21:30:08,478][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 21:30:08,478][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 21:30:08,478][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 21:30:08,478][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 21:30:08,478][root][INFO] - ㄴ do_combination       : True
[2024-10-23 21:30:08,478][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 21:30:08,478][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 21:30:08,479][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 21:30:08,479][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 21:30:08,479][root][INFO] - 

[2024-10-23 21:30:08,479][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 21:30:08,479][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 21:30:08,479][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 21:30:08,479][root][INFO] - * tb interval   : 10000

[2024-10-23 21:30:08,479][root][INFO] - 

[2024-10-23 21:30:08,479][root][INFO] - Start the Training !
[2024-10-23 21:30:08,482][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 21:44:35,315][root][INFO] - Step: 1711/8555  |  Loss: 0.3671  |  Score: 83.69 [%]  |  Seq Length: 256.0
[2024-10-23 21:45:18,483][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 21:45:18,483][root][INFO] - Score: 86.88 [%]  |  Evaluation Time: 43.16 [s]
[2024-10-23 21:47:39,460][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 21:47:39,460][root][INFO] - Score: 86.78 [%]  |  Evaluation Time: 140.97 [s]
[2024-10-23 21:47:39,462][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 21:47:39,462][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 21:47:39,465][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 21:47:40,542][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 21:47:40,660][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 21:47:40,661][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 21:47:40,661][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 21:47:40,661][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 21:47:40,661][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 21:47:40,662][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 21:47:41,504][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 21:57:29,076][root][INFO] - Step: 40000/73665  |  Loss: 0.5998  |  Score: 75.32 [%]  |  Seq Length: 256.0
[2024-10-23 22:02:06,406][root][INFO] - Step: 3422/8555  |  Loss: 0.2935  |  Score: 87.55 [%]  |  Seq Length: 256.0
[2024-10-23 22:02:49,648][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 22:02:49,648][root][INFO] - Score: 87.55 [%]  |  Evaluation Time: 43.24 [s]
[2024-10-23 22:05:11,404][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 22:05:11,405][root][INFO] - Score: 87.48 [%]  |  Evaluation Time: 141.75 [s]
[2024-10-23 22:05:11,406][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 22:05:11,407][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 22:05:11,411][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 22:05:13,373][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 22:05:13,639][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 22:05:13,640][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 22:05:13,640][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 22:05:13,640][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 22:05:13,641][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 22:05:13,644][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 22:05:15,335][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 22:19:44,257][root][INFO] - Step: 5133/8555  |  Loss: 0.2524  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-23 22:20:27,732][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 22:20:27,732][root][INFO] - Score: 88.55 [%]  |  Evaluation Time: 43.47 [s]
[2024-10-23 22:22:51,080][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 22:22:51,080][root][INFO] - Score: 88.32 [%]  |  Evaluation Time: 143.35 [s]
[2024-10-23 22:22:51,082][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 22:22:51,082][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 22:22:51,085][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 22:22:52,920][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 22:22:53,180][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 22:22:53,181][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 22:22:53,181][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 22:22:53,182][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 22:22:53,182][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 22:22:53,184][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 22:22:54,831][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 22:34:57,202][root][INFO] - Step: 44199/73665  |  Loss: 0.5854  |  Score: 75.91 [%]  |  Seq Length: 256.0
[2024-10-23 22:35:07,630][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 22:35:07,630][root][INFO] - Score: 73.45 [%]  |  Evaluation Time: 10.43 [s]
[2024-10-23 22:35:27,875][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 22:35:27,876][root][INFO] - Score: 75.29 [%]  |  Evaluation Time: 20.24 [s]
[2024-10-23 22:35:27,877][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 22:35:27,877][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-23 22:35:27,880][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 22:35:29,818][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 22:35:29,991][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 22:35:29,992][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 22:35:29,992][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 22:35:29,992][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 22:35:29,992][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 22:35:29,994][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 22:35:31,748][root][INFO] - 
[4/ 5 Epoch]
[2024-10-23 22:37:22,683][root][INFO] - Step: 6844/8555  |  Loss: 0.2157  |  Score: 91.24 [%]  |  Seq Length: 256.0
[2024-10-23 22:38:06,139][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-23 22:38:06,139][root][INFO] - Score: 88.69 [%]  |  Evaluation Time: 43.45 [s]
[2024-10-23 22:40:30,145][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-23 22:40:30,145][root][INFO] - Score: 88.50 [%]  |  Evaluation Time: 144.00 [s]
[2024-10-23 22:40:30,146][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-23 22:40:30,147][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 22:40:30,150][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 22:40:31,896][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 22:40:32,186][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 22:40:32,188][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 22:40:32,189][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 22:40:32,189][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 22:40:32,189][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 22:40:32,193][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 22:40:33,846][root][INFO] - 
[5/ 5 Epoch]
[2024-10-23 22:55:02,814][root][INFO] - Step: 8555/8555  |  Loss: 0.1899  |  Score: 92.48 [%]  |  Seq Length: 256.0
[2024-10-23 22:55:46,332][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-23 22:55:46,333][root][INFO] - Score: 88.74 [%]  |  Evaluation Time: 43.51 [s]
[2024-10-23 22:58:10,397][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-23 22:58:10,397][root][INFO] - Score: 88.49 [%]  |  Evaluation Time: 144.06 [s]
[2024-10-23 22:58:10,398][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-23 22:58:10,399][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 22:58:10,402][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 22:58:12,164][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 22:58:12,424][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 22:58:12,426][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 22:58:12,426][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 22:58:12,426][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 22:58:12,427][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 22:58:12,430][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 22:58:14,165][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-23 22:58:14,165][root][INFO] - - Epoch: 5
[2024-10-23 22:58:14,165][root][INFO] - - DEV score: 88.74 [%]
[2024-10-23 22:58:14,165][root][INFO] - - TEST score: 88.49 [%]
[2024-10-23 22:58:14,167][root][INFO] - Fine-tuning is done!
[2024-10-23 22:58:32,122][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,123][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,124][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,125][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,126][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,126][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,127][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,128][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,129][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,129][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,130][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,130][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,131][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,131][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,132][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,132][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,133][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,133][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,134][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,134][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,135][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,136][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,137][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-23 22:58:32,138][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-23 22:58:32,140][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-23 22:58:32,347][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-23 22:58:32,349][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-23 22:58:32,351][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-23 22:58:32,503][root][INFO] - 

[2024-10-23 22:58:32,503][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-23 22:58:32,503][root][INFO] - Data Preprocessing
[2024-10-23 22:58:32,503][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-23 22:58:32,503][root][INFO] - ㄴ do_hangeulize              False
[2024-10-23 22:58:32,503][root][INFO] - ㄴ data_remove                True

[2024-10-23 22:58:32,503][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-23 22:58:32,513][root][INFO] - vocab size              : 51200
[2024-10-23 22:58:32,513][root][INFO] - device                  : gpu
[2024-10-23 22:58:32,513][root][INFO] - random seed             : 2
[2024-10-23 22:58:32,513][root][INFO] - train data size         : 109504
[2024-10-23 22:58:32,513][root][INFO] - max epochs              : 5
[2024-10-23 22:58:32,513][root][INFO] - total steps             : 8555
[2024-10-23 22:58:32,513][root][INFO] - warmup steps            : 856
[2024-10-23 22:58:32,513][root][INFO] - batch size              : 64
[2024-10-23 22:58:32,514][root][INFO] - accumulation steps      : 1
[2024-10-23 22:58:32,514][root][INFO] - optimizer               : adamwscale
[2024-10-23 22:58:32,514][root][INFO] - lr_scheduler            : cosine
[2024-10-23 22:58:32,514][root][INFO] - learning rate           : 0.02
[2024-10-23 22:58:32,514][root][INFO] - max length              : 256

[2024-10-23 22:58:32,514][root][INFO] - LoRA Configuration
[2024-10-23 22:58:32,514][root][INFO] - ㄴ r                    : 32
[2024-10-23 22:58:32,514][root][INFO] - ㄴ alpha                : 128
[2024-10-23 22:58:32,514][root][INFO] - ㄴ dropout              : 0.03

[2024-10-23 22:58:32,514][root][INFO] - KOMBO Configuration
[2024-10-23 22:58:32,514][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-23 22:58:32,514][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-23 22:58:32,515][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-23 22:58:32,515][root][INFO] - ㄴ embedding_norm       : False
[2024-10-23 22:58:32,515][root][INFO] - ㄴ do_combination       : True
[2024-10-23 22:58:32,515][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-23 22:58:32,515][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-23 22:58:32,515][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-23 22:58:32,515][root][INFO] -   ㄴ add_lora           : False

[2024-10-23 22:58:32,515][root][INFO] - 

[2024-10-23 22:58:32,515][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs
[2024-10-23 22:58:32,516][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt
[2024-10-23 22:58:32,516][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/tb
[2024-10-23 22:58:32,516][root][INFO] - * tb interval   : 10000

[2024-10-23 22:58:32,516][root][INFO] - 

[2024-10-23 22:58:32,516][root][INFO] - Start the Training !
[2024-10-23 22:58:32,518][root][INFO] - 
[1/ 5 Epoch]
[2024-10-23 23:13:01,344][root][INFO] - Step: 1711/8555  |  Loss: 0.3667  |  Score: 83.83 [%]  |  Seq Length: 256.0
[2024-10-23 23:13:45,305][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-23 23:13:45,305][root][INFO] - Score: 85.72 [%]  |  Evaluation Time: 43.96 [s]
[2024-10-23 23:16:08,877][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-23 23:16:08,878][root][INFO] - Score: 85.74 [%]  |  Evaluation Time: 143.57 [s]
[2024-10-23 23:16:08,879][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-23 23:16:08,879][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 23:16:08,882][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 23:16:10,659][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 23:16:10,946][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 23:16:10,947][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 23:16:10,948][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 23:16:10,948][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 23:16:10,948][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 23:16:10,951][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 23:16:12,616][root][INFO] - 
[2/ 5 Epoch]
[2024-10-23 23:27:14,059][root][INFO] - Step: 50000/73665  |  Loss: 0.5544  |  Score: 77.47 [%]  |  Seq Length: 256.0
[2024-10-23 23:30:42,851][root][INFO] - Step: 3422/8555  |  Loss: 0.3106  |  Score: 86.64 [%]  |  Seq Length: 256.0
[2024-10-23 23:31:26,528][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-23 23:31:26,528][root][INFO] - Score: 86.19 [%]  |  Evaluation Time: 43.67 [s]
[2024-10-23 23:33:51,158][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-23 23:33:51,159][root][INFO] - Score: 86.17 [%]  |  Evaluation Time: 144.63 [s]
[2024-10-23 23:33:51,160][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-23 23:33:51,160][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 23:33:51,163][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 23:33:52,979][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 23:33:53,228][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 23:33:53,229][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 23:33:53,230][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 23:33:53,230][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 23:33:53,230][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 23:33:53,233][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 23:33:54,934][root][INFO] - 
[3/ 5 Epoch]
[2024-10-23 23:48:24,937][root][INFO] - Step: 5133/8555  |  Loss: 0.2741  |  Score: 88.56 [%]  |  Seq Length: 256.0
[2024-10-23 23:49:08,710][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-23 23:49:08,710][root][INFO] - Score: 88.41 [%]  |  Evaluation Time: 43.77 [s]
[2024-10-23 23:51:31,671][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-23 23:51:31,672][root][INFO] - Score: 87.80 [%]  |  Evaluation Time: 142.96 [s]
[2024-10-23 23:51:31,674][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-23 23:51:31,675][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-23 23:51:31,681][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-23 23:51:33,434][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-23 23:51:33,641][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-23 23:51:33,642][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-23 23:51:33,643][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-23 23:51:33,643][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-23 23:51:33,643][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-23 23:51:33,646][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-23 23:51:35,278][root][INFO] - 
[4/ 5 Epoch]
[2024-10-24 00:05:59,786][root][INFO] - Step: 6844/8555  |  Loss: 0.2247  |  Score: 90.83 [%]  |  Seq Length: 256.0
[2024-10-24 00:06:43,933][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 00:06:43,934][root][INFO] - Score: 88.78 [%]  |  Evaluation Time: 44.14 [s]
[2024-10-24 00:09:05,802][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 00:09:05,802][root][INFO] - Score: 88.45 [%]  |  Evaluation Time: 141.87 [s]
[2024-10-24 00:09:05,803][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 00:09:05,803][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-24 00:09:05,806][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 00:09:07,548][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 00:09:07,839][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 00:09:07,840][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 00:09:07,840][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 00:09:07,841][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 00:09:07,841][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 00:09:07,844][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 00:09:09,502][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 00:23:35,420][root][INFO] - Step: 8555/8555  |  Loss: 0.1846  |  Score: 92.72 [%]  |  Seq Length: 256.0
[2024-10-24 00:24:18,550][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 00:24:18,550][root][INFO] - Score: 88.77 [%]  |  Evaluation Time: 43.13 [s]
[2024-10-24 00:26:40,395][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 00:26:40,396][root][INFO] - Score: 88.57 [%]  |  Evaluation Time: 141.84 [s]
[2024-10-24 00:26:40,397][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-24 00:26:40,397][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best
[2024-10-24 00:26:40,400][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 00:26:42,114][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 00:26:42,405][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 00:26:42,407][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 00:26:42,407][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 00:26:42,407][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 00:26:42,407][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 00:26:42,411][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_2rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 00:26:44,054][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 00:26:44,054][root][INFO] - - Epoch: 5
[2024-10-24 00:26:44,055][root][INFO] - - DEV score: 88.77 [%]
[2024-10-24 00:26:44,055][root][INFO] - - TEST score: 88.57 [%]
[2024-10-24 00:26:44,057][root][INFO] - Fine-tuning is done!
[2024-10-24 00:26:44,058][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-24 00:26:44,058][root][INFO] - - BEST LR: 0.02
[2024-10-24 00:26:44,058][root][INFO] - - DEV score: 88.77 [%]
[2024-10-24 00:26:44,059][root][INFO] - - TEST score: 88.57 [%]
[2024-10-24 00:26:50,915][root][INFO] - 

[2024-10-24 00:26:50,915][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-24 00:26:50,915][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs
[2024-10-24 00:26:50,915][root][INFO] - 

[2024-10-24 00:26:50,915][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': False, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': False, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-24 00:27:10,400][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,400][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,401][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,402][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,402][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,403][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,403][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,404][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,404][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,405][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,405][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,406][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,407][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,407][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,408][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,408][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,409][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,409][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,410][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,410][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,411][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,412][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,412][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-24 00:27:10,413][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-24 00:27:10,415][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-24 00:27:10,600][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-24 00:27:12,495][root][INFO] - 

[2024-10-24 00:27:12,496][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-24 00:27:12,496][root][INFO] - Data Preprocessing
[2024-10-24 00:27:12,496][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-24 00:27:12,496][root][INFO] - ㄴ do_hangeulize              False
[2024-10-24 00:27:12,496][root][INFO] - ㄴ data_remove                True

[2024-10-24 00:27:12,496][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-24 00:27:12,508][root][INFO] - vocab size              : 51200
[2024-10-24 00:27:12,508][root][INFO] - device                  : gpu
[2024-10-24 00:27:12,508][root][INFO] - random seed             : 3
[2024-10-24 00:27:12,508][root][INFO] - train data size         : 109504
[2024-10-24 00:27:12,508][root][INFO] - max epochs              : 5
[2024-10-24 00:27:12,508][root][INFO] - total steps             : 8555
[2024-10-24 00:27:12,508][root][INFO] - warmup steps            : 856
[2024-10-24 00:27:12,508][root][INFO] - batch size              : 64
[2024-10-24 00:27:12,509][root][INFO] - accumulation steps      : 1
[2024-10-24 00:27:12,509][root][INFO] - optimizer               : adamwscale
[2024-10-24 00:27:12,509][root][INFO] - lr_scheduler            : cosine
[2024-10-24 00:27:12,509][root][INFO] - learning rate           : 0.01
[2024-10-24 00:27:12,509][root][INFO] - max length              : 256

[2024-10-24 00:27:12,509][root][INFO] - LoRA Configuration
[2024-10-24 00:27:12,509][root][INFO] - ㄴ r                    : 32
[2024-10-24 00:27:12,509][root][INFO] - ㄴ alpha                : 128
[2024-10-24 00:27:12,509][root][INFO] - ㄴ dropout              : 0.03

[2024-10-24 00:27:12,509][root][INFO] - 

[2024-10-24 00:27:12,509][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs
[2024-10-24 00:27:12,510][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-24 00:27:12,510][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-24 00:27:12,510][root][INFO] - * tb interval   : 10000

[2024-10-24 00:27:12,510][root][INFO] - 

[2024-10-24 00:27:12,510][root][INFO] - Start the Training !
[2024-10-24 00:27:12,513][root][INFO] - 
[1/ 5 Epoch]
[2024-10-24 00:37:39,378][root][INFO] - Step: 1711/8555  |  Loss: 0.3680  |  Score: 83.81 [%]  |  Seq Length: 256.0
[2024-10-24 00:38:06,935][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-24 00:38:06,935][root][INFO] - Score: 86.86 [%]  |  Evaluation Time: 27.55 [s]
[2024-10-24 00:39:37,560][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-24 00:39:37,560][root][INFO] - Score: 86.91 [%]  |  Evaluation Time: 90.62 [s]
[2024-10-24 00:39:37,561][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-24 00:39:37,562][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 00:39:38,401][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 00:39:38,427][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 00:39:38,427][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 00:39:38,427][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 00:39:38,427][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 00:39:38,427][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 00:39:38,429][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 00:39:39,082][root][INFO] - 
[2/ 5 Epoch]
[2024-10-24 00:47:04,540][root][INFO] - Step: 58932/73665  |  Loss: 0.5411  |  Score: 78.12 [%]  |  Seq Length: 256.0
[2024-10-24 00:47:15,086][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 00:47:15,087][root][INFO] - Score: 75.10 [%]  |  Evaluation Time: 10.54 [s]
[2024-10-24 00:47:35,731][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 00:47:35,731][root][INFO] - Score: 76.39 [%]  |  Evaluation Time: 20.64 [s]
[2024-10-24 00:47:35,733][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 00:47:35,733][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 00:47:35,736][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 00:47:37,676][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 00:47:37,852][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 00:47:37,853][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 00:47:37,854][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 00:47:37,854][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 00:47:37,854][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 00:47:37,856][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 00:47:39,605][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 00:50:05,280][root][INFO] - Step: 3422/8555  |  Loss: 0.2913  |  Score: 87.68 [%]  |  Seq Length: 256.0
[2024-10-24 00:50:32,856][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-24 00:50:32,856][root][INFO] - Score: 87.21 [%]  |  Evaluation Time: 27.57 [s]
[2024-10-24 00:52:03,551][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-24 00:52:03,552][root][INFO] - Score: 87.41 [%]  |  Evaluation Time: 90.69 [s]
[2024-10-24 00:52:03,553][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-24 00:52:03,553][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 00:52:05,079][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 00:52:05,110][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 00:52:05,110][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 00:52:05,110][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 00:52:05,110][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 00:52:05,111][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 00:52:05,112][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 00:52:06,479][root][INFO] - 
[3/ 5 Epoch]
[2024-10-24 00:57:15,136][root][INFO] - Step: 60000/73665  |  Loss: 0.5097  |  Score: 79.62 [%]  |  Seq Length: 256.0
[2024-10-24 01:02:32,545][root][INFO] - Step: 5133/8555  |  Loss: 0.2517  |  Score: 89.52 [%]  |  Seq Length: 256.0
[2024-10-24 01:03:00,155][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-24 01:03:00,155][root][INFO] - Score: 87.97 [%]  |  Evaluation Time: 27.61 [s]
[2024-10-24 01:04:30,825][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-24 01:04:30,825][root][INFO] - Score: 88.20 [%]  |  Evaluation Time: 90.67 [s]
[2024-10-24 01:04:30,826][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-24 01:04:30,826][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 01:04:32,362][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 01:04:32,407][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 01:04:32,408][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 01:04:32,408][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 01:04:32,408][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 01:04:32,408][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 01:04:32,409][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 01:04:33,789][root][INFO] - 
[4/ 5 Epoch]
[2024-10-24 01:14:59,929][root][INFO] - Step: 6844/8555  |  Loss: 0.2166  |  Score: 91.23 [%]  |  Seq Length: 256.0
[2024-10-24 01:15:27,513][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 01:15:27,514][root][INFO] - Score: 88.70 [%]  |  Evaluation Time: 27.58 [s]
[2024-10-24 01:16:58,201][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 01:16:58,201][root][INFO] - Score: 88.66 [%]  |  Evaluation Time: 90.69 [s]
[2024-10-24 01:16:58,202][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 01:16:58,203][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 01:16:59,763][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 01:16:59,794][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 01:16:59,794][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 01:16:59,794][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 01:16:59,794][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 01:16:59,795][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 01:16:59,796][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 01:17:01,261][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 01:27:26,899][root][INFO] - Step: 8555/8555  |  Loss: 0.1921  |  Score: 92.33 [%]  |  Seq Length: 256.0
[2024-10-24 01:27:54,450][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 01:27:54,450][root][INFO] - Score: 88.73 [%]  |  Evaluation Time: 27.55 [s]
[2024-10-24 01:29:25,077][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 01:29:25,077][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 90.62 [s]
[2024-10-24 01:29:25,078][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-24 01:29:25,079][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 01:29:26,614][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 01:29:26,645][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 01:29:26,645][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 01:29:26,645][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 01:29:26,645][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 01:29:26,646][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 01:29:26,647][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 01:29:28,150][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 01:29:28,150][root][INFO] - - Epoch: 5
[2024-10-24 01:29:28,151][root][INFO] - - DEV score: 88.73 [%]
[2024-10-24 01:29:28,151][root][INFO] - - TEST score: 88.65 [%]
[2024-10-24 01:29:28,152][root][INFO] - Fine-tuning is done!
[2024-10-24 01:29:44,726][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,727][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,728][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,728][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,729][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,729][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,730][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,730][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,731][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,731][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,732][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,732][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,733][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,733][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,734][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,734][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,735][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,735][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,736][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,736][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,737][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,737][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,738][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-24 01:29:44,738][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-24 01:29:44,740][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-24 01:29:44,742][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-24 01:29:44,937][root][INFO] - 

[2024-10-24 01:29:44,937][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-24 01:29:44,937][root][INFO] - Data Preprocessing
[2024-10-24 01:29:44,938][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-24 01:29:44,938][root][INFO] - ㄴ do_hangeulize              False
[2024-10-24 01:29:44,938][root][INFO] - ㄴ data_remove                True

[2024-10-24 01:29:44,938][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-24 01:29:44,945][root][INFO] - vocab size              : 51200
[2024-10-24 01:29:44,945][root][INFO] - device                  : gpu
[2024-10-24 01:29:44,945][root][INFO] - random seed             : 3
[2024-10-24 01:29:44,945][root][INFO] - train data size         : 109504
[2024-10-24 01:29:44,945][root][INFO] - max epochs              : 5
[2024-10-24 01:29:44,945][root][INFO] - total steps             : 8555
[2024-10-24 01:29:44,945][root][INFO] - warmup steps            : 856
[2024-10-24 01:29:44,945][root][INFO] - batch size              : 64
[2024-10-24 01:29:44,946][root][INFO] - accumulation steps      : 1
[2024-10-24 01:29:44,946][root][INFO] - optimizer               : adamwscale
[2024-10-24 01:29:44,946][root][INFO] - lr_scheduler            : cosine
[2024-10-24 01:29:44,946][root][INFO] - learning rate           : 0.02
[2024-10-24 01:29:44,946][root][INFO] - max length              : 256

[2024-10-24 01:29:44,946][root][INFO] - LoRA Configuration
[2024-10-24 01:29:44,946][root][INFO] - ㄴ r                    : 32
[2024-10-24 01:29:44,946][root][INFO] - ㄴ alpha                : 128
[2024-10-24 01:29:44,946][root][INFO] - ㄴ dropout              : 0.03

[2024-10-24 01:29:44,946][root][INFO] - 

[2024-10-24 01:29:44,946][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs
[2024-10-24 01:29:44,947][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-24 01:29:44,947][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-24 01:29:44,947][root][INFO] - * tb interval   : 10000

[2024-10-24 01:29:44,947][root][INFO] - 

[2024-10-24 01:29:44,947][root][INFO] - Start the Training !
[2024-10-24 01:29:44,949][root][INFO] - 
[1/ 5 Epoch]
[2024-10-24 01:40:10,286][root][INFO] - Step: 1711/8555  |  Loss: 0.3671  |  Score: 83.88 [%]  |  Seq Length: 256.0
[2024-10-24 01:40:37,865][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-24 01:40:37,866][root][INFO] - Score: 86.19 [%]  |  Evaluation Time: 27.58 [s]
[2024-10-24 01:42:08,471][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-24 01:42:08,471][root][INFO] - Score: 86.52 [%]  |  Evaluation Time: 90.60 [s]
[2024-10-24 01:42:08,473][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-24 01:42:08,473][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 01:42:10,005][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 01:42:10,046][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 01:42:10,046][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 01:42:10,047][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 01:42:10,047][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 01:42:10,047][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 01:42:10,048][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 01:42:11,564][root][INFO] - 
[2/ 5 Epoch]
[2024-10-24 01:52:37,094][root][INFO] - Step: 3422/8555  |  Loss: 0.3100  |  Score: 86.82 [%]  |  Seq Length: 256.0
[2024-10-24 01:53:04,652][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-24 01:53:04,653][root][INFO] - Score: 85.84 [%]  |  Evaluation Time: 27.56 [s]
[2024-10-24 01:54:35,230][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-24 01:54:35,230][root][INFO] - Score: 86.29 [%]  |  Evaluation Time: 90.58 [s]
[2024-10-24 01:54:35,233][root][INFO] - 
[3/ 5 Epoch]
[2024-10-24 02:05:00,704][root][INFO] - Step: 5133/8555  |  Loss: 0.2730  |  Score: 88.57 [%]  |  Seq Length: 256.0
[2024-10-24 02:05:28,252][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-24 02:05:28,252][root][INFO] - Score: 87.30 [%]  |  Evaluation Time: 27.54 [s]
[2024-10-24 02:06:58,752][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-24 02:06:58,752][root][INFO] - Score: 87.54 [%]  |  Evaluation Time: 90.50 [s]
[2024-10-24 02:06:58,753][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-24 02:06:58,753][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 02:07:00,301][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 02:07:00,341][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 02:07:00,342][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 02:07:00,342][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 02:07:00,342][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 02:07:00,342][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 02:07:00,343][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 02:07:01,907][root][INFO] - 
[4/ 5 Epoch]
[2024-10-24 02:17:27,045][root][INFO] - Step: 6844/8555  |  Loss: 0.2256  |  Score: 90.79 [%]  |  Seq Length: 256.0
[2024-10-24 02:17:54,562][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 02:17:54,562][root][INFO] - Score: 88.72 [%]  |  Evaluation Time: 27.51 [s]
[2024-10-24 02:19:25,116][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 02:19:25,116][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 90.55 [s]
[2024-10-24 02:19:25,117][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 02:19:25,118][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 02:19:26,667][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 02:19:26,707][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 02:19:26,708][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 02:19:26,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 02:19:26,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 02:19:26,708][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 02:19:26,709][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/lora/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 02:19:28,268][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 02:26:37,381][root][INFO] - Step: 70000/73665  |  Loss: 0.5075  |  Score: 79.61 [%]  |  Seq Length: 256.0
[2024-10-24 02:29:53,690][root][INFO] - Step: 8555/8555  |  Loss: 0.1836  |  Score: 92.75 [%]  |  Seq Length: 256.0
[2024-10-24 02:30:21,239][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 02:30:21,239][root][INFO] - Score: 88.60 [%]  |  Evaluation Time: 27.55 [s]
[2024-10-24 02:31:51,763][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 02:31:51,763][root][INFO] - Score: 88.64 [%]  |  Evaluation Time: 90.52 [s]
[2024-10-24 02:31:51,764][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 02:31:51,764][root][INFO] - - Epoch: 4
[2024-10-24 02:31:51,764][root][INFO] - - DEV score: 88.72 [%]
[2024-10-24 02:31:51,764][root][INFO] - - TEST score: 88.62 [%]
[2024-10-24 02:31:51,766][root][INFO] - Fine-tuning is done!
[2024-10-24 02:31:51,766][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-24 02:31:51,766][root][INFO] - - BEST LR: 0.01
[2024-10-24 02:31:51,766][root][INFO] - - DEV score: 88.73 [%]
[2024-10-24 02:31:51,766][root][INFO] - - TEST score: 88.65 [%]
[2024-10-24 02:31:57,746][root][INFO] - 

[2024-10-24 02:31:57,746][root][INFO] - This train_log.txt inform the Running Progress.

[2024-10-24 02:31:57,746][root][INFO] - Save the parser information to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs
[2024-10-24 02:31:57,746][root][INFO] - 

[2024-10-24 02:31:57,746][root][INFO] - Arguments: {'port': 5678, 'host': 'localhost', 'device': 'gpu', 'mixed_precision': 'bf16', 'eval_only': False, 'predict_only': False, 'seed': 3, 'seeds': '', 'model': {'name': 'skt/kogpt2-base-v2', 'hf_model': True, 'n_positions': 2048, 'ckpt_dir': '', 'compile': True, 'set_lora': True, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}, 'set_kombo': True, 'kombo': {'tok_type': 'jamo_var', 'lang': 'ko', 'reducer': 'linear', 'hidden_dim': 768, 'kombo_max_length': 2048, 'do_combination': True, 'embedding_norm': False, 'combination': {'combination_type': 'gru', 'intermediate_size': 3072, 'num_attention_heads': 12, 'num_trans_layers': 3}, 'add_lora': False, 'lora': {'r': 32, 'alpha': 128, 'dropout': 0.03}}}, 'data': {'language': 'ko', 'tok_type': 'morphemeSubword', 'vocab_size': '32k', 'raw_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated.txt', 'train_data_path': '/data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt', 'split_by_doc': True, 'is_toyset': False, 'max_length': 256, 'num_workers': 4, 'num_labels': 2, 'remain_lang': 'ko_punc', 'do_hangeulize': False, 'data_remove': True, 'task_name': 'NSMC'}, 'optim': {'name': 'adamwscale', 'base_lr': 5e-05, 'base_lrs': '1e-02 2e-02', 'batch_size': 64, 'total_steps': -1, 'epochs': 5, 'warmup_steps': -1, 'warmup_ratio': 0.1, 'lr_scheduler': 'cosine', 'weight_decay': 0.0, 'grad_clip': 1.0, 'grad_acc': 1, 'final_cosine': 1e-05, 'early_stop_patience': 3, 'dropout_prob': 0.1}, 'eval': {'eval_steps': 10000, 'steps': 500}, 'checkpoint': {'save_steps': 50000, 'max_number': 3}, 'logging': {'log_steps': 10000, 'grad_l2': True, 'weights_l2': True, 'log_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs', 'tb_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/tb', 'save_dir': 'logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt'}, 'mode': 'nlu_ft'}

[2024-10-24 02:32:16,733][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,734][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,734][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,735][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,735][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,736][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,736][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,737][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,737][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,737][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,738][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,738][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,739][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,739][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,740][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,740][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,740][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,741][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,741][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,742][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,742][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,743][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,743][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-24 02:32:16,743][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-24 02:32:16,745][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-24 02:32:16,750][root][INFO] - Change the max_length to 2046 for the kombo_tokenizer's truncation.
[2024-10-24 02:32:16,948][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-24 02:32:16,951][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-24 02:32:17,142][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-24 02:32:20,189][root][INFO] - 

[2024-10-24 02:32:20,190][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-24 02:32:20,190][root][INFO] - Data Preprocessing
[2024-10-24 02:32:20,190][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-24 02:32:20,190][root][INFO] - ㄴ do_hangeulize              False
[2024-10-24 02:32:20,190][root][INFO] - ㄴ data_remove                True

[2024-10-24 02:32:20,190][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-24 02:32:20,198][root][INFO] - vocab size              : 51200
[2024-10-24 02:32:20,198][root][INFO] - device                  : gpu
[2024-10-24 02:32:20,198][root][INFO] - random seed             : 3
[2024-10-24 02:32:20,198][root][INFO] - train data size         : 109504
[2024-10-24 02:32:20,198][root][INFO] - max epochs              : 5
[2024-10-24 02:32:20,198][root][INFO] - total steps             : 8555
[2024-10-24 02:32:20,198][root][INFO] - warmup steps            : 856
[2024-10-24 02:32:20,198][root][INFO] - batch size              : 64
[2024-10-24 02:32:20,198][root][INFO] - accumulation steps      : 1
[2024-10-24 02:32:20,198][root][INFO] - optimizer               : adamwscale
[2024-10-24 02:32:20,198][root][INFO] - lr_scheduler            : cosine
[2024-10-24 02:32:20,199][root][INFO] - learning rate           : 0.01
[2024-10-24 02:32:20,199][root][INFO] - max length              : 256

[2024-10-24 02:32:20,199][root][INFO] - LoRA Configuration
[2024-10-24 02:32:20,199][root][INFO] - ㄴ r                    : 32
[2024-10-24 02:32:20,199][root][INFO] - ㄴ alpha                : 128
[2024-10-24 02:32:20,199][root][INFO] - ㄴ dropout              : 0.03

[2024-10-24 02:32:20,199][root][INFO] - KOMBO Configuration
[2024-10-24 02:32:20,199][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-24 02:32:20,199][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-24 02:32:20,199][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-24 02:32:20,199][root][INFO] - ㄴ embedding_norm       : False
[2024-10-24 02:32:20,200][root][INFO] - ㄴ do_combination       : True
[2024-10-24 02:32:20,200][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-24 02:32:20,200][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-24 02:32:20,200][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-24 02:32:20,200][root][INFO] -   ㄴ add_lora           : False

[2024-10-24 02:32:20,200][root][INFO] - 

[2024-10-24 02:32:20,200][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs
[2024-10-24 02:32:20,200][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-24 02:32:20,200][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-24 02:32:20,201][root][INFO] - * tb interval   : 10000

[2024-10-24 02:32:20,201][root][INFO] - 

[2024-10-24 02:32:20,201][root][INFO] - Start the Training !
[2024-10-24 02:32:20,204][root][INFO] - 
[1/ 5 Epoch]
[2024-10-24 02:46:35,996][root][INFO] - Step: 1711/8555  |  Loss: 0.3677  |  Score: 83.74 [%]  |  Seq Length: 256.0
[2024-10-24 02:47:18,650][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-24 02:47:18,650][root][INFO] - Score: 86.55 [%]  |  Evaluation Time: 42.65 [s]
[2024-10-24 02:49:37,462][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-24 02:49:37,462][root][INFO] - Score: 86.51 [%]  |  Evaluation Time: 138.81 [s]
[2024-10-24 02:49:37,463][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-24 02:49:37,464][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 02:49:37,466][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 02:49:38,350][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 02:49:38,462][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 02:49:38,463][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 02:49:38,463][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 02:49:38,463][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 02:49:38,463][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 02:49:38,464][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 02:49:39,210][root][INFO] - 
[2/ 5 Epoch]
[2024-10-24 02:59:09,459][root][INFO] - Step: 73665/73665  |  Loss: 0.5067  |  Score: 79.62 [%]  |  Seq Length: 256.0
[2024-10-24 02:59:19,805][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 02:59:19,806][root][INFO] - Score: 74.87 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-24 02:59:39,871][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 02:59:39,872][root][INFO] - Score: 76.92 [%]  |  Evaluation Time: 20.06 [s]
[2024-10-24 02:59:39,873][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-24 02:59:39,873][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 02:59:39,876][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 02:59:41,593][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 02:59:41,869][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 02:59:41,871][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 02:59:41,871][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 02:59:41,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 02:59:41,872][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 02:59:41,875][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 02:59:43,610][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 02:59:43,610][root][INFO] - - Epoch: 5
[2024-10-24 02:59:43,610][root][INFO] - - DEV score: 74.87 [%]
[2024-10-24 02:59:43,610][root][INFO] - - TEST score: 76.92 [%]
[2024-10-24 02:59:43,612][root][INFO] - Fine-tuning is done!
[2024-10-24 03:01:41,913][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,914][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,914][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,915][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,916][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,916][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,917][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,917][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,918][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,918][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,919][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,919][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,920][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,921][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,921][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,922][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,922][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,923][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,924][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,924][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,925][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,925][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,926][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-24 03:01:41,927][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-24 03:01:41,929][root][INFO] - Trainable params: 1769472 || all params: 126935808 || trainable: 1.39 %
[2024-10-24 03:01:42,129][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-24 03:01:42,131][root][INFO] - Trainable params: 17845248 || all params: 143011584 || trainable: 12.48 %
[2024-10-24 03:01:42,132][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-24 03:01:42,324][root][INFO] - 

[2024-10-24 03:01:42,324][root][INFO] - ========== Fine-tuning on KorNLI ==========
[2024-10-24 03:01:42,324][root][INFO] - Data Preprocessing
[2024-10-24 03:01:42,324][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-24 03:01:42,324][root][INFO] - ㄴ do_hangeulize              False
[2024-10-24 03:01:42,324][root][INFO] - ㄴ data_remove                False

[2024-10-24 03:01:42,324][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-24 03:01:42,336][root][INFO] - vocab size              : 51200
[2024-10-24 03:01:42,337][root][INFO] - device                  : gpu
[2024-10-24 03:01:42,337][root][INFO] - random seed             : 3
[2024-10-24 03:01:42,337][root][INFO] - train data size         : 942912
[2024-10-24 03:01:42,337][root][INFO] - max epochs              : 5
[2024-10-24 03:01:42,337][root][INFO] - total steps             : 73665
[2024-10-24 03:01:42,337][root][INFO] - warmup steps            : 7366
[2024-10-24 03:01:42,337][root][INFO] - batch size              : 64
[2024-10-24 03:01:42,337][root][INFO] - accumulation steps      : 1
[2024-10-24 03:01:42,337][root][INFO] - optimizer               : adamwscale
[2024-10-24 03:01:42,337][root][INFO] - lr_scheduler            : cosine
[2024-10-24 03:01:42,338][root][INFO] - learning rate           : 0.005
[2024-10-24 03:01:42,338][root][INFO] - max length              : 256

[2024-10-24 03:01:42,338][root][INFO] - LoRA Configuration
[2024-10-24 03:01:42,338][root][INFO] - ㄴ r                    : 32
[2024-10-24 03:01:42,338][root][INFO] - ㄴ alpha                : 128
[2024-10-24 03:01:42,338][root][INFO] - ㄴ dropout              : 0.03

[2024-10-24 03:01:42,338][root][INFO] - KOMBO Configuration
[2024-10-24 03:01:42,338][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-24 03:01:42,338][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-24 03:01:42,338][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-24 03:01:42,338][root][INFO] - ㄴ embedding_norm       : False
[2024-10-24 03:01:42,339][root][INFO] - ㄴ do_combination       : True
[2024-10-24 03:01:42,339][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-24 03:01:42,339][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-24 03:01:42,339][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-24 03:01:42,339][root][INFO] -   ㄴ add_lora           : False

[2024-10-24 03:01:42,339][root][INFO] - 

[2024-10-24 03:01:42,339][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs
[2024-10-24 03:01:42,339][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt
[2024-10-24 03:01:42,339][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/tb
[2024-10-24 03:01:42,340][root][INFO] - * tb interval   : 10000

[2024-10-24 03:01:42,340][root][INFO] - 

[2024-10-24 03:01:42,340][root][INFO] - Start the Training !
[2024-10-24 03:01:42,342][root][INFO] - 
[1/ 5 Epoch]
[2024-10-24 03:03:53,433][root][INFO] - Step: 3422/8555  |  Loss: 0.2924  |  Score: 87.58 [%]  |  Seq Length: 256.0
[2024-10-24 03:04:35,857][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-24 03:04:35,857][root][INFO] - Score: 87.77 [%]  |  Evaluation Time: 42.42 [s]
[2024-10-24 03:06:55,203][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-24 03:06:55,203][root][INFO] - Score: 87.86 [%]  |  Evaluation Time: 139.34 [s]
[2024-10-24 03:06:55,205][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-24 03:06:55,205][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 03:06:55,208][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 03:06:56,905][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 03:06:57,165][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 03:06:57,166][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 03:06:57,167][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 03:06:57,167][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 03:06:57,167][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 03:06:57,170][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 03:06:58,768][root][INFO] - 
[3/ 5 Epoch]
[2024-10-24 03:21:21,419][root][INFO] - Step: 5133/8555  |  Loss: 0.2515  |  Score: 89.65 [%]  |  Seq Length: 256.0
[2024-10-24 03:22:04,357][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-24 03:22:04,358][root][INFO] - Score: 88.52 [%]  |  Evaluation Time: 42.94 [s]
[2024-10-24 03:24:25,885][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-24 03:24:25,885][root][INFO] - Score: 88.52 [%]  |  Evaluation Time: 141.52 [s]
[2024-10-24 03:24:25,887][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-24 03:24:25,887][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 03:24:25,891][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 03:24:27,625][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 03:24:27,898][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 03:24:27,925][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 03:24:27,925][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 03:24:27,925][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 03:24:27,926][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 03:24:27,929][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 03:24:29,592][root][INFO] - 
[4/ 5 Epoch]
[2024-10-24 03:38:49,694][root][INFO] - Step: 6844/8555  |  Loss: 0.2153  |  Score: 91.22 [%]  |  Seq Length: 256.0
[2024-10-24 03:39:32,516][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 03:39:32,516][root][INFO] - Score: 88.65 [%]  |  Evaluation Time: 42.82 [s]
[2024-10-24 03:41:53,155][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 03:41:53,155][root][INFO] - Score: 88.58 [%]  |  Evaluation Time: 140.64 [s]
[2024-10-24 03:41:53,156][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 03:41:53,157][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 03:41:53,159][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 03:41:54,866][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 03:41:55,163][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 03:41:55,165][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 03:41:55,165][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 03:41:55,166][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 03:41:55,166][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 03:41:55,169][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 03:41:56,938][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 03:56:17,681][root][INFO] - Step: 8555/8555  |  Loss: 0.1910  |  Score: 92.41 [%]  |  Seq Length: 256.0
[2024-10-24 03:57:00,066][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 03:57:00,066][root][INFO] - Score: 88.80 [%]  |  Evaluation Time: 42.38 [s]
[2024-10-24 03:59:21,055][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 03:59:21,055][root][INFO] - Score: 88.73 [%]  |  Evaluation Time: 140.99 [s]
[2024-10-24 03:59:21,057][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-24 03:59:21,057][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 03:59:21,060][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 03:59:22,767][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 03:59:23,063][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 03:59:23,064][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 03:59:23,065][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 03:59:23,065][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 03:59:23,066][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 03:59:23,068][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 03:59:24,830][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 03:59:24,830][root][INFO] - - Epoch: 5
[2024-10-24 03:59:24,830][root][INFO] - - DEV score: 88.80 [%]
[2024-10-24 03:59:24,830][root][INFO] - - TEST score: 88.73 [%]
[2024-10-24 03:59:24,832][root][INFO] - Fine-tuning is done!
[2024-10-24 03:59:41,370][root][INFO] - Replaced transformer.h.0.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,371][root][INFO] - Replaced transformer.h.0.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,372][root][INFO] - Replaced transformer.h.1.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,372][root][INFO] - Replaced transformer.h.1.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,373][root][INFO] - Replaced transformer.h.2.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,374][root][INFO] - Replaced transformer.h.2.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,374][root][INFO] - Replaced transformer.h.3.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,375][root][INFO] - Replaced transformer.h.3.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,376][root][INFO] - Replaced transformer.h.4.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,377][root][INFO] - Replaced transformer.h.4.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,378][root][INFO] - Replaced transformer.h.5.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,379][root][INFO] - Replaced transformer.h.5.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,380][root][INFO] - Replaced transformer.h.6.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,380][root][INFO] - Replaced transformer.h.6.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,381][root][INFO] - Replaced transformer.h.7.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,381][root][INFO] - Replaced transformer.h.7.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,382][root][INFO] - Replaced transformer.h.8.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,382][root][INFO] - Replaced transformer.h.8.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,383][root][INFO] - Replaced transformer.h.9.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,383][root][INFO] - Replaced transformer.h.9.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,384][root][INFO] - Replaced transformer.h.10.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,385][root][INFO] - Replaced transformer.h.10.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,385][root][INFO] - Replaced transformer.h.11.attn.c_attn with LoRA_Layer
[2024-10-24 03:59:41,386][root][INFO] - Replaced transformer.h.11.attn.c_proj with LoRA_Layer
[2024-10-24 03:59:41,388][root][INFO] - Trainable params: 1769472 || all params: 126935040 || trainable: 1.39 %
[2024-10-24 03:59:41,587][root][INFO] - Replaced transformer.wte with KOMBO_LoRA_Layer
[2024-10-24 03:59:41,589][root][INFO] - Trainable params: 17845248 || all params: 143010816 || trainable: 12.48 %
[2024-10-24 03:59:41,591][accelerate.utils.other][WARNING] - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-10-24 03:59:41,806][root][INFO] - 

[2024-10-24 03:59:41,806][root][INFO] - ========== Fine-tuning on NSMC ==========
[2024-10-24 03:59:41,806][root][INFO] - Data Preprocessing
[2024-10-24 03:59:41,806][root][INFO] - ㄴ remain_lang                ko_punc
[2024-10-24 03:59:41,806][root][INFO] - ㄴ do_hangeulize              False
[2024-10-24 03:59:41,806][root][INFO] - ㄴ data_remove                True

[2024-10-24 03:59:41,806][root][INFO] - model                   : skt/kogpt2-base-v2
[2024-10-24 03:59:41,814][root][INFO] - vocab size              : 51200
[2024-10-24 03:59:41,814][root][INFO] - device                  : gpu
[2024-10-24 03:59:41,815][root][INFO] - random seed             : 3
[2024-10-24 03:59:41,815][root][INFO] - train data size         : 109504
[2024-10-24 03:59:41,815][root][INFO] - max epochs              : 5
[2024-10-24 03:59:41,815][root][INFO] - total steps             : 8555
[2024-10-24 03:59:41,815][root][INFO] - warmup steps            : 856
[2024-10-24 03:59:41,815][root][INFO] - batch size              : 64
[2024-10-24 03:59:41,815][root][INFO] - accumulation steps      : 1
[2024-10-24 03:59:41,815][root][INFO] - optimizer               : adamwscale
[2024-10-24 03:59:41,815][root][INFO] - lr_scheduler            : cosine
[2024-10-24 03:59:41,815][root][INFO] - learning rate           : 0.02
[2024-10-24 03:59:41,815][root][INFO] - max length              : 256

[2024-10-24 03:59:41,815][root][INFO] - LoRA Configuration
[2024-10-24 03:59:41,816][root][INFO] - ㄴ r                    : 32
[2024-10-24 03:59:41,816][root][INFO] - ㄴ alpha                : 128
[2024-10-24 03:59:41,816][root][INFO] - ㄴ dropout              : 0.03

[2024-10-24 03:59:41,816][root][INFO] - KOMBO Configuration
[2024-10-24 03:59:41,816][root][INFO] - ㄴ tok_type             : jamo_var
[2024-10-24 03:59:41,816][root][INFO] - ㄴ hidden_dim           : 768
[2024-10-24 03:59:41,816][root][INFO] - ㄴ kombo_max_length     : 2046
[2024-10-24 03:59:41,816][root][INFO] - ㄴ embedding_norm       : False
[2024-10-24 03:59:41,816][root][INFO] - ㄴ do_combination       : True
[2024-10-24 03:59:41,816][root][INFO] -   ㄴ num_attn_heads     : 12
[2024-10-24 03:59:41,817][root][INFO] -   ㄴ intermediate_size  : 3072
[2024-10-24 03:59:41,817][root][INFO] -   ㄴ num_trans_layers   : 3
[2024-10-24 03:59:41,817][root][INFO] -   ㄴ add_lora           : False

[2024-10-24 03:59:41,817][root][INFO] - 

[2024-10-24 03:59:41,817][root][INFO] - * log dir       : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs
[2024-10-24 03:59:41,817][root][INFO] - * save dir      : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt
[2024-10-24 03:59:41,817][root][INFO] - * tb dir        : logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/tb
[2024-10-24 03:59:41,817][root][INFO] - * tb interval   : 10000

[2024-10-24 03:59:41,817][root][INFO] - 

[2024-10-24 03:59:41,817][root][INFO] - Start the Training !
[2024-10-24 03:59:41,819][root][INFO] - 
[1/ 5 Epoch]
[2024-10-24 04:14:00,964][root][INFO] - Step: 1711/8555  |  Loss: 0.3673  |  Score: 83.86 [%]  |  Seq Length: 256.0
[2024-10-24 04:14:43,742][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-24 04:14:43,742][root][INFO] - Score: 85.36 [%]  |  Evaluation Time: 42.77 [s]
[2024-10-24 04:17:04,718][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-24 04:17:04,719][root][INFO] - Score: 85.82 [%]  |  Evaluation Time: 140.97 [s]
[2024-10-24 04:17:04,720][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-24 04:17:04,720][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 04:17:04,723][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 04:17:06,422][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 04:17:06,728][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 04:17:06,729][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 04:17:06,730][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 04:17:06,730][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 04:17:06,730][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 04:17:06,733][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 04:17:08,504][root][INFO] - 
[2/ 5 Epoch]
[2024-10-24 04:30:43,484][root][INFO] - Step: 10000/73665  |  Loss: 0.7586  |  Score: 66.62 [%]  |  Seq Length: 256.0
[2024-10-24 04:31:28,716][root][INFO] - Step: 3422/8555  |  Loss: 0.3098  |  Score: 86.74 [%]  |  Seq Length: 256.0
[2024-10-24 04:32:11,578][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-24 04:32:11,578][root][INFO] - Score: 87.35 [%]  |  Evaluation Time: 42.86 [s]
[2024-10-24 04:34:32,772][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-24 04:34:32,772][root][INFO] - Score: 87.14 [%]  |  Evaluation Time: 141.19 [s]
[2024-10-24 04:34:32,773][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-24 04:34:32,774][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 04:34:32,776][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 04:34:34,483][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 04:34:34,781][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 04:34:34,783][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 04:34:34,783][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 04:34:34,783][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 04:34:34,783][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 04:34:34,786][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 04:34:36,573][root][INFO] - 
[3/ 5 Epoch]
[2024-10-24 04:49:01,169][root][INFO] - Step: 5133/8555  |  Loss: 0.2732  |  Score: 88.61 [%]  |  Seq Length: 256.0
[2024-10-24 04:49:44,432][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-24 04:49:44,433][root][INFO] - Score: 88.24 [%]  |  Evaluation Time: 43.26 [s]
[2024-10-24 04:52:08,104][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-24 04:52:08,104][root][INFO] - Score: 88.18 [%]  |  Evaluation Time: 143.67 [s]
[2024-10-24 04:52:08,105][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-24 04:52:08,106][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 04:52:08,108][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 04:52:09,820][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 04:52:10,133][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 04:52:10,135][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 04:52:10,135][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 04:52:10,135][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 04:52:10,135][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 04:52:10,139][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 04:52:11,934][root][INFO] - 
[4/ 5 Epoch]
[2024-10-24 05:06:37,171][root][INFO] - Step: 6844/8555  |  Loss: 0.2254  |  Score: 90.81 [%]  |  Seq Length: 256.0
[2024-10-24 05:07:20,372][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 05:07:20,372][root][INFO] - Score: 88.62 [%]  |  Evaluation Time: 43.20 [s]
[2024-10-24 05:09:44,146][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 05:09:44,146][root][INFO] - Score: 88.48 [%]  |  Evaluation Time: 143.77 [s]
[2024-10-24 05:09:44,148][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 05:09:44,148][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 05:09:44,150][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 05:09:45,857][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 05:09:46,169][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 05:09:46,171][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 05:09:46,171][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 05:09:46,171][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 05:09:46,172][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 05:09:46,175][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 05:09:47,839][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 05:13:05,167][root][INFO] - Step: 14733/73665  |  Loss: 0.6593  |  Score: 72.23 [%]  |  Seq Length: 256.0
[2024-10-24 05:13:15,937][root][INFO] - ########################  DEV REPORT #EP1  ########################
[2024-10-24 05:13:15,938][root][INFO] - Score: 72.01 [%]  |  Evaluation Time: 10.77 [s]
[2024-10-24 05:13:36,732][root][INFO] - ########################  TEST REPORT #EP1  ########################
[2024-10-24 05:13:36,732][root][INFO] - Score: 73.74 [%]  |  Evaluation Time: 20.79 [s]
[2024-10-24 05:13:36,734][root][INFO] - 
Save new Best Score (Epoch: 1)
[2024-10-24 05:13:36,734][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 05:13:36,737][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 05:13:38,479][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 05:13:38,777][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 05:13:38,779][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 05:13:38,779][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 05:13:38,779][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 05:13:38,780][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 05:13:38,783][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 05:13:40,526][root][INFO] - 
[2/ 5 Epoch]
[2024-10-24 05:24:12,258][root][INFO] - Step: 8555/8555  |  Loss: 0.1845  |  Score: 92.76 [%]  |  Seq Length: 256.0
[2024-10-24 05:24:55,194][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 05:24:55,194][root][INFO] - Score: 88.71 [%]  |  Evaluation Time: 42.93 [s]
[2024-10-24 05:27:17,329][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 05:27:17,329][root][INFO] - Score: 88.70 [%]  |  Evaluation Time: 142.13 [s]
[2024-10-24 05:27:17,330][root][INFO] - 
Save new Best Score (Epoch: 5)
[2024-10-24 05:27:17,331][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 05:27:17,333][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 05:27:19,075][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 05:27:19,337][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 05:27:19,338][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 05:27:19,338][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 05:27:19,339][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 05:27:19,339][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 05:27:19,342][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/NSMC/ko_punc_dr/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 05:27:21,018][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 05:27:21,018][root][INFO] - - Epoch: 5
[2024-10-24 05:27:21,018][root][INFO] - - DEV score: 88.71 [%]
[2024-10-24 05:27:21,018][root][INFO] - - TEST score: 88.70 [%]
[2024-10-24 05:27:21,021][root][INFO] - Fine-tuning is done!
[2024-10-24 05:27:21,021][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-24 05:27:21,022][root][INFO] - - BEST LR: 0.01
[2024-10-24 05:27:21,022][root][INFO] - - DEV score: 88.80 [%]
[2024-10-24 05:27:21,022][root][INFO] - - TEST score: 88.73 [%]
[2024-10-24 06:00:43,860][root][INFO] - Step: 20000/73665  |  Loss: 0.6240  |  Score: 74.20 [%]  |  Seq Length: 256.0
[2024-10-24 07:25:04,808][root][INFO] - Step: 29466/73665  |  Loss: 0.6100  |  Score: 74.81 [%]  |  Seq Length: 256.0
[2024-10-24 07:25:15,156][root][INFO] - ########################  DEV REPORT #EP2  ########################
[2024-10-24 07:25:15,157][root][INFO] - Score: 73.05 [%]  |  Evaluation Time: 10.34 [s]
[2024-10-24 07:25:35,192][root][INFO] - ########################  TEST REPORT #EP2  ########################
[2024-10-24 07:25:35,192][root][INFO] - Score: 73.77 [%]  |  Evaluation Time: 20.03 [s]
[2024-10-24 07:25:35,193][root][INFO] - 
Save new Best Score (Epoch: 2)
[2024-10-24 07:25:35,193][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 07:25:35,196][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 07:25:37,059][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 07:25:37,243][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 07:25:37,244][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 07:25:37,245][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 07:25:37,245][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 07:25:37,245][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 07:25:37,248][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 07:25:38,980][root][INFO] - 
[3/ 5 Epoch]
[2024-10-24 07:30:22,204][root][INFO] - Step: 30000/73665  |  Loss: 0.5786  |  Score: 76.35 [%]  |  Seq Length: 256.0
[2024-10-24 08:58:56,356][root][INFO] - Step: 40000/73665  |  Loss: 0.5744  |  Score: 76.55 [%]  |  Seq Length: 256.0
[2024-10-24 09:36:48,585][root][INFO] - Step: 44199/73665  |  Loss: 0.5640  |  Score: 76.94 [%]  |  Seq Length: 256.0
[2024-10-24 09:36:59,791][root][INFO] - ########################  DEV REPORT #EP3  ########################
[2024-10-24 09:36:59,792][root][INFO] - Score: 73.56 [%]  |  Evaluation Time: 11.20 [s]
[2024-10-24 09:37:20,881][root][INFO] - ########################  TEST REPORT #EP3  ########################
[2024-10-24 09:37:20,881][root][INFO] - Score: 75.73 [%]  |  Evaluation Time: 21.08 [s]
[2024-10-24 09:37:20,882][root][INFO] - 
Save new Best Score (Epoch: 3)
[2024-10-24 09:37:20,883][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 09:37:20,887][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 09:37:22,770][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 09:37:22,946][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 09:37:22,947][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 09:37:22,947][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 09:37:22,947][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 09:37:22,947][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 09:37:22,950][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 09:37:24,721][root][INFO] - 
[4/ 5 Epoch]
[2024-10-24 10:29:37,055][root][INFO] - Step: 50000/73665  |  Loss: 0.5420  |  Score: 78.05 [%]  |  Seq Length: 256.0
[2024-10-24 11:50:12,191][root][INFO] - Step: 58932/73665  |  Loss: 0.5363  |  Score: 78.30 [%]  |  Seq Length: 256.0
[2024-10-24 11:50:22,828][root][INFO] - ########################  DEV REPORT #EP4  ########################
[2024-10-24 11:50:22,829][root][INFO] - Score: 74.58 [%]  |  Evaluation Time: 10.63 [s]
[2024-10-24 11:50:43,726][root][INFO] - ########################  TEST REPORT #EP4  ########################
[2024-10-24 11:50:43,727][root][INFO] - Score: 76.53 [%]  |  Evaluation Time: 20.90 [s]
[2024-10-24 11:50:43,728][root][INFO] - 
Save new Best Score (Epoch: 4)
[2024-10-24 11:50:43,728][accelerate.accelerator][INFO] - Saving current state to logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best
[2024-10-24 11:50:43,730][accelerate.utils.other][WARNING] - Removed shared tensor {'transformer.wte.kombo_combination.get_org_shape_emb.bias_hh_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.bias_ih_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.bias_ih_l0', 'transformer.wte.kombo_combination.get_org_shape_emb.weight_hh_l0', 'transformer.wte.kombo_combination.contextualization.0.weight_hh_l0'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading
[2024-10-24 11:50:45,631][accelerate.checkpointing][INFO] - Model weights saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/model.safetensors
[2024-10-24 11:50:45,806][accelerate.checkpointing][INFO] - Optimizer state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/optimizer.bin
[2024-10-24 11:50:45,807][accelerate.checkpointing][INFO] - Scheduler state saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/scheduler.bin
[2024-10-24 11:50:45,807][accelerate.checkpointing][INFO] - Sampler state for dataloader 0 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler.bin
[2024-10-24 11:50:45,807][accelerate.checkpointing][INFO] - Sampler state for dataloader 1 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_1.bin
[2024-10-24 11:50:45,807][accelerate.checkpointing][INFO] - Sampler state for dataloader 2 saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/sampler_2.bin
[2024-10-24 11:50:45,810][accelerate.checkpointing][INFO] - Random states saved in logs/skt_kogpt2-base-v2/kombo/nlu_tasks_lrs/KorNLI/ko_punc/256t_64b_1s_3rs/ckpt/checkpoint-best/random_states_0.pkl
[2024-10-24 11:50:47,589][root][INFO] - 
[5/ 5 Epoch]
[2024-10-24 12:00:22,831][root][INFO] - Step: 60000/73665  |  Loss: 0.5176  |  Score: 79.19 [%]  |  Seq Length: 256.0
[2024-10-24 13:30:16,053][root][INFO] - Step: 70000/73665  |  Loss: 0.5181  |  Score: 79.14 [%]  |  Seq Length: 256.0
[2024-10-24 14:03:06,778][root][INFO] - Step: 73665/73665  |  Loss: 0.5191  |  Score: 79.09 [%]  |  Seq Length: 256.0
[2024-10-24 14:03:17,570][root][INFO] - ########################  DEV REPORT #EP5  ########################
[2024-10-24 14:03:17,570][root][INFO] - Score: 74.51 [%]  |  Evaluation Time: 10.79 [s]
[2024-10-24 14:03:38,282][root][INFO] - ########################  TEST REPORT #EP5  ########################
[2024-10-24 14:03:38,282][root][INFO] - Score: 76.15 [%]  |  Evaluation Time: 20.71 [s]
[2024-10-24 14:03:38,283][root][INFO] - ########################  BEST RESULT  ########################
[2024-10-24 14:03:38,283][root][INFO] - - Epoch: 4
[2024-10-24 14:03:38,283][root][INFO] - - DEV score: 74.58 [%]
[2024-10-24 14:03:38,283][root][INFO] - - TEST score: 76.53 [%]
[2024-10-24 14:03:38,285][root][INFO] - Fine-tuning is done!
[2024-10-24 14:03:38,285][root][INFO] - ########################  BEST LR RESULT  ########################
[2024-10-24 14:03:38,285][root][INFO] - - BEST LR: 0.01
[2024-10-24 14:03:38,285][root][INFO] - - DEV score: 74.87 [%]
[2024-10-24 14:03:38,285][root][INFO] - - TEST score: 76.92 [%]
