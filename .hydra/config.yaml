port: 5678
host: localhost
device: gpu
mixed_precision: bf16
eval_only: false
predict_only: false
seed: 42
seeds: 1 2 3
model:
  name: skt/kogpt2-base-v2
  hf_model: true
  n_positions: 2048
  ckpt_dir: ''
  compile: true
  set_lora: true
  lora:
    r: 32
    alpha: 128
    dropout: 0.03
  set_kombo: false
  kombo:
    tok_type: jamo_var
    lang: ko
    reducer: linear
    hidden_dim: 768
    kombo_max_length: 2048
    do_combination: false
    combination:
      combination_type: gru
      intermediate_size: 3072
      num_attention_heads: 12
      num_trans_layers: 3
    add_lora: false
    lora:
      r: 32
      alpha: 128
      dropout: 0.03
data:
  language: ko
  tok_type: morphemeSubword
  vocab_size: 32k
  raw_data_path: /data3/user21/KOMBO/datasets/pretraining/concatenated.txt
  train_data_path: /data3/user21/KOMBO/datasets/pretraining/concatenated_doc.txt
  split_by_doc: true
  is_toyset: false
  max_length: 256
  num_workers: 4
  num_labels: null
  remain_lang: ko_punc
  do_hangeulize: false
  data_remove: true
  task_name: PAWS_X
optim:
  name: adamwscale
  base_lr: 0.01
  batch_size: 64
  total_steps: -1
  epochs: 10
  warmup_steps: -1
  warmup_ratio: 0.1
  lr_scheduler: cosine
  weight_decay: 0.0
  grad_clip: 1.0
  grad_acc: 1
  final_cosine: 1.0e-05
  dropout_prob: 0.1
eval:
  eval_steps: 10000
  steps: 500
checkpoint:
  save_steps: 50000
  max_number: 3
logging:
  log_steps: 75
  grad_l2: true
  weights_l2: true
  log_dir: logs/${data.tok_type}_${data.language}_${data.vocab_size}/nlu_tasks/${data.task_name}/${data.remain_lang}/${data.max_length}t_${optim.batch_size}b_${optim.grad_acc}s_${optim.base_lr}lr_${seed}rs
  tb_dir: ${logging.log_dir}/tb
  save_dir: ${logging.log_dir}/ckpt
mode: nlu_ft
